<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>标签: Docker - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="website"><meta property="og:title" content="Hanzawa の 部屋"><meta property="og:url" content="http://qfxiao.me/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://qfxiao.me/img/og_image.png"><meta property="article:author" content="Hanzawa"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://qfxiao.me"},"headline":"Hanzawa の 部屋","image":["http://qfxiao.me/img/og_image.png"],"author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":null}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">Docker</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-06-02T04:26:13.000Z" title="2020-6-2 12:26:13 ├F10: PM┤">2020-06-02</time>发表</span><span class="level-item"><time dateTime="2020-08-01T04:00:16.325Z" title="2020-8-1 12:00:16 ├F10: PM┤">2020-08-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Technical-Notes/">Technical Notes</a><span> / </span><a class="link-muted" href="/categories/Technical-Notes/Misc/">Misc</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">面向OpenPAI的Docker镜像配置及OpenPAI基本使用方法</a></h1><div class="content"><h1 id="introduction">Introduction</h1>
<p>实验室服务器集群采用OpenPAI来进行GPU资源的管理，而OpenPAI采用了Docker作为基础，即代码都放在Docker容器中运行。由于Docker的使用、Docker镜像的配置都有一定的门槛，所以这里写一篇Tutorial来进行介绍。本文不是网上资料的拼凑，而是经过本人走弯路踩坑形成的"Best practice"。主要内容包括Docker的介绍、Docker的基本使用、如何配置自己的Docker镜像以及OpenPAI平台的基本使用，但不包括Docker和OpenPAI的安装。</p>
<blockquote>
<p>2020.8.1 Update: 加入通过HDFS读取容器保存的文件的方法</p>
</blockquote>
<h1 id="docker-from-scratch">Docker from Scratch</h1>
<p>要理解Docker是什么，从虚拟机开始讲可能会比较好理解。虚拟机大家可能都很熟悉了，比如说我用的系统是Windows，但我需要Linux系统来作为一个Flask编写的网站的服务器，但是又不想单独安装Linux系统，于是可以使用虚拟机来解决这个问题。安装VMWare Workstation，去官网下载Ubuntu系统镜像，然后在VMWare中安装好系统，然后从头配置Flask相关环境。实际上我需要的仅仅是一个Flask运行环境而已，而使用虚拟机却需要如此“大费周章”，这时Docker出现了，网上有大量现成的Flask Docker镜像，配置好了你所需的Flask环境，你只需要下载这些镜像，然后运行它，你就得到了一个Flask运行环境，而与你当前使用的系统无关。如果你需要一个Tomcat的运行环境，那么去找一个Tomcat的Docker镜像就行。Docker将需求或者说服务绑定在了Docker镜像中（<strong>轻量化</strong>，一个需求对应一个Docker镜像，每个镜像都很小），你有什么需求，去找相应的镜像即可（或者自己写一个），镜像的运行是以虚拟机的形式存在，所以他们之间也是互不干扰的。同时，你在写好一个Docker镜像之后，你还可以<strong>分享</strong>给别人，这样其他人就不用重新配置，直接运行你给他的镜像即可。Docker有两个比较关键的概念：</p>
<ul>
<li><strong>镜像 Images：</strong> 这里的镜像不是指我们安装系统时下载的ISO镜像，Docker镜像就是把你需要的东西（一个系统+需要的服务）集中到一起，相当于做菜的菜谱；</li>
<li><strong>容器 Containers：</strong> 如果一个Docker镜像启动了，那么就会有一个Docker容器产生，相当于按照菜谱做出来的菜。</li>
</ul>
<p><img src="https://i.loli.net/2020/06/24/H2x9mnPwkVQyO6p.png" alt="img" style="zoom: 33%;" /></p>
<p><img src="https://i.loli.net/2020/06/24/7k6S3yecX2lbvQY.png" alt="img" style="zoom: 33%;" /></p>
<p>这一节我们先不讨论如何自己写Docker镜像，只是先讨论Docker的基本操作。</p>
<h2 id="basic-operations">Basic Operations</h2>
<p>Docker新安装好当然是没有什么镜像的，首先我们使用<code>docker pull hello-world</code>来下载一个测试镜像。</p>
<blockquote>
<p>拉取镜像 <code>docker pull &lt;image_name&gt;</code></p>
</blockquote>
<p>在输入之后，Docker会自动在远程服务器上查找对应的镜像进行下载。由于我的电脑上已经有这个镜像了，所以显示是下面的样子：</p>
<p><img src="https://i.loli.net/2020/06/24/rvqcAwzOYJtF6T8.png" /></p>
<p>接下来，我们输入<code>docker run hello-world</code>运行这个镜像。</p>
<blockquote>
<p>运行镜像<code>docker run &lt;image_name&gt;</code></p>
</blockquote>
<p>可以看到，Docker输出了一些信息就自己退出了，这和我们理解的虚拟机不太一样。在Docker里面，我们既可以创建一个完整的系统，用户在运行之后就可以正常使用这个操作系统，也可以创建一个简单的服务，默认运行完一些指令就退出了。这里的<code>hello-world</code>镜像这是输出了一些信息后就自动退出了，因为这就是这个镜像的全部内容。</p>
<p><img src="https://i.loli.net/2020/06/24/Zb1VKjFyMh8gHf2.png" /></p>
<p>我们尝试来运行一个完整的系统，先用<code>docker pull ubuntu</code>拉取Ubuntu Docker镜像：</p>
<p><img src="https://i.loli.net/2020/06/24/zEerb2gPwYWX8O7.png" /></p>
<p>接下来我们使用：</p>
<p><img src="https://i.loli.net/2020/06/24/6cMz1WGH4fgpBsS.png" /></p>
<blockquote>
<p><code>-it</code>的意思是什么？根据<code>docker run --help</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-i, --interactive                    Keep STDIN open even if not attached</span><br><span class="line">    --ip string                      IPv4 address (e.g., 172.30.100.104)</span><br><span class="line">    --ip6 string                     IPv6 address (e.g., 2001:db8::33)</span><br><span class="line">    --ipc string                     IPC mode to use</span><br><span class="line">    --isolation string               Container isolation technology</span><br><span class="line">    --kernel-memory bytes            Kernel memory limit</span><br><span class="line">-t, --tty                            Allocate a pseudo-TTY</span><br><span class="line">    --ulimit ulimit                  Ulimit options (default [])</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure>
<p>其实<code>-it</code>是<code>-i</code>和<code>-t</code>的合并写法，意思是运行后进入这个容器并且启用shell，不然运行之后就会放到后台而不会进入容器中。而<code>--rm</code>则代表容器退出之后会被删除（镜像不会被删除），每次运行实际上会创建一个新的容器，如果不加<code>--rm</code>或退出之后不手动删除的话会看到一堆停止运行的容器。</p>
</blockquote>
<p>输入<code>cat /etc/issue</code>可以看到默认拉取的是最新的Ubuntu 20.04 LTS：</p>
<p><img src="https://i.loli.net/2020/06/24/wldBMFtx3eIk98C.png" /></p>
<h1 id="build-customized-docker-images">Build Customized Docker Images</h1>
<p>如果没有现成的Docker镜像能满足我们的需求，我们可以考虑自己写一个。要自定义一个Docker镜像需要两步，第一步是编写Dockerfile，第二步是使用<code>docker build</code>命令构建镜像。Dockerfile可以看作是一个脚本，描述了我们构建镜像所需要的全部命令，比如要构建一个用于Python科学计算的Docker镜像，我们需要在Dockerfile中编写安装Python的命令，安装Numpy、Scipy等常用包的命令等等。我们先来上手编写Dockerfile，这里我准备写一个包含<a target="_blank" rel="noopener" href="https://hexo.io/">hexo博客框架</a>的镜像，这个框架需要node作为基础环境，不过我们不需要在Dockerfile里写安装node的命令。因为类似于<code>C++</code>或<code>Python</code>中的对象的继承，Dockerfile也可以“继承”，这意味着我们不必从头写起。我们先来看一下完整的Dockfile和效果，再来一一解释。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM node</span><br><span class="line"></span><br><span class="line">--------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">RUN npm install -g hexo-cli</span><br><span class="line">EXPOSE 4000</span><br><span class="line">CMD hexo init blog &amp;&amp; cd blog &amp;&amp; hexo generate &amp;&amp; hexo serverCopy</span><br></pre></td></tr></table></figure>
<p>运行结果如下所示，可以看到Docker按照我们写的Dockerfile一行一行的进行镜像的构建：</p>
<p><img src="https://i.loli.net/2020/06/24/tZ3JW4SPNhxUwEn.png" /></p>
<p>现在来解释Docerfile里的内容。<code>FROM &lt;docker image&gt;</code>表示继承其他的镜像，这里我们使用node官方的镜像。接下来是安装hexo，<code>RUN &lt;command&gt;</code>表示执行命令，这里我们直接用<code>npm install -g hexo-cli</code>进行安装。由于要浏览博客网页需要开放端口，而Docker容器运行的时候和外部主机是完全隔断的，要使外部主机访问Docker容器端口，需要暴露端口。<code>EXPOSE &lt;port&gt;</code>代表暴露端口，这里用的是4000端口。之后是创建博客和启动本地服务，<code>CMD &lt;command&gt;</code>和<code>RUN &lt;command&gt;</code>的区别是RUN会在构建的时候执行，而CMD是在容器启动之后才会执行。<code>hexo init blog &amp;&amp; cd blog &amp;&amp; hexo generate &amp;&amp; hexo server</code>分别代表初始化博客、进入博客所在文件夹、生成博客网站、启动本地服务器。更多指令可以参考<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/reference/builder/">官方文档</a>。</p>
<p>然后我们使用<code>docker build -t test_hexo .</code>命令构建镜像。</p>
<blockquote>
<p>构建镜像 <code>docker build -t &lt;image_name&gt; &lt;direcotry&gt;</code></p>
</blockquote>
<p>运行镜像：</p>
<p><img src="https://i.loli.net/2020/06/24/m4FSe15kMIDCHXy.png" /></p>
<p>可以看到容器启动后开始执行博客初始化。</p>
<p><img src="https://i.loli.net/2020/06/24/BEdibvgPTMz4sn8.png" /></p>
<p>最后在<code>locahost:4000</code>上启动了一个本地服务器，在浏览器中输入这个地址，可以看到刚刚构建好的博客：</p>
<p><img src="https://i.loli.net/2020/06/24/vmSUb5QH6l4afzF.png" /></p>
<p>值得注意的是，在Dockerfile中我们暴露了4000端口，使用<code>-p</code>标签可以达到同样的效果：<code>docker run -p &lt;docker_port&gt;:&lt;local_port&gt; &lt;image_name&gt;</code>。比如<code>docker run -p 9999:8888 xxxx</code>代表将Docker容器中的9999端口转发到外部主机的8888端口。如果你是在远程服务器上使用的Docker，那么端口只是被转发到了远程服务器上，还得手动将远程服务器再转发到你本机上才能直接在本机浏览器上看到页面。</p>
<h2 id="build-docker-images-with-aliyun-container-registry">Build Docker Images with Aliyun Container Registry</h2>
<p>因为某些原因，如果在构建镜像的时候需要通过<code>apt-get update</code>更新源，会发现无论如何都会卡住。这个时候可以使用<a target="_blank" rel="noopener" href="https://cr.console.aliyun.com/">阿里云容器镜像服务</a>，在阿里的服务器上构建好镜像，再拉取到自己的机器上。注册好帐号之后，点击创建镜像仓库：</p>
<p><img src="https://i.loli.net/2020/06/24/u4DGHv3En1iLI5z.png" /></p>
<p>这里仓库类型如果没有特殊需求建议使用公开，然后填写一些基本信息：</p>
<p><img src="https://i.loli.net/2020/06/24/Qipw5hAg136afnL.png" /></p>
<p>之后设置代码源，其实就是告诉阿里云从哪儿获取Dockerfile，我这里用的是Github，所以需要先在阿里云中关联Github账号，然后在Github中创建一个用来放Dockerfile的仓库。构建设置里有一个“海外机器构建”，这正是我们使用阿里云容器服务的主要目的，勾选。</p>
<p><img src="https://i.loli.net/2020/06/24/ksvZJG9lKfdh6aR.png" /></p>
<p>镜像仓库创建好之后，点进去，在构建页面点击添加规则：</p>
<p><img src="https://i.loli.net/2020/06/24/irBm3QcqjVhGMsv.png" /></p>
<p>按下图进行设置即可，镜像版本就是你想要的镜像名字：</p>
<p><img src="https://i.loli.net/2020/06/24/7pAFvM8CJQbq6mU.png" /></p>
<p>点击“立即构建”：</p>
<p><img src="https://i.loli.net/2020/06/24/GlMwqDInL7zVOpf.png" /></p>
<p>等待一段时间后，如果构建成功，便可以进行拉取了，在镜像仓库的基本信息页面可以看到地址：</p>
<p><img src="https://i.loli.net/2020/06/24/57jmEv8PYkr2nQG.png" /></p>
<p>将阿里云上的镜像拉取到本机之后一般会想要对镜像改名，可以使用<code>docker tag &lt;old_name&gt; &lt;new_name&gt;</code>。</p>
<h1 id="build-docker-images-for-deep-learning">Build Docker Images for Deep Learning</h1>
<h2 id="startup">Startup</h2>
<p>在Docker中配置适用于OpenPAI的深度学习镜像不是一件容易的事，会有很多的坑，这里专门说一下如何配置。推荐在阿里云容器镜像服务中进行构建，会少很多麻烦。</p>
<p>第一步是初始镜像，由于需要用到CUDA，这里可以根据自己的需求（比如不同CUDA版本支持的GPU驱动版本不一样，还有Tensorflow不同版本对CUDA和cuDNN要求也不一样）从Nvidia的Dockerhub<a target="_blank" rel="noopener" href="https://hub.docker.com/r/nvidia/cuda">官方页面</a>选择合适的CUDA和cuDNN版本：</p>
<p><img src="https://i.loli.net/2020/06/24/pftdhmHiWkTq8Fj.png" /></p>
<p>这里我们选择CUDA10.1 + cuDNN7：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM nvidia&#x2F;cuda:10.1-cudnn7-devel-ubuntu18.04Copy</span><br></pre></td></tr></table></figure>
<p>这一条主要是解决乱码问题以及定义用到的软件包的版本，这里Miniconda版本设置为4.5.4的原因是这是最后一个自带Python3.6的版本，我在这儿为了稳定所以用了Python3.6，大家也可以安装最新版的Miniconda：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ENV LANG&#x3D;C.UTF-8 LC_ALL&#x3D;C.UTF-8</span><br><span class="line">ENV HADOOP_VERSION&#x3D;2.7.2</span><br><span class="line">LABEL HADOOP_VERSION&#x3D;2.7.2</span><br><span class="line">ENV MINICONDA_VERSION&#x3D;4.5.4Copy</span><br></pre></td></tr></table></figure>
<p>接下来安装必须的包，大家可以根据需求自行调整，<code>-y</code>标签代表Yes，即自动同意安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive &amp;&amp; \</span><br><span class="line">    apt-get -y update &amp;&amp; \</span><br><span class="line">    apt-get -y install build-essential \</span><br><span class="line">        wget \</span><br><span class="line">        git \</span><br><span class="line">        curl \</span><br><span class="line">        unzip \</span><br><span class="line">        automake \</span><br><span class="line">        openjdk-8-jdk \</span><br><span class="line">        openssh-server \</span><br><span class="line">        openssh-client \</span><br><span class="line">        lsof \</span><br><span class="line">        libcupti-dev &amp;&amp; \</span><br><span class="line">    apt-get clean &amp;&amp; \</span><br><span class="line">    rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*Copy</span><br></pre></td></tr></table></figure>
<p>安装Miniconda并设置环境变量，<code>-b</code>标签可以让Miniconda无交互自动安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RUN wget --quiet https:&#x2F;&#x2F;repo.anaconda.com&#x2F;miniconda&#x2F;Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh &amp;&amp; &#x2F;bin&#x2F;bash Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh -b -p &#x2F;opt&#x2F;miniconda \</span><br><span class="line">&amp;&amp; rm Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh</span><br><span class="line">ENV PATH &#x2F;opt&#x2F;miniconda&#x2F;bin:$PATHCopy</span><br></pre></td></tr></table></figure>
<p>安装Hadoop，OpenPAI平台会用到：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RUN wget -qO- http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hadoop&#x2F;common&#x2F;hadoop-$&#123;HADOOP_VERSION&#125;&#x2F;hadoop-$&#123;HADOOP_VERSION&#125;.tar.gz | \</span><br><span class="line">    tar xz -C &#x2F;usr&#x2F;local &amp;&amp; \</span><br><span class="line">    mv &#x2F;usr&#x2F;local&#x2F;hadoop-$&#123;HADOOP_VERSION&#125; &#x2F;usr&#x2F;local&#x2F;hadoopCopy</span><br></pre></td></tr></table></figure>
<p><code>ENV</code>的作用是配置环境变量。配置JAVA和Hadoop环境变量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ENV JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-8-openjdk-amd64 \</span><br><span class="line">    HADOOP_INSTALL&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop \</span><br><span class="line">    NVIDIA_VISIBLE_DEVICES&#x3D;all</span><br><span class="line"></span><br><span class="line">ENV HADOOP_PREFIX&#x3D;$&#123;HADOOP_INSTALL&#125; \</span><br><span class="line">    HADOOP_BIN_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;bin \</span><br><span class="line">    HADOOP_SBIN_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;sbin \</span><br><span class="line">    HADOOP_HDFS_HOME&#x3D;$&#123;HADOOP_INSTALL&#125; \</span><br><span class="line">    HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;lib&#x2F;native \</span><br><span class="line">    HADOOP_OPTS&#x3D;&quot;-Djava.library.path&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;lib&#x2F;native&quot;Copy</span><br></pre></td></tr></table></figure>
<p>设置PATH环境变量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:$&#123;HADOOP_BIN_DIR&#125;:$&#123;HADOOP_SBIN_DIR&#125; \</span><br><span class="line">LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;lib:&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;targets&#x2F;x86_64-linux&#x2F;lib&#x2F;stubs:$&#123;JAVA_HOME&#125;&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;serverCopy</span><br></pre></td></tr></table></figure>
<p>完整的Dockerfile如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">FROM nvidia&#x2F;cuda:10.1-cudnn7-devel-ubuntu18.04</span><br><span class="line"></span><br><span class="line">ENV LANG&#x3D;C.UTF-8 LC_ALL&#x3D;C.UTF-8</span><br><span class="line">ENV HADOOP_VERSION&#x3D;2.7.2</span><br><span class="line">LABEL HADOOP_VERSION&#x3D;2.7.2</span><br><span class="line">ENV MINICONDA_VERSION&#x3D;4.5.4</span><br><span class="line"></span><br><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive &amp;&amp; \</span><br><span class="line">    apt-get -y update &amp;&amp; \</span><br><span class="line">    apt-get -y install build-essential \</span><br><span class="line">        wget \</span><br><span class="line">        git \</span><br><span class="line">        curl \</span><br><span class="line">        unzip \</span><br><span class="line">        automake \</span><br><span class="line">        openjdk-8-jdk \</span><br><span class="line">        openssh-server \</span><br><span class="line">        openssh-client \</span><br><span class="line">        lsof \</span><br><span class="line">        libcupti-dev &amp;&amp; \</span><br><span class="line">    apt-get clean &amp;&amp; \</span><br><span class="line">    rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br><span class="line"></span><br><span class="line">RUN wget --quiet https:&#x2F;&#x2F;repo.anaconda.com&#x2F;miniconda&#x2F;Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh &amp;&amp; &#x2F;bin&#x2F;bash Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh -b -p &#x2F;opt&#x2F;miniconda \</span><br><span class="line">&amp;&amp; rm Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh</span><br><span class="line">ENV PATH &#x2F;opt&#x2F;miniconda&#x2F;bin:$PATH</span><br><span class="line">    </span><br><span class="line">RUN wget -qO- http:&#x2F;&#x2F;archive.apache.org&#x2F;dist&#x2F;hadoop&#x2F;common&#x2F;hadoop-$&#123;HADOOP_VERSION&#125;&#x2F;hadoop-$&#123;HADOOP_VERSION&#125;.tar.gz | \</span><br><span class="line">    tar xz -C &#x2F;usr&#x2F;local &amp;&amp; \</span><br><span class="line">    mv &#x2F;usr&#x2F;local&#x2F;hadoop-$&#123;HADOOP_VERSION&#125; &#x2F;usr&#x2F;local&#x2F;hadoop</span><br><span class="line">    </span><br><span class="line">ENV JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-8-openjdk-amd64 \</span><br><span class="line">    HADOOP_INSTALL&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop \</span><br><span class="line">    NVIDIA_VISIBLE_DEVICES&#x3D;all</span><br><span class="line"></span><br><span class="line">ENV HADOOP_PREFIX&#x3D;$&#123;HADOOP_INSTALL&#125; \</span><br><span class="line">    HADOOP_BIN_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;bin \</span><br><span class="line">    HADOOP_SBIN_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;sbin \</span><br><span class="line">    HADOOP_HDFS_HOME&#x3D;$&#123;HADOOP_INSTALL&#125; \</span><br><span class="line">    HADOOP_COMMON_LIB_NATIVE_DIR&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;lib&#x2F;native \</span><br><span class="line">    HADOOP_OPTS&#x3D;&quot;-Djava.library.path&#x3D;$&#123;HADOOP_INSTALL&#125;&#x2F;lib&#x2F;native&quot;</span><br><span class="line"></span><br><span class="line">ENV PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin:$&#123;HADOOP_BIN_DIR&#125;:$&#123;HADOOP_SBIN_DIR&#125;:$PATH \</span><br><span class="line">LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;extras&#x2F;CUPTI&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;lib:&#x2F;usr&#x2F;local&#x2F;nvidia&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64:&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;targets&#x2F;x86_64-linux&#x2F;lib&#x2F;stubs:$&#123;JAVA_HOME&#125;&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;serverCopy</span><br></pre></td></tr></table></figure>
<p>建议先把这一部分进行构建，作为基础镜像，后面要配置其他环境（如安装Pytorch框架登），就不用重复构建这部分，还减少了出错的可能性。这里说一下，启动带CUDA的Docker镜像需要在<code>docker run</code>加上额外的参数<code>--runtime nvidia</code>。</p>
<p>接下来安装深度学习框架。</p>
<h2 id="configure-pytorch">Configure PyTorch</h2>
<p>假设上面的镜像我们命名为xiaoqinfeng/base，那么构建PyTorch的Dockerfile可以像下面这么写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM xiaoqinfeng&#x2F;base</span><br><span class="line"></span><br><span class="line">RUN pip install -U pip</span><br><span class="line">RUN pip install numpy scipy pandas matplotlib tqdm</span><br><span class="line">RUN pip install torch&#x3D;&#x3D;1.5.0+cu101 torchvision&#x3D;&#x3D;0.6.0+cu101 -f https:&#x2F;&#x2F;download.pytorch.org&#x2F;whl&#x2F;torch_stable.htmlCopy</span><br></pre></td></tr></table></figure>
<p>因为这里我用的CUDA10.1，其他版本的CUDA安装指令可能不太一样，具体可以参考<a target="_blank" rel="noopener" href="https://pytorch.org/get-started/locally/">官网</a>。</p>
<h2 id="configure-tensorflow">Configure Tensorflow</h2>
<p>如果是安装Tensorflow，那么构建Tensorflow的Dockerfile可以像下面这么写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM xiaoqinfeng&#x2F;base</span><br><span class="line"></span><br><span class="line">RUN pip install -U pip</span><br><span class="line">RUN pip install numpy scipy pandas matplotlib tqdm tensorflow-gpuCopy</span><br></pre></td></tr></table></figure>
<p>这里会自动安装最新版本的Tensorflow2。Tensorflow不同版本对CUDA和cuDNN版本甚至Python版本的支持都不太一样，可以参考<a target="_blank" rel="noopener" href="https://www.tensorflow.org/install/source#linux">官网</a>的说明。</p>
<h1 id="deep-learning-with-openpai">Deep Learning with OpenPAI</h1>
<h2 id="what-is-openpai">What is OpenPAI</h2>
<p>OpenPAI是一个分布式深度学习计算资源管理平台，对于我们用户来说，只需要定义好Docker镜像，然后编写好任务设置，提交到平台之后，平台便会自动分配计算资源来运行任务。</p>
<p>OpenPAI界面：</p>
<p><img src="https://i.loli.net/2020/06/24/CDrZjgYR7lNcieh.png" style="zoom: 50%;" /></p>
<p><img src="https://i.loli.net/2020/06/24/FGJpVCbls7YP4aM.png" style="zoom: 50%;" /></p>
<p>下面我们来讲讲怎么向OpenPAI平台提交任务。</p>
<h2 id="submit-jobs-to-openpai">Submit Jobs to OpenPAI</h2>
<h3 id="pack-code-data-files">Pack Code &amp; Data Files</h3>
<p>假设你已经完成了代码的编写和测试，你的目录结构可能看起来是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── data</span><br><span class="line">│   └── dataset.csv</span><br><span class="line">├── main.py</span><br><span class="line">└── src</span><br><span class="line">    ├── data.py</span><br><span class="line">    └── net.pyCopy</span><br></pre></td></tr></table></figure>
<p>因为OpenPAI会创建一个虚拟容器来运行你的代码，所以你的数据和代码必须要以某种方式传送到OpenPAI上的虚拟容器中。我们先来打包，在代码目录下执行<code>tar -cvf files.tar ./</code>。之后，运行<code>python -m http.server &lt;port&gt;</code>。打开浏览器输入<code>&lt;server_ip&gt;:&lt;port&gt;</code>应该就能看到你的文件了：</p>
<p><img src="https://i.loli.net/2020/06/24/Cbgiw3XKnGYsNHp.png" /></p>
<p>由于这个http进程需要一直运行，所以建议使用<code>screen</code>放到后台执行。</p>
<h3 id="configure-tasks">Configure Tasks</h3>
<p>像OpenPAI提交任务可以采用网页提交也可以使用VSCode插件，这里我们采用网页提交。登入OpenPAI界面，点击Submit Job：</p>
<p><img src="https://i.loli.net/2020/06/24/bhXAcJfOmo8RtT2.png" /></p>
<p>可以看到提交任务的界面：</p>
<p><img src="https://i.loli.net/2020/06/24/KME8GuN49gyY1ph.png" /></p>
<p>Job name大家可以自己设置。在Command一栏，是执行任务所需的全部命令，首先我们要做的就是将代码数据压缩包下载到容器中并解压：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget &lt;server_ip&gt;:&lt;port&gt;&#x2F;files.tar</span><br><span class="line"></span><br><span class="line">tar -xvf files.tarCopy</span><br></pre></td></tr></table></figure>
<p>然后是运行代码，假设我这里的任务比较简单，只有一行main.py的调用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python main.pyCopy</span><br></pre></td></tr></table></figure>
<p>如果任务的执行比较复杂，也只需把命令填到Command里即可，OpenPAI会自动执行。接下来是设置配置，可以选GPU的数量，内存大小等等：</p>
<p><img src="https://i.loli.net/2020/06/24/T7ryOxjpJP4FWYR.png" style="zoom:67%;" /></p>
<p>然后是镜像的选择：</p>
<p><img src="https://i.loli.net/2020/06/24/3n7SpNlsLjBRvgE.png" style="zoom:67%;" /></p>
<p>要注意在本机上构建好镜像之后，需要把镜像重命名为<code>&lt;repository_address&gt;/&lt;image_name&gt;</code>的格式（我们的<code>&lt;repository&gt;</code>是<code>lin-ai-27:5000</code>，假设我的镜像名是<code>xiaoqinfeng/pytorch</code>，那就是改成<code>lin-ai-27:5000/xiaoqinfeng/pytorch</code>），然后执行<code>docker push</code>推送到Docker镜像服务器上才能在OpenPAI上使用。</p>
<p>提交之后，可以在Jobs界面看到任务的运行情况：</p>
<p><img src="https://i.loli.net/2020/06/24/ZD4cUgOCIqnyHdB.png" style="zoom: 50%;" /></p>
<h1 id="misc">Misc</h1>
<h2 id="store-files-in-containers">Store Files in Containers</h2>
<p>我们往往需要在程序运行的时候保存文件，如checkpoints等。在OpenPAI上执行程序的话文件是保存在程序中的，如果我们想要在运行完之后把文件复制到本地电脑上呢？这个时候就需要在任务的配置文件里加上复制文件到HDFS的语句。首先确认你的HDFS的URL：如<code>hdfs://172.31.246.52:9000/你的OpenPAI用户名/</code>。</p>
<p>如果要创建文件夹，则可以使用<code>hdfs dfs -mkdir -p &lt;HDFS URL&gt;+&lt;New Folder&gt;</code>。这里<code>&lt;New Folder&gt;</code>是你要创建的的文件夹的路径，用起来和Linux的<code>mkdir</code>命令其实是差不多的。</p>
<p>要复制文件（夹）则使用<code>hdfs dfs -cp &lt;Source Dir&gt; &lt;Dest Dir&gt;</code>。</p>
</div></article></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>