<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>标签: Representation Learning - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="website"><meta property="og:title" content="Hanzawa の 部屋"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://larryshaw0079.github.io/img/og_image.png"><meta property="article:author" content="Hanzawa"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog"},"headline":"Hanzawa の 部屋","image":["https://larryshaw0079.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":null}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">Representation Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-09-23T12:36:57.000Z" title="2020-9-23 8:36:57 ├F10: PM┤">2020-09-23</time>发表</span><span class="level-item"><time dateTime="2021-02-28T04:58:08.309Z" title="2021-2-28 12:58:08 ├F10: PM┤">2021-02-28</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Self-supervised-Learning/">Self-supervised Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/09/23/Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination/">Unsupervised Feature Learning via Non-Parametric Instance Discrimination</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文基于样本分类和噪声对比估计提出了一个无监督表示学习算法。下图展示了一个Intuition Example：</p>
<img src="https://i.loli.net/2020/07/28/AimfJM7gtuDsPGQ.png"  />

<p>对于一个有监督的分类器，输入一张图片，作者观察到分类器的Softmax Response中较高的那些类都是在视觉上看起来比较接近的（美洲豹Leopard，美洲虎Jaguar，印度豹Cheetah），也就是说网络捕捉到了类间的视觉相似性，不过这是在有标签的情况下。对于无监督表示学习任务，作者将这个观察推广到了一个极端情况，就是把每一个样本都视作不同的类，然后让分类器来学习样本（类）间的视觉相似性。不过直接这么做会有严重的效率问题，所以作者还利用了Memory Bank机制和噪声对比估计来提高效率。</p>
<h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><p>学习一个嵌入表示函数$\mathbf v=f_\theta(x)$。在表示空间中$d_\theta(x,y)=\parallel f_\theta(x)-f_\theta(y)\parallel$</p>
<p><img src="https://i.loli.net/2020/07/26/WICKVkhrBu6Mci5.png"></p>
<h2 id="Non-Parametric-Softmax-Classifier"><a href="#Non-Parametric-Softmax-Classifier" class="headerlink" title="Non-Parametric Softmax Classifier"></a>Non-Parametric Softmax Classifier</h2><h3 id="Parametric-Classifier"><a href="#Parametric-Classifier" class="headerlink" title="Parametric Classifier"></a>Parametric Classifier</h3><p>在经过嵌入表示函数之后，得到表示向量$\mathbf v_i=f_\theta(\mathbf x_i)$。要基于这个向量进行分类，<br>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf w_i^\top\mathbf v)}{\sum_j\exp(\mathbf w_j^\top\mathbf v)}<br>$$</p>
<h3 id="Non-Parametric-Classifier"><a href="#Non-Parametric-Classifier" class="headerlink" title="Non-Parametric Classifier"></a>Non-Parametric Classifier</h3><p>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf v_i^\top\mathbf v/\tau)}{\sum_j\exp(\mathbf v_j^\top\mathbf v/\tau)}<br>$$</p>
<p>同时约束$\parallel \mathbf v\parallel=1$</p>
<p>最后的损失函数为负对数似然损失（negative log-likelihood）：<br>$$<br>J(\theta)=-\sum_{i=1}^n\log P(i|f_\theta(x_i))<br>$$</p>
<p>到这里，算法的大框架就确定下来了，剩下的就是解决两个效率上的问题。一个是损失函数的计算每次都需要计算整个训练集的表示，同时Softmax函数由于分母对应的项目很多（等于训练集大小）在效率上也有问题。</p>
<h3 id="Learning-with-A-Memory-Bank"><a href="#Learning-with-A-Memory-Bank" class="headerlink" title="Learning with A Memory Bank"></a>Learning with A Memory Bank</h3><p>这里解决第一个效率问题。要计算损失函数，需要遍历整个训练集获得对应的表示，而在训练的时候是一批一批的数据，每次重新计算表示效率很低。为了解决这个问题，作者引入了缓存机制，即加入一个memory bank $V$，用来保存计算好的表示$\mathbf f_i=f_\theta(x_i)$。一开始$V$采用单位随机向量初始化，之后在训练的时候不断更新$\mathbf f_i\rightarrow \mathbf v_i$。</p>
<h2 id="Noise-Contrastive-Estimation"><a href="#Noise-Contrastive-Estimation" class="headerlink" title="Noise Contrastive Estimation"></a>Noise Contrastive Estimation</h2><p>第二个效率问题很容易想到使用噪声对比估计（Noise Contrastive Estimation, NCE）来做。NCE主要是将计算复杂的分母作为一个参数来进行优化：<br>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf v^\top\mathbf f_i/\tau)}{Z_i}<br>$$</p>
<p>其中$Z_i=\sum_{j=1}^n\exp(\mathbf v^\top_j\mathbf f_i/\tau)$，噪声分布$P_n=1/n$，如果噪声样本数量是真实数据的$m$倍，那么随意给定一个样本，其属于真实样本的后验概率为：<br>$$<br>h(i,\mathbf v)=P(D=1|i,\mathbf v)=\frac{P(i|\mathbf v)}{P(i|\mathbf v)+mP_n(i)}=\sigma\left(s(\mathbf v)-\log {m P_n(i)}\right)<br>$$<br>其中$\Delta s=s(\mathbf v)-\log [m P_n(i)]$。这里的真实数据分布$P_d$为。NCE的损失函数就是要最大化$h(i,\mathbf v)$，最小化$h(i,\mathbf v^\prime)$<br>$$<br>J_{NCE}(\theta)=-E_{P_d}[\log h(i,\mathbf v)]-m\cdot E_{P_n}[\log(1-h(i,\mathbf v^\prime))]<br>$$<br>为了计算$Z_i$<br>$$<br>Z\simeq Z_i\simeq nE_j[\exp(\mathbf v_j^\top\mathbf f_i/\tau)]=\frac{n}{m}\sum_{k=1}^m\exp(\mathbf v_{j_k}^\top\mathbf f_i/\tau)<br>$$</p>
<h2 id="Proximal-Regularization"><a href="#Proximal-Regularization" class="headerlink" title="Proximal Regularization"></a>Proximal Regularization</h2><p>每个类别只有一个样本<br>$$<br>-\log h(i,\mathbf v_i^{(t-1)})+\lambda\parallel\mathbf v_i^{(i)}-\mathbf v_i^{(i-1)}\parallel^2_2<br>$$</p>
<p>最终的损失函数：</p>
<p>$$<br>J_{NCE}(\theta)=-E_{P_d}\left[\log h(i,\mathbf v_i^{(t-1)})-\lambda\parallel\mathbf v_i^{(t)}-\mathbf v_i^{(t-1)}\parallel^2_2\right]\<br>-m\cdot E_{P_n}\left[\log(1-h(i,\mathbf v^{\prime(t-1)}))\right]<br>$$</p>
<img src="https://i.loli.net/2020/08/06/nvS3Z7jEldVcCep.png" style="zoom:67%;" />

<h2 id="Weighted-k-Nearest-Neighbor-Classifier"><a href="#Weighted-k-Nearest-Neighbor-Classifier" class="headerlink" title="Weighted k-Nearest Neighbor Classifier"></a>Weighted k-Nearest Neighbor Classifier</h2><p>$s_i=\cos(\mathbf v_i,\hat{\mathbf f})$。记$\mathcal N_k$。$w_c=\sum_{i\in\mathcal N_k}\alpha_i\cdot 1(c_i=c)$。</p>
<img src="https://i.loli.net/2020/07/29/Cl8xHeFZzXpvosL.png" style="zoom:67%;" />

<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><img src="https://i.loli.net/2020/08/07/Zj628R7WYixJGog.png" style="zoom:67%;" />



<img src="https://i.loli.net/2020/08/07/k6rx1LoaZiFYGpQ.png" style="zoom:67%;" />





<p><img src="https://i.loli.net/2020/08/07/a3tNMQ7I2xmGdYA.png"></p>
<img src="https://i.loli.net/2020/08/07/CK7s3wHbmgnv2j4.png" style="zoom:80%;" />



<img src="https://i.loli.net/2020/08/07/rM7n3jhOiBbvJXf.png" style="zoom:67%;" />



<img src="https://i.loli.net/2020/08/07/PVL4nlGFtqOdyRh.png" style="zoom:67%;" />



<img src="https://i.loli.net/2020/08/07/F3miMXyOqg1DUtK.png" style="zoom:67%;" /></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-08-24T08:17:36.000Z" title="2020-8-24 4:17:36 ├F10: PM┤">2020-08-24</time>发表</span><span class="level-item"><time dateTime="2020-08-24T10:25:42.220Z" title="2020-8-24 6:25:42 ├F10: PM┤">2020-08-24</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Representation-Learning/">Representation Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/">Unsupervised Representation Learning by Predicting Random Distances</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>针对高维表格数据的表示学习，作者提出了基于预测预计变换后的距离的无监督表示学习框架RDP，并进行了理论上的讨论。To be finished…</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.12186">论文地址</a>         <a target="_blank" rel="noopener" href="https://github.com/billhhh/RDP">代码地址</a></p>
<h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Random-Distance-Prediction-Model"><a href="#Random-Distance-Prediction-Model" class="headerlink" title="Random Distance Prediction Model"></a>Random Distance Prediction Model</h2><p>对于很多下游任务来说，高维数据对模型效率和性能都很大，所以学习低维的有意义（能够最大限度保存原始空间的信息）的表示十分重要。本文的大致思想是给定一个确定的随机映射将样本映射到一个新的空间，然后构造数据集，输入时任意一对样本，标签是两个样本在新的空间的距离，之后训练一个模型来学习这个距离。作者认为通过该任务的训练，模型能够学到有意义的低维表示。模型的框架如下图：</p>
<img src="https://i.loli.net/2020/07/19/vRV32EgLiYkWaQN.png" style="zoom: 50%;" />

<p>其中$\phi(\mathbf x;\Theta):\mathbb R^D\mapsto\mathbb R^M$为孪生神经网络（Siamese Neural Network），将数据映射到$M$的新空间。损失函数为：</p>
<p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=l(\langle \phi(\mathbf x_i;\Theta),\phi(\mathbf x_j;\Theta)\rangle,\langle\eta(\mathbf x_i),\eta(\mathbf x_j)\rangle)<br>$$</p>
<p>其中$\eta(\cdot)$为已知的映射，$l(\cdot)$为衡量两个输入相似程度的度量。具体的来说，文中选取了简单的实现方案，即采用内积作为映射后的样本的距离度量：</p>
<p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=\left(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)\right)^2<br>$$</p>
<p>$\eta(\cdot)$为现成的映射。至于为什么要这么做，可以先接着看下面原文给出的理论分析，然后我再说说我自己的理解。</p>
<h2 id="Incorporating-Task-Dependent-Complementary-Auxiliary-Loss"><a href="#Incorporating-Task-Dependent-Complementary-Auxiliary-Loss" class="headerlink" title="Incorporating Task-Dependent Complementary Auxiliary Loss"></a>Incorporating Task-Dependent Complementary Auxiliary Loss</h2><p>对于特定的下游任务，作者提出可以整合额外的误差函数来提高模型行性能。比如说针对聚类任务可以使用重构误差：</p>
<p>$$<br>\mathcal L_{aux}^{clu}(\mathbf x)=(\mathbf x-\phi^\prime(\phi(\mathbf x;\Theta); \Theta^\prime))^2<br>$$</p>
<p>其中$\phi(\cdot)$和$\phi^\prime(\cdot):\mathbb R^M\mapsto\mathbb R^D$分别为编码器和解码器。</p>
<p>对于异常检测任务，可以使用下式：<br>$$<br>\mathcal L_{aux}^{ad}(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2<br>$$</p>
<p>这一个Loss本来是出现在强化学习的论文中，用来检测一个状态$\mathbf x$出现的频率，如果预测误差较小，说明这个样本之前见过或见过类似的，否则没怎么见过，可以认为是异常。由于本文的目的主要是降维加保留原始空间信息，可以认为使用线性变换的话此目的已经达到了。</p>
<h2 id="Theoretical-Analysis"><a href="#Theoretical-Analysis" class="headerlink" title="Theoretical Analysis"></a>Theoretical Analysis</h2><h3 id="Using-Linear-Projection"><a href="#Using-Linear-Projection" class="headerlink" title="Using Linear Projection"></a>Using Linear Projection</h3><p>这里讨论使用线性映射的情况，设数据集$\mathcal X\subset\mathbb R^{N\times D}$，映射矩阵$\mathbf A\subset\mathbb R^{K\times D}$为一随机矩阵，映射之后的数据为$\mathbf A\mathcal X^\top$。对于$\epsilon\in(0,\frac{1}{2})$和$K=\frac{20\log n}{\epsilon^2}$，存在$f:\mathbb R^D\mapsto\mathbb R^K$使得对于所有的$\mathbf x_i,\mathbf x_j\in\mathcal X$有：</p>
<p>$$<br>(1-\epsilon)\parallel\mathbf x_i-\mathbf x_j \parallel^2\leq \parallel f(\mathbf x_i)-f(\mathbf x_j)\parallel^2\leq (1+\epsilon)\parallel\mathbf x_i-\mathbf x_j\parallel^2<br>$$</p>
<p>如果$\mathbf A$的每个元素独立采样自标准正态分布那么有：</p>
<p>$$<br>\text{Pr}\left((1-\epsilon)\parallel\mathbf x\parallel^2\leq\parallel\frac{1}{\sqrt{K}}\mathbf A\mathbf x\parallel^2\leq(1+\epsilon)\parallel\mathbf x\parallel^2\right)\geq 1-2e^{\frac{-(\epsilon^2-\epsilon^3)K}{4}}<br>$$</p>
<p>在该随机映射下有：</p>
<p>$$<br>\text{Pr}(|\hat{\mathbf x}_i\cdot\hat{\mathbf x}_j-f(\hat{\mathbf x}_i)\cdot f(\hat{\mathbf x}_j)|\geq\epsilon)\leq 4e^{\frac{-(\epsilon^2-\epsilon^3)\cdot K}{4}}<br>$$</p>
<p>直观的解释就是说使用线性映射的情况下，只要使用的变换矩阵采样自标准正态分布，那么变换之后样本对之间的距离信息能够以一定的概率保留。</p>
<h3 id="Using-Non-Linear-Projection"><a href="#Using-Non-Linear-Projection" class="headerlink" title="Using Non-Linear Projection"></a>Using Non-Linear Projection</h3><p>这里作者试图说明，在某些条件下，非线性随机映射的作用和核函数接近。对于一个确定的随机映射函数$g:\mathbb R^D\mapsto\mathbb R^K$，在某些特定的条件下，函数$g$和核函数存在下列关系：</p>
<p>$$<br>k(\mathbf x_i,\mathbf x_j)=\langle\psi(\mathbf x_i),\psi(\mathbf x_j)\rangle\approx g(\mathbf x_i)\cdot g(\mathbf x_j)<br>$$</p>
<p>这个条件是函数$g$为一个乘以一个线性矩阵$\mathbf A$然后在经过一个具备平移不变性的傅里叶基函数（如cosine）。由于核函数能够保留原始空间的信息，所以作者认为使用非线性函数也能保留原始空间的信息。</p>
<blockquote>
<p>PS: 感觉作者在理论部分的讨论还是有点模糊，因为把一个随机的映射作为（伪）监督信息来进行学习，神经网络学到的不也就是随机噪声信息吗？对于这个方法work的原因，我在这里不负责任的分析一下。</p>
</blockquote>
<h3 id="Learning-Class-Structure-by-Random-Distance-Prediction"><a href="#Learning-Class-Structure-by-Random-Distance-Prediction" class="headerlink" title="Learning Class Structure by Random Distance Prediction"></a>Learning Class Structure by Random Distance Prediction</h3><p>这一节主要解释为什么神经网络$\phi(\cdot)$学到的要比随机映射$\eta(\cdot)$要好。模型的优化目标可以写成如下的形式：</p>
<p>$$<br>\mathop{\arg\min}<em>{\Theta}\sum</em>{\mathbf x_i,\mathbf x_j\in\mathcal X}(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-y_{ij})^2<br>$$</p>
<p>其中$y_{ij}=\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)$。设$\mathbf Y_\eta\in\mathbb R^{N\times N}$为距离矩阵。这个目标函数是在最小化每一对样本在经过$\phi(\cdot)$和$\eta(\cdot)$映射后之间的距离的差距。通过公式(7)和公式(8)我们知道，在合适的条件下，随机映射$\eta(\cdot)$能够保留原始空间的距离信息（即原始空间相近的样本在映射后也相近）。不过，上述公式的成立都依赖于对数据分布的一定假设，当真实的数据不满足条件时，结论就会有所偏差。</p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Performance-Evaluation-in-Anomaly-Detection"><a href="#Performance-Evaluation-in-Anomaly-Detection" class="headerlink" title="Performance Evaluation in Anomaly Detection"></a>Performance Evaluation in Anomaly Detection</h2><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/3G7DNKjwfQkiIz4.png"></p>
<p>异常分数定义为$\mathcal S(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2$。</p>
<h3 id="Comparison-to-the-State-of-the-art-Competing-Methods"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/8Ie2Q3mpdPHtrYF.png"></p>
<p><img src="https://i.loli.net/2020/07/20/OEcQSvZmfBz1ACt.png"></p>
<h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p><img src="https://i.loli.net/2020/07/20/7GtKlN8q5Mvygre.png"></p>
<h2 id="Performance-Evaluation-in-Clustering"><a href="#Performance-Evaluation-in-Clustering" class="headerlink" title="Performance Evaluation in Clustering"></a>Performance Evaluation in Clustering</h2><h3 id="Experimental-Settings-1"><a href="#Experimental-Settings-1" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/9xW12MVkoXgFZ6J.png"></p>
<h3 id="Comparison-to-the-State-of-the-art-Competing-Methods-1"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods-1" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/pUZ64aX1xWiLf2q.png"></p>
<p><img src="https://i.loli.net/2020/07/20/VrnXuJsymiMItUf.png" alt="image-20200720014002063"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-05-06T03:05:37.000Z" title="2020-5-6 11:05:37 ├F10: AM┤">2020-05-06</time>发表</span><span class="level-item"><time dateTime="2020-06-25T08:15:23.573Z" title="2020-6-25 4:15:23 ├F10: PM┤">2020-06-25</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Anomaly-Detection/">Anomaly Detection</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/">Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文提出了一种针对高维数据异常检测的表示学习方法。文中提出了<strong>RAMODO</strong>框架，一种基于排序的结合表示学习和异常检测的无监督框架。除此之外，基于<strong>RAMODO</strong>，文中还提出了基于此框架的模型<strong>REPEN</strong>。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1806.04808">Paper📰</a></p>
<h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="The-Proposed-Framework-RAMODO"><a href="#The-Proposed-Framework-RAMODO" class="headerlink" title="The Proposed Framework: RAMODO"></a>The Proposed Framework: <strong>RAMODO</strong></h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>我们的目的是为高维数据学习低维表示，同时在学到的低维表示中能够更好地进行异常检测。设有数据集$\mathcal{X}={\mathbf x_1,\mathbf x_2,\cdots, \mathbf x_N}$ ($\mathbf x_i\in \mathbb{R}^D$) 和一个基于随机距离的异常检测器$\phi:\mathcal{X}\mapsto \mathbb{R}$，我们的目标是学习一个表示函数$f:\mathcal{X}\mapsto\mathbb{R}^M (M\ll D)$使得对于所有异常样本$\mathbf x_i$和正常样本$\mathbf x_j$都有$\phi(f(\mathbf x_i))&gt;\phi(f(\mathbf x_j))$。</p>
<h3 id="Ranking-Model-based-Representation-Learning-Framework"><a href="#Ranking-Model-based-Representation-Learning-Framework" class="headerlink" title="Ranking Model-based Representation Learning Framework"></a>Ranking Model-based Representation Learning Framework</h3><p><strong>RAMODO</strong>基于<em>pairwise ranking model</em>。第一步是通过一定的预处理算法（原文中称为<em>outlier thresholding</em>）将数据划分为inlier候选集和outlier候选集；第二步通过随机从inlier候选集采样$n$个样本生成query set $(\mathbf x_i,\cdots,\mathbf x_{i+n-1})$，从inlier候选集采样一个样本生成<em>positive example</em> $(\mathbf x^+)$，从outlier候选集采样一个样本生成<em>negative example</em> $(\mathbf x^-)$，将三者组合生成 <em>metatriplet</em> $T=(&lt;\mathbf x_i,\cdots,\mathbf x_{i+n-1}&gt;,\mathbf x^+,\mathbf x^-)$；第三步通过神经网络$f$学习表示；第四步通过<em>outlier score-based ranking loss</em> $L(\phi(f(\mathbf x^+)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;),\phi(f(\mathbf x^-)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;))$来进行优化，其中$\phi(\cdot|\cdot)$为基于距离的异常检测器。</p>
<p><img src="https://i.loli.net/2020/06/25/4I7fx5ZjBhueUDz.png"></p>
<h2 id="A-RAMODO-Instance-REPEN"><a href="#A-RAMODO-Instance-REPEN" class="headerlink" title="A RAMODO Instance: REPEN"></a>A <strong>RAMODO</strong> Instance: <strong>REPEN</strong></h2><p><strong>REPEN</strong>为<strong>RAMODO</strong>的实例模型，使用Sp作为异常检测器。</p>
<h3 id="Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality"><a href="#Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality" class="headerlink" title="Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality"></a>Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality</h3><p>第一步使用Sp作为基础获得初始anomaly score：</p>
<blockquote>
<p><strong>Definition 1</strong> (<em>Sp-based Outlier Scoring</em>). 给定样本$x_i$，Sp 以以下方式定义该样本的异常程度：<br>$$<br>r_i=\frac{1}{m}\sum\limits_{j=1}^m nn_dist(\mathbf x_i|\mathcal{S}_j)<br>$$<br>其中$\mathcal S_j\subset \mathcal X$为数据集随机采样的子集，$m$为集成大小，$nn_dist(\cdot|\cdot)$为$\mathcal S_j$中最近邻居的距离。</p>
</blockquote>
<p>接着通过<em>Cantelli’s Inequality</em>来定义<em>Pseudo Outlier</em>：</p>
<blockquote>
<p>*<em>Definition 2 **(<em>Cantelli’s Inequality-based Outlier Thresholding</em>). 给定异常分数向量$\mathbf r\in\mathbb R^N$，更高异常分数代表更高的可能性为异常，设$\mu$和$\delta^2$分别为均值和方差，</em>Outlier*候选集由以下方式确定：<br>$$<br>\mathcal{O}={\mathbf x_i|r_i \geq \mu + \alpha\delta}, \space\forall \mathbf x_i\in\mathcal X, \space r_i\in\mathbf r<br>$$<br>其中$\alpha\geq 0$为自定义的阈值。</p>
</blockquote>
<p><em>Inlier</em>候选集$\mathcal I=\mathcal X\backslash \mathcal O$。</p>
<h3 id="Triplet-Sampling-Based-on-Outlier-Scores"><a href="#Triplet-Sampling-Based-on-Outlier-Scores" class="headerlink" title="Triplet Sampling Based on Outlier Scores"></a>Triplet Sampling Based on Outlier Scores</h3><p>首先，从$\mathcal I$采样一定数量的样本组成<em>query set</em>，每个样本被采样的概率与其对应的异常分数有关：</p>
<p>$$<br>p(\mathbf x_i)=\frac{\mathbb Z-r_i}{\sum_{t=1}^{|\mathcal I|}[\mathbb Z-r_t]}<br>$$</p>
<p>其中$\mathbb Z=\sum_{t=1}^{|\mathcal I|}r_t$。</p>
<p>之后从<em>inlier set</em>中均匀随机采样一个<em>positive sample</em> $\mathbf x^+$。最后从<em>outlier set</em>中根据以下概率采样一个<em>negative sample</em> $\mathbf x^-$：<br>$$<br>p(\mathbf x_j)=\frac{r_j}{\sum_{t=1}^{|\mathcal O|}r_t}<br>$$</p>
<h3 id="A-Shallow-Data-Representation"><a href="#A-Shallow-Data-Representation" class="headerlink" title="A Shallow Data Representation"></a>A Shallow Data Representation</h3><p>单层神经网络用来获得浅层的表示：</p>
<blockquote>
<p>**Definition 3 **(<em>Single-layer Fully-connected Representations</em>) 给定输入$x$，<br>$$<br>f_\Theta(\mathbf x)={\psi(\mathbf w_1^\top\mathbf x),\psi(\mathbf w_2^\top\mathbf x),\cdots,\psi(\mathbf w_M^\top\mathbf x)}<br>$$<br>其中$\psi(\cdot)$为激活函数，$\mathbf w$为权重矩阵。</p>
</blockquote>
<h3 id="Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores"><a href="#Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores" class="headerlink" title="Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores"></a>Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores</h3><p>设$\mathcal{Q}=&lt;f_\Theta(\mathbf x_i),\cdots,f_\Theta(\mathbf x_{i+n-1})&gt;$为<em>query set</em>，给定样本$\mathbf x$，<strong>REPEN</strong>根据最近邻距离定义了$f_\Theta(\mathbf x)$的异常程度：<br>$$<br>\phi(f_\Theta(\mathbf x)|\mathcal{Q})=nn_dist(f_\Theta(\mathbf x)|\mathcal Q)<br>$$<br>因此，给定三元组$T=(\mathcal Q,f_\Theta(\mathbf x^+),f_\Theta(\mathbf x^-))$，我们的目标是学得表示$f(\cdot)$使得：<br>$$<br>nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)&lt;nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)<br>$$<br>损失函数：<br>$$<br>J(\Theta;T)=L(\phi(f_\Theta(\mathbf x^+)|\mathcal Q),\phi(f_\Theta(\mathbf x^-)|\mathcal Q))=\\max{0, c+nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)-nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)}<br>$$<br>其中$c$为边界参数。给定一系列三元组，最终优化目标如下：<br>$$<br>\mathop{\text{arg min}}\limits_{\Theta}\frac{1}{|\mathcal{T}|}\sum\limits_{i=1}^{|\mathcal T|}J(\Theta;T_i)<br>$$</p>
<h3 id="The-Algorithm-and-Its-Time-Complexity"><a href="#The-Algorithm-and-Its-Time-Complexity" class="headerlink" title="The Algorithm and Its Time Complexity"></a>The Algorithm and Its Time Complexity</h3><p><img src="https://i.loli.net/2020/06/25/eYtKHBJ7szCgjNa.png"></p>
<h3 id="Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling"><a href="#Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling" class="headerlink" title="Leveraging A Few Labeled Outliers to Improve Triplet Sampling"></a>Leveraging A Few Labeled Outliers to Improve Triplet Sampling</h3><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul>
<li>AD：网络广告检测</li>
<li>LC：肺癌疾病监测</li>
<li>p53：异常蛋白质活动检测</li>
<li>R8：文本分类</li>
<li>News20：文本分类</li>
<li>URL：异常网址检测</li>
<li>Webspam：Pascal Large Scale LearningChallenge</li>
</ul>
<h2 id="Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features"><a href="#Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features" class="headerlink" title="Effectiveness in Real-world Data with Thousands to Millions of Features"></a>Effectiveness in Real-world Data with Thousands to Millions of Features</h2><p>作者分别使用原始特征和<em>REPEN</em>学到的特征进行异常检测，IMP代表性能提升比例，SU代表加速比例。</p>
<p><img src="https://i.loli.net/2020/06/25/mvUiE1NzyTwOgV8.png"></p>
<h2 id="Comparing-to-State-of-the-art-Representation-Learning-Competitors"><a href="#Comparing-to-State-of-the-art-Representation-Learning-Competitors" class="headerlink" title="Comparing to State-of-the-art Representation Learning Competitors"></a>Comparing to State-of-the-art Representation Learning Competitors</h2><ul>
<li>**AE: **自编码器</li>
<li>**HLLE: ** <em>Hessian Locally Linear Embedding</em></li>
<li>**SRP: ** <em>Sparse Random Projection</em></li>
<li>**CoP: ** <em>Coherent Pursuit</em></li>
</ul>
<p><img src="https://i.loli.net/2020/06/25/yQumCRNrHAheJ34.png"></p>
<h2 id="The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge"><a href="#The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge" class="headerlink" title="The Capability of Leveraging Labeled Outliers as Prior Knowledge"></a>The Capability of Leveraging Labeled Outliers as Prior Knowledge</h2><p><img src="https://i.loli.net/2020/06/25/NOLfKQd2u1JMPtp.png"></p>
<h2 id="Sensitivity-Test-w-r-t-the-Representation-Dimension"><a href="#Sensitivity-Test-w-r-t-the-Representation-Dimension" class="headerlink" title="Sensitivity Test w.r.t. the Representation Dimension"></a>Sensitivity Test w.r.t. the Representation Dimension</h2><p><img src="https://i.loli.net/2020/06/25/BoGjY5SEu6vrK3X.png"></p>
<p><img src="https://i.loli.net/2020/06/25/Rlx7Df9Hvsjp2Eg.png"></p>
<p>文中提到了对于R8、URL、News20这三个数据集在维度$M=1$的时候表现和其他维度一样好，作者给出的解释是在这几个数据集中异常部分是线性可分的，所以1维就足够了，另一个解释是优化问题。</p>
<h2 id="Scalability-Test"><a href="#Scalability-Test" class="headerlink" title="Scalability Test"></a>Scalability Test</h2><p><img src="https://i.loli.net/2020/06/25/1JfUclWyFYgLdNp.png"></p>
</div></article></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>