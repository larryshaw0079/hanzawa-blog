{"pages":[],"posts":[{"title":"ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection","text":"Introduction 本文针对面向区间的KPI异常检测提出了Label Screening方法和Relearning Algorithm. 原文 Contribution 提出了一种Label Screening方法来对区间内不同重要性进行过滤 提出了一种Relearning Algorithm来对FP和TP进行Relearning，在不减少Recall的条件下增大Precision Methodology Overall Structure 算法的整体框架如下： Label Screening Model 预训练的结果被分为\\(TP_{po},FP_{po},TN_{po},FN_{po}\\)四类，\\(TP_{po}\\)和\\(FN_{po}\\)可以被细分如下： \\[ \\begin{align}TP_{po}&amp;=TP_{po,withinT}+TP_{po,afterT}\\\\&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+TP_{po,after,fnl}\\end{align} \\] \\[ \\begin{align}FN_{po}&amp;=FN_{po,withinT}+FN_{po,afterT}\\\\&amp;=FN_{po,withinT,tpl}+FN_{po,,withinT,fnl}+FN_{po,afterT,tpl}+FN_{po,afterT,fnl}\\end{align} \\] 其中下标\\({}_{withinT}\\)代表在异常片段第一个点\\(T\\)距离内的所有点，下标\\({}_{afterT}\\)代表\\(T\\)距离之后。下标\\({}_{tpl}\\)和\\({}_{fnl}\\)分别代表在异常片段中，包含和不包含\\(TP_{po,withinT}\\)的点。 以TP为例，Point-based的TP包含了在T范围之内的（即在Interval-based的标准中也会被认为是TP的点）和T范围之外的点（即在Interval-based的标准中不认为是TP的点）。而在T范围之外的点又可以细分为该异常片段是否包含\\(TP_{po,withinT}\\)的点（即该点在Interval-based的标准中不会被判定为TP，但该异常片段有其点会被判定为TP）。 类似的，\\(TP_{io}\\)和\\(FN_{io}\\)可以被分解为： \\[ \\begin{align}TP_{io}&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}\\\\&amp;=TP_{po}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}-TP_{po,afterT,fnl}\\end{align} \\] \\[ \\begin{align}FN_{io}&amp;=FN_{po,withinT,fnl}+FN_{po,afterT,fnl}+TP_{po,afterT,fnl}\\\\&amp;=FN_{po}+TP_{po,afterT,fnl}-FN_{po,withinT,tpl}-FN_{po,afterT,tpl}\\end{align} \\] 文中对该部分的分析可以分为以下几点： 在Interval-oriented的标准中，\\(FN_{po,tpl}\\)的点仍会被认为是\\(TP_{io}\\)，而\\(TP_{po,afterT}\\)（不带\\({}_{tpl}\\)）不会被认为是\\(TP_{io}\\)，所以最终\\(TP_{io}\\)由所有\\(TP_{po}\\)加上那些会被认为是\\(TP_{io}\\)的\\(FN_{po,tpl}\\)再去掉不带\\({}_{tpl}\\)的\\(TP_{po,afterT}\\)组成，即公式(6) 同时，根据公式(6)，如果\\(TP_{po}\\)变为\\(FN_{po,tpl}\\)，也不会对最终结果造成影响。但是根据公式(5)和公式(7)，\\(TP_{po,withinT}\\)变成\\(FN_{po,withinT,fnl}\\)会减小\\(TP_{io}\\)同时增大\\(FN_{io}\\) 文章指出，虽然\\(FN_{po,withinT,tpl}\\)和\\(FN_{po,afterT,tpl}\\)最后都会被认为是\\(TP_{io}\\)，但作者假设\\(FN_{po,withinT,tpl}\\)更难检测，所以应该保留，而\\(FN_{po,afterT,tpl}\\)应该削减 Label Screening方法去除了\\(FN_{po,afterT}\\)的点 Screened之后的训练集被用来训练DNN主模型，但Label Screening的预测结果也会被保留，和DNN主模型的结果进行组合 算法流程如下： Relearning Algorithm Relearning Model的输入是DNN主模型预测出来的异常，其中包括TP和FP。Relearning Model采用的是随机森林，其输入的样本通过采样得到： \\[ \\begin{align} \\text{relearning}\\space&amp;\\text{training set}=\\\\&amp; shuffle\\{4C\\ast\\text{randomof}(TP_{po})\\\\&amp;+C\\cdot\\text{randomof}(FP_{po})+C\\cdot\\text{randomof}(TN_{po})\\} \\end{align} \\] 其中\\(C\\)为常数。TN和FP都看作是负例(正常样本)，TP看作是正例。 Detection 对于一个滑动窗口\\(x_t=\\{x_{t-w+1},\\cdots,x_t\\}\\)，异常检测算法的目标是输出检测结果\\(y_t\\in\\{0,1\\}\\)来表示时间\\(t\\)是否发生异常。实际上算法输出的是\\(p_{y_t}\\in[0,1]\\)概率值来表示在时间\\(t\\)发生异常的概率。文中三个模型会得到三个输出：\\(y_{t,ls},y_{t,main},y_{t,re}\\)。最终结果为： \\[ y_t=y_{t,ls}\\space\\&amp;\\space y_{t,main}\\space\\&amp; \\space y_{t,re} \\] 在绘制PR曲线时，采用的公式为： \\[ \\begin{align} p_{y_t}(th)=&amp;(1-sig(p_{y_t,ls},th))\\cdot(p_{y_t,ls})\\\\ &amp;+sig(p_{y_t,ls},th)\\cdot(1-sig(p_{y_t,main},th))\\cdot p_{y_t,main}\\\\ &amp;+sig(p_{y_t,ls},th)\\cdot sig(p_{y_t,main},th)\\cdot p_{y_t,re}\\\\ \\end{align} \\] \\[ y_t(th)=sig(p_{y_t}(th),th) \\] 算法流程如下： Experiments Datasets 清华AIOps数据集，选取了25条KPI。 Preprocessing Missing Data. 去除。 Standardization. Minmax Standardization，Feature Extraction使用的是Standardization后的数据。 Feature Extraction. 使用了12种特征。 Group Feature Name Values The original values standardized Statistical Features Mean, Standard Deviation, Range, Difference... Fitting Features EWMA, AR Wavelet Features Db2 wavelet decomposition Results AUCPR F1 Remark 这篇文章的Label Screening方法实际上是在处理样本分类难易度的问题，将异常区间内容易的样本去除了 对于时间序列的异常检测问题，我们的目标一般是Point-based的异常标签，一个时间点的特征是有限的。如果用窗口的方式，以\\(\\{x_{t-w+1},\\cdots,x_t\\}\\)作为时间\\(t\\)的输入（当然每个\\(x_t\\)可以有多个Channel），然后把预测结果作为时间\\(t\\)的输出","link":"/2019/09/22/ALSR-An-adaptive-label-screening-and-relearning-approach-for-interval-oriented-anomaly-detection/"},{"title":"Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series","text":"Introduction 这篇文章提出了一个基于GAN的时间序列异常检测模型。 原文 Contribution 提出了基于GAN的时间序列无监督异常检测模型 我们使用基于LSTM的GAN来对多变量时间序列进行建模 结合使用了Residual Loss和Discrimination Loss来进行异常的判断 Background Generative Adversarial Networks GANs In a Nutshell, an extremely simple explanation 我们想要从一个复杂的、高维的数据分布\\(p_r(x)\\)上采样得到我们想要的数据点，然而\\(p_r(x)\\)无法直接求得 代替方法：从一个简单的、已知的分布\\(p_z(z)\\)上采样，然后学习一个Transformation \\(G(z): z\\rightarrow x\\)来将\\(z\\)映射到\\(x\\) Training: Two-player Game Generator Network: 从随机分布\\(p_z(z)\\)采样\\(z\\)，通过映射生成样本\\(x\\)，这个生成的样本要尽量“真实”。怎么“真实”？优化生成器参数\\(\\theta_G\\)最大化判别器对生成样本的评分即可 Discriminator Network: 接受一个样本\\(x\\)，判断其是生成的样本还是真实的样本。在训练阶段，我们是知道一个样本\\(x\\)到底是生成的还是真实的，所以优化判别器参数\\(\\theta_D\\)最小化判别器对生成样本的评分，最大化对真实样本的评分（即最大化分辨真实样本的能力） 形式化的来讲，优化函数如下： \\[\\min\\limits_{\\theta_G}\\max\\limits_{\\theta_D}V(G,D)=\\mathbb{E}_{x\\sim p_{data}(x)\\log(\\underbrace{D_{\\theta{D}}(x)}_{判别器对真实样本的评分})}+\\mathbb{E}_{z\\sim p_z(z)}\\log(1-\\underbrace{D_{\\theta_d}(G_{\\theta_G}(z))}_{判别器对生成样本的评分})\\] 训练过程如下： Long Short Time Memory Networks Vanilla Recurrent Neural Networks 普通的神经网络： 概括的来讲，可以涵盖为一个公式\\(\\hat{\\mathbf{y}}=f(\\mathbf{x})\\)。对于一个样本\\(\\mathbf{x}\\)，通过多层神经网络映射，输出\\(\\mathbf{y}\\)。 对于RNN，我们处理的是序列数据，也就是说所有样本之间并不是相互独立的。对于一个序列中的一个样本\\(x_t\\in\\{x_1,x_2,\\cdots,x_n\\}\\)，将其输入到神经网络的时候，为了建模\\(x_t\\)之前的子序列对\\(x_t\\)的影响关系，需要将这个子序列的信息也输入到神经网络中，怎么做呢？为每一个样本点保存一个State。即定义\\(h_t=g(\\hat{y_t})=g(f(x_t))\\)，对于当前样本点，\\(\\hat{y_t}=f(x_t,h_{t-1})\\)。也就是说神经网络的输入不仅包含了当前样本点的特征，也包含了上一个样本点的“状态”(上一个样本点的“状态”又隐含了上上个样本点的“状态”...)，就像是为网络加上了短期记忆。 Gradient Flow of Vanilla RNN 下面来进行一些形式化的定义，假设在时刻\\(t\\)网络输入特征为\\(x_t\\)，输出隐含状态为\\(h_{t}\\)，其不仅和当前输入\\(x_t\\)有关，还和上一个隐含状态\\(h_{t-1}\\)有关： 当前时刻总的净输入\\(z_t=Uh_{t-1}+Wx_t+b\\) 当前时刻输出隐含状态\\(h_t=f(z_t)\\) 当前时刻输出\\(\\hat{y}_t=Vh_t\\) RNN的梯度更新公式(推导过程比较复杂)： \\[\\frac{\\partial{\\mathcal{L}}}{\\partial U}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t \\delta_{t,k}\\mathbf{h}_{k-1}^T\\] \\[\\frac{\\partial{\\mathcal{L}}}{\\partial{W}}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t \\delta_{t,k}x_k^T\\] \\[\\frac{\\partial\\mathcal{L}}{\\partial{b}}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t\\delta_{t,k}\\] 其中\\(\\delta_{t,k}=\\frac{\\partial{\\mathcal{L}}}{\\partial{z_k}}=\\text{diag}(f^\\prime(z_k))U^T\\delta_{t,k+1}\\)定义为第\\(t\\)时刻的损失对第\\(k\\)时刻隐藏神经层的净输入\\(z_k\\)的导数，且\\(z_k=Uh_{k-1}+Wx_k+b,1\\leq k&lt;t\\)。 RNN的梯度流向如下图红箭头所示： RNN会遇到梯度消失和梯度爆炸的问题。根据前面的公式，\\(\\delta_{t,k}\\)实际上是递归定义的，展开得到： \\[\\delta_{t,k}=\\prod\\limits_{\\tau=k}^{t-1}(\\text{diag}(f^\\prime(z_\\tau))U^T)\\delta_{t,t}\\] 如果定义\\(\\gamma\\cong\\parallel\\text{diag}(f^\\prime(z_\\tau))U^T\\parallel\\)，那么\\(\\delta_{t,k}\\cong\\gamma^{t-k}\\delta_{t,t}\\)。在\\(t-k\\)很大时，\\(\\gamma&lt;1\\)会导致梯度消失，\\(\\gamma&gt;1\\)时会导致梯度爆炸。 Long Short Time Memory LSTM是一种解决RNN梯度消失问题的改进版本： 在LSTM中，维护了两个State，\\(c_t\\)和\\(h_t\\)。其中\\(c_t\\)由遗忘门\\(f\\)与上一个\\(c_{t-1}\\)相乘(代表继承上一个Cell的信息并加以一定程度的遗忘)，加上输出门\\(i\\)与Gate Gate \\(g\\)相乘(Gate Gate代表当前的候选状态，输出门\\(i\\)控制当前候选状态有多少信息需要保存)。最后，输出门\\(o\\)控制当前时刻的Cell State \\(c_t\\)有多少信息需要输出给外部状态\\(h_t\\)。 三个门的计算方式为： \\[i_t=\\sigma(W_ix_t+U_ih_{t-1}+b_i)\\] \\[f_t=\\sigma(W_fx_t+U_fh_{t-1}+b_f)\\] \\[o_t=\\sigma(W_ox_t+U_oh_{t-1}+b_o)\\] Methodology 总体框架图如Fig 1所示： GAN with LSTM-RNN 网络结构上生成器和判别器都是LSTM，优化函数和普通GAN一样： \\[\\min\\limits_G\\max\\limits_D V(D,G)=\\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)]+\\mathbb{E}_{z\\sim p_z(z)}[\\log (1-D(G(z)))]\\] GAN-based Anomaly Score 在测试阶段，需要使用梯度优化寻找一个使得\\(G_{rnn}(z)\\)最接近\\(X^{test}\\)的\\(z^k\\)： \\[\\min\\limits_{Z^k}Error(X^{test},G_{rnn}(Z^k))=1-Similarity(X^{test},G_{rnn}(Z^k))\\] 本文定义了两种Anomaly Score，一种是Residual Loss： \\[Res(X^{test}_t)=\\sum\\limits_{i=1}^n|x^{test,i}_t-G_{rnn}(Z^{k,i}_t)|\\] 一种是Discrimination Loss，即判别器的输出\\(D_{rnn}(x_t^{test})\\)。 总的Anomaly Score： \\[S^{test}_t=\\lambda Res(X^{test}_t)+(1-\\lambda)D_{rnn}(x^{test}_t)\\] Anomaly Detection Framework 模型的算法流程如下： 由于本文是多变量时间序列预测，而且时间序列的长度有可能比较长，作者使用了滑动窗口和PCA来进行预处理。 Experiments","link":"/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/"},{"title":"Deep Anomaly Detection with Deviation Networks","text":"Introduction 本文关注Deep Anomaly Detection，也就是用深度学习的方法来进行异常检测。文中提到现有的Deep Anomaly Detection存在两个弊端：一个是采用深度学习方法来进行特征学习，然后通过下游任务得到Anomaly Score，相比文中End-to-End的Anomaly Score学习，存在优化不充分的风险；另一个是现有的方法主要是无监督学习，无法利用已知的信息（如少量标签）。为此，本文提出了一种端到端的异常检测框架，来解决上述问题。 本文的主要贡献如下： 提出了一种端到端的异常检测框架，直接学习Anomaly Score并且可以利用已知信息； 基于提出的框架，文中提出了一种实例方法 (DevNet)。 Proposed Model End-To-End Anomaly Score Learning Problem Statement 为了区别于传统的两阶段异常检测（先学习特征表示，然后在学到的特征上定义一个anomaly measure来得到anomaly score），作者对端到端的异常检测问题重新进行形式化。 给定\\(N+K\\)个样本\\(\\mathcal{X}=\\{\\boldsymbol x_1,\\boldsymbol x_2,\\cdots,\\boldsymbol x_N,\\boldsymbol x_{N+1},\\cdots,\\boldsymbol x_{N+K}\\}\\)，其中\\(\\boldsymbol x_i\\in\\mathbb{R}^D\\)，无标签样本集\\(\\mathcal{U}=\\{\\boldsymbol x_1,\\boldsymbol x_2,\\cdots,\\boldsymbol x_N\\}\\)，有标签样本集\\(\\mathcal{K}=\\{\\boldsymbol x_{N+1},\\cdots,\\boldsymbol x_{N+K}\\}\\)，且\\(K\\ll N\\)。异常检测的目标是学习一个anomaly scoring function\\(\\phi:\\mathcal{X}\\mapsto\\mathbb{R}\\)使得\\(\\phi(\\boldsymbol x_i)&gt;\\phi(\\boldsymbol x_j)\\)，其中\\(\\boldsymbol x_i\\)为异常样本，\\(\\boldsymbol x_j\\)为正常样本。 The Proposed Framework 为了解决这个问题，文中提出了一种通用异常检测框架，模型框架如下图所示： 模型框架如下图所示： 主要包含三个部分： anomaly scoring network. 图中左边的部分，一个函数\\(\\phi\\)，输入样本\\(\\mathbf{x}\\)，输出anomaly score reference score generator. 图中右边的部分。只有一个anomaly scoring network并不能进行训练，需要训练的目标。为此加入reference score generator，输入为随机选择的\\(l\\)个正常样本，输出reference score（这\\(l\\)个正常样本anomaly score的均值，记为\\(\\mu_\\mathcal{R}\\)） deviation loss. \\(\\phi(\\mathbf{x})\\)，\\(\\mu_\\mathcal{R}\\)及对应的标准差\\(\\sigma_\\mathcal{R}\\)作为deviation loss函数的输入。因为\\(\\mu_\\mathcal{R}\\)和\\(\\sigma_\\mathcal{R}\\)对应正常样本集的均值和方差，那么异常样本的anomaly score应该和\\(\\mu_\\mathcal{R}\\)差别比较大，而正常样本则应该接近\\(\\mu_\\mathcal{R}\\)。 Deviation Networks 下面是上述三个部件的具体实现。 End-To-End Anomaly Scoring Network 记\\(\\mathcal{Q}\\in\\mathbb{R}^M\\)为中间表示空间，anomaly scoring network\\(\\phi(\\cdot;\\Theta):\\mathcal{X}\\mapsto\\mathbb{R}\\)可以定义为数据表示学习\\(\\psi(\\cdot;\\Theta_t):\\mathcal{X}\\mapsto\\mathcal{Q}\\)和异常分数学习\\(\\eta(\\cdot;\\Theta_s):\\mathcal{Q}\\mapsto\\mathbb{R}\\)两阶段的组合，其中\\(\\Theta=\\{\\Theta_t,\\Theta_s\\}\\)。 \\(\\psi(\\cdot;\\Theta_t)\\)可以用一个\\(H\\)层神经网络来实现： \\[ \\mathrm{q}=\\psi(\\mathbf{x};\\Theta_t) \\] 其中\\(\\mathbf{x}\\in\\mathcal{X}\\)，\\(\\mathrm{q}\\in\\mathcal{Q}\\)。 \\(\\eta(\\cdot;\\Theta_s)\\)可以用一个单层的神经网络来实现： \\[ \\eta(\\mathrm q;\\Theta_s)=\\sum\\limits_{i=1}^M w_i^oq_i+w_{M+1}^o \\] 其中\\(\\mathrm q\\in\\mathcal Q\\)，\\(\\Theta_s=\\{\\mathbf{w}^o\\}\\)。 所以有： \\[ \\phi(\\mathbf{x};\\Theta)=\\eta(\\psi(\\mathbf{x};\\Theta_t);\\Theta_s) \\] Gaussian Prior-based Reference Scores 有两种方法来获得\\(\\mu_\\mathcal{R}\\)，一种是data-driven，一种是prior-driven。如果是data-driven的话则采用另一个神经网络，文中表示为了更好的解释性和计算效率，所以采用的是prior-driven。 \\[ \\begin{align} r_1,r_2,\\cdots,r_l\\sim \\mathcal{N}(\\mu,\\sigma^2),\\\\ \\mu_\\mathcal{R}=\\frac{1}{l}\\sum\\limits_{i=1}^l r_i \\end{align} \\] 在文中，采用的prior是标准高斯分布。 Z-Score Based Deviation Loss anomaly scoring network的优化目标可以定义为Z-Score的方式： \\[ dev(\\boldsymbol x)=\\frac{\\phi(\\boldsymbol x;\\Theta)-\\mu_{\\mathcal{R}}}{\\sigma_{\\mathcal{R}}} \\] \\(dev(\\boldsymbol x)\\)可以看作是样本偏离标准的程度，而我们肯定希望异常样本偏离标准越大，正常样本越接近标准。文中采用的损失函数是Contrastive Loss： \\[ L(\\phi(\\boldsymbol x;\\Theta),\\mu_\\mathcal{R},\\sigma_\\mathcal{R})=(1-y)|dev(\\boldsymbol x)| + y \\max(0, a - dev(\\boldsymbol x)) \\] Contrastive Loss的直观解释可以看下图： 对于负例（正常），优化过程将他们尽量向原点靠近，对于正例（异常），优化过程将他们拉向边界。 The DevNet Algorithm DevNet的算法流程图如下： Interpretability of Anomaly Scores 因为reference score generator选择的是确定的高斯分布，于是可以用概率论给出一些解释性。作者给出了一个结论， PROPOSITION： 设\\(\\boldsymbol x\\in\\mathcal{X}\\)，\\(z_p\\)为\\(\\mathcal{N}(\\mu,\\sigma^2)\\)的分位数，那么\\(\\phi(\\boldsymbol x)\\)在区间\\(\\mu\\pm z_p\\sigma\\)的概率为\\(2(1-p)\\)。 例如，假设\\(p=0.95\\)，那么\\(z_{0.95}=1.96\\)，表示异常分数高于1.96的样本将以0.95的置信度为异常。 Experiment 实验用到了9个数据集，4个Baseline (REPEN，DSVDD，FSNET，iForest)，以及ROC和PR曲线两种评测标准。 Effectiveness in Real-world Data Sets Experiment Settings 这一个实验主要是为了验证算法在真实场景下的效果，即大量无标签数据和极少量标签数据。训练集包含两部分，一部分是无标签数据\\(\\mathcal{U}\\),包含\\(2\\%\\)的异常样本，另一部分是有标签数据\\(\\mathcal{K}\\)，由随机采样\\(0.005\\%-1\\%\\)的训练数据和\\(0.08\\%-6\\%\\)的异常样本组成。 Findings 实验结果如下表所示： 从结果上看来，本文提出的方法在所有数据集上都比Baseline好，说明DevNet端到端直接优化Anomaly Score的方式是有效的。 Data Efficiency Experiment Settings 这一个实验主要是为了探究基于深度的异常检测方法的data efficiency。和上一个实验一样，无标签数据集包含\\(2\\%\\)的异常，而有标签的异常数量从\\(5\\)到\\(120\\)不等。本实验试图回答以下两个问题： DevNet的data efficiency如何？ 基于深度的方法在多大程度上能够利用标签信息？ Findings 在几个基于深度的Baseline中，DevNet的效果是最好的，同时在有标签异常非常有限的情况下，DevNet也能很好的利用标签信息，达到更好的效果。 Robustness w.r.t. Anomaly Contamination Experiment Settings 在第一个实验中，无标签数据集\\(\\mathcal{U}\\)包含的是固定的异常比例\\(2\\%\\)，而在这个实验中，作者测试了从\\(0\\%\\)到\\(20\\%\\)之间不同异常比例来测试算法的鲁棒性（即使\\(\\mathcal{U}\\)中包含异常，由于没有标签，在训练的时候仍然假设都为正常来进行训练）。本实验试图回答以下问题： 基于深度的异常检测方法的鲁棒性如何？ 当训练集中异常污染的比例较高的时候基于深度的方法能否打败无监督的方法？ Findings 下图为实验结果： 从结果上来看，DevNet比其他基于深度的方法鲁棒性更好，同时在高异常污染的情况下仍然比纯无监督方法效果要好。 Ablation Study 本实验设置了DevNet的三个变体（默认的DevNet-Def为单层隐层加上一个输出层）来进行消融实验，分别是： DevNet-Rep，去掉了anomaly scoring network网络的输出层，对应end-to-end learning of anomaly scores和deviation loss； DevNet-Linear，去掉了网络中的非线性层，对应learning of non-linear features； DevNet-3HL，隐层数量为3层。 对比结果如下： 通过实验可以发现，DevNet-Rep说明了end-to-end learning of anomaly scores和deviation loss的有效性，而DevNet-Linear说明了learning of non-linear features的重要性。DevNet-3HL说明了加深网络并不总能带来性能的提升。 Scalability Test 这一个实验使用合成的数据来测试算法对大规模数据的处理能力，分别从Data Size和Data Dimensionality两方面来测试。结果如下： 可以看出，DevNet对Data Size并不敏感，同时，面对高维数据，DevNet也没有表现出劣势。","link":"/2020/02/24/Deep-Anomaly-Detection-with-Deviation-Networks/"},{"title":"Discovering Physical Concepts with Neural Networks","text":"Introduction 如题目所示，本文的目的是利用神经网络来发掘物理概念。其思路是从实验数据学到表示，然后用学到的表示来回答物理问题，由此物理概念可以从学到的表示来提取出。作者进行了4个实验： 在阻尼振动实验中，模型学到了相关的物理参数； 在角动量守恒实验中，模型预测了质点的运动； 给定量子系统的观测数据，模型正确的识别出了量子状态的自由度； 给定从地球观测的太阳和火星的位置时间序列数据，模型发现了日心说模型。 Preliminaries 作者在附录中对神经网络的基础知识进行了介绍，这里不再赘述，只截取了一些相对前沿的内容。 Variational Autoencoders 本文用到的模型基础是VAE： Representation Learning Representation learning的主要目标是将数据映射到一个隐向量 (encoder)，为了保证隐向量包含了所有相关信息， 那么应该能够从隐向量还原原数据 (decoder)。传统的Autoencoder是这个思想的最简单实现，而VAE则将AE和Variational Inference结合了起来，是一种经典的生成式模型。现在很多研究关注Disentangled Representation Learning，也就是说我们希望模型能够无监督地学习数据，从中学到有意义的表示。 \\(\\boldsymbol \\beta\\)-VAE \\(\\beta\\)-VAE是一种特殊的VAE，也是一个经典的Disentangled Representation Learning模型，它和VAE主要的区别是对KL散度一项加上了权重\\(\\beta\\)进行调节： \\[ C_\\beta(x)=-\\left[\\mathbb{E}_{z\\sim p_\\phi(z|x)}\\log p_\\theta(x|z)\\right] + \\beta D_\\text{KL}\\left[p_\\phi(z|x)\\parallel h(z)\\right] \\] 如果假设\\(p_\\phi(z|x)=\\mathcal{N}(\\mu,\\sigma)\\)，那么损失函数可以进行简化： \\[ C_\\beta(x)=\\parallel \\hat{x} - x \\parallel^2_2-\\frac{\\beta}{2}\\left(\\sum\\limits_i\\log(\\sigma_i^2)-\\mu_i^2-\\sigma_i^2\\right)+C \\] Network Structure Network Structure: SciNet 模仿物理学家建模物理问题的过程，作者提出了SciNet，如下图所示： 物理学家在建模物理问题的时候，往往是从一些实验数据出发，根据物理常识提取更加精练的表示，然后用学到的表示来回答物理问题。 对于单纯的输入输出问题，SciNet可以看作是一个映射，\\(F:\\mathcal{O}\\times\\mathcal{Q}\\rightarrow\\mathcal{A}\\)。\\(\\mathcal{O}\\)是可能的实验数据集合，\\(\\mathcal{Q}\\)是可能的问题集合，\\(\\mathcal{A}\\)是可能的答案集合。可以将其分为两个步骤：编码过程\\(E:\\mathcal{O}\\rightarrow\\mathcal{R}\\)从实验数据学到表示，解码过程\\(D:\\mathcal{R}\\times \\mathcal{Q}\\rightarrow \\mathcal{A}\\)根据给定的问题从表示来回答问题。由此，\\(F(o,q)=D(E(o),q)\\)。在实现方面，SciNet采用的是全连接网络。 Training and Testing SciNet 用来训练的数据形式为\\((o,q,a_{cor}(o,q))\\)，观测\\(o\\)和问题\\(q\\)分别从观测集\\(\\mathcal{O}\\)和问题集\\(\\mathcal{Q}\\)选出，\\(a_{cor}(o,q)\\)为对应的正确答案。在训练过程中，我们希望准确度尽量高，并且学到minimal uncorrelated representations。为此，作者采用disentangling variational autoencoder作为模型。 Results 在文中，作者进行了4个实验来验证模型的有效性。 Damped Pendulum 阻尼振动实验： 任务：预测一维阻尼振动在不同时间的位置。 物理模型：\\(-kx-b\\dot{x}=m\\ddot{x}\\)，\\(k\\)为弹性模量，\\(b\\)为阻尼系数，通解为\\(x(t)=A_0e^{-\\frac{b}{2m}t}\\cos(\\omega t+\\delta_0), \\space \\omega=\\sqrt{\\frac{k}{m}}\\sqrt{1-\\frac{b^2}{4mk}}\\) 观测数据：位置时间序列数据\\(o=[x(t_i)]_{i\\in\\{1,\\cdots,50\\}}\\in\\mathbb{R}^{50}\\)，时间间隔相等，质量\\(m=1\\text{kg}\\)，振幅\\(A_0=1\\text{m}\\)，相位\\(\\delta_0=0\\)，弹性模量\\(k\\in[5,10]\\text{kg}/\\text{s}^2\\)，阻尼系数\\(b\\in[0.5,1]\\text{kg}/\\text{s}\\)。 问题：预测\\(q=t_\\text{pred}\\in\\mathbb{R}\\) 隐变量大小设置为3，结果如下图所示： (b)中的三幅图分别是学到的三个隐变量和我们感兴趣的参数\\(k\\)和\\(b\\)的关系图。第一幅图中变量\\(1\\)与\\(b\\)几乎完全线性相关，与\\(k\\)基于线性无关，变量\\(2\\)只和\\(k\\)相关。变量\\(3\\)几乎为一个常数，故不提供额外的信息。由此作者认为SciNet学到了我们关心的两个参数的知识。 Conservation of Angular Momentum 角动量守恒实验： 任务：预测一个由长度为\\(r\\)的绳子捆绑着的旋转质点在位置\\((0,r)\\)经一个自由质点撞击后的位置 物理模型：给定撞击之前的角动量，自由质点撞击之后的速度，旋转质点在撞击之后在时间\\(t_\\text{pred}^\\prime\\)的位置可以由角动量守恒定律给出： \\[ J=m_\\text{rot}r^2\\omega-rm_\\text{free}(\\mathbf{v}_\\text{free})_x=m_\\text{rot}r^2\\omega^\\prime-rm_\\text{free}(\\mathbf{v}^\\prime_\\text{free})_x=J^\\prime \\] 观测数据：在撞击之前两个质点的位置数据\\(o=[(t_i^\\text{rot},q_\\text{rot}(t_i^\\text{rot})),(t_i^\\text{free},q_\\text{free}(t_i^\\text{free}))]_{i\\in\\{1,\\cdots,5\\}}\\)，质量为固定值，半径\\(r\\)也为固定值。数据添加高斯噪声。 问题：预测撞击之后自由质点在时间\\(t_\\text{pred}^\\prime\\)的位置 实验室意图如下： 实验结果表明SciNet能够正确预测质点撞击之后的位置，同时对噪音鲁棒。根据(b)，隐变量和角动量存在线性相关关系，作者认为SciNet学到了守恒的动量这一概念。 Representation of Qubits 量子比特实验： 任务：预测在\\(n=1,2\\)的纯\\(n\\)量子位状态\\(\\psi\\in\\mathbb{C}^{2^n}\\)下任何二进制投影测量\\(\\omega\\in\\mathbb{C}^{2^n}\\)的测量概率。 物理模型：在执行测量\\(\\omega\\in\\mathbb{C}^{2^n}\\)的状态\\(\\psi\\in\\mathbb{C}^{2^n}\\)下测量0的概率\\(p(\\omega,\\psi)\\)由\\(p(\\omega,\\psi)=|\\left&lt;\\omega,\\psi\\right&gt;|^2\\)给定 观测数据：状态\\(\\psi: o=[p(\\alpha_i,\\psi)]_{i\\in\\{i,\\cdots,n_1\\}}\\)的操作参数化：表示一组固定的随机二元射影测量值\\(\\mathcal{M}_1=\\{\\alpha_1,\\cdots,\\alpha_{n_1}\\}\\)（一个量子位\\(n_1 = 10\\)，两个量子位\\(n_1 = 30\\)） 问题：对于固定的一组随机二元射影测量\\(\\mathcal{M}_2=\\{\\beta_1,\\cdots,\\beta_{n_2}\\}\\)，测量\\(\\omega:q=[p(\\beta_i,\\omega)]_{i\\in\\{1,\\cdots,n_2\\}}\\)的Operational参数化（一个量子位\\(n_2 = 10\\)，两个量子位\\(n_2 = 30\\)） 实验结果如下： 通过实验发现，SciNet可以在不提供先验物理知识的条件下确定表述状态\\(\\psi\\)最小的参数数量。同时，SciNet还能分辨tomographically complete和tomographically incomplete。 Heliocentric Model of the Solar System 日心说模型： 问题：在给定初始条件下预测相对与地球的太阳和火星的角度\\(\\theta_M(t)\\)和\\(\\theta_S(t)\\) 物理模型：地球和火星围绕太阳以一定角速度做近似圆周运动 观测数据：给定初始角度，随机选择周周期的哥白尼的观测数据 模型的实现稍有变化，如下图所示： 这样，对于不同时间都对应一个隐变量\\(r(t_i)\\)，而且隐变量是时间依赖的，对于一个隐变量\\(r(t_i)\\)有一个解码器来输出答案。 实验结果表示，SciNet不仅正确预测了太阳和火星相对地球的角度，同时隐变量揭示了火星和地球相对太阳的角度。","link":"/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/"},{"title":"GAIN: Missing Data Imputation using Generative Adversarial Nets","text":"Abstract 本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器\\(G\\)从隐空间\\(Z\\)生成完整的样本，而判别器\\(D\\)则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。 原文 Methodology Problem Formulation 考虑一个\\(d\\)维的空间\\(\\mathcal{X}=\\mathcal{X}_1\\times \\cdots\\times \\mathcal{X}_d\\)，设\\(\\mathbf{X}=(X_1,\\cdots,X_d)\\)维空间\\(\\mathcal{X}\\)上的随机向量（即理想的完整的时间序列），记其分布为\\(P(\\mathbf{X})\\)。设\\(\\mathbf{M}=(M_1,\\cdots,M_d)\\)为Mask向量表示\\(\\mathbf{X}\\)中被观察到的部分。（即标识时间序列哪些部分有缺失），取值为\\(\\{0,1\\}^d\\)。 对于每一个\\(i\\in\\{1,\\cdots,d\\}\\)，我们定义一个新空间\\(\\tilde{\\mathcal{X}}=\\mathcal{X}\\cup\\{*\\}\\)，其中\\(*\\)表示不属于任意\\(\\mathcal{X}_i\\)的一个点。令\\(\\tilde{\\mathcal{X}}=\\tilde{\\mathcal{X}_1}\\times\\cdots\\times\\tilde{\\mathcal{X}_d}\\)，同时定义一个新的随机变量（即我们观测到的含有缺失值的时间序列）\\(\\tilde{\\mathbf{X}}=(\\tilde{X}_1,\\cdots,\\tilde{X}_d)\\in \\tilde{\\mathcal{X}}\\)： \\[ \\tilde{X}_i=\\begin{cases}X_i,&amp;\\text{if } M_i=1\\\\*,&amp;\\text{otherwise}\\end{cases} \\] 假设数据集的形式为\\(\\mathcal{D}=\\{(\\tilde{x}^i,m^i)\\}^n_{i=1}\\)，我们的任务是从\\(P(\\mathbf{X}|\\tilde{\\mathbf{X}}=\\tilde{x}^i)\\)上采样来对缺失值进行填充。 Model Architecture 模型的架构如下图所示： Generator 生成器的输入有三项：\\(\\tilde{\\mathbf{X}}\\)，\\(\\mathbf{M}\\)和随机噪声\\(\\mathbf{Z}\\)，输出设为\\(\\bar{\\mathbf{X}}\\)。设生成器为映射\\(G: \\tilde{\\mathcal{X}}\\times\\{0,1\\}^d\\times[0,1]^d\\rightarrow \\mathcal{X}\\)，而\\(\\mathbf{Z}\\)为\\(d\\)维的高斯噪声。生成器的输出和填充后的时间序列定义为： \\[ \\begin{align} \\bar{\\mathbf{X}}&amp;=G(\\tilde{\\mathbf{X}},\\mathbf{M},(1-\\mathbf{M})\\odot\\mathbf{Z})\\\\ \\hat{\\mathbf{X}}&amp;=\\mathbf{M}\\odot\\tilde{\\mathbf{X}}+(1-\\mathbf{M})\\odot\\bar{\\mathbf{X}} \\end{align} \\] \\(\\bar{\\mathbf{X}}\\)即为生成器的直接输出，因为其实有些部分没有缺失，生成器还是会为每个部分输出值。 \\(\\hat{\\mathbf{X}}\\)为填充后的时间序列，对于缺失的部分采用生成器的输出进行填充。 Discriminator 和原始的GAN不同的是，我们不需要判断整个样本是真实的或者是生成的，而是需要判断样本的那些部分是真实的或者是生成的，所以判别器为映射\\(D: \\mathcal{X}\\rightarrow[0,1]^d\\)。判别器的具体目标函数将在后面讨论。 Hint Hint是一种提示机值，是一个和\\(\\mathbf{X}\\)相同维度的随机变量\\(\\mathbf{H}\\)，其分布依赖于\\(\\mathbf{M}\\)。\\(\\mathbf{H}\\)是由用户自己定义的，相当于一种不完整的\\(\\mathbf{M}\\)，用来作为判别器的额外输入。 Objective 我们训练判别器最大化正确预测\\(\\mathbf{M}\\)的概率，而生成器最小化判别器正确预测\\(\\mathbf{M}\\)的概率，目标函数如下： \\[ \\begin{align} V(D,G)=&amp;\\mathbb{E}_{\\hat{X},M,H}[\\mathbf{M}^T\\log D(\\hat{\\mathbf{X}},\\mathbf{H})\\\\&amp;+(1-\\mathbf{M})^T\\log(1-D(\\hat{\\mathbf{X}},\\mathbf{H}))] \\end{align} \\] 按照标准的GAN可以将优化函数写成以下的形式： \\[ \\min_G\\max_D V(D,G) \\] 在这里判别器的任务可以看作是一个二分类，而目标函数就是二值交叉熵的定义，因此可以写为： \\[ \\mathcal{L}(a,b)=\\sum\\limits_{i=1}^d[a_i\\log(b_i)+(1-a_i)\\log(1-b_i)] \\] \\(\\mathbf{M}\\)可以看作Ground Truth，记\\(\\hat{\\mathbf{M}}=D(\\hat{\\mathbf{X},\\mathbf{H}})\\)，即判别器输出的预测，因此优化函数可以简记为： \\[ \\min_G\\max_D\\mathbb{E}[\\mathcal{L}(\\mathbf{M},\\hat{\\mathbf{M}})] \\] GAIN Algorithm 下面讨论GAIN算法的训练流程。 本文通过理论讨论，给出了生成Hint Vector的一个方法，首先定义随机变量\\(\\mathbf{B}=(B_1,\\cdots,B_d)\\in\\{0,1\\}^d\\)，\\(\\mathbf{B}\\)通过从\\(\\{1,\\cdots,d\\}\\)随机均匀采样一个\\(k\\)，然后由下列公式得到： \\[ B_j=\\begin{cases}1, &amp;\\text{if }j\\neq k\\\\0, &amp;\\text{if }j=k\\end{cases} \\] 定义空间\\(\\mathcal{H}=\\{0,0.5,1\\}^d\\)，Hint Vector为\\(\\mathbf{H}=\\mathbf{B}\\odot\\mathbf{M}+0.5(1-\\mathbf{B})\\in\\mathcal{H}\\)。 判别器的训练过程如下：固定生成器\\(G\\)，对一个大小为\\(k_D\\)的mini-batch，独立同分布采样\\(k_D\\)个\\(z\\)和\\(b\\)，用来计算\\(\\mathbf{Z}\\)和\\(\\mathbf{B}\\)。判别器的损失函数定义如下： \\[ \\mathcal{L}_D(m,\\hat{m},b)=\\sum\\limits_{i:b_i=0}[m_i\\log(\\hat{m}_i)+(1-m_i)\\log(1-\\hat{m}_i)] \\] 判别器的优化函数为： \\[ \\min_D-\\sum\\limits_{j=1}^{k_D}\\mathcal{L}_D(m(j),\\hat{m}(j),b(j)) \\] 其中\\(\\hat{m}(j)=D(\\hat{x}(j),m(j))\\)。 在优化了判别器之后，需要优化生成器，对一个大小为\\(k_G\\)的mini-batch，生成器的损失函数包含两个部分，一个是在缺失部分的损失： \\[ \\mathcal{L}_G(m,\\hat{m},b)=-\\sum\\limits_{i:b_i=0}(1-m_i)\\log(\\hat{m}_i) \\] 一个是未缺失部分的损失： \\[ \\mathcal{L}_M(x,x^\\prime)=\\sum\\limits_{i=1}^d m_iL_M(x_i,x_i^\\prime) \\] 其中： \\[ L_M(x_i,x_i^\\prime)=\\begin{cases}(x_i^\\prime-x_i)^2, &amp;\\text{if }x_i\\text{ is continuours},\\\\-x_i\\log(x_i^\\prime), &amp;\\text{if }x_i\\text{ is binary}.\\end{cases} \\] 最终的优化函数为： \\[ \\min_G\\sum\\limits_{j=1}^{k_G}\\mathcal{L}_G(m(j),\\hat{m}(j),b(j))+\\alpha\\mathcal{L}_M(\\tilde{x}(j),\\hat{x}(j)) \\] 算法流程如下： Experiments 下表为在5个不同数据集上实验，与其他5种方法对比的结果： 上图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例、样本数量、特征维度下的对比曲线图。 下表为使用不同模型对时间序列进行填充之后，使用逻辑回归进行回归任务的性能： 下图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例下的AUROC曲线图： 下表展示的是作者对时间序列填充算法保持特征-标签关系的能力。作者分别用完整的数据和填充后的数据用逻辑回归模型进行训练，将两者的权重求绝对值和均方根的结果。","link":"/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"},{"title":"Geant4 安装教程与调试环境配置","text":"Introduction Geant4安装的教程很多，版本都很旧了，这里写一个新版本（10.6）基于Ubuntu的安装教程，并且开启CLion IDE调试。 Step 1: Download Packages 首先进入官网(http://geant4.web.cern.ch/support/download)下载源代码（推荐tar.gz格式）及数据文件，解压。新建一个文件夹专门用来放Geant4相关文件，新建data，source，build文件夹，将Geant4的文件复制进来并按如下结构组织： 1234567891011121314151617.├── build├── data│ ├── G4ABLA3.1│ ├── G4EMLOW7.9│ ├── G4ENSDFSTATE2.2│ ├── G4INCL1.0│ ├── G4NDL4.6│ ├── G4PARTICLEXS2.1│ ├── G4PII1.3│ ├── G4SAIDDATA2.0│ ├── G4TENDL1.3.2│ ├── PhotonEvaporation5.5│ ├── RadioactiveDecay5.4│ └── RealSurface2.1.1└── source └── geant4.10.06 Step 2: Install Dependencies 安装编译所需环境： 1sudo apt-get install build-essential cmake 安装相关依赖： 1sudo apt-get install libgl1-mesa-dev libglu1-mesa-dev libxt-dev libxmu-dev libxi-dev zlib1g-dev libgl2ps-dev libexpat1-dev libxerces-c-dev 如果要用到QT需要单独安装QT。 Step 3: Compile 进入build文件夹，用cmake命令： 1cmake ../source/geant4.10.06/ -DCMAKE_BUILD_TYPE=DEBUG -DGEANT4_USE_GDML=ON -DGEANT4_USE_OPENGL_X11=ON -DGEANT4_USE_RAYTRACER_X11=ON -DGEANT4_BUILD_MULTITHREADED=ON 其中../source/geant4.10.06/替换成换成（如果版本不一样）你自己的Geant4源代码所在目录，需要QT则加上-DGEANT4_USE_QT=ON。如果不需要调试则把-DCMAKE_BUILD_TYPE=DEBUG改成-DCMAKE_BUILD_TYPE=RELEASE。-DGEANT4_BUILD_MULTITHREADED=ON是多线程，视情况开启。 完成之后开始编译： 1make -jX -jX为多线程编译，如-j8。 编译完成之后进行安装： 1sudo make install Step 4: Configure 安装的默认路径在/usr/local/share/Geant4-10.6.0，将下载的数据文件复制到该文件夹： 1sudo cp -r ./data/ /usr/local/share/Geant4-10.6.0/ 之后，在~/.bashrc里添加/usr/local/share/Geant4-10.6.0/geant4make/geant4make.sh，如果你的版本和我的不一样，相应修改即可。 Step 5: CLion Configuration 最后我们来配置CLion环境，配好之后可以在IDE中编写Geant4代码，还可以断点调试，非常方便。安装CLion的过程这里省略，打开一个Geant4自带的例子或者自己新建一个项目，打开Edit Configurations。 随便打开一个终端，输入一下命令获取环境变量： 1env | grep G4 在Environment variables填入刚才获取的环境变量（复制之后按一下粘贴就可以了），然后把Working directory设置成当前文件夹。 现在就大功告成了！","link":"/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"title":"Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network","text":"Abstract 本文提出了OmniAnomaly：一种针对多变量时间序列的随机循环神经网络异常检测算法。该模型运用了一系列技术来捕捉多变量时间序列的正常模式，并在检测阶段基于重构误差来检测异常，同时本文还提供了一定的理论解释。 原文 Contribution 提出了OmniAnomaly，一种基于随机循环神经网络的多变量时间序列异常检测算法； 提出了针对多变量时间序列异常检测的解释方法； 通过实验证明了OmniAnomaly中所用的关键技术的有效性，包括GRU，planar NF, stochastic variable connection和adjusted Peaks-Over-Threshold method； 通过大量的实验我们证明了OmniAnomaly的有效性； 发布了代码和数据集。 Background Linear Gaussian State Space Model 状态空间模型（State Space Model, SSM）的概念来自于控制理论，在这里我们主要讨论其在时间序列中的应用。其大概思想是我们认为时间序列在时刻\\(t\\)的观测值\\(z_t\\)是一个隐含状态\\(\\boldsymbol{l}_t\\)的条件分布\\(p(z_t|\\boldsymbol{l}_t)\\)，而这个隐含状态\\(\\boldsymbol{l}_t\\)刻画了时间序列的内在规律，同时隐含状态会随着时间更新，即服从条件分布\\(p(\\boldsymbol{l}_t|\\boldsymbol{l}_{t-1})\\)。 在线性状态空间模型（Linear State Space Model）中我们以如下的方式刻画隐含状态的更新： \\[ \\boldsymbol{l}_t=\\boldsymbol{F}_t\\boldsymbol{l}_{t-1}+\\boldsymbol{g}_t\\varepsilon_t, \\space\\space\\space\\varepsilon_t\\sim\\mathcal{N}(0,1) \\] \\(\\boldsymbol{F}_t\\)为确定的状态转移矩阵，而\\(\\boldsymbol{g}_t\\varepsilon_t\\)则表示了状态转移的随机性。 观测值\\(z_t\\)从隐含状态\\(\\boldsymbol{l}_t\\)计算而来： \\[ \\begin{align} z_t&amp;=y_t+\\sigma_t\\epsilon_t,\\\\ y_t&amp;=\\boldsymbol{a}_t^\\top\\boldsymbol{l}_{t-1}+b_t,\\\\ \\epsilon_t&amp;\\sim\\mathcal{N}(0,1) \\end{align} \\] 其中\\(\\boldsymbol{a}_t\\in\\mathbb{R}^L,\\sigma_t\\in \\mathbb{R},b_t\\in\\mathbb{R}\\)都是额外的参数。初始状态\\(\\boldsymbol{l}_0\\)则从一个独立的高斯分布得来，即\\(\\boldsymbol{l}_0\\sim N(\\boldsymbol\\mu_0,\\text{diag}(\\boldsymbol{\\sigma}_0^2))\\)。 令参数集合\\(\\Theta_t=(\\boldsymbol{\\mu}_0,\\boldsymbol{\\Sigma}_0,\\boldsymbol{F}_t,\\boldsymbol{g}_t,\\boldsymbol{a}_t,b_t,\\sigma_t),\\forall t&gt;0\\)，一般来说参数集合不会随着时间变化，即每个时刻\\(t\\)共享同样的参数\\(\\Theta_t=\\Theta,\\forall t&gt;0\\)。对参数的估计可以采用极大似然估计： \\[ \\begin{align} \\Theta^*_{1:T}&amp;=\\arg\\max_{\\Theta_{1:T}}p(z_{1:T}|\\Theta_{1:T}),\\\\ \\end{align} \\] 其中： \\[ \\begin{align} p(z_{1:T}|\\Theta_{1:T})&amp;=p(z_1|\\Theta_1)\\prod\\limits_{t=2}^T p(z_t|z_{1:t-1},\\Theta_{1:t})\\\\ &amp;=\\int p(\\boldsymbol{l}_0)\\left[\\prod\\limits_{t=1}^T p(z_t|\\boldsymbol{l}_t)p(\\boldsymbol{l}_t|\\boldsymbol{l}_{t-1})\\right]\\mathrm{d}\\boldsymbol{l}_{0:T} \\end{align} \\] Planar Normalizing Flow Normalizing Flows VAE采用一个变分分布\\(q_\\phi(z|x)\\)来近似真实的后验分布\\(p(z|x)\\)，并推导出\\(\\log p_\\theta(x)\\)的下界（称为ELBO）来作为优化目标函数： \\[ \\begin{align} \\log p_\\theta(x)&amp;=\\log \\int p_\\theta(x|z)p(z)\\mathrm{d}z\\\\ &amp;=\\log\\int\\frac{q_\\phi(z|x)}{q_\\phi(z|x)}p_\\theta(x|z)p(z)\\mathrm{d}z\\\\ &amp;\\geq-D_{KL}[q_\\phi(z|x)\\parallel p(z)]+\\mathbb{E}_q[\\log p_\\theta(x|z)] \\end{align} \\] \\(\\log p_\\theta(x)\\)与ELBO取等的条件是\\(D_{KL}[q_\\phi(z|x)\\parallel p(z)]\\)，表明变分分布完全匹配了真实的后验分布。但在实际应用中，真实的后验分布可能会非常复杂，而我们的变分分布通常是一个确定的较为简单的分布，如高斯分布。这样变分分布可能很难对真实后验分布得到一个很好的拟合。 一个解决方案是使用标准化流（Normalizing Flows）。标准化流是从一个相对简单的分布出发，执行一系列可逆的映射，将原始简单的分布转化为一个复杂的分布。 首先考虑一个光滑的、可逆的映射\\(f:\\mathbb{R}^d\\mapsto \\mathbb{R}^d\\)，记\\(g=f^{-1}\\)，那么\\(g\\circ f(\\mathbf{z})=\\mathbf{z}\\)。令\\(\\mathbf{z}^\\prime=f(\\mathbf{z})\\)，那么\\(\\mathbf{z}^\\prime\\)的分布为： \\[ q(\\mathbf{z}^\\prime)=q(\\mathbf{z})\\left|\\text{det}\\frac{\\partial f^{-1}}{\\partial \\mathbf{z}^\\prime}\\right|=q(z)\\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|^{-1} \\] 式中\\(q(\\mathbf{z}^\\prime)=q(z)\\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|^{-1}\\)说明了\\(\\mathbf{z}^\\prime\\)的分布等于\\(\\mathbf{z}\\)的分布乘上\\(f\\)的Jacobian矩阵的行列式的倒数。那么对于映射多次的情况： \\[ \\mathbf{z}_K=f_K\\circ\\cdots\\circ f_2\\circ f_1(\\mathbf{z}_0) \\] \\(\\mathbf{z}_K\\)的分布可以通过链式计算得到： \\[ \\ln q_K(\\mathbf{z}_K)=\\ln q_0(\\mathbf{z}_0)-\\sum\\limits_{k=1}^K\\ln\\left|\\text{det}\\frac{\\partial f_k}{\\partial \\mathbf{z}_{k-1}}\\right| \\] Planar Flows 考虑一个变换族： \\[ f(\\mathbf{z})=\\mathbf{z}+\\mathbf{u}h(\\mathbf{w}^\\top\\mathbf{z}+b) \\] 其中\\(\\lambda=\\{\\mathbf{w}\\in \\mathbb{R}^d,\\mathbf{u}\\in\\mathbb{R}^d,b\\in\\mathbb{R}\\}\\)为参数集合，\\(h(\\cdot)\\)为元素级的非线性函数（如各种激活函数）。令\\(\\psi(\\mathbf{z})=h^\\prime(\\mathbf{w}^\\top\\mathbf{z}+b)\\mathbf{w}\\)，则\\(f\\)的Jacobian矩阵行列式绝对值等于： \\[ \\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|=\\left|\\text{det}(\\mathbf{I}+\\mathbf{u}\\psi(\\mathbf{z})^\\top)\\right|=\\left|1+\\mathbf{u}^\\top\\psi(\\mathbf{z})\\right| \\] 但是\\(f\\)并不保证总是可逆的，如\\(h(x)=\\tanh(x)\\)时，\\(f\\)可逆的条件是\\(\\mathbf{w}^\\top \\mathbf{u}\\geq-1\\)。 下面讨论如何保证可逆的条件。考虑将\\(\\mathbf{z}\\)分解为\\(\\mathbf{z}=\\mathbf{z}_\\bot+\\mathbf{z}_\\parallel\\)，其中\\(\\mathbf{z}_\\bot\\)与\\(\\mathbf{w}\\)正交，\\(\\mathbf{z}_\\parallel\\)与\\(\\mathbf{w}\\)平行，那么： \\[ f(z)=\\mathbf{z}_\\bot+\\mathbf{z}_\\parallel+\\mathbf{u}h(\\mathbf{w}^\\top \\mathbf{z}_\\parallel +b) \\] 实际上得到\\(\\mathbf{z}_\\parallel\\)之后可以很容易的得到\\(\\mathbf{z}_\\bot\\)，令\\(\\mathbf{y}=f(\\mathbf{z})\\)，有： \\[ \\mathbf{z}_\\bot=\\mathbf{y}-\\mathbf{z}_\\parallel-\\mathbf{u}h(\\mathbf{w}^\\top\\mathbf{z}_\\parallel+b) \\] 而\\(\\mathbf{z}_\\parallel\\)与\\(\\mathbf{w}\\)平行，易知\\(\\mathbf{z}_\\parallel=\\alpha\\frac{\\mathbf{w}}{\\parallel\\mathbf{w}\\parallel^2}\\)，其中\\(\\alpha\\in\\mathbb{R}\\)。 对式(16)两边同时乘以\\(\\mathbf{w}^\\top\\)可得： \\[ \\mathbf{w}^\\top f(\\mathbf{z})=\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b) \\] 当\\(\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b)\\)对于\\(\\alpha\\)是非递减函数的时候，\\(f\\)是可逆的。因为\\(\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b)\\)是非递减函数时有\\(1+\\mathbf{w}^\\top\\mathbf{u}h^\\prime(\\alpha+b)\\geq 0\\equiv \\mathbf{w}^\\top \\mathbf{u}\\geq -\\frac{1}{h^\\prime(\\alpha + b)}\\)，而\\(0\\leq h^\\prime(\\alpha + b) \\leq 1\\)（\\(\\tanh\\)函数的性质），所以总是有\\(\\mathbf{w}^\\top \\mathbf{u}\\geq-1\\)。 对于任意一个\\(\\mathbf{u}\\)，我们可以通过特定的方式构造一个\\(\\hat{\\mathbf{u}}\\)使得\\(\\mathbf{w}^\\top\\hat{\\mathbf{u}}&gt;-1\\)，即令\\(\\hat{\\mathbf{u}}(\\mathbf{w},\\mathbf{u})=\\mathbf{u}+[m(\\mathbf{w}^\\top\\mathbf{u})-(\\mathbf{w}^\\top\\mathbf{u})]\\frac{\\mathbf{w}}{\\parallel\\mathbf{w}\\parallel^2}\\)，其中\\(m(x)=-1+\\log(1+e^x)\\)。 Methodology Problem Statement 本文针对的是多变量时间序列\\(x=\\{x_1,x_2,\\cdots,x_N\\}\\in R^{M\\times N}\\)，\\(N\\)为时间长度，其中某一时刻的观测值\\(x_t\\in R^M\\)为一个\\(M\\)维的向量。作者使用\\(x_{t-T:t}\\in R^{M\\times(T+1)}\\)来表示\\(t-T\\)到\\(t\\)之间的时间序列。 Overall Structure 算法的总体框架如下图所示： 预处理模块主要是对数据进行标准化以及窗口切分。训练模块则根据输入的数据对正常模式进行捕捉，输出异常分数。在线检测模块则会定期执行。 Network Architecture 模型的总体结构如下图所示： 在qnet中，首先GRU被用来建模样本的时间依赖关系，之后VAE将样本\\(\\mathbf{x}\\)映射到隐空间\\(\\mathbf{z}\\)。文中使用了Linear Gaussian State Space Model来建模隐变量之间的时间依赖关系。除此之外，作者还使用了Planar Normalizing Flow来将隐变量映射到复杂的非高斯分布。在pnet中，隐变量\\(\\mathbf{z}_{t-T:t}\\)被用来重建\\(\\mathbf{x}_{t-T:t}\\)，直观上来说，对样本的好的隐变量表示可以带来更好的重构效果。 从细节上来说，在时间\\(t\\)，qnet的输入为\\(\\mathbf{x}_t\\)和\\(\\mathbf{e}_{t-1}\\)，两者经过GRU Cell之后会产生\\(t\\)时间的\\(\\mathbf{e_t}\\)。\\(\\mathbf{e}_t\\)是GRU捕捉时间依赖性的关键，可以认为它包含了\\(\\mathbf{x}_{1:t}\\)的信息。之后\\(\\mathbf{e}_t\\)会和\\(\\mathbf{z}_{t-1}\\)进行拼接，进入标准的VAE变分网络结构，通过网络输出的参数\\(\\mu_{z_t},\\sigma_{z_t}\\)采样得到隐变量\\(\\mathbf{z}_t^0\\)，此时隐变量可以说捕捉了时间依赖性。 网络中涉及到的公式如下所示： \\[ \\begin{align} e_t&amp;=(1-c_t^e)\\circ\\text{tanh}(w^ex_t+u^e(r_t^e\\circ e_{t-1})+b^e)+c_t^e\\circ e_{t-1}\\\\ \\mu_{z_t}&amp;=w^{\\mu_z}h^\\phi([z_{t-1},e_t])+b^{\\mu_z}\\\\ \\sigma_{z_t}&amp;=\\text{softplus}(w^{\\sigma_z}h^\\phi([z_{t-1},e_t])+b^{\\sigma_z})+\\epsilon^{\\sigma_z} \\end{align} \\] 其中\\(r_t^e=\\text{sigmoid}(\\mathbf{w}^{r^e}\\mathbf{x}_t+\\mathbf{u}^{r^e}\\mathbf{e}_{t-1}+b^{r^e})\\)是GRU中的重置门，\\(c_t^e=\\text{sigmoid}(\\mathbf{w}^{c^e}\\mathbf{x}_t+\\mathbf{u}^{c^e}\\mathbf{e}_{t-1}+b^{c^e})\\)是GRU中的更新门。 此时\\(\\mathbf{z}_t^0\\)服从高斯分布，为了拟合复杂的后验分布，我们使用Planar Normalizing Flow来对\\(\\mathbf{z}_t^0\\)进行变换，最后得到经\\(K\\)次变换后的随机变量\\(\\mathbf{z}_t^K\\)。 在时间\\(t\\)，pnet试图通过\\(\\mathbf{z}_t^K\\)来重构\\(\\mathbf{x}_t\\)。首先\\(\\mathbf{z}\\)空间中的变量会根据Linear Gaussian State Space Model来进行“连接“，公式为\\(\\mathbf{z}_t=\\mathbf{O}_\\theta(\\mathbf{T}_\\theta\\mathbf{z}_{t-1}+\\mathbf{v}_t)+\\boldsymbol{\\epsilon}_t\\)，其中\\(\\mathbf{O}_\\theta\\)和\\(\\mathbf{T}_\\theta\\)为状态转移矩阵，\\(\\mathbf{v}_t\\)和\\(\\boldsymbol{\\epsilon}_t\\)为随机噪声。之后\\(\\mathbf{z}_t\\)和\\(\\mathbf{d}_{t-1}\\)会作为GRU的输入，产生\\(\\mathbf{d}_t\\)。之后\\(\\mathbf{d}_t\\)会经过标准VAE中的生成网络，通过网络输出的高斯分布参数\\(\\mu_{x_t},\\sigma_{x_t}\\)采样得到重构后的样本\\(\\mathbf{x}^\\prime_t\\)。pnet中涉及到的公式如下所示： \\[ \\begin{align} d_t&amp;=(1-c_t^d)\\circ\\text{tanh}(w^dz_t+u^d(r_t^d\\circ d_{t-1})+b^d)+c_t^d\\circ d_{t-1}\\\\ \\mu_{x_t}&amp;=w^{\\mu_x}h^\\theta(d_t)+b^{\\mu_x}\\\\ \\sigma_{x_t}&amp;=\\text{softplus}(w^{\\sigma_x}h^\\theta(d_t)+b^{\\sigma_x})+\\epsilon^{\\sigma_x} \\end{align} \\] 其中\\(r_t^d=\\text{sigmoid}(\\mathbf{w}^{r^d}\\mathbf{x}_t+\\mathbf{u}^{r^d}\\mathbf{d}_{t-1}+b^{r^d})\\)是GRU中的重置门，\\(c_t^d=\\text{sigmoid}(\\mathbf{w}^{c^d}\\mathbf{x}_t+\\mathbf{u}^{c^d}\\mathbf{d}_{t-1}+b^{c^d})\\)是GRU中的更新门。 Offline Model Training 和传统VAE类似，模型的训练可以通过优化ELBO来完成。记长度为\\(T+1\\)的输入序列为\\(\\mathbf{x}_{t-T:t}\\)，隐空间变量采样次数为\\(L\\)，第\\(l\\)个隐空间变量为\\(\\mathbf{l}^{(l)}_{t-T:t}\\)，损失函数可以写成如下形式： \\[ \\tilde{\\mathcal{L}}(\\mathbf{x}_{t-T:t})\\approx\\frac{1}{L}\\sum_{t=1}^L[\\log(p_\\theta(\\mathbf{x}_{t-T:t}|\\mathbf{z}_{t-T:t}^{(l)}))+\\log(p_\\theta(\\mathbf{z}_{t-T:t}^{(l)}))-\\log(q_\\phi(\\mathbf{z}_{t-T:t}^|\\mathbf{x}_{t-T:t}))] \\] 第一项\\(\\log(p_\\theta(\\mathbf{x}_{t-T:t}|\\mathbf{z}_{t-T:t}^{(l)}))\\)可以看作是重构误差；第二项\\(\\log(p_\\theta(\\mathbf{z}_{t-T:t}))=\\sum_{i=t-T}^t \\log(p_\\theta(\\mathbf{z}_i|\\mathbf{z}_{i-1}))\\)通过Linear Gaussian State Space Model计算；第三项\\(-\\log(q_\\phi(\\mathbf{z}_{t-T:t}|\\mathbf{x}_{t-T:t}))=-\\sum_{i=t-T}^t\\log(q_\\phi(\\mathbf{z}_i|\\mathbf{z}_{i-1},\\mathbf{x}_{t-T:i}))\\)为隐变量\\(\\mathbf{z}\\)后验分布的估计，同时\\(\\mathbf{z}_i\\)是经Planar Normalizing Flow转换过的。 Online Detection 在训练好模型之后，就可以进行异常检测了。在时间\\(t\\)，我们通过根据长度为\\(T+1\\)的序列\\(\\mathbf{x}_{t-T:t}\\)来重构\\(\\mathbf{x}_t\\)，并根据重构概率\\(\\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))\\)来判定异常。定义\\(\\mathbf{x}_t\\)对应的异常分数\\(S_t=\\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))\\)，高异常分数代表样本\\(\\mathbf{x}_t\\)能够以大概率重构（因为模型是用正常样本训练，可以认为模型建模的是正常样本的分布，重构概率高就代表符合正常分布）。给定阈值之后便可根据异常分数来进行异常的判定。 Automatic Threshold Selection 在异常检测阶段，需要根据设定的阈值和每个样本的异常分数来判断该样本是否为异常，所以阈值的选择十分重要。文中用到了一种根据Extreme Value Theory自动选择阈值的算法。对于一个分布，其中的极端事件往往位于分布的末尾，而Extreme Value Theory第一定理给出不管原始分布如何，这些极端事件的分布服从一个带参的分布族。因此，可以在对数据分布未知的情况下估计极端事件的分布。 除了Extreme Value Theory第一定理之外，Extreme Value Theory第二定理给出随机变量大于特定阈值\\(t\\)的分布可以用Generalized Pareto Distribution来描述。作者使用了基于Extreme Value Theory第二定理的Peaks-Over-Threshold算法来进行阈值的选择。因为Extreme Value Theory第二定理给出随机变量大于特定阈值\\(t\\)的分布，而在本文的场景中我们需要刻画的异常点的分布应该是小于一个给定阈值的分布，所以需要修改一下公式。 对于给定的数据，模型会给出对应的异常分数序列\\(\\{S_1,S_2,\\cdots,S_{N^\\prime}\\}\\)，给定预先设定的阈值\\(th\\)，\\(S_i\\)极端部分（即小于\\(th\\)的部分）的分布符合Generalized Pareto Distribution，公式如下： \\[ \\bar{F}(s)=P(th-S&gt;s|S&lt;th)\\sim(1+\\frac{\\gamma s}{\\beta})^{-\\frac{1}{\\gamma}} \\] 其中\\(\\gamma\\)和\\(\\beta\\)为分布的形状参数，本文使用极大似然估计来对参数进行估计。设参数的估计值分别为\\(\\hat{\\gamma}\\)和\\(\\hat{\\beta}\\)，最终的阈值\\(th_F\\)由拟合得到的分布的分位数确定： \\[ th_F\\simeq th-\\frac{\\hat{\\beta}}{\\hat{\\gamma}}((\\frac{qN^\\prime}{N^\\prime_{th}})^{-\\hat{\\gamma}}-1) \\] 其中\\(q\\)为期望\\(S&lt;th\\)的概率，\\(N^\\prime\\)为观测值的数量，\\(N^\\prime_{th}\\)为\\(S_i&lt;th\\)的个数。 Anomaly Interpretation \\[ \\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))=\\sum_{i=1}^M\\log(p_\\theta(x_t^i|\\mathbf{z}_{t-T:t})) \\] Experiments Datasets and Metrics Overall Performance Effects of Major Techniques Visualization on Z-Space Representations","link":"/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/"},{"title":"Recurrent Neural Networks for Multivariate Time Series with Missing Values","text":"Abstract 文中提出了一种可以处理带缺失值多为时间序列的GRU模型：GRU-D。本模型不仅可以捕捉时间序列中的长期依赖模式，并且还能利用时间序列中的缺失模式来达到更好的时间序列预测效果。 原文 Methodology Notations 记包含\\(D\\)个变量的多变量时间序列为\\(X=(x_1,x_2,\\cdots,x_T)^T\\in\\mathbb{R}^{T\\times D}\\)，其中对于每个\\(t\\in\\{1,2,\\cdots,T\\},x_t\\in\\mathbb{R}^D\\)表示时间序列在时间\\(t\\)的观测值，\\(x_t^d\\)表示\\(x_t\\)的第\\(d\\)个成分。记\\(s_t\\in\\mathbb{R}\\)为\\(t\\)时刻的时间戳，并假设第一个观测值的时间戳为\\(0\\)。对于包含缺失值的时间序列，我们用Masking Vector \\(m_t\\in\\{0,1\\}\\)进行标记，同时对每个\\(x_t^d\\)维护距离上一个观测值的Time Interval \\(\\delta_t^d\\in\\mathbb{R}\\)，公式如下： \\[ m_t^d=\\begin{cases}1, &amp;\\text{if }x_t^d\\text{ is observed}\\\\0, &amp;\\text{otherwise}\\end{cases} \\] \\[ \\delta_t^d=\\begin{cases}s_t-s_{t-1}+\\delta_{t-1}^d, &amp;t&gt;1,m_{t-1}^d=0\\\\s_t-s_{t-1}, &amp;t&gt;1, m_{t-1}^d=1\\\\0, &amp;t=1\\end{cases} \\] 下图是一些示例： 在本文中，我们主要关注时间序列的分类问题，即给定数据集\\(\\mathcal{D}=\\{(X_n,s_n,M_n)\\}_{n=1}^N\\)，我们要对每个样本的类别进行预测\\(l_n\\in\\{1,\\cdots,L\\}\\)。 GRU-RNN for Time Series Classification GRU是一种改进版本的RNN，其最大不同是加入了门控机制。GRU单元的结构如下图所示： GRU包含了重置门和更新门，其中重置门\\(R_t\\)负责控制上一时间的隐状态\\(h_{t-1}\\)有多少部分需要保留，而更新门则决定由\\(R_t\\)计算出来的候选隐状态\\(\\tilde{h}_t\\)有多少部分需要保留。最后当前时间的隐状态由\\(h_{t-1}\\)和\\(\\tilde{h}_t\\)共同算出。GRU的状态更新公式如下： \\[ \\begin{align} R_t&amp;=\\sigma(W_rx_t+U_rh_{t-1}+b_r)\\\\ Z_t&amp;=\\sigma(W_zx_t+U_zh_{t-1}+b_z)\\\\ \\tilde{h}_t&amp;=\\text{tanh}(Wx_t+U(R_t\\odot h_{t-1})+b)\\\\ h_t&amp;=(1-Z_t)\\odot h_{t-1}+Z_t\\odot \\tilde{h}_t \\end{align} \\] 文中提出了一些处理缺失值的简单方法： 直接用均值替代：\\(x_t^d\\leftarrow m_t^dx_t^d+(1-m_t^d)\\tilde{x}^d\\)，其中\\(\\tilde{x}^d=\\frac{\\sum_{n=1}^N\\sum_{t=1}^{T_n}m_{t,n}^d x_{t,n}^d}{\\sum_{n=1}^N\\sum_{t=1}^{T_n}m_{t,n}^d\\tilde{x}^d}\\)。这种方法称为GRU-Mean； 用上一个观测值替代：\\(x_t^d\\leftarrow m_t^d x_t^d+(1-m_t^d)x_{t^\\prime}^d\\)。这种方法称为GRU-Forward； 不填充，将是否缺失，距离上一个观测值的时间作为额外信息输入：\\(x_t^{(n)}\\leftarrow[x_t^{(n)};m_t^{(n)};\\delta_t^{(n)}]\\)。这种方法称为GRU-Simple。 GRU-D: Model with Trainable Decays 文中提出了时间序列缺失值的两个性质：一个是在上一个观测值距离很远的情况下缺失值倾向于接近一个默认的值，第二个是缺失值的影响会随着时间减弱。为了体现上述两点，文中提出了GPU-D模型，模型框架如下： 在模型中，Decay Rates被设定为一个带参数的函数和GRU一起训练： \\[ \\gamma_t=\\exp\\{-\\max(0,W_\\gamma\\delta_t+b_\\gamma)\\} \\] \\[ \\hat{x}_t^d=m_t^dx_t^d+(1-m_t^d)(\\gamma_{x_t}^dx_{t^\\prime}^d+(1-\\gamma_{x_t}^d)\\tilde{x}^d) \\] 其中\\(x_{t^\\prime}^d\\)是第\\(d\\)个变量的上一个观测值，\\(\\tilde{x}^d\\)是第\\(d\\)个变量的经验均值。这样\\(\\hat{x}_t^d\\)就代表经过Input Decay的输入。 文中提到只用Input Decay是不够的，除此之外作者还使用了Hidden State Decay，即对\\(h_{t-1}\\)进行Decay，公式如下： \\[ \\hat{h}_{t-1}=\\gamma_{h_t}\\odot h_{t-1} \\] 用Decay之后的\\(\\hat{x}_t\\)和\\(\\hat{h}_{t-1}\\)替换原始的GRU公式就得到了GRU-D模型： \\[ \\begin{align} R_t&amp;=\\sigma(W_r\\hat{x}_t-U_r\\hat{h}_{t-1}+V_rm_t+b_r)\\\\ Z_t&amp;=\\sigma(W_z\\hat{x}_t+U_z\\hat{h}_{t-1}+V_zm_t+b_z)\\\\ \\tilde{h}_t&amp;=\\text{tanh}(W\\hat{x}_t+U(R_t\\odot \\hat{h}_{t-1})+Vm_t+b)\\\\ h_t&amp;=(1-z_t)\\odot \\hat{h}_{t-1}+z_t\\odot\\tilde{h}_t \\end{align} \\] Experiments Baseline Imputation Methods 下图为文中比较中用到的Baseline： Baseline Prediction Methods 下图为文中用到的用来预测的Baseline： Results 文中用到的数据集如下： Gesture phase segmentation dataset (Gesture). PhysioNet Challenge 2012 dataset (PhysioNet). MIMIC-Ⅲ dataset (MIMIC-Ⅲ). 下图展示了不同方法在人工合成数据集上的表现： 下表展示了不同模型在预测任务表现的对比： 下表展示了不同方法在MIMIC-Ⅲ和PhysioNet数据集上的多任务表现： 下图分别展示了模型学到的Input Decay和Hidden State Decay：","link":"/2019/10/18/Recurrent-Neural-Networks-for-Multivariate-Time-Series-with-Missing-Values/"},{"title":"Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications","text":"Abstract 本文提出了Donut，一个基于VAE的无监督时间序列异常检测系统。 原文 Contribution Donut中使用到了三个技巧，包括改进后的ELBO、缺失数据注入和MCMC插值； 提出基于VAE的异常检测训练既需要正常样本也需要异常样本； 对Donut提出了在z-空间中基于KDE的理论解释。 Background Anomaly Detection 对于任意时间\\(t\\)，给定历史观察值\\(x_{t-T+1},\\cdots,x_t\\)，确定异常是否发生(记为\\(y_t=1\\))。通常来收异常检测算法给出的是发生异常的可能性，如\\(p(y_t=1|x_{t-T+1},\\cdots,x_t)\\)。 Methodology Problem Statement 本文的目的是基于深度生成网络开发具有理论解释性的无监督异常检测算法，并且在有标签的情况下能利用标签信息提升性能。本文基于VAE来构建模型。 Network Structure 算法的总体框架如下图所示： 一共包含了预处理、训练和检测三个部分。 下图为模型的概率图模型： 图中双实线的框为本文模型有别于传统VAE的地方，其余地方和VAE一样。先验概率\\(p_\\theta(z)\\)选为标准正态分布\\(\\mathcal{N}(0,I)\\)，后验概率\\(x\\)和\\(z\\)都是对角化高斯分布，即\\(p_\\theta(x|z)=\\mathcal{N}(\\mu_x,\\sigma_x^2 I),q_\\phi(z|x)=\\mathcal{N}(\\mu_z,\\sigma_z^2 I)\\)。如Figure 4所示，推断网络和生成网络中分别都有隐含层\\(f_\\phi(x)\\)和\\(f_\\theta(z)\\)对网络的输入进行特征抽取。高斯分布的参数即从这些抽取出来的特征上得到。均值通过线性层得到：\\(\\mu_x=W^T_{\\mu_x}f_\\theta(z)+b_{\\mu_x}, \\mu_z=W^T_{\\mu_z}f_\\theta(x)+b_{\\mu_z}\\)。标准差通过Soft Plus层加一个高斯噪声得到：\\(\\sigma_x=\\text{SoftPlus}[W^T_{\\sigma_x}f_\\theta(z)+b_{\\sigma_x}]+\\varepsilon，\\sigma_x=\\text{SoftPlus}[W^T_{\\sigma_z}f_\\theta(x)+b_{\\sigma_z}]+\\varepsilon\\)。 文中提到因为KPI的局部方差非常小，所以采用直接建模\\(\\sigma_x,\\sigma_z\\)的方式而不是采用对数。除此之外，为了理论上的解释性，文中的神经网络只使用了全连接层。 Training 训练可以直接采用经典的SGVB来优化ELBO： \\[ \\begin{align} \\log p_\\theta(x)&amp;\\geq\\log p_\\theta(x)-\\text{KL}[q_\\phi(z|x)\\parallel p_\\theta(z|x)]\\\\ &amp;=\\mathcal{L}\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x)+\\log p_\\theta(z|x)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x,z)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)+\\log p_\\theta(z)-\\log q_\\phi(z|x)] \\end{align} \\] 但是在实际的训练过程中，训练数据需要保证都是正常样本，但实际上训练样本有可能会包含异常或者是缺失值。一种做法是用缺失值填充的算法来填充这些异常值和缺失值，但作者认为使用缺失值填充算法并不能很好的还原数据的正常模式，从而保证算法的有效性。在文中作者采用了修改ELBO的方法，并将其称之为Modified ELBO (M-ELBO)，公式如下： \\[ \\tilde{\\mathcal{L}}=\\mathbb{E}_{q_\\phi(z|x)}[\\sum\\limits_{w=1}^W{\\alpha_w\\log p_\\theta(x_w|z)+\\beta\\log p_\\theta(z)-\\log q_\\phi(z|x)}] \\] 其中\\(\\alpha_w\\)为指示标记，\\(\\alpha_w=1\\)代表不是异常也不是缺失。\\(\\beta\\)定义为\\(\\beta=\\frac{\\sum_{w=1}^W\\alpha_w}{W}\\)。 在M-ELBO中，异常或缺失值对应的\\(\\log p_\\theta(x_w|z)\\)的贡献会被排除，同时\\(\\log p_\\theta(z)\\)在乘以\\(\\beta\\)后会相应缩小。作者没有修改\\(\\log q_\\phi(z|x)\\)这一项的原因有二：一是\\(q_\\phi(z|x)\\)仅仅是从\\(x\\)到\\(z\\)的映射，并不需要考虑“正常模式”；二是\\(\\mathbb{E}_{q_\\phi(z|x)}[-\\log q_\\phi(z|x)]\\)就是\\(q_\\phi(z|x)\\)的熵，而这个在后面的理论分析中有特别的含义。 除此之外还有一种解决方法就是把所有包含异常值和缺失值的窗口去除，这种方法的性能在实验中会进行讨论。 在文中作者还使用了一种Missing Data Injection技术，即在每个Epoch随机的按照一个预设比例\\(\\lambda\\)将正常的数据设为缺失。作者认为这样有助于性能的提升。 Detection 在检测阶段，对于一个输入样本，我们需要模型输出其异常的概率。因为我们建模了\\(p_\\theta(x|z)\\)，一种方法是采样计算\\(p_\\theta(x)=\\mathbb{E}_{p_\\theta(z)}[p_\\theta(x|z)]\\)，但这种方法计算代价十分昂贵。其他的一些方案有计算\\(\\mathbb{E}_{q_\\phi(z|x)}[p_\\theta(x|z)]\\)或\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)，其中后者被称为&quot;Reconstruction Probability&quot;，作者便采用了这种方案。 同时，作者认为输入的检测样本的缺失值会对结果造成较大偏差，于是使用了一种MCMC-based Missing Data Imputation的方法来对检测样本的缺失值进行填充。具体做法是将测试样本分为已观测和缺失两部分\\(x=(x_o,x_m)\\)，然后使用训练好的VAE进行重构得到\\((x^\\prime_o,x^\\prime_m)\\)，然后用\\(x^\\prime_m\\)替换\\(x_m\\)，这样不断循环如下图所示： 作者使用了\\(L\\)个样本来计算Reconstruction Probability，虽然得到的输出是针对整个窗口每个点的，但作者只使用最后一个点。 Experiments Datasets 作者选择了三条KPI作为测试数据，分别记为\\(\\mathcal{A}\\)，\\(\\mathcal{B}\\)，\\(\\mathcal{C}\\)，其基本数据如下表所示： Metrics 因为异常检测类别的极不均衡性，传统的性能指标并不太合适（异常样本极少，且异常一般呈连续的片段）。作者认为在实际应用场景中运维人员需要尽量早的获知异常的发生，于是提出了新的评测机制。 如上图所示，第一行为真实的标签，第二行为预测的异常概率，第三行为预测的标签。第一行中异常片段被加粗表示，对于每一个异常片段的第一个位置\\({y}_{t^\\prime}\\)，如果预测的标签中存在\\(\\hat{y}_{t}\\)满足\\(t^\\prime&lt;t\\)且\\(|t-t^\\prime|\\)小于等于预设的阈值\\(T\\)，那么\\(y_{t^\\prime}\\)对应的整段异常都被认为正确检测，否则整段异常都认为没有被正确检测。然后在此基础上计算F1-score，AUC等指标作为评测手段。 Results Overall Performance 下图展示了不同方法在不同数据集上的表现： Effects of Donut Techniques 为了探究Donut中所做的各种改进的实际作用，作者做了大量对比实验，结果如下图所示： M-ELBO 从图中可以看出M-ELBO对性能提升最大。作者在文中提到一开始并没期望M-ELBO能带来性能的提升，只是希望它能够Work。这表明在VAE的训练中，只使用正常样本是不够的，也需要加入非正常的信息； Missing Data Injection 该技巧的主要作用是增强M-ELBO的效果。从结果上来看作用并不是十分的显著，只是在一些情况下获得了少量的提升； MCMC Imputation 作者认为虽然该技巧只在一部分情况下显著提升了性能，但总体来说值得使用。 Impact of K 该部分作者探究了隐变量\\(z\\)的维度\\(K\\)对性能的影响，结果如下图： 从图上来看，对数据集\\(\\mathcal{A}\\)，\\(\\mathcal{B}\\)，\\(\\mathcal{C}\\)最佳的\\(K\\)分别是\\(5\\)，\\(4\\)和\\(3\\)，但是设定较大的\\(K\\)并不会对性能有严重的损害。作者还发现对于较为平滑的KPI需要较大的\\(K\\)。 Analysis KDE Interpretation 在这一节作者对Reconstruction Probability的意义进行了深入的探讨。首先作者对\\(q_\\phi(z|x)\\)进行了可视化，在图中作者将时间维度用颜色来表示。如Figure 11(a) 所示，\\(z\\)几乎是按照\\(x\\)对应的时间呈一个连续的流形分布，作者将这种现象称为Time Gradient。即使Donut没有显式的用到时间信息，不过因为实验用到的数据基本是平滑的，所以说相邻的\\(x\\)会比较相似，因此经过映射后的\\(z\\)也会比较相似。作者据此提出Donut的一个优势便是对于没有见过的后验分布\\(q_\\phi(z|x)\\)，只要其位于训练过的两个后验之间，也会产生合理的分布。 对于异常的样本\\(x\\)，假设其对应的正常模式为\\(\\tilde{x}\\)，作者认为\\(q_\\phi(z|x)\\)会在某种程度上对正常的\\(q_\\phi(z|\\tilde{x})\\)进行近似。因为模型是用正常样本进行训练的，隐变量\\(z\\)的维度通常来说小于样本\\(x\\)，这就导致\\(z\\)只会保留一部分主要的信息。对于异常样本，其异常模式在编码时就被丢掉了。作者还指出如果\\(x\\)包含的异常太多，那么模型将难以对\\(x\\)进行还原。 基于上述讨论，作者对使用\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)作为Reconstruction Probability的意义进行了阐释。设输入样本为\\(x\\)，如果其包含异常，假设其对应的正常样本为\\(\\tilde{x}\\)，那么\\(q_\\phi(z|x)\\)部分地和\\(q_\\phi(z|\\tilde{x})\\)相似。如果\\(x\\)和\\(\\tilde{x}\\)相似程度高，那么\\(\\log p_\\theta(x|z)\\)就会很大（其中\\(z\\sim q_\\phi(z|\\tilde{x})\\)）。\\(\\log p_\\theta(x|z)\\)类似于一个密度估计器，代表\\(x\\)在多大程度上与\\(\\tilde{x}\\)接近，\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)相当于对每一个\\(z\\)对应的\\(\\log p_\\theta(x|z)\\)乘以一个权重\\(q_\\phi(z|x)\\)然后相加。于是作者提出了Reconstruction Probability的KDE Interpretation:在Donut模型中，Reconstruction Probability \\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)可以看作是以\\(q_\\phi(z|x)\\)为权重，\\(\\log p_\\theta(x|z)\\)为核的核密度估计 (Kernel Density Estimation)。 三维可视化如下图所示： 作者还对直接计算\\(p_\\theta(x)=\\mathbb{E}_{p_\\theta(z)}[p_\\theta(x|z)]\\)进行了质疑，因为这种方法直接求\\(x\\)的先验，仅仅考虑了\\(x\\)的总体模式，而忽略了\\(x\\)的个体模式。 Find Good Posteriors for Abnormal \\(x\\) 通过上面的讨论我们知道了Donut通过找到\\(x\\)的正常后验来估计\\(x\\)在多大程度上与\\(\\tilde{x}\\)相似，在这一节作者讨论了文中使用的不同技巧对找到\\(x\\)的后验的作用。对于Missing Data Injection作者认为该技巧增强了M-ELBO的效果。对于MCMC Imputation，作者认为该技巧主要是在检测阶段通过不断迭代提供了更好的后验，如下图所示： 作者认为，虽然对于包含大量异常的样本，Donut不能很好的还原，但在运维场景中，只要对大段异常的开始阶段进行准确预测即可。 Causes of Time Gradient 在这一节作者讨论了Time Gradient出现的原因。首先假设\\(x\\)都是正常点，这时\\(x\\)的ELBO为： \\[ \\begin{align} \\mathcal{L}(x)&amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)+\\log p_\\theta(z)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}[\\log p_\\theta(x|z)]+\\mathbb{E}[\\log p_\\theta(z)]+\\text{H}[z|x] \\end{align} \\] 第一项表明在\\(z\\sim q_\\phi(z|x)\\)下尽可能重构\\(x\\)。第二项表明\\(q_\\phi(z|x)\\)尽量与\\(z\\)的先验\\(\\mathcal{N}(0,I)\\)接近。第三项为\\(q_\\phi(z|x)\\)的熵，表明\\(q_\\phi(z|x)\\)应尽量分散。然而第二项又限制了这种分散的区域，如 Figure 11(c) 所示。同时考虑这三项的话，第一项使得\\(z\\)不能自由地分散，对于不相似的\\(x\\)其对应的\\(z\\)也是不相似的，因为要最大化\\(x\\)的重构概率。然而对于相似的\\(x\\)来说，其对应的\\(q_\\phi(z|x)\\)会出现很多重复的部分。当达到平衡时，Time Gradient就出现了。 在训练过程中，当\\(x\\)越不相似，\\(q_\\phi(z|x)\\)就会相距越远，如上图所示。然而在一开始，参数经过随机初始化，\\(q_\\phi(z|x)\\)都是随机散乱的，如 Figure 11(b) 所示。随着训练的进行，\\(q_\\phi(z|x)\\)将会不断优化。由于KPI数据往往是光滑的，那么在时间上相距越远的样本就会越不相似，对应的\\(q_\\phi(z|x)\\)也会相距更远。这也说明了，训练结束后，时间上相距越远的，\\(q_\\phi(z|x)\\)也会相距越远，反之亦然。同时这也表明学习率的设置对本模型的稳定性有至关重要的作用。 Sub-Optimal Equilibrium 上面我们讨论了随着训练进行\\(q_\\phi(z|x)\\)的演变，作者提出在训练过程中可能会遇到模型收敛到次优的情况，如下图所示： 第一行展示的是收敛到最优的情况，第二行展示的是收敛到次优的情况。从第二行的第一个图（Step 100）来看，紫色的点开始穿过绿色的点，随着训练的进行，紫色的点开始将绿色的点推开。到Step 5000的时候，绿色的点已经被分成了两半。下图展示了对应的训练误差和验证误差： 这样的现象会导致在两半绿色区域之间的测试样本会被识别为紫色，从而降低性能。作者提出在\\(K\\)较大的时候这种现象不容易发生，但这时训练的收敛又会成为一个问题。","link":"/2019/09/22/Unsupervised-Anomaly-Detection-via-Variational-Auto-Encoder-for-Seasonal-KPIs-in-Web-Applications/"},{"title":"Transfer Anomaly Detection by Inferring Latent Domain Representations","text":"Introduction 作者提出了一种利用迁移学习提升target domain异常检测性能的算法。文中指出现有的基于迁移学习的异常检测算法需要对每个 target domain 进行单独训练，这样做会带来很大的计算开销。本文通过latent domain vectors来实现无需重新训练的异常检测。latent domain vectors是domain的一种隐含表示，通过该domain中的正常样本得到。在本文中，anomaly score function通过Auto-encoder得到。 Proposed Method Task 令\\(\\mathbf{X}_d^+:=\\{\\mathbf{x}^+_{dn}\\}^{N^+_d}_{n=1}\\)为第\\(d\\)个domain的异常样本集，\\(\\mathbf{x}_{dn}^+\\in\\mathbb{R}^M\\)为其中第\\(n\\)个样本的\\(M\\)维特征向量，\\(N^+_d\\)为第\\(d\\)个domain异常样本的数量。 类似的，令\\(\\mathbf{X}_d^-:=\\{\\mathbf{x}^-_{dn}\\}^{N^-_d}_{n=1}\\)为第\\(d\\)个domain的正常样本集。我们假设对于每个domain都有\\(N^+_d\\ll N^-_d\\)，且特征向量维度都为\\(M\\)。 假设在 source domain \\(D_S\\)都有正常样本和异常样本，记为\\(\\{\\mathbf{X}^+_d\\cup\\mathbf{X}_d^-\\}^{D_S}_{d=1}\\)，在 target domain \\(D_T\\)只有正常样本\\(\\{\\mathbf{X}_d^-\\}^{D_S+D_T}_{d=D_S+1}\\)。我们的目标是得到一个对于 target domain 合适的 domain-specific 的异常打分函数。 Domain-specific Anomaly Score Function 我们基于Auto-encoder定义异常打分函数。对于每个domain，我们假设存在一个\\(K\\)维的隐变量\\(\\mathbf{z}_d\\in\\mathbb{R}^K\\)。对于第\\(d\\)个 domain，异常打分函数定义如下： \\[ s_\\theta(\\mathbf{x}_{dn}|\\mathbf{z}_d):=\\parallel\\mathbf{x}_{dn}-G_{\\theta_G}(F_{\\theta_F}(\\mathbf{x}_{dn},\\mathbf{z}_d))\\parallel^2 \\] 其中参数\\(\\theta:=(\\theta_G,\\theta_F)\\)在所有 domain 之间共享。 Models for Latent Domain Vectors 隐变量\\(\\mathbf{z}_d\\)是无法观测到的，只能通过数据来估计。首先\\(\\mathbf{z}_d\\)在\\(\\mathbf{X}_d^-\\)条件下的条件分布假设为高斯分布： \\[ q_\\theta(\\mathbf{z}_d|\\mathbf{X}_d^-):=\\mathcal{N}(\\mathbf{z}_d|\\mu_\\phi(\\mathbf{X}_d^-),\\text{diag}(\\sigma_\\phi^2(\\mathbf{X}_d^-))) \\] 其中均值\\(\\mu_\\phi(\\mathbf{X}_d^-)\\in\\mathbb{R}^K\\)和方差\\(\\sigma^2_\\phi(\\mathbf{X}_d^-)\\in\\mathbb{R}^K_+\\)由神经网络建模，且在所有 domain 之间共享。在\\(\\mathbf{X}_d^-\\)给定的时候，我们便能够推断出该 domain 对应的隐变量， \\(q_\\phi\\)的输入为正常样本的集合，故神经网络需要满足permutation invariant。\\(\\tau(\\mathbf{X}_d^-)=\\rho(\\sum_{n=1}^{N_d^-}\\eta(\\mathbf{x}_{dn}^-))\\)，其中\\(\\tau(\\mathbf{X}_d^-)\\)表示\\(\\mu_\\phi(\\mathbf{X_d^-})\\)或\\(\\ln\\sigma_\\phi^2(\\mathbf{X}_d^-)\\)，\\(\\rho\\)和\\(\\eta\\)为神经网络， Objective Function 目标函数由anomaly score函数和隐变量组成。第\\(d\\)个domain在对应的隐变量\\(\\mathbf{z}_d\\)条件下的目标函数为： \\[ L_d(\\theta|\\mathbf{z}_d):=\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)-\\frac{\\lambda}{N_d^-N_d^+}\\sum\\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)-s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)) \\] 其中\\(\\lambda\\geq 0\\)为超参数，\\(f\\)为sigmoid函数。公式的第一项表示第\\(d\\)个domain正常样本对应的anomaly score。第二项为可微分的AUC。异常样本的anomaly score应当大于正常样本，所以对任何\\(\\mathbf x_{dm}^+\\in\\mathbf X_d^+, \\mathbf x_{dn}^-\\in\\mathbf X_d^-\\)有\\(s_\\theta(\\mathbf x_{dm}^+|\\mathbf z_d)&gt;s_\\theta(\\mathbf x_{dn}^-|\\mathbf z_d)\\)。第二项\\(\\frac{\\lambda}{N_d^-N_d^+}\\sum\\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)-s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d))\\)的取值范围是\\([0,1]\\)，当所有的\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\gg s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)时该项为1，当所有的\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\ll s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)时该项为0，所以最小化该项的相反数相当于鼓励\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\gg s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)。 因为隐变量\\(\\mathbf z_d\\)包含不确定性，我们应该在目标函数里考虑这一点： \\[ \\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z_d})) \\] 第一项是\\(L_d(\\theta|\\mathbf z_d)\\)关于\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)的期望，第二项是\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)和\\(p(\\mathbf z_d):=\\mathcal{N}(\\boldsymbol 0,\\boldsymbol I)\\)的KL散度。第一项可以用monte carlo估计\\(\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]\\approx\\frac{1}{L}\\sum_{\\ell=1}^L L_d(\\theta|\\mathbf z_d^{(\\ell)})\\)，除此之外还需要用到reparametrization trick。 对于第\\(d\\)个target domain，因为没有异常样本（假设），所以\\(L_d(\\theta|\\mathbf{z}_d):=\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)\\)，有： \\[ \\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z}_d)) \\] 所以总的损失函数为各domain对应的损失函数之和\\(\\mathcal{L}(\\theta,\\phi):=\\sum_{d=1}^{D_S+D_T}\\alpha_d\\mathcal{L}_d(\\theta,\\phi)\\)。 Inference 训练好之后，domain-specific的anomaly score可以由下式计算出： \\[ s(\\mathbf{x}_{d^\\prime}):=\\int s_{\\theta_*}(\\mathbf{x_{d^\\prime}}|\\mathbf{z}_{d^\\prime})q_{\\phi_*}(\\mathbf{z}_{d^\\prime}|\\mathbf{X}_{d^\\prime}^-)\\mathrm{d}\\mathbf{z}_{d^\\prime}\\approx\\frac{1}{L}\\sum\\limits_{\\ell=1}^L s_{\\theta_*}(\\mathbf{x}_{d^\\prime}|\\mathbf{z}_{d^\\prime}^{(\\ell)}) \\] Experiments Data 实验包含五个数据集，第一个是合成数据集。如下图(a)所示，围绕\\((0,0)\\)有\\(8\\)个圈，每个圈包含了一个内圈作为异常样本，第\\(7\\)个圈被选为target domain，其余的为source domain。第二个是MNIST-r，是加入旋转的MNIST，包含6个domain，其中数字“4”被选为异常样本，其余为正常。第三个为Anuran Calls，包含5个domain。第四个是Landmine，主要用在多任务学习中。第五个是IoT，网络流量数据，包含8个domain。 Comparison Methods 对比的baseline包括NN（普通多层神经网络），NNAUC（加入可微分AUC作为损失函数），AE（普通Autoencoer），AEAUC（加入可微分AUC的AE），OSVM（单类支持向量机），CCSA，TOSVM和OTL。 Results 4个真实数据集的结果如下： 表5为考虑隐变量不确定性的ablation study。将原来的公式\\(\\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z_d}))\\)中\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)用迪利克雷分布\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)=\\delta(\\mathbf z_d-\\mu_\\phi(\\mathbf X_d^-))\\)代替并且去掉KL散度。 表6展示了不同异常比例对效果的影响。","link":"/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/"},{"title":"An Introduction to Variational Autoencoders","text":"Deep Generative Models 生成模型是指一系列用于随机生成可观测数据的模型。假设在一个高维空间\\(\\mathcal{X}\\)中，存在一个随机向量\\(\\mathbf{X}\\)服从一个未知的分布\\(p_r(x),x\\in \\mathcal{X}\\)。生成模型就是根据一些可观测的样本\\(x^{(1)},x^{(2)},\\cdots,x^{(N)}\\)来学习一个参数化的模型\\(p_\\theta(x)\\)来近似未知分布\\(p_r(x)\\)。 生成模型主要用于密度估计和样本生成。 密度估计即给定一组数据\\(\\mathcal{D}=\\{x^{(i)}\\},1\\leq i\\leq N\\)，假设他们都是从相同的概率密度函数\\(p_r(x)\\)独立产生的。密度估计就是根据数据集\\(\\mathcal{D}\\)来估计其概率密度函数\\(p_r(x)\\)。 如果将生成模型用于监督学习，那么就是输出标签的条件概率分布\\(p(y|x)\\)，根据贝叶斯公式： \\[p(y|x)=\\frac{p(x,y)}{\\sum_y p(x,y)}\\] 问题就变为了联合概率\\(p(x,y)\\)的密度估计问题。 样本生成即根据给定的概率分布\\(p_\\theta(x)\\)生成一些服从这个分布的样本，即采样。在含隐变量的生成模型中，生成\\(x\\)的过程一般包含两步： 根据隐变量的分布\\(p_\\theta(z)\\)采样得到\\(z\\)； 根据条件分布\\(p_\\theta(x|z;\\theta)\\)进行采样得到\\(x\\)。 所以在生成模型中的重点是估计条件分布\\(p(x|z;\\theta)\\)。 Parameter Estimation for Hidden Variable with EM Algorithm 如果图模型中存在隐变量，就需要使用EM算法进行参数估计。 在一个包含隐变量的图模型中，令\\(\\mathbf{X}\\)为可观测变量集合，\\(\\mathbf{Z}\\)为隐变量集合，则一个样本\\(x\\)的边际似然函数为： \\[p(x;\\theta)=\\sum_z p(x,z;\\theta)\\] 给定包含\\(N\\)个训练样本的训练集\\(\\mathcal{D}=\\{x^{(n)}\\},1\\leq i\\leq N\\)，则训练集的对数边际似然为： \\[\\begin{align}\\mathcal{L}(\\mathcal{D};\\theta)&amp;=\\frac{1}{N}\\sum_{n=1}^N \\log p(x^{(n)};\\theta)\\\\&amp;=\\frac{1}{N}\\sum_{n=1}^N \\log \\sum_z p(x^{(n)},z;\\theta)\\end{align}\\] 这时，只要最大化整个训练集的对数边际似然\\(\\mathcal{L}(\\mathcal{D};\\theta)\\)，即可估计出最优的参数\\(\\theta^*\\)。不过在计算梯度的时候，需要在对数函数内部进行求和或积分计算。为了更好的计算\\(\\log p(x;\\theta)\\)，我们引入一个额外的变分函数\\(q(z)\\)，\\(q(z)\\)为定义在隐变量\\(z\\)上的分布。样本\\(x\\)的对数边际似然函数为： \\[\\begin{align}\\log p(x;\\theta)&amp;=\\log \\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)}\\\\&amp;\\geq\\sum_z q(z)\\log \\frac{p(x,z;\\theta)}{q(z)}\\\\&amp;\\triangleq ELBO(q,x;\\theta)\\end{align}\\] 其中\\(ELBO(q,x;\\theta)\\)为对数边际似然函数\\(\\log p(x;\\theta)\\)的下界，称为证据下界。公式中使用了Jensen不等式(即对于凹函数\\(g\\)，有\\(g(\\mathbb{E}[x])\\geq\\mathbb{E}[g(X)]\\))。在这里，\\(\\frac{p(x,z;\\theta)}{q(z)}\\)可视为\\(q(z)\\)的函数，记为\\(f(q(z))\\)，那么\\(f(q(z))\\)的期望即\\(\\mathbb{E}[f(q(z))]=\\sum_z q(z)f(q(z))=\\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)}\\)。而根据Jensen不等式，有\\(g(\\mathbb{E}[f(q(z))])\\geq\\mathbb{E}[g(f(q(z)))]\\Leftrightarrow g(\\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)})\\geq \\sum_z q(z)g(\\frac{p(x,z;\\theta)}{q(z)})\\)，在这里\\(g\\)就是对数函数。 根据Jensen不等式取等的条件：\\(\\frac{p(x,z;\\theta)}{q(z)}=c\\)，\\(c\\)为常数，有： \\[\\begin{align}\\sum_z p(x,z;\\theta)&amp;=c\\sum_z q(z)\\\\\\Leftrightarrow\\sum_z p(x,z;\\theta)&amp;=c\\cdot1\\end{align}\\] 因此： \\[\\begin{align}q(z)&amp;=\\frac{p(x,z;\\theta)}{\\sum_z p(x,z;\\theta)}\\\\&amp;=\\frac{p(x,z;\\theta)}{p(x;\\theta)}\\\\&amp;=p(z|x;\\theta)\\end{align}\\] 所以，当且仅当\\(q(z)=p(z|x;\\theta)\\)时，\\(\\log p(x;\\theta)=ELBO(q,x;\\theta)\\)。 于是最大化对数边际似然函数\\(\\log p(x;\\theta)\\)的过程可以分解为两个步骤： 先找到近似分布\\(q(z)\\)使得\\(\\log p(x;\\theta)=ELBO(q,x;\\theta)\\)； 再寻找参数\\(\\theta\\)最大化\\(ELBO(q,x;\\theta)\\)。 这就是期望最大化(Expectation-Maximum,EM)算法。 EM算法通过迭代的方法，不断重复直到收敛到某个局部最优解。在第\\(t\\)步更新时，E步和M步分别为： E步：固定参数\\(\\theta_t\\)，找到一个分布使\\(ELBO(q,x;\\theta_t)\\)最大，即等于\\(\\log p(x;\\theta_t)\\)：\\(q_{t+1}(z)=\\text{arg}_q \\max ELBO(q,x;\\theta_t)\\)； M步：固定\\(q_{t+1}(z)\\)，找到一组参数使得证据下界最大，即：\\(\\theta_{t+1}=\\text{arg}_\\theta\\max ELBO(q_{t+1},x;\\theta)\\)。 对数边际似然也可以通过信息论的视角来进行分解： \\[\\begin{align}\\log p(x;\\theta)&amp;=\\sum_z q(z)\\log p(x;\\theta)\\\\&amp;=\\sum_z q(z)(\\log p(x,z;\\theta)-\\log p(z|x;\\theta))\\\\&amp;=\\sum_z q(z)\\log\\frac{p(x,z;\\theta)}{q(z)}-\\sum_z q(z)\\log\\frac{p(z|x;\\theta)}{q(z)}\\\\&amp;=ELBO(q,x;\\theta)+D_{KL}(q(z)\\parallel p(z|x;\\theta))\\end{align}\\] 其中\\(D_{KL}(q(z)\\parallel p(z|x;\\theta))\\) Generative Model with Hidden Variable 假设一个生成模型包含不可观测的隐变量，其中可观测变量\\(x\\)为一个高维空间中的随机向量，而不可观测的隐变量\\(z\\)为一个相对低维空间中的随机向量。 这个生成模型的联合概率密度函数可以表达为： \\[p(x,z;\\theta)=p(x|z;\\theta)p(z;\\theta)\\] 其中\\(p(z;\\theta)\\)为隐变量\\(z\\)的先验概率分布；\\(p(x|z;\\theta)\\)为已知\\(z\\)条件下\\(x\\)的概率分布。通常情况下，我们可以假设\\(p(z;\\theta)\\)和\\(p(x|z;\\theta)\\)服从某种带参的分布族，其形式已知，而参数可以通过最大似然来进行估计。 给定一个样本\\(x\\)，其对数边际似然\\(\\log p(x;\\theta)\\)可以分解为： \\[\\log p(x;\\theta)=ELBO(q,x;\\theta,\\phi)+D_{KL}(q(z;\\phi)\\parallel p(z|x;\\theta))\\] 其中\\(q(z;\\phi)\\)为额外引入的变分密度函数，\\(ELBO(q,x;\\theta,\\phi)\\)为证据下界： \\[ELBO(q,x;\\theta,\\phi)=\\mathbb{E}_{z\\sim q(z;\\phi)}[\\log{\\frac{p(x,z;\\theta)}{q(z;\\phi)}}]\\] 最大化\\(\\log p(x;\\theta)\\)可以用EM算法来求解： E-step: 寻找一个密度函数\\(q(z;\\phi)\\)使其等于或接近于后验密度函数\\(p(z|x;\\theta)\\); M-step: 保持\\(q(z;\\phi)\\)固定，寻找\\(\\theta\\)来最大化\\(ELBO(q,x;\\theta,\\phi)\\)。 在EM算法的每次迭代中，理论上最优的\\(q(z;\\phi)\\)为隐变量的后验概率密度函数\\(p(z|x;\\theta)\\)： \\[p(z|x;\\theta)=\\frac{p(x|z;\\theta)p(z;\\theta)}{\\int_z p(x|z;\\theta)p(z;\\theta)\\text{d}z}\\] 后验密度函数\\(p(z|x;\\theta)\\)的计算是一个统计推断的问题，在一般情况下\\(p(x|z;\\theta)\\)也比较难以计算。 Variational Autoencoder 变分自编码器(Variational Autoencoder, VAE)的主要思想是利用神经网络来分别建模两个复杂的条件概率密度函数： 用神经网络来产生变分分布\\(q(z;\\phi)\\)，称为推断网络。推断网络的输入为\\(x\\)，输出为变分分布\\(q(z|x;\\phi)\\)； 用神经网络来产生概率分布\\(p(x|z;\\theta)\\)，称为生成网络。生成网络的输入为\\(z\\)，输出为概率分布\\(p(x|z;\\theta)\\)。 VAE的图模型如下图所示： Variational Network 假设\\(q(z|x;\\phi)\\)是服从对角化协方差的高斯分布： \\[q(z|x;\\phi)=\\mathcal{N}(z;\\mu_I,\\sigma^2_I I)\\] 其中\\(\\mu_I\\)和\\(\\sigma_I^2\\)是高斯分布的均值和方差，可以通过推断网络\\(f_I(x;\\phi)\\)来预测： \\[ \\left[\\begin{matrix}\\mu_I\\\\\\sigma_I\\end{matrix}\\right]=f_I(x;\\phi) \\] 推断网络\\(f_I(x;\\phi)\\)可以是一般的全连接网络或卷积网络，比如一个两层的神经网络： \\[\\begin{align}h&amp;=\\sigma(W^{(1)}x+b^{(1)})\\\\\\mu_I&amp;=W^{(2)}h+b^{(2)}\\\\\\sigma_I&amp;=\\text{softplus}(W^{(3)}h+b^{(3)})\\end{align}\\] 其中所有网络参数\\(\\{W^{(1)},W^{(2)},W^{(3)},b^{(1)},b^{(2)},b^{(3)}\\}\\)即对应了变分参数\\(\\phi\\)。 推断网络的目标是使得\\(q(z|x;\\phi)\\)来尽可能接近真实的后验\\(p(z|x;\\theta)\\)，需要找到变分参数\\(\\phi^*\\)来最小化两个分布的KL散度： \\[\\phi^*=\\text{arg}_\\phi\\min{D_{KL}(q(z|x;\\phi)\\parallel p(z|x;\\theta))}\\] 由于\\(p(z|x;\\theta)\\)未知，故KL散度无法直接计算，不过由于\\(D_{KL}(q(z|x;\\phi)\\parallel p(z|x;\\theta))=\\log p(x;\\theta)-ELBO(q,x;\\theta,\\phi)\\)，所以可以直接最大化证据下界，有： \\[\\phi^*=\\text{arg}_\\phi\\max{ELBO(q,x;\\theta,\\phi)}\\] Generative Network 生成模型的联合分布可以分解为两部分：隐变量\\(z\\)的先验分布\\(p(z;\\theta)\\)和条件概率分布\\(p(x|z;\\theta)\\)。为简单起见，一般假设隐变量\\(z\\)的先验分布为标准正态分布\\(\\mathcal{N}(z|0,I)\\)，隐变量每一维之间都是独立的。条件概率分布\\(p(x|z;\\theta)\\)可以通过生成网络来建模，我们同样用参数化的分布族来表示条件概率分布\\(p(x|z;\\theta)\\)，这些分布族的函数可以用生成网络计算得到。根据变量\\(x\\)的类型不同，可以假设\\(p(x|z;\\theta)\\)服从不同的分布族。如果\\(x\\in\\{0,1\\}^d\\)是\\(d\\)维的二值向量，可以假设\\(\\log p(x|z;\\theta)\\)服从多变量的伯努利分布，即： \\[\\begin{align}p(x|z;\\theta)&amp;=\\prod\\limits_{i=1}^d p(x_i|z;\\theta)\\\\&amp;=\\prod\\limits_{i=1}^d \\gamma_i^{x_i}(1-\\gamma_i)^{(1-x_i)}\\end{align}\\] 如果\\(x\\in\\mathbb{R}^d\\)是\\(d\\)维的连续向量，可以假设\\(p(x|z;\\theta)\\)服从对角化协方差的高斯分布，即： \\[p(x|z;\\theta)=\\mathcal{N}(x;\\mu_G,\\sigma_G^2 I)\\] 生成网络的目标是找到一组\\(\\theta^*\\)最大化证据下界\\(ELBO(q,x;\\theta,\\phi)\\)： \\[\\theta^*=\\text{arg}_\\theta\\max ELBO(q,x;\\theta,\\phi)\\] Model Combination 推断网络和生成网络的目标都是最大化证据下界因此总的目标函数为： \\[\\begin{align}\\max_{\\theta,\\phi}ELBO(q,x;\\theta,\\phi)&amp;=\\max_{\\theta,\\phi}\\mathbb{E}_{z\\sim q(z;\\phi)}[\\log\\frac{p(x|z;\\theta)p(z;\\theta)}{q(z;\\theta)}]\\\\&amp;=\\max_{\\theta,\\phi}\\mathbb{E}_{z\\sim q(z|x;\\phi)}[\\log p(x|z;\\theta)]-D_{KL}(q(z|x;\\phi)\\parallel p(z;\\theta))\\end{align}\\] 其中先验分布\\(p(z;\\theta)=\\mathcal{N}(z|0,I)\\)。 公式中\\(\\mathbb{E}_{z\\sim q(z|x;\\phi)}[\\log p(x|z;\\theta)]\\)一般通过采样的方式进行计算，最后取平均值。 Model Training 给定数据集\\(\\mathcal{D}\\)，包含\\(N\\)个从未知数据分布中抽取的独立同分布样本\\(x^{(1)},x^{(2)},\\cdots,x^{(N)}\\)。变分自编码器的目标函数为： \\[\\mathcal{J}(\\phi,\\theta|\\mathcal{D})=\\sum\\limits_{n=1}^N(\\frac{1}{M}\\sum\\limits_{m=1}^M\\log p(x^{(n)}|z^{(n,m)};\\theta)-D_{KL}(q(z|x^{(n)};\\phi)\\parallel\\mathcal{N}(z;0,I)))\\] 如果采用随机梯度下降法，每次从数据集中采一个样本\\(x\\)，然后根据\\(q(z|x;\\phi)\\)采一个隐变量\\(z\\)，则目标函数变为： \\[\\mathcal{J}(\\phi,\\theta|x)=\\log p(x|z;\\theta)-D_{KL}(q(z|x;\\phi)\\parallel\\mathcal{N}(z;0,I))\\] 假设\\(q(z|x;\\phi)\\)是正态分布，KL散度可直接算出： \\[D_{KL}(\\mathcal{N}(\\mu_1,\\Sigma_1)\\parallel\\mathcal(\\mu_2,\\Sigma_2))\\\\=\\frac{1}{2}(\\text{tr}(\\sigma_I^2 I)+\\mu_I^T\\mu_I-d-\\log(|\\sigma_I^2 I|))\\] 再参数化是将一个参数为\\(u\\)的函数\\(f(u)\\)，通过一个函数\\(u=g(v)\\)，转换为参数为\\(v\\)的函数\\(\\hat{f}(v)=f(g(v))\\)。在变分自编码器中，一个问题是如何求随机变量\\(z\\)关于\\(\\phi\\)的导数。但由于是采样的方式，无法直接刻画\\(z\\)和\\(\\phi\\)之间的函数关系，因此也无法计算导数。 如果\\(z\\sim q(z|x;\\phi)\\)的随机性独立于参数\\(\\phi\\)，我们可以通过再参数化的方法来计算导数。假设\\(q(z|x;\\phi)\\)为正态分布\\(\\mathcal{N}(\\mu_I,\\sigma^2_I I)\\)，其中\\(\\mu_I\\)和\\(\\sigma_I\\)是推断网络\\(f_I(x;\\phi)\\)的输出。我们可以通过下面的方式采样\\(z\\)： \\[z=\\mu_I+\\sigma_I\\odot \\varepsilon\\] 其中\\(\\varepsilon\\sim\\mathcal{N}(0,I)\\)。这样\\(z\\)和\\(\\mu_I,\\sigma_I\\)的关系从采样关系变为函数关系。 如果进一步假设\\(p(x|z;\\theta)\\)服从高斯分布\\(\\mathcal{N}(x|\\mu_G,I)\\)，其中\\(\\mu_G=f_G(z;\\theta)\\)是生成网络的输出，则目标函数可以简化为： \\[\\mathcal{J}(\\phi,\\theta|x)=-\\parallel x-\\mu_G\\parallel^2+D_{KL}(\\mathcal{N}(\\mu_I,\\sigma_I)\\parallel\\mathcal{N}(0,I))\\] 其中第一项可以近似看作是输入\\(x\\)的重构正确性，第二项可以看作是正则化项。","link":"/2019/10/22/An-Introduction-to-Variational-Autoencoders/"},{"title":"Time Series Anomaly Detection Paper List","text":"Introduction 时间序列异常检测在很多领域例如运维、金融、交通都扮演者重要的角色，其定义如下： 给定时间序列\\(X=\\{\\mathbf{x}_1,\\mathbf{x}_2,\\cdots,\\mathbf{x}_n\\}\\in\\mathbb{R}^{m\\times n}\\)，异常检测的任务是输出异常标签\\(y=\\{y_1,y_2,\\cdots,y_n\\}\\in\\mathbb{R}^n\\)，其中\\(y_t=1\\)代表\\(\\mathbf{x}_t\\)为异常，\\(y_t=0\\)代表\\(\\mathbf{x}_t\\)正常 本文罗列了一些时间序列异常检测领域值得读的一些文章，Model一章主要按时间序列、通用和图的异常检测分类，Related主要是一些非异常检测、但是能够解决异常检测研究中的一些问题的文章。 Model Time Series Statistical 主要包括偏向统计方法的模型： Title Conf/Journal Description Links Temporal Anomaly Detection: Calibrating the Surprise 📃Paper Non-Parametric Outliers Detection in Multiple Time Series A Case Study: Power Grid Data Analysis 📃Paper Anomaly Detection in Streams with Extreme Value Theory KDD17 提出了以Extreme Value Theory为基础的时序异常检测和参数选择方法 📃Paper Semi-Markov Switching Vector Autoregressive Model-Based Anomaly Detection in Aviation Systems 📃Paper Stochastic Online Anomaly Analysis for Streaming Time Series 📃Paper Unsupervised Real-time Anomaly Detection for Streaming Data 📃Paper Automatic Anomaly Detection in the Cloud Via Statistical Learning 📃Paper Classic Machine Learning Title Conf/Journal Description Links Semi-supervised Anomaly Detection with an Application to Water Analytics 📃Paper DILOF: Effective and Memory Efficient Local Outlier Detection in Data Streams 📃Paper Robust Random Cut Forest Based Anomaly Detection On Streams ICML16 孤立森林的改进版本来做时序异常检测 📃Paper 📥Code Anomaly Detection for an E-commerce Pricing System 📃Paper An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time Series 📃Paper Opprentice: Towards Practical and Automatic Anomaly Detection Through Machine Learning IMC15 以随机森林为基础的时序异常检测 📃Paper Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series 📃Paper A Self-Learning and Online Algorithm for Time SeriesAnomaly Detection, with Application in CPU Manufacturing 📃Paper VAE Title Conf/Journal Description Links Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications WWW18 普通VAE 📃Paper 📥Code ✍Blog Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder IPCCC18 条件VAE 📃Paper 📥Code Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE INFOCOM19 VAE加对抗训练 📃Paper Multidimensional Time Series Anomaly Detection: A GRU-based Gaussian Mixture Variational Autoencoder Approach 📃Paper Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network KDD19 多变量基于VAE和RNN的时序异常检测 📃Paper 📥Code A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-based Variational Autoencoder 📃Paper RNN Title Conf/Journal Description Links Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding 📃Paper BINet: Multivariate Business Process Anomaly Detection Using Deep Learning 📃Paper Outlier Detection for Time Series with Recurrent Autoencoder Ensembles 📃Paper LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection 📃Paper Detecting Anomalies in Space using Multivariate Convolutional LSTM with Mixtures of Probabilistic PCA KDD19 📃Paper GAN Title Conf/Journal Description Links Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series 📃Paper 📥Blog MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks ICANN19 普通GAN做时序异常检测，没有编码结构 📃Paper 📥Code BeatGAN: Anomalous Rhythm Detection using Adversarially Generated Time Series IJCAI19 ECG异常检测，没有隐变量约束 📃Paper Miscellaneous Title Conf/Journal Description Links A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data 📃Paper ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection Expert Systems With Applications 有监督KPI异常检测，使用两阶段训练来提升性能 📃Paper ✍Blog Time-Series Anomaly Detection Service at Microsoft KDD19 将视觉异常检测中的谱残差应用到了时序异常检测 📃Paper 📥Code ✍Blog Outlier Detection for Multidimensional Time Series using Deep Neural Networks 📃Paper General Survey Deep Learning for Anomaly Detection: A Survey [Paper] Classic Machine Learning Title Conf/Journal Description Links LOF: Identifying Density-Based Local Outliers 📃Paper Isolation Forest 📃Paper Extended Isolation Forest 📃Paper Hidden Markov Anomaly Detection 📃Paper Linear-Time Outlier Detection via Sensitivity 📃Paper Reverse Nearest Neighbors in Unsupervised Distance-Based Outlier Detection 📃Paper Theoretical Foundations and Algorithms for Outlier Ensembles 📃Paper R1SVM: A Randomised Nonlinear Approach to Large-Scale Anomaly Detection 📃Paper Random Gradient Descent Tree: A Combinatorial Approach for SVM with Outliers 📃Paper Sparse Gaussian Markov Random Field Mixtures for Anomaly Detection 📃Paper Sequential Ensemble Learning for Outlier Detection: A Bias-Variance Perspective 📃Paper Sparse Modeling-Based Sequential Ensemble Learning for Effective Outlier Detection in High-Dimensional Numeric Data 📃Paper Contextual Spatial Outlier Detection with Metric Learning 📃Paper Human-Assisted Online Anomaly Detection with Normal Outlier Retraining 📃Paper Efficient Anomaly Detection via Matrix Sketching 📃Paper Dual-Regularized Multi-View Outlier Detection 📃Paper Deep Anomaly Detection Using Geometric Transformations 📃Paper Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models 📃Paper Partial Multi-View Outlier Detection Based on Collective Learning 📃Paper Multi-View Anomaly Detection: Neighborhood in Locality Matters 📃Paper Latent Discriminant Subspace Representations for Multi-View Outlier Detection 📃Paper Anomaly Detection with Partially Observed Anomalies 📃Paper One-Class Active Learning for Outlier Detection with Multiple Subspaces 📃Paper Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection NIPS19 📃Paper SNIPER: Few-shot Learning for Anomaly Detection to Minimize False-negative Rate with Ensured True-positive Rate ICASSP19 📃Paper AE/VAE Title Conf/Journal Description Links Estimation of Dimensions Contributing to Detected Anomalies with Variational Autoencoders 📃Paper Anomaly Detection with Robust Deep Autoencoders 📃Paper Complementary Set Variational Autoencoder for Supervised Anomaly Detection 📃Paper A Two-class Hyper-spherical Autoencoder for Supervised Anomaly Detection 📃Paper GAN Title Conf/Journal Description Links Adversarially Learned Anomaly Detection 📃Paper AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and Time-Evolving Categorical Data 📃Paper Adversarially Learned One-Class Classifier for Novelty Detection 📃Paper 📥Code Generative Probabilistic Novelty Detection with Adversarial Autoencoders 📃Paper 📥Code OCGAN: One-class Novelty Detection Using GANs with Constrained Latent Representations 📃Paper Fence GAN: Towards Better Anomaly Detection Arxiv 📃Paper Anomaly Detection via Minimum Likelihood Generative Adversarial Networks Arxiv 📃Paper DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN ICDM18 📃Paper Learning Competitive and Discriminative Reconstructions for Anomaly Detection AAAI19 📃Paper Miscellaneous Title Conf/Journal Description Links Deep Structured Energy Based Models for Anomaly Detection 📃Paper Anomaly Detection using One-Class Neural Networks 📃Paper 📥Code High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning 📃Paper Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection 📃Paper Deep Anomaly Detection with Outlier Exposure 📃Paper Are Generative Deep Models for Novelty Detection Truly Better? KDD18 Workshop 📃Paper Probabilistic-Mismatch Anomaly Detection: Do one's Medications Match with the Diagnoses? ICDM16 📃Paper Deep Anomaly Detection with Deviation Networks KDD19 📃Paper Weakly-supervised Deep Anomaly Detection with Pairwise Relation Learning AAAI20 📃Paper Transfer Anomaly Detection by Inferring Latent Domain Representations NIPS19 📃Paper Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models NIPS16 📃Paper Continual Learning for Anomaly Detection with Variational Autoencoder ICASSP19 📃Paper AdaFlow: Domain-adaptive Density Estimator with Application to Anomaly Detection and Unpaired Cross-domain Translation ICASSP19 📃Paper Graph AddGraph: Anomaly Detection in Dynamic Graph Using Attention-based Temporal GCN [Paper] Outlier Detection in Graph Streams [Paper] NetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks [Paper] Anomaly Detection in Dynamic Networks using Multi-view Time-Series Hypersphere Learning [Paper] Related 这一部分主要是一些非异常检测文章，但是可以用来解决异常检测中的问题的相关文章。 Infrastructure GAN Generative Adversarial Networks [Paper] VAE &amp; GAN Combination Variational Approaches for Auto-Encoding Generative Adversarial Networks [Paper] Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks [Paper] On Unifying Deep Generative Models [Paper] Bidirectional GANs Adversarial Feature Learning [Paper] Adversarially Learned Inference [Paper] It Takes (Only) Two: Adversarial Generator-Encoder Networks [Paper] VAE Auto-Encoding Variational Bayes [Paper] Class Imbalance Focal Loss for Dense Object Detection [Paper] Gradient Harmonized Single-stage Detector [Paper] Stochastic Temporal Modeling Sequential Neural Models with Stochastic Layers [Paper] A Recurrent Latent Variable Model for Sequential Data [Paper] Deep State Space Models for Time Series Forecasting [Paper] Bayesian Recurrent Neural Networks [Paper] Detection without Closed-form Likelihood Reconstruction Adversarially Learned One-Class Classifier for Novelty Detection [Paper] Generative Adversarial Network Based Novelty Detection Using Minimized Reconstruction Error [Paper] Learning Discriminative Reconstructions for Unsupervised Outlier Removal [Paper] Discriminator A Lipschitz-constrained Anomaly Discriminator Framework [Paper] Out-of-distribution Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks [Paper] Learning Confidence for Out-of-Distribution Detection in Neural Networks [Paper] A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Paper] A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks [Paper] GANs for Incomplete Data AmbientGAN: Generative Models From Lossy Measurements [Paper] MisGAN: Learning from Incomplete Data with Generative Adversarial Networks [Paper] Dataset 详见http://qfxiao.me/2020/02/03/Datasets-for-Time-Series-Anomaly-Detection/。","link":"/2020/01/08/Time-Series-Anomaly-Detection-Paper-List/"},{"title":"Time-Series Anomaly Detection Service at Microsoft","text":"Abstract 本文借鉴计算机视觉中的显著性检测，提出了一种基于Spectral Residual的时间序列异常检测算法。 原文 这篇文章还提出了几个时间序列异常检测落地的难点： Lack of Labels. 在实际生产环境中会产生大量的KPI，而很难对每个KPI进行人工标注。 Generalization. 不同KPI所表现出来的模式也不尽相同，如Figure 1所示。现有方法很难在所有模式的KPI上都表现良好。 Efficiency. 在实际场景中，会产生大量的时间序列数据，同时对异常检测算法的时间效率有要求。 Contribution 将Visual Saliency Detection的方法引入了时间序列异常检测。 结合Spectral Residual和CNN提高了异常检测的效果。 算法具有良好的时间效率和通用性。 Background Spectral Residual SR(Spectral Residual)算法主要包含三个步骤： 通过傅里叶变换得到log amplitude spectrum； 计算spectral residual； 通过傅里叶逆变换回到时间域。 更形式化的表述为如下： 给定一个序列\\(\\mathbb{x}\\)，则有： \\[A(f)=Amplitude(\\mathscr{F}(\\mathbb{x}))\\] \\[P(f)=Phrase(\\mathscr{F}(\\mathbb{x}))\\] \\[L(f)=\\log(A(f))\\] \\[AL(F)=h_1(f)\\cdot L(f)\\] \\[R(f)=L(f)-AL(f)\\] \\[S(\\mathbb{x})=\\parallel\\mathscr{F}^{-1}(\\exp(R(f)+iP(f)))\\parallel\\] 其中\\(\\mathscr{F}\\)和\\(\\mathscr{F}^{-1}\\)分别表示傅里叶变换和傅里叶逆变换；\\(\\mathbb{x}\\in \\mathbb{R}^{n\\times 1}\\)表示输入序列；\\(A(f)\\)为幅度谱，\\(P(f)\\)为相位谱，\\(L(f)\\)为对数幅度谱，\\(AL(F)\\)为均值滤波后的对数幅度谱；\\(R(f)\\)为spectral residual；\\(S(\\mathbb{x})\\)称为saliency map。Figure 4为文中给出的Saliency Map示意图。 Methodology Problem Definition 给定一系列实数值\\(\\mathbb{x}=x_1,x_2,\\cdots,x_n\\)，时间序列异常检测的任务是产生一个输出序列\\(\\mathbb{y}=y_1,y_2,\\cdots,y_n\\)其中\\(y_i\\in\\{0,1\\}\\)表示\\(x_i\\)是否为异常点。 SR 对于给定序列\\(\\mathbb{x}\\)，计算Saliency Map \\(S(\\mathbb{x})\\)，输出序列\\(O(\\mathbb{x})\\)定义为： \\[O(x_i)=\\begin{cases}1,\\quad \\text{if}\\frac{S(x_i)-\\overline{S(x_i)}}{\\overline{S(x_i)}}&gt;\\tau\\\\\\\\0,\\quad \\text{otherwise}\\end{cases}\\] 其中\\(S(x_i)\\)为\\(x_i\\)对应的Saliency Map的值，\\(\\overline{S(x_i)}\\)为\\(x_i\\)附近Saliency Map局部均值。 在实际操作中，FFT是在一个滑动窗口中进行的，文中提到SR方法在点位于窗口中央时效果更好，所以在进行测试的时候，按照如下方法对当前点\\(x_n\\)(也就是当前序列最后一个点)之后的点进行预测： \\[\\overline{g}=\\frac{1}{m}\\sum_{i=1}^m g(x_n,x_{n-i})\\] \\[x_{n+1}=x_{n-m+1}+\\overline{g}\\cdot m\\] 其中\\(g(x_i,x_j)\\)代表\\(x_i\\)和\\(x_j\\)两点构成的直线的梯度；\\(\\overline{g}\\)代表所处理的点的平均梯度；\\(m\\)为所处理的点的数量。在本文中设置\\(m=5\\)。文中发现第一个预测的值很重要，所以直接把\\(x_{n+1}\\)赋值\\(k\\)次添加到序列的末尾。 SR-CNN 本文提到，仅仅使用一个阈值来进行异常的判断太过简单，于是提出使用一个判别模型来进行异常的判断。由于训练数据没有标签，所以使用如下的公式人工加入异常： \\[x=(\\overline{x}+mean)(1+var)\\cdot r+x\\] 其中\\(\\overline{x}\\)所处理的点的局部均值；\\(mean\\)和\\(var\\)为当前滑动窗口点的均值和方差；\\(r\\sim \\mathcal{N}(0,1)\\)为服从标准正态分布的噪声。 对于判别模型使用的是CNN，主要包含两个1维卷积层(kernel size等于窗口大小\\(w\\))和两个全连接层。两个卷积层的channel size分别为\\(w\\)和\\(2w\\)。 Experiments Datasets 所用数据集包含清华AIOps竞赛数据、Yahoo和Microsoft的KPI数据。 Evaluation Metrics 算法准确率方面用了precision，recall和\\(F_1\\)-score。 由于在实际场景中KPI的异常往往是以一段一段的形式出现，且并不要求某一个时间点出现异常算法就马上检测出来，只要检测出来的时间在一定的容忍范围内即可。本文使用了一些调整的手段，如Figure 6。对于某一段异常，设段首的异常位于时间点\\(t_{truth}\\)，预测为异常的结果中时间在\\(t_{truth}\\)之后且距\\(t_{truth}\\)最近的时间点设为\\(t_{predict}\\)，那么对于一个预先设定的容忍范围\\(k\\)，只要\\(t_{predict}-t_{truth}\\leq k+1\\)那么在预测结果中整段异常就会重置为\\(1\\)，否则全部重置为\\(0\\)。 Results 实验部分使用了两种训练方式，一种是cold-start，即把所有数据都用来测试，另一种是把数据分为训练测试两部分，在训练集上训练，最后在测试集上进行测试。两种方法适用的baseline不同，最后结果如Table 2和Table 3所示： 在SR的参数设置上，\\(h_q(f)\\)中的\\(q\\)为3，局部平均所用的点数目\\(z\\)为21，阈值\\(\\tau\\)为3，估计点的数量\\(k\\)为5，滑动窗口的大小\\(w\\)在KPI、Yahoo、Microsoft三个数据集上分别为1440、64和30。SR-CNN的\\(q\\)，\\(z\\)，\\(k\\)，\\(w\\)设置与SR相同。 Additional Experiments with DNN 文中还对有监督的情况进行了测试，具体做法是从时间序列提取特征，然后将Saliency Map也作为特征引入，构造一个有监督的Neural Network进行测试。 提取的特征如Table 5所示： 神经网络的结构为两层全连接层，并添加了Dropout Ratio为0.5的Dropout Layer。两个Layer使用了\\(L_1=L_2=0.0001\\)的正则化。同时为了处理样本不平衡的情况使用了过采样来使正负样本的比例为\\(1:2\\)。结构如Figure 7所示： 训练测试集的情况如Table 6所示，最终结果如Table 7所示，P-R曲线如Figure 8所示。可以看到使用了SR特征的DNN效果由于没有使用SR特征的DNN。","link":"/2019/09/22/Time-Series-Anomaly-Detection-Service-at-Microsoft/"},{"title":"Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE","text":"Introduction 论文📃 代码📥 本文介绍了一种利用对抗训练来进行时间序列异常检测的方法Buzz。作者认为在现实中复杂的KPI数据大量存在，这种数据通常带有非高斯分布的噪声，同时数据分布复杂，导致一般的生成式模型无法对数据进行很好的建模，所以作者提出了基于对抗训练的模型。在文中，作者的创新点主要有三个： 为了处理复杂数据，将数据空间分为多个子空间，在每个子空间上进行距离的度量； 采用Wasserstein距离度量模型建模的分布和真实分布之间的距离； 建立了基于对抗训练的Buzz的损失函数和VAE之间的关系。 Background Anomaly Detection 对于任意时间\\(t\\)，给定历史观察值\\(x_{t-T+1},\\cdots,x_t\\)，确定异常是否发生(记为\\(y_t=1\\))。通常来收异常检测算法给出的是发生异常的可能性，如\\(p(y_t=1|x_{t-T+1},\\cdots,x_t)\\)。 VAE Model Latent Data Auto-encoder (AE) None L1Loss Variational Auto-encoder (VAE) KL Divergence Log Likelihood Adversarial Auto-encoder (AAE) Discriminator L1Loss Wasserstein Auto-encoder (WAE) MaxMeanDiscrepancy or Discriminator L1Loss AlphaGAN Discriminator Discriminator+L1Loss GAN and WGAN-GP 原始GAN等价于优化： \\[ \\mathbb{E}_{x\\sim P_r}\\log{\\frac{P_r(x)}{\\frac{1}{2}\\left[P_r(x)+P_g(x)\\right]}}+\\mathbb{E}_{x\\sim P_g}\\log{\\frac{P_g(x)}{\\frac{1}{2}\\left[P_r(x)+P_g(x)\\right]}} \\] 根据KL散度和JS散度的定义： \\[ \\text{KL}(P_1\\parallel P_2)=\\mathbb{E}_{x\\sim P_1}\\log{\\frac{P_1}{P_2}} \\] \\[ \\text{JS}(P_1\\parallel P_2)=\\frac{1}{2}\\text{KL}(P_1\\parallel \\frac{P_1+P_2}{2})+\\frac{1}{2}\\text{KL}(P_2\\parallel \\frac{P_1+P_2}{2}) \\] 可重写为： \\[ 2\\text{JS}(P_r\\parallel P_g)-2\\log 2 \\] 当\\(P_r\\)与\\(P_g\\)的支撑集（support）是高维空间中的低维流形（manifold）时，\\(P_r\\)与\\(P_g\\)重叠部分测度（measure）为0的概率为1。 支撑集（support）其实就是函数的非零部分子集，比如ReLU函数的支撑集就是[公式]，一个概率分布的支撑集就是所有概率密度非零部分的集合。 流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。 测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。 Wasserstein距离定义如下： \\[ W(P_r,P_g)=\\inf\\limits_{\\gamma\\sim\\prod(P_r,P_g)}\\mathbb{E}_{(x,y)\\sim \\gamma}\\left[\\parallel x-y\\parallel\\right] \\] 下确界\\(\\inf\\)没法直接求解，不过根据相关定理其等价于： \\[ W(P_r,P_g)=\\frac{1}{K}\\sup\\limits_{\\parallel f\\parallel_L\\leq K}\\mathbb{E}_{x\\sim P_r}[f(x)]-\\mathbb{E}_{x\\sim P_g}[f(x)] \\] Lipschitz连续是指存在一个常数\\(K\\geq 0\\)使得定义域内任意两个元素\\(x_1\\)和\\(x_2\\)都满足： \\[ |f(x_1)-f(x_2)|\\leq K|x_1-x_2| \\] WAN的损失函数： \\[ \\mathcal{L}=\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_g}\\left[D({\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] \\] WGAN-GP的损失函数为： \\[ \\mathcal{L}=\\mathop{\\mathbb{E}}\\limits_{\\tilde{\\mathbf{x}}\\sim\\mathbb{P}_g}\\left[D(\\tilde{\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] + \\lambda\\mathop{\\mathbb{E}}\\limits_{\\hat{\\mathbf{x}}\\sim\\mathbb{P}_{\\hat{\\mathbf{x}}}}\\left[(\\parallel\\nabla_{\\hat{\\mathbf{x}}}D(\\hat{\\mathbf{x}})\\parallel_2-1)^2\\right] \\] Proposed Method 下图为Buzz的总体流程： 数据会首先进行一些预处理，之后进行训练。在检测阶段会根据异常分数来判定异常。 Motivation 在文中，最关键的两个创新点分别是Wasserstein距离和对数据分布进行分区的方法。 在使用距离度量方面， 因为Wasserstein在WGAN中取得了很好的效果，是一种鲁棒的距离度量，所以作者在文中采用了Wasserstein距离来衡量生成的分布和真实的分布之间的距离，并由此引入了对抗训练； 在分区方法方面，作者认为原始数据过于复杂，所以将数据空间\\(\\mathcal{X}\\)进行划分，然后在每个子空间上使用Wasserstein度量距离，而总体的距离由每个分区的距离的期望求得。 作者还发现，当划分地越来越细时，总体距离接近于特定形式的VAE的重构误差项。 Network Structure 下图为模型的网络结构： Training Objective Function 先定义一些符号： \\(b\\)和\\(s\\)分别为Batch的大小和邻居的大小，数据集按\\(s\\)进行切分，然后随机打乱，每个Batch包含\\(b\\)个\\(s\\)，之后\\(s/=2,b*=2\\)； \\(\\mathcal{W}=\\{w_1,w_2,\\cdots,w_b\\}\\)为一个Batch，且满足每个\\(w_i\\)是\\(s\\)的倍数； \\(w\\in\\mathcal{W}\\)的邻域集(neighborhood set)为一个时间上的partition，记为\\(\\{w,w+1,\\cdots,w+s-1\\}\\) \\(\\mathbf{x}^{(w)},\\mathbf{x}^{(w+1)},\\cdots,\\mathbf{x}^{(w+s-1)}\\)为在空间\\(\\mathcal{X}\\)上的一个partition，记为\\(S_w\\)，其中\\(\\mathbf{x}^{(w)}\\)表示以\\(w\\)为结尾的时间窗口。 Buzz的损失函数和WGAN-GP类似，但做了一些改进，由下面四部分组成，下面分别解释。 第一个是每一个partition的\\(\\mathbf{z}\\)后验的KL散度： \\[ \\mathcal{K} = \\frac{1}{bs}\\sum\\limits_{w\\in\\mathcal{W}}\\sum\\limits_{i=1}^{s-1}\\text{KL}\\left[q_\\phi(\\mathbf{z}|\\mathbf{x})\\parallel\\mathcal{N}(\\mathbf{0},\\mathbf{1})\\right] \\] 第二个在训练时是一个常数： \\[ Z(\\lambda) = \\frac{\\Gamma(W)}{\\Gamma(\\frac{W}{2})}2\\pi^{\\frac{W}{2}}\\lambda^{-W} \\] 其中\\(\\Gamma\\)是Gamma函数。 第三个是Wasserstein距离： \\[ \\mathcal{T}(F,w)=\\frac{1}{bs}\\sum\\limits_{i=1}^{s-1}\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x}^{w+i})}\\left[F(\\mathbf{x}^{(w+i)})-F(G(\\mathbf{z}))\\right] \\] 第四个是Gradient Penalty： \\[ \\mathcal{R}(F,w)=\\frac{1}{bs}\\sum\\limits_{i=1}^{s-1}\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x}^{(w+i)})}\\left[\\mathbb{E}_{\\varepsilon\\sim[0,1]}(\\parallel\\nabla_{\\hat{\\mathbf{x}}}(\\hat{\\mathbf{x}})\\parallel-\\mathbf{1})^2\\right] \\] 其中\\(\\hat{\\mathbf{x}}=\\varepsilon \\mathbf{x}^{w+i}+(1-\\varepsilon)G(\\mathbf{z})\\)为生成数据与真实数据的插值。 原始的WGAN-GP的损失函数为： \\[ L=\\mathop{\\mathbb{E}}\\limits_{\\tilde{\\mathbf{x}}\\sim\\mathbb{P}_g}\\left[D(\\tilde{\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] + \\lambda\\mathop{\\mathbb{E}}\\limits_{\\hat{\\mathbf{x}}\\sim\\mathbb{P}_{\\hat{\\mathbf{x}}}}\\left[(\\parallel\\nabla_{\\hat{\\mathbf{x}}}D(\\hat{\\mathbf{x}})\\parallel_2-1)^2\\right] \\] 其中\\(\\mathbb{P}_g\\)为生成器的分布，\\(\\mathbb{P}_r\\)为真实分布，\\(\\mathbb{P}_{\\hat{\\mathbf{x}}}\\)为真实数据和生成数据插值得到的分布。 \\[ \\hat{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_F\\left[\\sum\\limits_{w\\in\\mathcal{W}}(\\left|\\mathcal{T}(F,w)\\right|-\\eta\\mathcal{R}(F,w))\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] Training Procedure Buzz的训练过程与WGAN-GP类似， Detection 文中假设解码器的输出服从如下分布： \\[ p_\\theta(\\mathbf{x}|\\mathbf{z})=\\frac{1}{Z(\\lambda)}\\exp\\{-\\lambda\\parallel\\mathbf{x}-G(\\mathbf{z})\\parallel\\} \\] 作者定义异常分数为： \\[ \\mathcal{S}=\\log p_\\theta(\\mathbf{x})-\\log p_\\theta(\\bar{\\mathbf{x}}) \\] 其中\\(\\bar{\\mathbf{x}}\\)为经过MCMC填充后的样本。 异常分数也可以展开为： \\[ \\log\\frac{1}{L}\\sum\\limits_{l=1}^L\\left[\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z^{(l)}})p_\\theta(\\mathbf{z}^{(l)})}{q_\\phi(\\mathbf{z}^{(l)}|\\bar{\\mathbf{x}})}\\right]-\\log\\frac{1}{L}\\sum\\limits_{l=1}^L\\left[\\frac{p_\\theta(\\bar{\\mathbf{x}}|\\mathbf{z}^{(l)})p_\\theta(\\mathbf{z}^{(l)})}{q_\\phi(\\mathbf{z}^{(l)}|\\bar{\\mathbf{x}})}\\right] \\] 最终算法流程图为： Theoretical Analysis 在理论分析中，作者主要是想建立\\(\\mathcal{L}_{Buzz}\\)和VAE的损失函数\\(\\mathcal{L}_{vae}\\)之间的联系，损失函数\\(\\mathcal{\\hat{L}}_{Buzz}\\)为： \\[ \\hat{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_F\\left[\\sum\\limits_{w\\in\\mathcal{W}}(\\left|\\mathcal{T}(F,w)\\right|-\\eta\\mathcal{R}(F,w))\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] 为了便于分析，去掉Gradient Penalty的部分，公式可简化为： \\[ \\mathcal{L}_{Buzz}=-\\lambda\\mathbb{E}_{p(w)}W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] 实际上\\(Z(\\lambda)=\\mathfrak{S}_W\\Gamma(W)\\lambda^{-W}\\)，其中\\(\\mathfrak{S}_W\\)为\\(W\\)维单位球的表面积。 \\(n\\)维空间单位球表面积公式： \\[ \\omega_n=\\frac{2\\pi^{\\frac{n}{2}}}{\\Gamma(\\frac{n}{2})} \\] 而\\(W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]\\)为Wasserstein距离： \\[ W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]=\\sup\\limits_{Lip(f)\\leq 1}\\left\\{\\int_\\mathcal{X}f(\\mathbf{x})p(\\mathbf{x}|w)\\mathrm{d}\\mathbf{x}-\\int_\\mathcal{X}f(\\mathbf{y})p(\\mathbf{y}|w)\\mathrm{d}\\mathbf{y}\\right\\} \\] Lemma 1 通过设定具体形式的后验分布，VAE的损失函数可以写为： 设\\(\\mathbf{x}\\)的后验分布\\(p(\\mathbf{x}|\\mathbf{z})=\\frac{1}{Z(\\lambda)}\\exp\\{-\\lambda\\parallel\\mathbf{x}-G(\\mathbf{z})\\parallel\\}\\)，那么VAE的损失函数为： \\[ \\mathcal{L}_{vae}=\\lambda\\mathbb{E}_{p(w)}\\left[\\mathbb{E}_{p(\\mathbf{x}|w)}\\mathbb{E}_{p_G(\\mathbf{y}|\\mathbf{x})}-\\parallel\\mathbf{x}-\\mathbf{y}\\parallel\\right]-\\mathcal{K}-\\log{Z(\\lambda)} \\] 后验分布实际上是一个Laplace分布： Laplace Distribution: \\[ f(x|\\theta,\\lambda)=\\frac{1}{2\\lambda}\\exp{\\left(-\\frac{|x-\\theta|}{\\lambda}\\right)} \\] 可以直接把后验分布带入VAE的损失函数就得到了。 Lemma 2 \\(S_w\\)定义为数据空间\\(\\mathcal{X}\\)的一个partition，而\\(S=\\{(\\mathbf{x}_1,\\mathbf{x}_2)|\\exist w, \\mathbf{x}_1\\in S_w,\\mathbf{x}_2\\in S_w\\}\\)。 当\\(G,\\phi,\\lambda\\)固定时，\\(S\\downarrow\\)有\\(\\mathcal{L}_{Buzz}\\downarrow\\) Lemma 3 \\(\\max\\mathcal{L}_{Buzz}\\geq\\max{\\mathcal{L}_{vae}}\\)，同时，当\\(S\\downarrow\\text{diag}{\\mathcal{X}}\\)时\\(\\max\\mathcal{L}_{Buzz}\\downarrow\\max\\mathcal{L}_{vae}\\) Lemma 4 令\\(p^\\prime_G(\\mathbf{y}|\\mathbf{x})\\)表示\\(\\mathbb{E}_{q_{\\phi^\\prime}}\\left[p_G(\\mathbf{y}|\\mathbf{z})\\right]\\)。如果\\((G,\\phi,\\lambda)\\)是一个解，那么存在\\((G,\\phi^\\prime,\\lambda)\\)使得： \\[ \\mathbb{E}_{p(\\mathbf{x}|w)}\\mathbb{E}_{p_G^\\prime(\\mathbf{y}|\\mathbf{x})}\\parallel\\mathbf{x}-\\mathbf{y}\\parallel=W^1\\left[P(\\mathbf{x}|w)\\parallel P_G(\\mathbf{y}|w)\\right] \\] 此时\\(\\mathcal{L}_{Buzz}-\\mathcal{L}_{vae}^\\prime=\\mathcal{K}^\\prime-\\mathcal{K}\\)，其中\\(\\mathcal{L}^\\prime,\\mathcal{K}^\\prime\\)分别为\\((G,\\phi^\\prime,\\lambda)\\)时的\\(\\mathcal{L}\\)和\\(\\mathcal{K}\\)。 \\[ \\mathcal{L}^\\dagger_{Buzz}=\\mathbb{E}_{p(\\mathbf{x})}\\left[\\mathbb{E}_{q_{\\phi^\\prime}(\\mathbf{z}|\\mathbf{x})}\\log_{p_\\theta}(\\mathbf{x}|\\mathbf{z})\\right]-\\min\\limits_{\\bar{\\phi}\\sim\\phi^\\prime}\\bar{\\mathcal{K}} \\] Lemma 5 这里主要是想证明 对于固定的\\(w\\)，令： \\[ \\mathcal{F}=\\{f|Lip(f)\\leq 1\\}, \\space \\mathcal{F}^*=\\left\\{f|_{S_w}\\bigg|Lip(f|_{S_w})\\leq 1\\right\\} \\] 有\\(\\sup_{f\\in\\mathcal{F}}\\mathcal{T}(f)=\\sup_{f|_{S_w}\\in\\mathcal{F}^*}\\mathcal{T}^*\\left(f|_{S_w}\\right)\\)。 Theorem 6 \\(\\mathcal{L}_{Buzz}\\)的对偶形式为： \\[ \\mathcal{L}_{Buzz}=-\\lambda\\sup\\limits_{Lip(F;S)\\leq 1}\\mathbb{E}_{p(w)}\\mathcal{T}^*(F)-\\mathcal{K}-\\log Z(\\lambda) \\] 近似的\\(\\mathcal{L}_{Buzz}\\)的对偶形式为： \\[ \\bar{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_{Lip(F;S)\\leq 1}\\mathbb{E}_{p(w)}\\mathcal{T}(F)-\\mathcal{K}-\\log Z(\\lambda) \\] Experiment","link":"/2020/01/06/Unsupervised-Anomaly-Detection-for-Intricate-KPIs-via-Adversarial-Training-of-VAE/"},{"title":"Variational Approaches for Auto-Encoding Generative Adversarial Networks","text":"Abstract 本文揭示了对抗生成网络（Generative Adversarial Networks, GAN）和变分自编码器（Variational Auto-encoders, VAE）之间的联系，并据此提出了一种将两者结合的新模型。文中主要是将不可解的似然函数和未知的后验分布用一个非确定的分布（Immplicit Distribution）替代，并加入判别器来使得该分布逼近真实的分布。通过这个方法，作者将VAE中的损失函数进行了替换，变成了GAN中的“生成-判别”模式。 原文 Contribution 本文有如下贡献： 本文提出变分推断（Variational Inference）也能通过对非确定分布的估计应用在GAN中； 基于似然的模型（Likelihood-based Models）和非似然模型（Likelihood-free Models）能够通过对抗学习结合起来； 作者根据文中提出的新观点修改了VAE的损失函数，将其称之为Auto-encoding GAN (\\(\\alpha\\)-GAN)，并提出了对应的实用的改进； 本文与众多State-of-Art模型进行了对比 Methodology Overcoming Intractability in Generative Models Latent Variable Models 隐变量模型通过隐变量的形式描述了数据的产生过程。最简单的形式是假设隐变量\\(\\mathbf{z}\\)服从一个先验分布\\(\\mathbf{z}\\sim p(\\mathbf{z})\\)，而数据\\(\\mathbf{x}\\)从条件分布\\(p(\\mathbf{x}|\\mathbf{z})\\)抽样产生。通常来说描述\\(p(\\mathbf{x}|\\mathbf{z})\\)的模型称为生成器\\(\\mathcal{G}_\\theta(\\mathbf{z})\\)，带有可优化的参数\\(\\theta\\)，而\\(\\mathbf{z}\\)通常假设为正态分布\\(\\mathbf{z}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\)。 文中区分了两种隐变量模型，一种是Implicit Latent Variable Models，一种是Prescribed Latent Variable Models。文中的描述不太清楚，个人认为两者的区别是前者图模型中的\\(\\mathbf{x}\\)不是一个随机变量，在优化的时候需要用一个刻画生成的\\(\\mathbf{x}\\)和真实的\\(\\mathbf{x}\\)的差别的函数\\(\\delta(\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z}))\\)，而后者图模型中\\(\\mathbf{x}\\)是一个随机变量，这样可以写出似然函数用极大似然估计。 无论是GAN还是VAE都需要通过边缘分布\\(p_\\theta(\\mathbf{x})\\)来刻画建模的好坏，比如说根据\\(p_\\theta(\\mathbf{x})\\)与真实分布\\(p^*_\\theta(\\mathbf{x})\\)之间的KL散度\\(\\text{KL}\\left[p_\\theta(\\mathbf{x})\\parallel p_\\theta^*(\\mathbf{x})\\right]\\)。但通常情况下\\(p_\\theta(\\mathbf{x})\\)都是不可解的，而GAN和VAE通过不同的途径解决了这个问题。 Generative Adversarial Networks GAN没有直接计算\\(p_\\theta(\\mathbf{x})\\)，而是使用了一个判别器来判别样本是从\\(p_\\theta(\\mathbf{x})\\)还是\\(p_\\theta^*(\\mathbf{x})\\)采样得到的，如果判别器无法进行区分，那我们认为此时\\(p_\\theta(\\mathbf{x})\\approx p_\\theta^*(\\mathbf{x})\\)。 令随机变量\\(y\\in\\{0,1\\}\\)，\\(y=1\\)表示样本\\(\\mathbf{x}\\)来自真实分布，\\(y=0\\)表示样本\\(\\mathbf{x}\\)来自生成分布，而判别器的输出为\\(\\mathbf{x}\\)来自真实分布的概率\\(\\mathcal{D}_\\phi(\\mathbf{x})=p(y=1|\\mathbf{x})\\)。GAN通过对来自真实分布和生成分布的样本求二元交叉熵来作为判别器损失函数： \\[ \\textbf{Discriminator Loss: }\\mathbb{E}_{p^*(\\mathbf{x})}[-\\log\\mathcal{D}_\\phi(\\mathbf{x})]+\\mathbb{E}_{p_\\theta(\\mathbf{x})}[-\\log(1-\\mathcal{D}_\\phi(\\mathbf{x}))] \\] 生成器将最大化判别器对生成样本判定为真的概率作为损失函数，同时还有一个等价的但在实践中表现更好的替代版本： \\[ \\textbf{Generator Loss: }\\mathbb{E}_{p_\\theta(\\mathbf{x})}[\\log(1-\\mathcal{D}_\\phi(\\mathbf{x}))];\\textbf{ Alternative Loss: }\\mathbf{E}_{p_\\theta(\\mathbf{x})}[-\\log\\mathcal{D}_\\phi(\\mathbf{x})] \\] The Density Ratio Trick 令\\(p^*(\\mathbf{x})=p(\\mathbf{x}|y=1)\\)，\\(p_\\theta(\\mathbf{x})=p(\\mathbf{x}|y=0)\\)。定义Density Ratio \\(r_\\phi(\\mathbf{x})\\)为真实分布和生成分布之间的比例： \\[ r_\\phi(\\mathbf{x})=\\frac{p^*(\\mathbf{x})}{p_\\theta(\\mathbf{x})}=\\frac{p(\\mathbf{x}|y=1)}{p(\\mathbf{x}|y=0)}=\\frac{p(y=1|\\mathbf{x})}{p(y=0|\\mathbf{x})}=\\frac{\\mathcal{D}_\\phi(\\mathbf{x})}{1-\\mathcal{D}_\\phi(\\mathbf{x})} \\] 上式表明了Density Ratio的计算可以仅通过从两个分布上采样得到的样本加上一个二分类器\\(\\mathcal{D}_\\phi(\\mathbf{x})\\)实现（假设\\(p(y=0)=p(y=1)\\)）。更深入的说，对于不可解的分布\\(p_\\theta^*(\\mathbf{x})\\)，我们可以通过计算Density Ratio来了解我们近似的分布\\(p_\\theta(\\mathbf{x})\\)和真实的\\(p_\\theta^*(\\mathbf{x})\\)之间的相对性。而且我们只需要能够在两个分布上进行采样，并且训练一个判别器即可。因为判别器是一个普通的分类器，所以大量的主流分类器都可以使用。 Variational Inference 现在来看VAE，另一种解决不可解分布的方法是近似。Variational Inference通过引入一个变分分布\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)推出了不可解的\\(\\mathbf{x}\\)的对数似然的下界（常被称为证据下界ELBO）： \\[ \\log p_\\theta(\\mathbf{x})=\\log\\int p_\\theta(\\mathbb{x}|\\mathbb{z})p(\\mathbf{z})\\text{d}\\mathbf{z}\\geq \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})\\right]-\\text{KL}\\left[q_\\eta(\\mathbf{z}|\\mathbf{x})\\parallel p(\\mathbf{z})\\right]=\\mathcal{F}(\\boldsymbol{\\theta}, \\boldsymbol{\\eta}) \\] VAE是Variational Inference的一种实现，变分分布通过一个神经网络进行建模，并且建立起了完整的可优化的模型。 Synthetic Likelihood 当似然函数未知（GAN中没有显式的似然函数，而VAE中有）的时候，Variational Inference便无法直接使用。对于没有显式的似然函数的情况，以VAE的ELBO的第一项为例，假设\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)分布的具体形式未知，我们只有从\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)采样得到的样本，如何计算\\(\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]\\)呢？一个方法是乘以\\(p_\\theta^*(\\mathbf{x})\\)再除以\\(p_\\theta^*(\\mathbf{x})\\)： \\[ \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z})}{p^*(\\mathbf{x})}\\right]+\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p^*(\\mathbf{x})] \\] 公式(5)中的第一项包括了合成似然\\(R(\\theta)=\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z})}{p^*(\\mathbf{x})}\\)，优化\\(R(\\theta)\\)相当于优化\\(\\log p_\\theta(\\mathbf{x}|\\mathbf{z})\\)。第二项与生成网络的参数\\(\\theta\\)无关，所以在优化的时候可以忽略。 A Fusion of Variational and Adversarial Learning GAN和VAE分别从不同的角度解决了生成模型的推断问题，我们下面从VAE出发，考虑将两者结合起来。 Implicit Variational Distributions 变分推断Variational Inference的主要任务就是确定\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)，通常的做法如Mean-field Variational Inference会假设一个简单的分布，如高斯分布。在本文中不对\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)的形式作假设，仅假设其为一个隐含的分布。运用上文提到的Density Ratio Trick，我们可以将VAE损失函数中的第二项改写为： \\[ -\\text{KL}[q_\\eta(\\mathbf{z}|\\mathbf{x})\\parallel p(\\mathbf{z})]=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{p(\\mathbf{z})}{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\right]\\approx\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}{1-\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}\\right] \\] 文中引入了一个隐变量分类器（Latent Classifier）\\(\\mathcal{C}_{\\boldsymbol{\\omega}}(\\mathbf{z})\\)，用来判别\\(\\mathbf{z}\\)是从编码网络还是从标准高斯分布中采样得到的（猜测这样做的好处是不用再对\\(\\mathbf{z}\\)的后验做高斯分布的假设了，也不需要在变分网络输出形成的高斯分布上采样得到\\(\\mathbf{z}\\)了，这样重参数技巧也省了）。具体实现上，期望可以用蒙特卡洛方法（采样多次取均值）进行计算。 Likelihood Choice 对于VAE损失函数第一项，对应生成网络，我们可以选择对\\(p(\\mathbf{x}|\\mathbf{z})\\)分布的具体形式做假设， 这样对应Likelihood-based的情况。文中选择的是Zero-mean Laplace Distribution \\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\propto\\exp(-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1)\\)（不就是\\(L_1\\) Loss吗？？？）。 对于Likelihood-free的情况，可以继续使用上面提到的Density Ratio Trick，这时需要加一个一个判别器。 \\[ \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1\\right]\\space\\space\\text{ or }\\space\\space\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}{1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}\\right] \\] 对于两种选择，前者对应VAE，好处是不会出现模式崩溃的情况，后者对应GAN，容易出现模式崩溃的情况，但是可以使用对抗学习的方式（这是优点？？？），本文选择两种都用（我全都要.jpg）。 Hybrid Loss Functions 将前面的讨论结合起来，最后的损失函数就是： \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\eta})=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1+\\log\\frac{\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}{1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}+\\log\\frac{\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}{1-\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}\\right] \\] 最后模型包含四个网络：生成网络\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)、推断网络\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)以及两个判别器\\(\\mathcal{C}_{\\boldsymbol{\\omega}}\\)和\\(\\mathcal{D}_\\phi\\)，作者将其命名为\\(\\alpha\\)-GAN。 算法流程如下： Improved Techniques 作者为了改进模型的稳定性和效率，将生成器的Loss中的\\(-\\log(1-\\mathcal{D}_\\phi)\\)修改为了\\(\\log\\mathcal{D}_\\phi-\\log(1-\\mathcal{D}_\\phi)\\)，并声称这样能提供非饱和（Non-saturating）的梯度： \\[ \\textbf{Generator Loss: } \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1-\\log\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))+\\log(1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z})))\\right] \\] 作者认为在生成器损失函数中加入\\(\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1\\)能够在一定程度防止模式崩溃。 除此之外，作者发现将真实样本（原文是The Samples）作为生成的样本输入到判别器中能够提升性能。作者给出的解释是根据Jensen不等式：\\(\\log p_\\theta(\\mathbf{x})=\\log\\int p_\\theta(\\mathbf{x}|\\mathbf{z})p(\\mathbf{z})\\text{d}\\mathbf{z}\\geq \\mathbb{E}_{p(\\mathbf{z})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]\\)， [TODO] Related Work [TODO] Experiments [TODO] Metrics 本文使用了几种不同的评测生成模型的方法： Inception Score: Multi-scale Structural Similarity (MS-SSIM): Independent Wasserstein Critic: Results on ColorMNIST Results on CelebA Results on CIFAR-10","link":"/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/"},{"title":"Anomaly Detection in Streams with Extreme Value Theory","text":"Introduction 本文基于Extreme Value Theory提出了一种不需要手动设置阈值也不需要对数据分布作任何假设的时间序列异常检测方法。除此之外，本方法可以用在通用的自动阈值选择的场合中。 原文 Background 在很多情况下我们需要进行阈值的选择。阈值的选择可以通过实验的方法或者对数据分布进行假设的方法来得到，不过这样做通常不准确。借助Extreme Value Theory我们可以在不需要对原始数据的分布作很强的假设的情况下，推断我们想要的极端事件的分布（在异常检测中就是异常值）。 下面给出一些数学符号，\\(X\\)为随机变量，\\(F\\)为累积分布函数，即\\(F(x)=\\mathbb{P}(X\\leq x)\\)。记\\(F\\)的“末尾”分布\\(\\bar{F}(x)=1-F(x)=\\mathbb{P}(X&gt;x)\\)。对于一个随机变量\\(X\\)和给定的概率\\(q\\)，记\\(z_q\\)为在\\(1-q\\)水平的分位数，即\\(z_q\\)为满足\\(\\mathbb{P}(X\\leq z_q)\\geq 1-q\\)最小的值。 Extreme Value Distributions Extreme Value Theory主要是为了找出极端事件发生的规律，有学者证明，在很弱的条件下，所有极端事件都服从一个特定的分布，而不管原始分布如何。具体形式如下： \\[ G_\\gamma:x\\mapsto \\exp(-(1+\\gamma x)^{-\\frac{1}{\\gamma}}), \\space\\space\\space\\space\\space\\gamma\\in\\mathbb{R}, \\space\\space\\space\\space\\space 1+\\gamma x&gt;0 \\] 其中\\(\\gamma\\)称为Extreme Value Index，由原始分布决定。 更严谨的说法是Fisher-Tippett-Gnedenko定理（极值理论第一定理）： THEOREM: (Fisher-Tippett-Gnedenko). 令\\(X_1,X_2,\\cdots,X_n,\\cdots\\)为独立同分布的随机变量序列，\\(M_n=\\max \\{X_1,\\cdots,X_n\\}\\)。如果实数对序列\\((a_n,b_n)\\)存在且满足\\(a_n&gt;0\\)和\\(\\lim\\limits_{n\\rightarrow \\infty}P\\left(\\frac{M_n-b_n}{a_n}\\leq x\\right)=F(x)\\)，其中\\(F\\)为非退化分布函数，那么\\(F\\)属于Gumbel、Fréchet或Weibull分布族（或总称Generalized Extreme Value Distribution）中的一种。 这是一个反直觉的结论，但是想到当事件发生变得极端时，即\\(\\mathbb{P}(X&gt;x)\\rightarrow 0\\)，\\(\\bar{F}(x)=\\mathbb{P}(X&gt;x)\\)分布的形状其实并没有很多种选择。Table 1展示了几种不同分布对应的\\(\\gamma\\)： Figure 1展示了几种不同\\(\\gamma\\)情况下的“末尾”分布： Power of EVT 根据Extreme Value Theory，我们可以在原始分布未知的情况下计算极端事件的概率。但是\\(\\bar{G}_\\gamma\\)分布中参数\\(\\gamma\\)是未知的，我们需要一种高效的方法来进行估计。The Peaks-Over-Threshold (POT) 方法是本文介绍的一种方法。 Peaks-Over-Threshold Approach POT方法依赖于Pickands-Balkema-De Haan定理（极值理论第二定理），维基百科版： 考虑一个未知分布\\(F\\)和随机变量\\(X\\)，我们的目标是估计\\(X\\)在超过确定阈值\\(u\\)下的条件分布\\(F_u\\)，定义为： \\[ F_u(y)=P(X-u\\leq y|X&gt;u)=\\frac{F(u+y)-F(u)}{1-F(u)} \\] 其中\\(0\\leq y\\leq x_F-u\\)，\\(x_F\\)为\\(F\\)的右端点。\\(F_u\\)描述了超过特征阈值\\(u\\)的分布，称为Conditional Excess Distribution Function。 STATEMENT: (Pickands-Balkema-De Haan). 设\\((X_1,X_2,\\cdots)\\)为独立同分布随机变量序列，\\(F_u\\)为相应的Conditional Excess Distribution Function。对于一大类的\\(F\\)和很大的\\(u\\)，\\(F_u\\)能够很好的被Generalized Pareto Distribution所拟合： \\[ F_u(y)\\rightarrow G_{k,\\sigma}(y),\\space\\space \\text{as } u\\rightarrow \\infty \\] 其中： \\[ G_{k,\\sigma}(y)= \\begin{cases} 1-(1+ky/\\sigma)^{-1/k}, &amp;\\text{if }k\\neq 0\\\\ 1-e^{-y/\\sigma}, &amp;\\text{if }k=0 \\end{cases} \\] 当\\(k\\geq 0\\)时\\(\\sigma&gt;0, y\\geq 0\\)，\\(k&lt;0\\)时\\(0\\leq y\\leq -\\sigma/k\\)。 论文中给出的定理如下： THEOREM: (Pickands-Balkema-De Haan). 累积概率密度函数\\(F\\in\\mathcal{D}_\\gamma\\)当且仅当函数\\(\\sigma\\)存在时，对所有\\(x\\in\\mathbb{R}\\)在\\(1+\\gamma x&gt;0\\)的条件下有： \\[ \\frac{\\bar{F}(t+\\sigma(t)x)}{\\bar{F}(t)}\\mathop{\\rightarrow}\\limits_{t\\rightarrow\\tau}(1+\\gamma x)^{-\\frac{1}{\\gamma}} \\] 上式可以写成如下形式： \\[ \\bar{F}_t(x)=\\mathbb{P}(X-t&gt;x|X&gt;t)\\mathop{\\sim}\\limits_{t\\rightarrow\\tau}\\left(1+\\frac{\\gamma x}{\\sigma(t)}\\right)^{-\\frac{1}{\\gamma}} \\] 该式表明\\(X\\)超过阈值\\(t\\)的概率（写为\\(X-t\\)）服从Generalized Pareto Distribution (GPD)，参数为\\(\\gamma\\)和\\(\\sigma\\)。POT主要是拟合GPD而不是EVT分布。 如果我们要估计参数\\(\\hat{\\gamma}\\)和\\(\\hat{\\sigma}\\)，分位数可以通过下式计算得到： \\[ z_q\\simeq t+\\frac{\\hat{\\sigma}}{\\hat{\\gamma}}\\left(\\left(\\frac{qn}{N_t}\\right)^{-\\hat{\\gamma}}-1\\right) \\] 其中\\(t\\)是一个“很高”的阈值，\\(q\\)是给定的概率值，\\(n\\)是所有观测样本的数量，\\(N_t\\)是peaks的数量，即\\(X_i&gt;t\\)的数量。为了进行高效的参数估计，文中使用了极大似然估计。 Maximum Likelihood Estimation 设\\(X_1,\\cdots,X_n\\)为独立同分布的随机变量，概率密度函数记为\\(f_\\theta\\)，\\(\\theta\\)为分布中的参数，那么似然函数可以写为： \\[ \\mathcal{L}(X_1,\\cdots,X_n;\\theta)=\\prod\\limits_{i=1}^n f_\\theta(X_i) \\] 在极大似然估计中，我们需要找到合适的参数使得似然函数最大化。在我们的问题中，似然函数如下： \\[ \\log\\mathcal{L}(\\gamma,\\sigma)=-N_t\\log\\sigma-\\left(1+\\frac{1}{\\gamma}\\right)\\sum\\limits_{i=1}^{N_t}\\log\\left(1+\\frac{\\gamma}{\\sigma}Y_i\\right) \\] 其中\\(Y_i&gt;0\\)表示\\(X_i\\)超过阈值\\(t\\)的部分。 文中使用了Grimshaw's Trick来将含两个参数的优化问题转换为只含一个参数的优化问题。记\\(\\ell(\\gamma,\\sigma)=\\log\\mathcal{L}(\\gamma,\\sigma)\\)，对于所有极值来说有\\(\\nabla \\ell(\\gamma, \\sigma)=0\\)。Grimshaw's Trick表明对于满足\\(\\nabla \\ell(\\gamma, \\sigma)=0\\)的一对\\((\\gamma^*,\\sigma^*)\\)，\\(x^*=\\frac{\\gamma^*}{\\sigma^*}\\)为等式\\(u(X)v(X)=1\\)的解，其中： \\[ \\begin{align} u(x)&amp;=\\frac{1}{N_t}\\sum\\limits_{i=1}^{N_t}\\frac{1}{1+xY_i}\\\\ v(x)&amp;=1+\\frac{1}{N_t}\\sum\\limits_{i=1}^{N_t}\\log(1+xY_i) \\end{align} \\] 在找到满足该等式的解\\(x^*\\)后，我们可以得到\\(\\gamma^*=v(x^*)-1\\)和\\(\\sigma^*=\\gamma^*/x^*\\)，于是问题就变成了如何寻找方程的所有根。 因为\\(\\log\\)的存在，所以有\\(1+xY_i&gt;0\\)。而\\(Y_i\\)是正数，所以\\(x^*\\)的范围一定在\\(\\left(-\\frac{1}{Y^M},+\\infty\\right)\\)，其中\\(Y^M=\\max Y_i\\)。 Grimshaw（作者参考的一篇论文）还给出了一个上界： \\[ x^*_{\\text{max}}=2\\frac{\\bar{Y}-Y^m}{(Y^m)^2} \\] 其中\\(Y^m=\\min Y_i\\)，\\(\\bar{Y}\\)为\\(Y_i\\)的均值。详细的优化方法会在下文讨论。 背景部分到此结束，接下来的部分就是作者提出的新方法。 Methodology Extreme Value Theory给出了在对原始分布未知的情况下估计使得\\(\\mathbb{P}(X&gt;z_q)&lt;q\\)的\\(z_q\\)的方法。 本文据此提出了时间序列流的异常检测方法。首先根据已知的观测值\\(X_1,\\cdots,X_n\\)得到阈值\\(z_q\\)，然后根据数据的特性运用两种不同方法来更新\\(z_q\\)。对于平稳时间序列，使用SPOT；对于非平稳时间序列，使用DSPOT。 Initialization Step 在进行异常检测之前，需要根据已有的观测数据进行\\(z_q\\)的估计。给定\\(n\\)个观测值\\(X_1,\\cdots,X_n\\)和一个固定的概率值\\(q\\)，我们的目标是估计阈值\\(z_q\\)使得\\(\\mathbb{P}(X&gt;z_q)&lt;q\\)。其主要流程是首先设定一个较大的阈值\\(t\\)，然后通过拟合GPD分布来计算\\(z_q\\)。过程如下图所示： 算法流程如下所示： \\(Y_t\\)代表大于\\(t\\)的观测值的集合，GPD分布的拟合使用了前文提到的Grimshaw's Trick。 Finding Anomalies in a Stream 通过Initialization Step使用POT算法得到的\\(z_q\\)，我们定义其为&quot;Normality Bound&quot;，用于后面的检测。在后面的步骤中，我们会根据新得到的观测值来更新\\(z_q\\)。 Stationary Case 我们首先来讨论时间序列没有时间依赖性的情况（\\(X_1,\\cdots,X_n\\)之间独立同分布）。通过POT算法对所有观测值得到\\(z_q\\)之后，Streaming POT (SPOT) 算法会检查\\(X_n\\)之后的值（数据流场景，\\(X_1,\\cdots,X_n\\)是历史数据，还会有新的数据进来），如果大于\\(z_q\\)，则将\\(X_i\\)加入异常点集合中；如果大于\\(t\\)但小于\\(z_q\\)，则将\\(X_i\\)加入观测值集合中，更新\\(z_q\\)；其他情况我们\\(X_i\\)是正常情况。算法流程图如下： Drifting Case SPOT算法只适用于平稳分布的情况，但在现实生活中这样的假设过强了。于是作者提出了能处理时间依赖性的Streaming POT with Drift (DSPOT) 算法。 在DSPOT中，我们不使用\\(X_i\\)的绝对值，而是用相对值\\(X^\\prime_i=X_i-M_i\\)，其中\\(M_i\\)是\\(i\\)时刻的局部特征，如Figure 4所示。最简单的实现是使用局部均值，即\\(M_i=(1/d)\\cdot\\sum\\limits_{k=1}^d X_{i-k}^*\\)，\\(X_{i-1}^*,\\cdots,X_{i-d}^*\\)是长度为\\(d\\)的窗口。我们假设\\(X^\\prime_i\\)服从平稳分布的假设。 算法流程图如下所示： Numerical Optimization 现在剩下的问题就是优化了，前文已经提到对GPD的拟合已经被优化成一个参数的优化问题，下面将会详细讨论优化算法。 Reduction of the Optimal Parameters Search 前文已经得到了一个初步的\\(x^*\\)的Bound，即\\(x^*&gt;-\\frac{1}{Y^M}\\)和\\(x^*\\leq 2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\)，下面将给出一个更严格的Bound。 PROPOSITION: 如果\\(x^*\\)是\\(u(x)v(x)=1\\)的解，那么： \\[ x^*\\leq 0 \\text{ or } x^*\\geq 2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m} \\] 证明见论文原文。 这样\\(x^*\\)的范围就进一步缩小了，于是有\\(u(x)v(X)=1\\)的解\\(x^*\\)在以下范围之内： \\[ \\left(-\\frac{1}{Y^M},0\\right]\\text{ and }\\left[2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m},2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\right] \\] How Can We Maximize the Likelihood Function? 接下来是优化的具体实现问题。文中首先设定了一个很小的值\\(\\epsilon&gt;0\\space(\\sim 10^{-8})\\)，然后在下面的范围内寻找函数\\(w:x\\mapsto u(x)v(x)-1\\)的根： \\[ \\left[-\\frac{1}{Y^M}+\\epsilon,-\\epsilon\\right]\\text{ and }\\left[2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m},2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\right] \\] 作者没有使用现有的寻找函数根的算法，而是转换为如下优化问题： \\[ \\min\\limits_{x_1,\\cdots,x_k\\in I}\\sum\\limits_{i=1}^k w(x_k)^2 \\] 其中\\(I\\)就是\\(x^*\\)的Bound。该问题是一个很典型的优化问题，可以被很多成熟的算法所解决。 Initial Threshold 在算法的Initialization Step，需要事先设定一个阈值\\(t\\)，如果设定的太大，那么\\(Y_t\\)的数量就会很少。作者给出的建议是保证\\(t&lt;z_q\\)，即\\(t\\)对应的概率值应该小于\\(1-q\\)。 Experiments 在实验部分，作者在合成数据和真实数据上试验了SPOT算法和DSPOT算法的有效性。 (D)SPOT Reliability 作者首先在合成数据上验证SPOT的有效性。具体做法是使用高斯分布生成数据（高斯分布的分位数能够直接计算），然后将SPOT得出的\\(z_q\\)和理论值进行对比。误差定义如下： \\[ \\text{error rate}=\\left|\\frac{z^{\\text{SPOT}}-z^{\\text{th}}}{z^{\\text{th}}}\\right| \\] 下图是采用不同数量观测值的结果： Finding Anomalies with SPOT 在这一节作者在真实数据集上进行了实验以验证SPOT算法的有效性，结果如下图： 在文中作者说算法的True Positive达到了\\(86\\%\\)，False Positive小于\\(4\\%\\)。 Finding Anomalies with DSPOT 在这一节作者使用DSPOT在真实数据集上进行了实验。窗口大小\\(d=450\\)，预设的风险概率值\\(q=10^{-3}\\)。结果如下图所示： 在图中可以看出在\\(8000\\) Minutes之后上界显著提高，作者分析了原因，认为是因为超过阈值\\(t\\)的点\\(Y_t\\)的存储是全局的，在前\\(8000\\) Minutes算法存储了很多较高的\\(Y_t\\)值，而在\\(8000\\) Minutes之后，真实数据的趋势开始下降，但算法仍是根据全局的\\(Y_t\\)来进行\\(z_q\\)的计算（这一段没有特别明白）。作者给出的修正方法是只保存固定数量的Peaks。 下图是作者在股票数据上得到的实验结果： Performances 作者还验证了算法的时间效率。 表中T代表的是每个Iteration的时间，M代表的是Peaks的比例，&quot;bi-&quot;前缀代表的是同时计算上界和下界。","link":"/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/"},{"title":"Complementary Set Variational Autoencoder for Supervised Anomaly Detection","text":"Introduction 对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。 Proposed Model Conventional VAE 首先回顾一下原始的VAE。 原始VAE中的损失函数为： \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})=\\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})}[\\log p(\\boldsymbol{x}|\\boldsymbol{z};\\boldsymbol{\\theta})]-\\text{KL}[q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi}\\parallel p(\\boldsymbol{z}))] \\] 原文中作者证明了\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\leq\\log p(\\boldsymbol{x};\\boldsymbol{\\theta})\\)，所以\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\)可以看作是数据分布\\(p(\\boldsymbol{x})\\)对数似然的一个下界。\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\)又被称为证据下界 (ELBO)。\\(\\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})}[\\log p(\\boldsymbol{x}|\\boldsymbol{z};\\boldsymbol{\\theta})]\\)中的期望一般用蒙特卡洛来进行估计： \\[ \\begin{align} \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\simeq&amp; \\frac{1}{L}\\sum\\limits_l\\log p(\\boldsymbol{x}|\\boldsymbol{z}^{(l)};\\boldsymbol{\\theta})-\\text{KL}[q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})\\parallel p(\\boldsymbol{z})],\\\\ \\boldsymbol{z}^{(l)}&amp;\\sim q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi}), \\space l\\in\\{1,2,\\cdots,L\\} \\end{align} \\] 对于隐变量\\(\\boldsymbol{z}\\)，一般假设先验服从标准高斯分布，后验服从均值为\\(\\mu\\)，方差为\\(\\sigma^2\\)的高斯分布，故KL散度能直接写出解析式： \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\simeq \\frac{1}{L}\\sum\\limits_l\\log p(\\boldsymbol{x}|\\boldsymbol{z}^{(l)};\\boldsymbol{\\theta})-C(-\\frac{1}{2}-\\log\\sigma+\\frac{1}{2}\\sigma^2+\\frac{1}{2}\\mu^2) \\] 使用VAE来做异常检测通常是在正常数据上进行训练，在检测阶段，如果是异常样本，那么VAE不能很好地重构它，这样会导致较大的重构误差。 Prior Distribution for Anomalies 在原始VAE异常检测中，无论输入样本\\(\\boldsymbol{x}\\)是否异常，VAE都会使对应编码的后验\\(p(\\boldsymbol{z}|\\boldsymbol{x})\\)服从高斯分布，且施加标准高斯分布的约束。在本文中，作者对异常和正常样本对应的隐变量的先验分布做了不同假设。首先，正常先验依然是标准高斯分布，记为\\(p_n(\\boldsymbol{z})\\)。而对于异常先验，作者认为异常即为“不正常”，和正常是补集的关系。作者在文中定义异常先验分布\\(p_a(\\boldsymbol{z})\\)为： \\[ p_a(\\boldsymbol{z})=\\frac{1}{Y^\\prime}(\\max\\limits_{\\boldsymbol{z}^\\prime}p_n(\\boldsymbol{z}^\\prime)-p_n(\\boldsymbol{z})) \\] 其中\\(Y^\\prime\\)为使\\(p_a(\\boldsymbol{z})\\)成为一个概率分布的调节因子。实际上，\\(Y^\\prime\\)往往会成为无限大，因为\\(p(\\boldsymbol z)\\)在整个定义域上都有定义。为了解决这个问题，作者加入了\\(p_w(\\boldsymbol z)\\)，一个在每个维度都足够宽的辅助分布： \\[ p_a(\\boldsymbol z)=\\frac{1}{Y}p_w(\\boldsymbol z)\\left(\\max\\limits_{\\boldsymbol z^\\prime}p_n(\\boldsymbol z^\\prime)-p_n(\\boldsymbol z)\\right) \\] 其中\\(Y\\)为有限的常数。在文中\\(p_n(\\boldsymbol z)\\)和\\(p_w(\\boldsymbol z)\\)都为高斯分布，那么\\(p_a(\\boldsymbol z)\\)的具体形式为： \\[ p_a(\\boldsymbol z)=\\frac{1}{Y}\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\{\\max\\limits_{\\boldsymbol z^\\prime}\\mathcal N(\\boldsymbol z^\\prime;\\boldsymbol 0,\\boldsymbol 1)-\\mathcal N(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol 1)\\} \\] 其中： \\[ \\max\\limits_{\\boldsymbol z^\\prime}\\mathcal N(\\boldsymbol z^\\prime;\\boldsymbol 0,\\boldsymbol 1)=\\frac{1}{\\sqrt{2\\pi}} \\] \\[ Y=\\int_{-\\infty}^{\\infty}p_a(\\boldsymbol z)\\mathrm{d}\\boldsymbol z=\\frac{1}{\\sqrt{2\\pi}}\\left\\{1-\\frac{1}{\\boldsymbol s^2+1}\\right\\} \\] \\(\\boldsymbol s^2\\)为超参数，控制分布的宽度。用文中的先验替换VAE原始的KL散度，可写为： \\[ \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]=\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\frac{\\mathcal N(\\boldsymbol z;\\boldsymbol\\mu,\\boldsymbol\\sigma^2)}{\\frac{1}{Y}\\mathcal N(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\left\\{\\frac{1}{2\\pi}-\\mathcal N(\\boldsymbol z;\\boldsymbol0,\\boldsymbol 1)\\right\\}}\\mathrm{d}\\boldsymbol z \\] 展开后： \\[ \\begin{align} \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]&amp;= \\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\mathcal{N}(\\boldsymbol z;\\boldsymbol\\mu,\\boldsymbol\\sigma^2)\\mathrm{d}\\boldsymbol z\\\\ &amp;+\\log Y\\\\ &amp;-\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\mathrm{d}\\boldsymbol z\\\\ &amp;-\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\left\\{\\frac{1}{\\sqrt{2\\pi}}-\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0, \\boldsymbol 1)\\right\\}\\mathrm{d}\\boldsymbol z \\end{align} \\] 使用泰勒展开，\\(\\log (x+\\frac{1}{2\\pi})\\simeq-\\log 2\\pi+2\\pi x\\)，KL散度可以用下式估计： \\[ \\begin{align} \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]&amp;\\simeq\\sqrt{\\frac{2\\pi}{\\boldsymbol\\sigma^2+1}}\\exp\\left(\\frac{-\\boldsymbol\\mu^2}{2(\\boldsymbol\\sigma^2+1)}\\right)\\\\ &amp;+\\frac{\\boldsymbol\\mu^2+\\boldsymbol\\sigma^2}{2\\boldsymbol s^2}-\\log\\boldsymbol\\sigma+\\log\\boldsymbol s+\\log\\left(\\sqrt{\\boldsymbol s^2+1}-1\\right)\\\\ &amp;-\\frac{\\log(\\boldsymbol s^2+1)}{2}+\\frac{\\log(2\\pi)-1}{2} \\end{align} \\] 下图为一维时\\(p_n(\\boldsymbol z)\\)和\\(p_a(\\boldsymbol z)\\)的示例： Implementation of proposed method 文中使用编码器输出的分布\\(\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu, \\boldsymbol \\sigma^2)\\)与标准正态分布之间的KL散度来作为异常分数。在每一轮的训练过程中，加入一轮使用Anomaly Prior的训练。 Experiments MNIST 作者设计了两个Task： Task 1. \\(N\\) vs. \\(\\bar{N}\\). 将手写数字中的一个作为已知异常，其他作为正常，并加入均匀分布作为未知的异常。 Task 2. 手写数字被分为3组：已知异常，正常，未知异常。 细节如下表所示： 在实现上，使用Adam优化器，batch_size为100，epochs为200。Encoder和Decoder都由三层感知机组成，超参数\\(s^2\\)设置为400。评测标准使用AUC (area under the receiver characteristic curve)。 下表为实验结果：","link":"/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"}],"tags":[{"name":"Time Series","slug":"Time-Series","link":"/tags/Time-Series/"},{"name":"Anomaly Detection","slug":"Anomaly-Detection","link":"/tags/Anomaly-Detection/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"VAE","slug":"VAE","link":"/tags/VAE/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"Flow-based Model","slug":"Flow-based-Model","link":"/tags/Flow-based-Model/"},{"name":"Transfer Learning","slug":"Transfer-Learning","link":"/tags/Transfer-Learning/"},{"name":"Variational Inference","slug":"Variational-Inference","link":"/tags/Variational-Inference/"},{"name":"Spectral","slug":"Spectral","link":"/tags/Spectral/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"}],"categories":[{"name":"Research","slug":"Research","link":"/categories/Research/"},{"name":"Misc","slug":"Research/Misc","link":"/categories/Research/Misc/"},{"name":"Anomaly Detection","slug":"Research/Anomaly-Detection","link":"/categories/Research/Anomaly-Detection/"},{"name":"Time Series Imputation","slug":"Research/Time-Series-Imputation","link":"/categories/Research/Time-Series-Imputation/"},{"name":"Technical Notes","slug":"Technical-Notes","link":"/categories/Technical-Notes/"},{"name":"RNN","slug":"Research/RNN","link":"/categories/Research/RNN/"},{"name":"Tutorial","slug":"Research/Tutorial","link":"/categories/Research/Tutorial/"},{"name":"GAN","slug":"Research/GAN","link":"/categories/Research/GAN/"},{"name":"Misc","slug":"Technical-Notes/Misc","link":"/categories/Technical-Notes/Misc/"}]}