{"pages":[],"posts":[{"title":"An Introduction to Variational Autoencoders","text":"Deep Generative Models ç”Ÿæˆæ¨¡å‹æ˜¯æŒ‡ä¸€ç³»åˆ—ç”¨äºéšæœºç”Ÿæˆå¯è§‚æµ‹æ•°æ®çš„æ¨¡å‹ã€‚å‡è®¾åœ¨ä¸€ä¸ªé«˜ç»´ç©ºé—´\\(\\mathcal{X}\\)ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªéšæœºå‘é‡\\(\\mathbf{X}\\)æœä»ä¸€ä¸ªæœªçŸ¥çš„åˆ†å¸ƒ\\(p_r(x),x\\in \\mathcal{X}\\)ã€‚ç”Ÿæˆæ¨¡å‹å°±æ˜¯æ ¹æ®ä¸€äº›å¯è§‚æµ‹çš„æ ·æœ¬\\(x^{(1)},x^{(2)},\\cdots,x^{(N)}\\)æ¥å­¦ä¹ ä¸€ä¸ªå‚æ•°åŒ–çš„æ¨¡å‹\\(p_\\theta(x)\\)æ¥è¿‘ä¼¼æœªçŸ¥åˆ†å¸ƒ\\(p_r(x)\\)ã€‚ ç”Ÿæˆæ¨¡å‹ä¸»è¦ç”¨äºå¯†åº¦ä¼°è®¡å’Œæ ·æœ¬ç”Ÿæˆã€‚ å¯†åº¦ä¼°è®¡å³ç»™å®šä¸€ç»„æ•°æ®\\(\\mathcal{D}=\\{x^{(i)}\\},1\\leq i\\leq N\\)ï¼Œå‡è®¾ä»–ä»¬éƒ½æ˜¯ä»ç›¸åŒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°\\(p_r(x)\\)ç‹¬ç«‹äº§ç”Ÿçš„ã€‚å¯†åº¦ä¼°è®¡å°±æ˜¯æ ¹æ®æ•°æ®é›†\\(\\mathcal{D}\\)æ¥ä¼°è®¡å…¶æ¦‚ç‡å¯†åº¦å‡½æ•°\\(p_r(x)\\)ã€‚ å¦‚æœå°†ç”Ÿæˆæ¨¡å‹ç”¨äºç›‘ç£å­¦ä¹ ï¼Œé‚£ä¹ˆå°±æ˜¯è¾“å‡ºæ ‡ç­¾çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ\\(p(y|x)\\)ï¼Œæ ¹æ®è´å¶æ–¯å…¬å¼ï¼š \\[p(y|x)=\\frac{p(x,y)}{\\sum_y p(x,y)}\\] é—®é¢˜å°±å˜ä¸ºäº†è”åˆæ¦‚ç‡\\(p(x,y)\\)çš„å¯†åº¦ä¼°è®¡é—®é¢˜ã€‚ æ ·æœ¬ç”Ÿæˆå³æ ¹æ®ç»™å®šçš„æ¦‚ç‡åˆ†å¸ƒ\\(p_\\theta(x)\\)ç”Ÿæˆä¸€äº›æœä»è¿™ä¸ªåˆ†å¸ƒçš„æ ·æœ¬ï¼Œå³é‡‡æ ·ã€‚åœ¨å«éšå˜é‡çš„ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œç”Ÿæˆ\\(x\\)çš„è¿‡ç¨‹ä¸€èˆ¬åŒ…å«ä¸¤æ­¥ï¼š æ ¹æ®éšå˜é‡çš„åˆ†å¸ƒ\\(p_\\theta(z)\\)é‡‡æ ·å¾—åˆ°\\(z\\)ï¼› æ ¹æ®æ¡ä»¶åˆ†å¸ƒ\\(p_\\theta(x|z;\\theta)\\)è¿›è¡Œé‡‡æ ·å¾—åˆ°\\(x\\)ã€‚ æ‰€ä»¥åœ¨ç”Ÿæˆæ¨¡å‹ä¸­çš„é‡ç‚¹æ˜¯ä¼°è®¡æ¡ä»¶åˆ†å¸ƒ\\(p(x|z;\\theta)\\)ã€‚ Parameter Estimation for Hidden Variable with EM Algorithm å¦‚æœå›¾æ¨¡å‹ä¸­å­˜åœ¨éšå˜é‡ï¼Œå°±éœ€è¦ä½¿ç”¨EMç®—æ³•è¿›è¡Œå‚æ•°ä¼°è®¡ã€‚ åœ¨ä¸€ä¸ªåŒ…å«éšå˜é‡çš„å›¾æ¨¡å‹ä¸­ï¼Œä»¤\\(\\mathbf{X}\\)ä¸ºå¯è§‚æµ‹å˜é‡é›†åˆï¼Œ\\(\\mathbf{Z}\\)ä¸ºéšå˜é‡é›†åˆï¼Œåˆ™ä¸€ä¸ªæ ·æœ¬\\(x\\)çš„è¾¹é™…ä¼¼ç„¶å‡½æ•°ä¸ºï¼š \\[p(x;\\theta)=\\sum_z p(x,z;\\theta)\\] ç»™å®šåŒ…å«\\(N\\)ä¸ªè®­ç»ƒæ ·æœ¬çš„è®­ç»ƒé›†\\(\\mathcal{D}=\\{x^{(n)}\\},1\\leq i\\leq N\\)ï¼Œåˆ™è®­ç»ƒé›†çš„å¯¹æ•°è¾¹é™…ä¼¼ç„¶ä¸ºï¼š \\[\\begin{align}\\mathcal{L}(\\mathcal{D};\\theta)&amp;=\\frac{1}{N}\\sum_{n=1}^N \\log p(x^{(n)};\\theta)\\\\&amp;=\\frac{1}{N}\\sum_{n=1}^N \\log \\sum_z p(x^{(n)},z;\\theta)\\end{align}\\] è¿™æ—¶ï¼Œåªè¦æœ€å¤§åŒ–æ•´ä¸ªè®­ç»ƒé›†çš„å¯¹æ•°è¾¹é™…ä¼¼ç„¶\\(\\mathcal{L}(\\mathcal{D};\\theta)\\)ï¼Œå³å¯ä¼°è®¡å‡ºæœ€ä¼˜çš„å‚æ•°\\(\\theta^*\\)ã€‚ä¸è¿‡åœ¨è®¡ç®—æ¢¯åº¦çš„æ—¶å€™ï¼Œéœ€è¦åœ¨å¯¹æ•°å‡½æ•°å†…éƒ¨è¿›è¡Œæ±‚å’Œæˆ–ç§¯åˆ†è®¡ç®—ã€‚ä¸ºäº†æ›´å¥½çš„è®¡ç®—\\(\\log p(x;\\theta)\\)ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªé¢å¤–çš„å˜åˆ†å‡½æ•°\\(q(z)\\)ï¼Œ\\(q(z)\\)ä¸ºå®šä¹‰åœ¨éšå˜é‡\\(z\\)ä¸Šçš„åˆ†å¸ƒã€‚æ ·æœ¬\\(x\\)çš„å¯¹æ•°è¾¹é™…ä¼¼ç„¶å‡½æ•°ä¸ºï¼š \\[\\begin{align}\\log p(x;\\theta)&amp;=\\log \\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)}\\\\&amp;\\geq\\sum_z q(z)\\log \\frac{p(x,z;\\theta)}{q(z)}\\\\&amp;\\triangleq ELBO(q,x;\\theta)\\end{align}\\] å…¶ä¸­\\(ELBO(q,x;\\theta)\\)ä¸ºå¯¹æ•°è¾¹é™…ä¼¼ç„¶å‡½æ•°\\(\\log p(x;\\theta)\\)çš„ä¸‹ç•Œï¼Œç§°ä¸ºè¯æ®ä¸‹ç•Œã€‚å…¬å¼ä¸­ä½¿ç”¨äº†Jensenä¸ç­‰å¼(å³å¯¹äºå‡¹å‡½æ•°\\(g\\)ï¼Œæœ‰\\(g(\\mathbb{E}[x])\\geq\\mathbb{E}[g(X)]\\))ã€‚åœ¨è¿™é‡Œï¼Œ\\(\\frac{p(x,z;\\theta)}{q(z)}\\)å¯è§†ä¸º\\(q(z)\\)çš„å‡½æ•°ï¼Œè®°ä¸º\\(f(q(z))\\)ï¼Œé‚£ä¹ˆ\\(f(q(z))\\)çš„æœŸæœ›å³\\(\\mathbb{E}[f(q(z))]=\\sum_z q(z)f(q(z))=\\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)}\\)ã€‚è€Œæ ¹æ®Jensenä¸ç­‰å¼ï¼Œæœ‰\\(g(\\mathbb{E}[f(q(z))])\\geq\\mathbb{E}[g(f(q(z)))]\\Leftrightarrow g(\\sum_z q(z)\\frac{p(x,z;\\theta)}{q(z)})\\geq \\sum_z q(z)g(\\frac{p(x,z;\\theta)}{q(z)})\\)ï¼Œåœ¨è¿™é‡Œ\\(g\\)å°±æ˜¯å¯¹æ•°å‡½æ•°ã€‚ æ ¹æ®Jensenä¸ç­‰å¼å–ç­‰çš„æ¡ä»¶ï¼š\\(\\frac{p(x,z;\\theta)}{q(z)}=c\\)ï¼Œ\\(c\\)ä¸ºå¸¸æ•°ï¼Œæœ‰ï¼š \\[\\begin{align}\\sum_z p(x,z;\\theta)&amp;=c\\sum_z q(z)\\\\\\Leftrightarrow\\sum_z p(x,z;\\theta)&amp;=c\\cdot1\\end{align}\\] å› æ­¤ï¼š \\[\\begin{align}q(z)&amp;=\\frac{p(x,z;\\theta)}{\\sum_z p(x,z;\\theta)}\\\\&amp;=\\frac{p(x,z;\\theta)}{p(x;\\theta)}\\\\&amp;=p(z|x;\\theta)\\end{align}\\] æ‰€ä»¥ï¼Œå½“ä¸”ä»…å½“\\(q(z)=p(z|x;\\theta)\\)æ—¶ï¼Œ\\(\\log p(x;\\theta)=ELBO(q,x;\\theta)\\)ã€‚ äºæ˜¯æœ€å¤§åŒ–å¯¹æ•°è¾¹é™…ä¼¼ç„¶å‡½æ•°\\(\\log p(x;\\theta)\\)çš„è¿‡ç¨‹å¯ä»¥åˆ†è§£ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š å…ˆæ‰¾åˆ°è¿‘ä¼¼åˆ†å¸ƒ\\(q(z)\\)ä½¿å¾—\\(\\log p(x;\\theta)=ELBO(q,x;\\theta)\\)ï¼› å†å¯»æ‰¾å‚æ•°\\(\\theta\\)æœ€å¤§åŒ–\\(ELBO(q,x;\\theta)\\)ã€‚ è¿™å°±æ˜¯æœŸæœ›æœ€å¤§åŒ–(Expectation-Maximum,EM)ç®—æ³•ã€‚ EMç®—æ³•é€šè¿‡è¿­ä»£çš„æ–¹æ³•ï¼Œä¸æ–­é‡å¤ç›´åˆ°æ”¶æ•›åˆ°æŸä¸ªå±€éƒ¨æœ€ä¼˜è§£ã€‚åœ¨ç¬¬\\(t\\)æ­¥æ›´æ–°æ—¶ï¼ŒEæ­¥å’ŒMæ­¥åˆ†åˆ«ä¸ºï¼š Eæ­¥ï¼šå›ºå®šå‚æ•°\\(\\theta_t\\)ï¼Œæ‰¾åˆ°ä¸€ä¸ªåˆ†å¸ƒä½¿\\(ELBO(q,x;\\theta_t)\\)æœ€å¤§ï¼Œå³ç­‰äº\\(\\log p(x;\\theta_t)\\)ï¼š\\(q_{t+1}(z)=\\text{arg}_q \\max ELBO(q,x;\\theta_t)\\)ï¼› Mæ­¥ï¼šå›ºå®š\\(q_{t+1}(z)\\)ï¼Œæ‰¾åˆ°ä¸€ç»„å‚æ•°ä½¿å¾—è¯æ®ä¸‹ç•Œæœ€å¤§ï¼Œå³ï¼š\\(\\theta_{t+1}=\\text{arg}_\\theta\\max ELBO(q_{t+1},x;\\theta)\\)ã€‚ å¯¹æ•°è¾¹é™…ä¼¼ç„¶ä¹Ÿå¯ä»¥é€šè¿‡ä¿¡æ¯è®ºçš„è§†è§’æ¥è¿›è¡Œåˆ†è§£ï¼š \\[\\begin{align}\\log p(x;\\theta)&amp;=\\sum_z q(z)\\log p(x;\\theta)\\\\&amp;=\\sum_z q(z)(\\log p(x,z;\\theta)-\\log p(z|x;\\theta))\\\\&amp;=\\sum_z q(z)\\log\\frac{p(x,z;\\theta)}{q(z)}-\\sum_z q(z)\\log\\frac{p(z|x;\\theta)}{q(z)}\\\\&amp;=ELBO(q,x;\\theta)+D_{KL}(q(z)\\parallel p(z|x;\\theta))\\end{align}\\] å…¶ä¸­\\(D_{KL}(q(z)\\parallel p(z|x;\\theta))\\) Generative Model with Hidden Variable å‡è®¾ä¸€ä¸ªç”Ÿæˆæ¨¡å‹åŒ…å«ä¸å¯è§‚æµ‹çš„éšå˜é‡ï¼Œå…¶ä¸­å¯è§‚æµ‹å˜é‡\\(x\\)ä¸ºä¸€ä¸ªé«˜ç»´ç©ºé—´ä¸­çš„éšæœºå‘é‡ï¼Œè€Œä¸å¯è§‚æµ‹çš„éšå˜é‡\\(z\\)ä¸ºä¸€ä¸ªç›¸å¯¹ä½ç»´ç©ºé—´ä¸­çš„éšæœºå‘é‡ã€‚ è¿™ä¸ªç”Ÿæˆæ¨¡å‹çš„è”åˆæ¦‚ç‡å¯†åº¦å‡½æ•°å¯ä»¥è¡¨è¾¾ä¸ºï¼š \\[p(x,z;\\theta)=p(x|z;\\theta)p(z;\\theta)\\] å…¶ä¸­\\(p(z;\\theta)\\)ä¸ºéšå˜é‡\\(z\\)çš„å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒï¼›\\(p(x|z;\\theta)\\)ä¸ºå·²çŸ¥\\(z\\)æ¡ä»¶ä¸‹\\(x\\)çš„æ¦‚ç‡åˆ†å¸ƒã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾\\(p(z;\\theta)\\)å’Œ\\(p(x|z;\\theta)\\)æœä»æŸç§å¸¦å‚çš„åˆ†å¸ƒæ—ï¼Œå…¶å½¢å¼å·²çŸ¥ï¼Œè€Œå‚æ•°å¯ä»¥é€šè¿‡æœ€å¤§ä¼¼ç„¶æ¥è¿›è¡Œä¼°è®¡ã€‚ ç»™å®šä¸€ä¸ªæ ·æœ¬\\(x\\)ï¼Œå…¶å¯¹æ•°è¾¹é™…ä¼¼ç„¶\\(\\log p(x;\\theta)\\)å¯ä»¥åˆ†è§£ä¸ºï¼š \\[\\log p(x;\\theta)=ELBO(q,x;\\theta,\\phi)+D_{KL}(q(z;\\phi)\\parallel p(z|x;\\theta))\\] å…¶ä¸­\\(q(z;\\phi)\\)ä¸ºé¢å¤–å¼•å…¥çš„å˜åˆ†å¯†åº¦å‡½æ•°ï¼Œ\\(ELBO(q,x;\\theta,\\phi)\\)ä¸ºè¯æ®ä¸‹ç•Œï¼š \\[ELBO(q,x;\\theta,\\phi)=\\mathbb{E}_{z\\sim q(z;\\phi)}[\\log{\\frac{p(x,z;\\theta)}{q(z;\\phi)}}]\\] æœ€å¤§åŒ–\\(\\log p(x;\\theta)\\)å¯ä»¥ç”¨EMç®—æ³•æ¥æ±‚è§£ï¼š E-step: å¯»æ‰¾ä¸€ä¸ªå¯†åº¦å‡½æ•°\\(q(z;\\phi)\\)ä½¿å…¶ç­‰äºæˆ–æ¥è¿‘äºåéªŒå¯†åº¦å‡½æ•°\\(p(z|x;\\theta)\\); M-step: ä¿æŒ\\(q(z;\\phi)\\)å›ºå®šï¼Œå¯»æ‰¾\\(\\theta\\)æ¥æœ€å¤§åŒ–\\(ELBO(q,x;\\theta,\\phi)\\)ã€‚ åœ¨EMç®—æ³•çš„æ¯æ¬¡è¿­ä»£ä¸­ï¼Œç†è®ºä¸Šæœ€ä¼˜çš„\\(q(z;\\phi)\\)ä¸ºéšå˜é‡çš„åéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°\\(p(z|x;\\theta)\\)ï¼š \\[p(z|x;\\theta)=\\frac{p(x|z;\\theta)p(z;\\theta)}{\\int_z p(x|z;\\theta)p(z;\\theta)\\text{d}z}\\] åéªŒå¯†åº¦å‡½æ•°\\(p(z|x;\\theta)\\)çš„è®¡ç®—æ˜¯ä¸€ä¸ªç»Ÿè®¡æ¨æ–­çš„é—®é¢˜ï¼Œåœ¨ä¸€èˆ¬æƒ…å†µä¸‹\\(p(x|z;\\theta)\\)ä¹Ÿæ¯”è¾ƒéš¾ä»¥è®¡ç®—ã€‚ Variational Autoencoder å˜åˆ†è‡ªç¼–ç å™¨(Variational Autoencoder, VAE)çš„ä¸»è¦æ€æƒ³æ˜¯åˆ©ç”¨ç¥ç»ç½‘ç»œæ¥åˆ†åˆ«å»ºæ¨¡ä¸¤ä¸ªå¤æ‚çš„æ¡ä»¶æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼š ç”¨ç¥ç»ç½‘ç»œæ¥äº§ç”Ÿå˜åˆ†åˆ†å¸ƒ\\(q(z;\\phi)\\)ï¼Œç§°ä¸ºæ¨æ–­ç½‘ç»œã€‚æ¨æ–­ç½‘ç»œçš„è¾“å…¥ä¸º\\(x\\)ï¼Œè¾“å‡ºä¸ºå˜åˆ†åˆ†å¸ƒ\\(q(z|x;\\phi)\\)ï¼› ç”¨ç¥ç»ç½‘ç»œæ¥äº§ç”Ÿæ¦‚ç‡åˆ†å¸ƒ\\(p(x|z;\\theta)\\)ï¼Œç§°ä¸ºç”Ÿæˆç½‘ç»œã€‚ç”Ÿæˆç½‘ç»œçš„è¾“å…¥ä¸º\\(z\\)ï¼Œè¾“å‡ºä¸ºæ¦‚ç‡åˆ†å¸ƒ\\(p(x|z;\\theta)\\)ã€‚ VAEçš„å›¾æ¨¡å‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š Variational Network å‡è®¾\\(q(z|x;\\phi)\\)æ˜¯æœä»å¯¹è§’åŒ–åæ–¹å·®çš„é«˜æ–¯åˆ†å¸ƒï¼š \\[q(z|x;\\phi)=\\mathcal{N}(z;\\mu_I,\\sigma^2_I I)\\] å…¶ä¸­\\(\\mu_I\\)å’Œ\\(\\sigma_I^2\\)æ˜¯é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®ï¼Œå¯ä»¥é€šè¿‡æ¨æ–­ç½‘ç»œ\\(f_I(x;\\phi)\\)æ¥é¢„æµ‹ï¼š \\[ \\left[\\begin{matrix}\\mu_I\\\\\\sigma_I\\end{matrix}\\right]=f_I(x;\\phi) \\] æ¨æ–­ç½‘ç»œ\\(f_I(x;\\phi)\\)å¯ä»¥æ˜¯ä¸€èˆ¬çš„å…¨è¿æ¥ç½‘ç»œæˆ–å·ç§¯ç½‘ç»œï¼Œæ¯”å¦‚ä¸€ä¸ªä¸¤å±‚çš„ç¥ç»ç½‘ç»œï¼š \\[\\begin{align}h&amp;=\\sigma(W^{(1)}x+b^{(1)})\\\\\\mu_I&amp;=W^{(2)}h+b^{(2)}\\\\\\sigma_I&amp;=\\text{softplus}(W^{(3)}h+b^{(3)})\\end{align}\\] å…¶ä¸­æ‰€æœ‰ç½‘ç»œå‚æ•°\\(\\{W^{(1)},W^{(2)},W^{(3)},b^{(1)},b^{(2)},b^{(3)}\\}\\)å³å¯¹åº”äº†å˜åˆ†å‚æ•°\\(\\phi\\)ã€‚ æ¨æ–­ç½‘ç»œçš„ç›®æ ‡æ˜¯ä½¿å¾—\\(q(z|x;\\phi)\\)æ¥å°½å¯èƒ½æ¥è¿‘çœŸå®çš„åéªŒ\\(p(z|x;\\theta)\\)ï¼Œéœ€è¦æ‰¾åˆ°å˜åˆ†å‚æ•°\\(\\phi^*\\)æ¥æœ€å°åŒ–ä¸¤ä¸ªåˆ†å¸ƒçš„KLæ•£åº¦ï¼š \\[\\phi^*=\\text{arg}_\\phi\\min{D_{KL}(q(z|x;\\phi)\\parallel p(z|x;\\theta))}\\] ç”±äº\\(p(z|x;\\theta)\\)æœªçŸ¥ï¼Œæ•…KLæ•£åº¦æ— æ³•ç›´æ¥è®¡ç®—ï¼Œä¸è¿‡ç”±äº\\(D_{KL}(q(z|x;\\phi)\\parallel p(z|x;\\theta))=\\log p(x;\\theta)-ELBO(q,x;\\theta,\\phi)\\)ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥æœ€å¤§åŒ–è¯æ®ä¸‹ç•Œï¼Œæœ‰ï¼š \\[\\phi^*=\\text{arg}_\\phi\\max{ELBO(q,x;\\theta,\\phi)}\\] Generative Network ç”Ÿæˆæ¨¡å‹çš„è”åˆåˆ†å¸ƒå¯ä»¥åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼šéšå˜é‡\\(z\\)çš„å…ˆéªŒåˆ†å¸ƒ\\(p(z;\\theta)\\)å’Œæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ\\(p(x|z;\\theta)\\)ã€‚ä¸ºç®€å•èµ·è§ï¼Œä¸€èˆ¬å‡è®¾éšå˜é‡\\(z\\)çš„å…ˆéªŒåˆ†å¸ƒä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒ\\(\\mathcal{N}(z|0,I)\\)ï¼Œéšå˜é‡æ¯ä¸€ç»´ä¹‹é—´éƒ½æ˜¯ç‹¬ç«‹çš„ã€‚æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ\\(p(x|z;\\theta)\\)å¯ä»¥é€šè¿‡ç”Ÿæˆç½‘ç»œæ¥å»ºæ¨¡ï¼Œæˆ‘ä»¬åŒæ ·ç”¨å‚æ•°åŒ–çš„åˆ†å¸ƒæ—æ¥è¡¨ç¤ºæ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ\\(p(x|z;\\theta)\\)ï¼Œè¿™äº›åˆ†å¸ƒæ—çš„å‡½æ•°å¯ä»¥ç”¨ç”Ÿæˆç½‘ç»œè®¡ç®—å¾—åˆ°ã€‚æ ¹æ®å˜é‡\\(x\\)çš„ç±»å‹ä¸åŒï¼Œå¯ä»¥å‡è®¾\\(p(x|z;\\theta)\\)æœä»ä¸åŒçš„åˆ†å¸ƒæ—ã€‚å¦‚æœ\\(x\\in\\{0,1\\}^d\\)æ˜¯\\(d\\)ç»´çš„äºŒå€¼å‘é‡ï¼Œå¯ä»¥å‡è®¾\\(\\log p(x|z;\\theta)\\)æœä»å¤šå˜é‡çš„ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œå³ï¼š \\[\\begin{align}p(x|z;\\theta)&amp;=\\prod\\limits_{i=1}^d p(x_i|z;\\theta)\\\\&amp;=\\prod\\limits_{i=1}^d \\gamma_i^{x_i}(1-\\gamma_i)^{(1-x_i)}\\end{align}\\] å¦‚æœ\\(x\\in\\mathbb{R}^d\\)æ˜¯\\(d\\)ç»´çš„è¿ç»­å‘é‡ï¼Œå¯ä»¥å‡è®¾\\(p(x|z;\\theta)\\)æœä»å¯¹è§’åŒ–åæ–¹å·®çš„é«˜æ–¯åˆ†å¸ƒï¼Œå³ï¼š \\[p(x|z;\\theta)=\\mathcal{N}(x;\\mu_G,\\sigma_G^2 I)\\] ç”Ÿæˆç½‘ç»œçš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ç»„\\(\\theta^*\\)æœ€å¤§åŒ–è¯æ®ä¸‹ç•Œ\\(ELBO(q,x;\\theta,\\phi)\\)ï¼š \\[\\theta^*=\\text{arg}_\\theta\\max ELBO(q,x;\\theta,\\phi)\\] Model Combination æ¨æ–­ç½‘ç»œå’Œç”Ÿæˆç½‘ç»œçš„ç›®æ ‡éƒ½æ˜¯æœ€å¤§åŒ–è¯æ®ä¸‹ç•Œå› æ­¤æ€»çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š \\[\\begin{align}\\max_{\\theta,\\phi}ELBO(q,x;\\theta,\\phi)&amp;=\\max_{\\theta,\\phi}\\mathbb{E}_{z\\sim q(z;\\phi)}[\\log\\frac{p(x|z;\\theta)p(z;\\theta)}{q(z;\\theta)}]\\\\&amp;=\\max_{\\theta,\\phi}\\mathbb{E}_{z\\sim q(z|x;\\phi)}[\\log p(x|z;\\theta)]-D_{KL}(q(z|x;\\phi)\\parallel p(z;\\theta))\\end{align}\\] å…¶ä¸­å…ˆéªŒåˆ†å¸ƒ\\(p(z;\\theta)=\\mathcal{N}(z|0,I)\\)ã€‚ å…¬å¼ä¸­\\(\\mathbb{E}_{z\\sim q(z|x;\\phi)}[\\log p(x|z;\\theta)]\\)ä¸€èˆ¬é€šè¿‡é‡‡æ ·çš„æ–¹å¼è¿›è¡Œè®¡ç®—ï¼Œæœ€åå–å¹³å‡å€¼ã€‚ Model Training ç»™å®šæ•°æ®é›†\\(\\mathcal{D}\\)ï¼ŒåŒ…å«\\(N\\)ä¸ªä»æœªçŸ¥æ•°æ®åˆ†å¸ƒä¸­æŠ½å–çš„ç‹¬ç«‹åŒåˆ†å¸ƒæ ·æœ¬\\(x^{(1)},x^{(2)},\\cdots,x^{(N)}\\)ã€‚å˜åˆ†è‡ªç¼–ç å™¨çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š \\[\\mathcal{J}(\\phi,\\theta|\\mathcal{D})=\\sum\\limits_{n=1}^N(\\frac{1}{M}\\sum\\limits_{m=1}^M\\log p(x^{(n)}|z^{(n,m)};\\theta)-D_{KL}(q(z|x^{(n)};\\phi)\\parallel\\mathcal{N}(z;0,I)))\\] å¦‚æœé‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼Œæ¯æ¬¡ä»æ•°æ®é›†ä¸­é‡‡ä¸€ä¸ªæ ·æœ¬\\(x\\)ï¼Œç„¶åæ ¹æ®\\(q(z|x;\\phi)\\)é‡‡ä¸€ä¸ªéšå˜é‡\\(z\\)ï¼Œåˆ™ç›®æ ‡å‡½æ•°å˜ä¸ºï¼š \\[\\mathcal{J}(\\phi,\\theta|x)=\\log p(x|z;\\theta)-D_{KL}(q(z|x;\\phi)\\parallel\\mathcal{N}(z;0,I))\\] å‡è®¾\\(q(z|x;\\phi)\\)æ˜¯æ­£æ€åˆ†å¸ƒï¼ŒKLæ•£åº¦å¯ç›´æ¥ç®—å‡ºï¼š \\[D_{KL}(\\mathcal{N}(\\mu_1,\\Sigma_1)\\parallel\\mathcal(\\mu_2,\\Sigma_2))\\\\=\\frac{1}{2}(\\text{tr}(\\sigma_I^2 I)+\\mu_I^T\\mu_I-d-\\log(|\\sigma_I^2 I|))\\] å†å‚æ•°åŒ–æ˜¯å°†ä¸€ä¸ªå‚æ•°ä¸º\\(u\\)çš„å‡½æ•°\\(f(u)\\)ï¼Œé€šè¿‡ä¸€ä¸ªå‡½æ•°\\(u=g(v)\\)ï¼Œè½¬æ¢ä¸ºå‚æ•°ä¸º\\(v\\)çš„å‡½æ•°\\(\\hat{f}(v)=f(g(v))\\)ã€‚åœ¨å˜åˆ†è‡ªç¼–ç å™¨ä¸­ï¼Œä¸€ä¸ªé—®é¢˜æ˜¯å¦‚ä½•æ±‚éšæœºå˜é‡\\(z\\)å…³äº\\(\\phi\\)çš„å¯¼æ•°ã€‚ä½†ç”±äºæ˜¯é‡‡æ ·çš„æ–¹å¼ï¼Œæ— æ³•ç›´æ¥åˆ»ç”»\\(z\\)å’Œ\\(\\phi\\)ä¹‹é—´çš„å‡½æ•°å…³ç³»ï¼Œå› æ­¤ä¹Ÿæ— æ³•è®¡ç®—å¯¼æ•°ã€‚ å¦‚æœ\\(z\\sim q(z|x;\\phi)\\)çš„éšæœºæ€§ç‹¬ç«‹äºå‚æ•°\\(\\phi\\)ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å†å‚æ•°åŒ–çš„æ–¹æ³•æ¥è®¡ç®—å¯¼æ•°ã€‚å‡è®¾\\(q(z|x;\\phi)\\)ä¸ºæ­£æ€åˆ†å¸ƒ\\(\\mathcal{N}(\\mu_I,\\sigma^2_I I)\\)ï¼Œå…¶ä¸­\\(\\mu_I\\)å’Œ\\(\\sigma_I\\)æ˜¯æ¨æ–­ç½‘ç»œ\\(f_I(x;\\phi)\\)çš„è¾“å‡ºã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„æ–¹å¼é‡‡æ ·\\(z\\)ï¼š \\[z=\\mu_I+\\sigma_I\\odot \\varepsilon\\] å…¶ä¸­\\(\\varepsilon\\sim\\mathcal{N}(0,I)\\)ã€‚è¿™æ ·\\(z\\)å’Œ\\(\\mu_I,\\sigma_I\\)çš„å…³ç³»ä»é‡‡æ ·å…³ç³»å˜ä¸ºå‡½æ•°å…³ç³»ã€‚ å¦‚æœè¿›ä¸€æ­¥å‡è®¾\\(p(x|z;\\theta)\\)æœä»é«˜æ–¯åˆ†å¸ƒ\\(\\mathcal{N}(x|\\mu_G,I)\\)ï¼Œå…¶ä¸­\\(\\mu_G=f_G(z;\\theta)\\)æ˜¯ç”Ÿæˆç½‘ç»œçš„è¾“å‡ºï¼Œåˆ™ç›®æ ‡å‡½æ•°å¯ä»¥ç®€åŒ–ä¸ºï¼š \\[\\mathcal{J}(\\phi,\\theta|x)=-\\parallel x-\\mu_G\\parallel^2+D_{KL}(\\mathcal{N}(\\mu_I,\\sigma_I)\\parallel\\mathcal{N}(0,I))\\] å…¶ä¸­ç¬¬ä¸€é¡¹å¯ä»¥è¿‘ä¼¼çœ‹ä½œæ˜¯è¾“å…¥\\(x\\)çš„é‡æ„æ­£ç¡®æ€§ï¼Œç¬¬äºŒé¡¹å¯ä»¥çœ‹ä½œæ˜¯æ­£åˆ™åŒ–é¡¹ã€‚","link":"/2019/10/22/An-Introduction-to-Variational-Autoencoders/"},{"title":"Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series","text":"Introduction è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªåŸºäºGANçš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ¨¡å‹ã€‚ åŸæ–‡ Contribution æå‡ºäº†åŸºäºGANçš„æ—¶é—´åºåˆ—æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æ¨¡å‹ æˆ‘ä»¬ä½¿ç”¨åŸºäºLSTMçš„GANæ¥å¯¹å¤šå˜é‡æ—¶é—´åºåˆ—è¿›è¡Œå»ºæ¨¡ ç»“åˆä½¿ç”¨äº†Residual Losså’ŒDiscrimination Lossæ¥è¿›è¡Œå¼‚å¸¸çš„åˆ¤æ–­ Background Generative Adversarial Networks GANs In a Nutshell, an extremely simple explanation æˆ‘ä»¬æƒ³è¦ä»ä¸€ä¸ªå¤æ‚çš„ã€é«˜ç»´çš„æ•°æ®åˆ†å¸ƒ\\(p_r(x)\\)ä¸Šé‡‡æ ·å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„æ•°æ®ç‚¹ï¼Œç„¶è€Œ\\(p_r(x)\\)æ— æ³•ç›´æ¥æ±‚å¾— ä»£æ›¿æ–¹æ³•ï¼šä»ä¸€ä¸ªç®€å•çš„ã€å·²çŸ¥çš„åˆ†å¸ƒ\\(p_z(z)\\)ä¸Šé‡‡æ ·ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ªTransformation \\(G(z): z\\rightarrow x\\)æ¥å°†\\(z\\)æ˜ å°„åˆ°\\(x\\) Training: Two-player Game Generator Network: ä»éšæœºåˆ†å¸ƒ\\(p_z(z)\\)é‡‡æ ·\\(z\\)ï¼Œé€šè¿‡æ˜ å°„ç”Ÿæˆæ ·æœ¬\\(x\\)ï¼Œè¿™ä¸ªç”Ÿæˆçš„æ ·æœ¬è¦å°½é‡â€œçœŸå®â€ã€‚æ€ä¹ˆâ€œçœŸå®â€ï¼Ÿä¼˜åŒ–ç”Ÿæˆå™¨å‚æ•°\\(\\theta_G\\)æœ€å¤§åŒ–åˆ¤åˆ«å™¨å¯¹ç”Ÿæˆæ ·æœ¬çš„è¯„åˆ†å³å¯ Discriminator Network: æ¥å—ä¸€ä¸ªæ ·æœ¬\\(x\\)ï¼Œåˆ¤æ–­å…¶æ˜¯ç”Ÿæˆçš„æ ·æœ¬è¿˜æ˜¯çœŸå®çš„æ ·æœ¬ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬æ˜¯çŸ¥é“ä¸€ä¸ªæ ·æœ¬\\(x\\)åˆ°åº•æ˜¯ç”Ÿæˆçš„è¿˜æ˜¯çœŸå®çš„ï¼Œæ‰€ä»¥ä¼˜åŒ–åˆ¤åˆ«å™¨å‚æ•°\\(\\theta_D\\)æœ€å°åŒ–åˆ¤åˆ«å™¨å¯¹ç”Ÿæˆæ ·æœ¬çš„è¯„åˆ†ï¼Œæœ€å¤§åŒ–å¯¹çœŸå®æ ·æœ¬çš„è¯„åˆ†ï¼ˆå³æœ€å¤§åŒ–åˆ†è¾¨çœŸå®æ ·æœ¬çš„èƒ½åŠ›ï¼‰ å½¢å¼åŒ–çš„æ¥è®²ï¼Œä¼˜åŒ–å‡½æ•°å¦‚ä¸‹ï¼š \\[\\min\\limits_{\\theta_G}\\max\\limits_{\\theta_D}V(G,D)=\\mathbb{E}_{x\\sim p_{data}(x)\\log(\\underbrace{D_{\\theta{D}}(x)}_{åˆ¤åˆ«å™¨å¯¹çœŸå®æ ·æœ¬çš„è¯„åˆ†})}+\\mathbb{E}_{z\\sim p_z(z)}\\log(1-\\underbrace{D_{\\theta_d}(G_{\\theta_G}(z))}_{åˆ¤åˆ«å™¨å¯¹ç”Ÿæˆæ ·æœ¬çš„è¯„åˆ†})\\] è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š Long Short Time Memory Networks Vanilla Recurrent Neural Networks æ™®é€šçš„ç¥ç»ç½‘ç»œï¼š æ¦‚æ‹¬çš„æ¥è®²ï¼Œå¯ä»¥æ¶µç›–ä¸ºä¸€ä¸ªå…¬å¼\\(\\hat{\\mathbf{y}}=f(\\mathbf{x})\\)ã€‚å¯¹äºä¸€ä¸ªæ ·æœ¬\\(\\mathbf{x}\\)ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ˜ å°„ï¼Œè¾“å‡º\\(\\mathbf{y}\\)ã€‚ å¯¹äºRNNï¼Œæˆ‘ä»¬å¤„ç†çš„æ˜¯åºåˆ—æ•°æ®ï¼Œä¹Ÿå°±æ˜¯è¯´æ‰€æœ‰æ ·æœ¬ä¹‹é—´å¹¶ä¸æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚å¯¹äºä¸€ä¸ªåºåˆ—ä¸­çš„ä¸€ä¸ªæ ·æœ¬\\(x_t\\in\\{x_1,x_2,\\cdots,x_n\\}\\)ï¼Œå°†å…¶è¾“å…¥åˆ°ç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œä¸ºäº†å»ºæ¨¡\\(x_t\\)ä¹‹å‰çš„å­åºåˆ—å¯¹\\(x_t\\)çš„å½±å“å…³ç³»ï¼Œéœ€è¦å°†è¿™ä¸ªå­åºåˆ—çš„ä¿¡æ¯ä¹Ÿè¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œæ€ä¹ˆåšå‘¢ï¼Ÿä¸ºæ¯ä¸€ä¸ªæ ·æœ¬ç‚¹ä¿å­˜ä¸€ä¸ªStateã€‚å³å®šä¹‰\\(h_t=g(\\hat{y_t})=g(f(x_t))\\)ï¼Œå¯¹äºå½“å‰æ ·æœ¬ç‚¹ï¼Œ\\(\\hat{y_t}=f(x_t,h_{t-1})\\)ã€‚ä¹Ÿå°±æ˜¯è¯´ç¥ç»ç½‘ç»œçš„è¾“å…¥ä¸ä»…åŒ…å«äº†å½“å‰æ ·æœ¬ç‚¹çš„ç‰¹å¾ï¼Œä¹ŸåŒ…å«äº†ä¸Šä¸€ä¸ªæ ·æœ¬ç‚¹çš„â€œçŠ¶æ€â€(ä¸Šä¸€ä¸ªæ ·æœ¬ç‚¹çš„â€œçŠ¶æ€â€åˆéšå«äº†ä¸Šä¸Šä¸ªæ ·æœ¬ç‚¹çš„â€œçŠ¶æ€â€...)ï¼Œå°±åƒæ˜¯ä¸ºç½‘ç»œåŠ ä¸Šäº†çŸ­æœŸè®°å¿†ã€‚ Gradient Flow of Vanilla RNN ä¸‹é¢æ¥è¿›è¡Œä¸€äº›å½¢å¼åŒ–çš„å®šä¹‰ï¼Œå‡è®¾åœ¨æ—¶åˆ»\\(t\\)ç½‘ç»œè¾“å…¥ç‰¹å¾ä¸º\\(x_t\\)ï¼Œè¾“å‡ºéšå«çŠ¶æ€ä¸º\\(h_{t}\\)ï¼Œå…¶ä¸ä»…å’Œå½“å‰è¾“å…¥\\(x_t\\)æœ‰å…³ï¼Œè¿˜å’Œä¸Šä¸€ä¸ªéšå«çŠ¶æ€\\(h_{t-1}\\)æœ‰å…³ï¼š å½“å‰æ—¶åˆ»æ€»çš„å‡€è¾“å…¥\\(z_t=Uh_{t-1}+Wx_t+b\\) å½“å‰æ—¶åˆ»è¾“å‡ºéšå«çŠ¶æ€\\(h_t=f(z_t)\\) å½“å‰æ—¶åˆ»è¾“å‡º\\(\\hat{y}_t=Vh_t\\) RNNçš„æ¢¯åº¦æ›´æ–°å…¬å¼(æ¨å¯¼è¿‡ç¨‹æ¯”è¾ƒå¤æ‚)ï¼š \\[\\frac{\\partial{\\mathcal{L}}}{\\partial U}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t \\delta_{t,k}\\mathbf{h}_{k-1}^T\\] \\[\\frac{\\partial{\\mathcal{L}}}{\\partial{W}}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t \\delta_{t,k}x_k^T\\] \\[\\frac{\\partial\\mathcal{L}}{\\partial{b}}=\\sum\\limits_{t=1}^T\\sum\\limits_{k=1}^t\\delta_{t,k}\\] å…¶ä¸­\\(\\delta_{t,k}=\\frac{\\partial{\\mathcal{L}}}{\\partial{z_k}}=\\text{diag}(f^\\prime(z_k))U^T\\delta_{t,k+1}\\)å®šä¹‰ä¸ºç¬¬\\(t\\)æ—¶åˆ»çš„æŸå¤±å¯¹ç¬¬\\(k\\)æ—¶åˆ»éšè—ç¥ç»å±‚çš„å‡€è¾“å…¥\\(z_k\\)çš„å¯¼æ•°ï¼Œä¸”\\(z_k=Uh_{k-1}+Wx_k+b,1\\leq k&lt;t\\)ã€‚ RNNçš„æ¢¯åº¦æµå‘å¦‚ä¸‹å›¾çº¢ç®­å¤´æ‰€ç¤ºï¼š RNNä¼šé‡åˆ°æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€‚æ ¹æ®å‰é¢çš„å…¬å¼ï¼Œ\\(\\delta_{t,k}\\)å®é™…ä¸Šæ˜¯é€’å½’å®šä¹‰çš„ï¼Œå±•å¼€å¾—åˆ°ï¼š \\[\\delta_{t,k}=\\prod\\limits_{\\tau=k}^{t-1}(\\text{diag}(f^\\prime(z_\\tau))U^T)\\delta_{t,t}\\] å¦‚æœå®šä¹‰\\(\\gamma\\cong\\parallel\\text{diag}(f^\\prime(z_\\tau))U^T\\parallel\\)ï¼Œé‚£ä¹ˆ\\(\\delta_{t,k}\\cong\\gamma^{t-k}\\delta_{t,t}\\)ã€‚åœ¨\\(t-k\\)å¾ˆå¤§æ—¶ï¼Œ\\(\\gamma&lt;1\\)ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ï¼Œ\\(\\gamma&gt;1\\)æ—¶ä¼šå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ã€‚ Long Short Time Memory LSTMæ˜¯ä¸€ç§è§£å†³RNNæ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„æ”¹è¿›ç‰ˆæœ¬ï¼š åœ¨LSTMä¸­ï¼Œç»´æŠ¤äº†ä¸¤ä¸ªStateï¼Œ\\(c_t\\)å’Œ\\(h_t\\)ã€‚å…¶ä¸­\\(c_t\\)ç”±é—å¿˜é—¨\\(f\\)ä¸ä¸Šä¸€ä¸ª\\(c_{t-1}\\)ç›¸ä¹˜(ä»£è¡¨ç»§æ‰¿ä¸Šä¸€ä¸ªCellçš„ä¿¡æ¯å¹¶åŠ ä»¥ä¸€å®šç¨‹åº¦çš„é—å¿˜)ï¼ŒåŠ ä¸Šè¾“å‡ºé—¨\\(i\\)ä¸Gate Gate \\(g\\)ç›¸ä¹˜(Gate Gateä»£è¡¨å½“å‰çš„å€™é€‰çŠ¶æ€ï¼Œè¾“å‡ºé—¨\\(i\\)æ§åˆ¶å½“å‰å€™é€‰çŠ¶æ€æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦ä¿å­˜)ã€‚æœ€åï¼Œè¾“å‡ºé—¨\\(o\\)æ§åˆ¶å½“å‰æ—¶åˆ»çš„Cell State \\(c_t\\)æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦è¾“å‡ºç»™å¤–éƒ¨çŠ¶æ€\\(h_t\\)ã€‚ ä¸‰ä¸ªé—¨çš„è®¡ç®—æ–¹å¼ä¸ºï¼š \\[i_t=\\sigma(W_ix_t+U_ih_{t-1}+b_i)\\] \\[f_t=\\sigma(W_fx_t+U_fh_{t-1}+b_f)\\] \\[o_t=\\sigma(W_ox_t+U_oh_{t-1}+b_o)\\] Methodology æ€»ä½“æ¡†æ¶å›¾å¦‚Fig 1æ‰€ç¤ºï¼š GAN with LSTM-RNN ç½‘ç»œç»“æ„ä¸Šç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨éƒ½æ˜¯LSTMï¼Œä¼˜åŒ–å‡½æ•°å’Œæ™®é€šGANä¸€æ ·ï¼š \\[\\min\\limits_G\\max\\limits_D V(D,G)=\\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)]+\\mathbb{E}_{z\\sim p_z(z)}[\\log (1-D(G(z)))]\\] GAN-based Anomaly Score åœ¨æµ‹è¯•é˜¶æ®µï¼Œéœ€è¦ä½¿ç”¨æ¢¯åº¦ä¼˜åŒ–å¯»æ‰¾ä¸€ä¸ªä½¿å¾—\\(G_{rnn}(z)\\)æœ€æ¥è¿‘\\(X^{test}\\)çš„\\(z^k\\)ï¼š \\[\\min\\limits_{Z^k}Error(X^{test},G_{rnn}(Z^k))=1-Similarity(X^{test},G_{rnn}(Z^k))\\] æœ¬æ–‡å®šä¹‰äº†ä¸¤ç§Anomaly Scoreï¼Œä¸€ç§æ˜¯Residual Lossï¼š \\[Res(X^{test}_t)=\\sum\\limits_{i=1}^n|x^{test,i}_t-G_{rnn}(Z^{k,i}_t)|\\] ä¸€ç§æ˜¯Discrimination Lossï¼Œå³åˆ¤åˆ«å™¨çš„è¾“å‡º\\(D_{rnn}(x_t^{test})\\)ã€‚ æ€»çš„Anomaly Scoreï¼š \\[S^{test}_t=\\lambda Res(X^{test}_t)+(1-\\lambda)D_{rnn}(x^{test}_t)\\] Anomaly Detection Framework æ¨¡å‹çš„ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š ç”±äºæœ¬æ–‡æ˜¯å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œè€Œä¸”æ—¶é—´åºåˆ—çš„é•¿åº¦æœ‰å¯èƒ½æ¯”è¾ƒé•¿ï¼Œä½œè€…ä½¿ç”¨äº†æ»‘åŠ¨çª—å£å’ŒPCAæ¥è¿›è¡Œé¢„å¤„ç†ã€‚ Experiments","link":"/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/"},{"title":"Complementary Set Variational Autoencoder for Supervised Anomaly Detection","text":"Introduction å¯¹äºå¼‚å¸¸æ£€æµ‹é—®é¢˜ï¼Œå¼‚å¸¸çš„æ¨¡å¼æ˜¯å¤šç§å¤šæ ·çš„ã€‚æœ‰ç›‘ç£æ¨¡å‹èƒ½å¤Ÿè¾ƒå¥½åœ°å¤„ç†è®­ç»ƒé›†ä¸­å‡ºç°è¿‡çš„æ¨¡å¼ï¼Œæ— ç›‘ç£æ¨¡å‹èƒ½å¤Ÿå¤„ç†è®­ç»ƒé›†ä¸­æœªå‡ºç°è¿‡çš„æ¨¡å¼ï¼Œä½†å¯¹äºè®­ç»ƒé›†ä¸­å‡ºç°è¿‡çš„å¼‚å¸¸æ¨¡å‹å¹¶æ²¡æœ‰å­¦ä¹ ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ—¢èƒ½å­¦ä¹ è®­ç»ƒé›†ä¸­å‡ºç°è¿‡çš„å¼‚å¸¸æ¨¡å¼ï¼ŒåŒæ—¶èƒ½å¤„ç†æœªå‡ºç°è¿‡çš„å¼‚å¸¸æ¨¡å¼çš„æ–¹æ³•ã€‚ Proposed Model Conventional VAE é¦–å…ˆå›é¡¾ä¸€ä¸‹åŸå§‹çš„VAEã€‚ åŸå§‹VAEä¸­çš„æŸå¤±å‡½æ•°ä¸ºï¼š \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})=\\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})}[\\log p(\\boldsymbol{x}|\\boldsymbol{z};\\boldsymbol{\\theta})]-\\text{KL}[q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi}\\parallel p(\\boldsymbol{z}))] \\] åŸæ–‡ä¸­ä½œè€…è¯æ˜äº†\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\leq\\log p(\\boldsymbol{x};\\boldsymbol{\\theta})\\)ï¼Œæ‰€ä»¥\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\)å¯ä»¥çœ‹ä½œæ˜¯æ•°æ®åˆ†å¸ƒ\\(p(\\boldsymbol{x})\\)å¯¹æ•°ä¼¼ç„¶çš„ä¸€ä¸ªä¸‹ç•Œã€‚\\(\\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\)åˆè¢«ç§°ä¸ºè¯æ®ä¸‹ç•Œ (ELBO)ã€‚\\(\\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})}[\\log p(\\boldsymbol{x}|\\boldsymbol{z};\\boldsymbol{\\theta})]\\)ä¸­çš„æœŸæœ›ä¸€èˆ¬ç”¨è’™ç‰¹å¡æ´›æ¥è¿›è¡Œä¼°è®¡ï¼š \\[ \\begin{align} \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\simeq&amp; \\frac{1}{L}\\sum\\limits_l\\log p(\\boldsymbol{x}|\\boldsymbol{z}^{(l)};\\boldsymbol{\\theta})-\\text{KL}[q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi})\\parallel p(\\boldsymbol{z})],\\\\ \\boldsymbol{z}^{(l)}&amp;\\sim q(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\phi}), \\space l\\in\\{1,2,\\cdots,L\\} \\end{align} \\] å¯¹äºéšå˜é‡\\(\\boldsymbol{z}\\)ï¼Œä¸€èˆ¬å‡è®¾å…ˆéªŒæœä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼ŒåéªŒæœä»å‡å€¼ä¸º\\(\\mu\\)ï¼Œæ–¹å·®ä¸º\\(\\sigma^2\\)çš„é«˜æ–¯åˆ†å¸ƒï¼Œæ•…KLæ•£åº¦èƒ½ç›´æ¥å†™å‡ºè§£æå¼ï¼š \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\phi};\\boldsymbol{x})\\simeq \\frac{1}{L}\\sum\\limits_l\\log p(\\boldsymbol{x}|\\boldsymbol{z}^{(l)};\\boldsymbol{\\theta})-C(-\\frac{1}{2}-\\log\\sigma+\\frac{1}{2}\\sigma^2+\\frac{1}{2}\\mu^2) \\] ä½¿ç”¨VAEæ¥åšå¼‚å¸¸æ£€æµ‹é€šå¸¸æ˜¯åœ¨æ­£å¸¸æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨æ£€æµ‹é˜¶æ®µï¼Œå¦‚æœæ˜¯å¼‚å¸¸æ ·æœ¬ï¼Œé‚£ä¹ˆVAEä¸èƒ½å¾ˆå¥½åœ°é‡æ„å®ƒï¼Œè¿™æ ·ä¼šå¯¼è‡´è¾ƒå¤§çš„é‡æ„è¯¯å·®ã€‚ Prior Distribution for Anomalies åœ¨åŸå§‹VAEå¼‚å¸¸æ£€æµ‹ä¸­ï¼Œæ— è®ºè¾“å…¥æ ·æœ¬\\(\\boldsymbol{x}\\)æ˜¯å¦å¼‚å¸¸ï¼ŒVAEéƒ½ä¼šä½¿å¯¹åº”ç¼–ç çš„åéªŒ\\(p(\\boldsymbol{z}|\\boldsymbol{x})\\)æœä»é«˜æ–¯åˆ†å¸ƒï¼Œä¸”æ–½åŠ æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„çº¦æŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…å¯¹å¼‚å¸¸å’Œæ­£å¸¸æ ·æœ¬å¯¹åº”çš„éšå˜é‡çš„å…ˆéªŒåˆ†å¸ƒåšäº†ä¸åŒå‡è®¾ã€‚é¦–å…ˆï¼Œæ­£å¸¸å…ˆéªŒä¾ç„¶æ˜¯æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼Œè®°ä¸º\\(p_n(\\boldsymbol{z})\\)ã€‚è€Œå¯¹äºå¼‚å¸¸å…ˆéªŒï¼Œä½œè€…è®¤ä¸ºå¼‚å¸¸å³ä¸ºâ€œä¸æ­£å¸¸â€ï¼Œå’Œæ­£å¸¸æ˜¯è¡¥é›†çš„å…³ç³»ã€‚ä½œè€…åœ¨æ–‡ä¸­å®šä¹‰å¼‚å¸¸å…ˆéªŒåˆ†å¸ƒ\\(p_a(\\boldsymbol{z})\\)ä¸ºï¼š \\[ p_a(\\boldsymbol{z})=\\frac{1}{Y^\\prime}(\\max\\limits_{\\boldsymbol{z}^\\prime}p_n(\\boldsymbol{z}^\\prime)-p_n(\\boldsymbol{z})) \\] å…¶ä¸­\\(Y^\\prime\\)ä¸ºä½¿\\(p_a(\\boldsymbol{z})\\)æˆä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„è°ƒèŠ‚å› å­ã€‚å®é™…ä¸Šï¼Œ\\(Y^\\prime\\)å¾€å¾€ä¼šæˆä¸ºæ— é™å¤§ï¼Œå› ä¸º\\(p(\\boldsymbol z)\\)åœ¨æ•´ä¸ªå®šä¹‰åŸŸä¸Šéƒ½æœ‰å®šä¹‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…åŠ å…¥äº†\\(p_w(\\boldsymbol z)\\)ï¼Œä¸€ä¸ªåœ¨æ¯ä¸ªç»´åº¦éƒ½è¶³å¤Ÿå®½çš„è¾…åŠ©åˆ†å¸ƒï¼š \\[ p_a(\\boldsymbol z)=\\frac{1}{Y}p_w(\\boldsymbol z)\\left(\\max\\limits_{\\boldsymbol z^\\prime}p_n(\\boldsymbol z^\\prime)-p_n(\\boldsymbol z)\\right) \\] å…¶ä¸­\\(Y\\)ä¸ºæœ‰é™çš„å¸¸æ•°ã€‚åœ¨æ–‡ä¸­\\(p_n(\\boldsymbol z)\\)å’Œ\\(p_w(\\boldsymbol z)\\)éƒ½ä¸ºé«˜æ–¯åˆ†å¸ƒï¼Œé‚£ä¹ˆ\\(p_a(\\boldsymbol z)\\)çš„å…·ä½“å½¢å¼ä¸ºï¼š \\[ p_a(\\boldsymbol z)=\\frac{1}{Y}\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\{\\max\\limits_{\\boldsymbol z^\\prime}\\mathcal N(\\boldsymbol z^\\prime;\\boldsymbol 0,\\boldsymbol 1)-\\mathcal N(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol 1)\\} \\] å…¶ä¸­ï¼š \\[ \\max\\limits_{\\boldsymbol z^\\prime}\\mathcal N(\\boldsymbol z^\\prime;\\boldsymbol 0,\\boldsymbol 1)=\\frac{1}{\\sqrt{2\\pi}} \\] \\[ Y=\\int_{-\\infty}^{\\infty}p_a(\\boldsymbol z)\\mathrm{d}\\boldsymbol z=\\frac{1}{\\sqrt{2\\pi}}\\left\\{1-\\frac{1}{\\boldsymbol s^2+1}\\right\\} \\] \\(\\boldsymbol s^2\\)ä¸ºè¶…å‚æ•°ï¼Œæ§åˆ¶åˆ†å¸ƒçš„å®½åº¦ã€‚ç”¨æ–‡ä¸­çš„å…ˆéªŒæ›¿æ¢VAEåŸå§‹çš„KLæ•£åº¦ï¼Œå¯å†™ä¸ºï¼š \\[ \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]=\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\frac{\\mathcal N(\\boldsymbol z;\\boldsymbol\\mu,\\boldsymbol\\sigma^2)}{\\frac{1}{Y}\\mathcal N(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\left\\{\\frac{1}{2\\pi}-\\mathcal N(\\boldsymbol z;\\boldsymbol0,\\boldsymbol 1)\\right\\}}\\mathrm{d}\\boldsymbol z \\] å±•å¼€åï¼š \\[ \\begin{align} \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]&amp;= \\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\mathcal{N}(\\boldsymbol z;\\boldsymbol\\mu,\\boldsymbol\\sigma^2)\\mathrm{d}\\boldsymbol z\\\\ &amp;+\\log Y\\\\ &amp;-\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0,\\boldsymbol s^2)\\mathrm{d}\\boldsymbol z\\\\ &amp;-\\int_{-\\infty}^\\infty\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu,\\boldsymbol \\sigma^2)\\log\\left\\{\\frac{1}{\\sqrt{2\\pi}}-\\mathcal{N}(\\boldsymbol z;\\boldsymbol 0, \\boldsymbol 1)\\right\\}\\mathrm{d}\\boldsymbol z \\end{align} \\] ä½¿ç”¨æ³°å‹’å±•å¼€ï¼Œ\\(\\log (x+\\frac{1}{2\\pi})\\simeq-\\log 2\\pi+2\\pi x\\)ï¼ŒKLæ•£åº¦å¯ä»¥ç”¨ä¸‹å¼ä¼°è®¡ï¼š \\[ \\begin{align} \\text{KL}\\left[q(\\boldsymbol z|\\boldsymbol x;\\phi)\\parallel p_a(\\boldsymbol z)\\right]&amp;\\simeq\\sqrt{\\frac{2\\pi}{\\boldsymbol\\sigma^2+1}}\\exp\\left(\\frac{-\\boldsymbol\\mu^2}{2(\\boldsymbol\\sigma^2+1)}\\right)\\\\ &amp;+\\frac{\\boldsymbol\\mu^2+\\boldsymbol\\sigma^2}{2\\boldsymbol s^2}-\\log\\boldsymbol\\sigma+\\log\\boldsymbol s+\\log\\left(\\sqrt{\\boldsymbol s^2+1}-1\\right)\\\\ &amp;-\\frac{\\log(\\boldsymbol s^2+1)}{2}+\\frac{\\log(2\\pi)-1}{2} \\end{align} \\] ä¸‹å›¾ä¸ºä¸€ç»´æ—¶\\(p_n(\\boldsymbol z)\\)å’Œ\\(p_a(\\boldsymbol z)\\)çš„ç¤ºä¾‹ï¼š Implementation of proposed method æ–‡ä¸­ä½¿ç”¨ç¼–ç å™¨è¾“å‡ºçš„åˆ†å¸ƒ\\(\\mathcal{N}(\\boldsymbol z;\\boldsymbol \\mu, \\boldsymbol \\sigma^2)\\)ä¸æ ‡å‡†æ­£æ€åˆ†å¸ƒä¹‹é—´çš„KLæ•£åº¦æ¥ä½œä¸ºå¼‚å¸¸åˆ†æ•°ã€‚åœ¨æ¯ä¸€è½®çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒåŠ å…¥ä¸€è½®ä½¿ç”¨Anomaly Priorçš„è®­ç»ƒã€‚ Experiments MNIST ä½œè€…è®¾è®¡äº†ä¸¤ä¸ªTaskï¼š Task 1. \\(N\\) vs. \\(\\bar{N}\\). å°†æ‰‹å†™æ•°å­—ä¸­çš„ä¸€ä¸ªä½œä¸ºå·²çŸ¥å¼‚å¸¸ï¼Œå…¶ä»–ä½œä¸ºæ­£å¸¸ï¼Œå¹¶åŠ å…¥å‡åŒ€åˆ†å¸ƒä½œä¸ºæœªçŸ¥çš„å¼‚å¸¸ã€‚ Task 2. æ‰‹å†™æ•°å­—è¢«åˆ†ä¸º3ç»„ï¼šå·²çŸ¥å¼‚å¸¸ï¼Œæ­£å¸¸ï¼ŒæœªçŸ¥å¼‚å¸¸ã€‚ ç»†èŠ‚å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š åœ¨å®ç°ä¸Šï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œbatch_sizeä¸º100ï¼Œepochsä¸º200ã€‚Encoderå’ŒDecoderéƒ½ç”±ä¸‰å±‚æ„ŸçŸ¥æœºç»„æˆï¼Œè¶…å‚æ•°\\(s^2\\)è®¾ç½®ä¸º400ã€‚è¯„æµ‹æ ‡å‡†ä½¿ç”¨AUC (area under the receiver characteristic curve)ã€‚ ä¸‹è¡¨ä¸ºå®éªŒç»“æœï¼š","link":"/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"},{"title":"Deep Anomaly Detection with Deviation Networks","text":"Introduction æœ¬æ–‡å…³æ³¨Deep Anomaly Detectionï¼Œä¹Ÿå°±æ˜¯ç”¨æ·±åº¦å­¦ä¹ çš„æ–¹æ³•æ¥è¿›è¡Œå¼‚å¸¸æ£€æµ‹ã€‚æ–‡ä¸­æåˆ°ç°æœ‰çš„Deep Anomaly Detectionå­˜åœ¨ä¸¤ä¸ªå¼Šç«¯ï¼šä¸€ä¸ªæ˜¯é‡‡ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•æ¥è¿›è¡Œç‰¹å¾å­¦ä¹ ï¼Œç„¶åé€šè¿‡ä¸‹æ¸¸ä»»åŠ¡å¾—åˆ°Anomaly Scoreï¼Œç›¸æ¯”æ–‡ä¸­End-to-Endçš„Anomaly Scoreå­¦ä¹ ï¼Œå­˜åœ¨ä¼˜åŒ–ä¸å……åˆ†çš„é£é™©ï¼›å¦ä¸€ä¸ªæ˜¯ç°æœ‰çš„æ–¹æ³•ä¸»è¦æ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œæ— æ³•åˆ©ç”¨å·²çŸ¥çš„ä¿¡æ¯ï¼ˆå¦‚å°‘é‡æ ‡ç­¾ï¼‰ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚ æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œç›´æ¥å­¦ä¹ Anomaly Scoreå¹¶ä¸”å¯ä»¥åˆ©ç”¨å·²çŸ¥ä¿¡æ¯ï¼› åŸºäºæå‡ºçš„æ¡†æ¶ï¼Œæ–‡ä¸­æå‡ºäº†ä¸€ç§å®ä¾‹æ–¹æ³• (DevNet)ã€‚ Proposed Model End-To-End Anomaly Score Learning Problem Statement ä¸ºäº†åŒºåˆ«äºä¼ ç»Ÿçš„ä¸¤é˜¶æ®µå¼‚å¸¸æ£€æµ‹ï¼ˆå…ˆå­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œç„¶ååœ¨å­¦åˆ°çš„ç‰¹å¾ä¸Šå®šä¹‰ä¸€ä¸ªanomaly measureæ¥å¾—åˆ°anomaly scoreï¼‰ï¼Œä½œè€…å¯¹ç«¯åˆ°ç«¯çš„å¼‚å¸¸æ£€æµ‹é—®é¢˜é‡æ–°è¿›è¡Œå½¢å¼åŒ–ã€‚ ç»™å®š\\(N+K\\)ä¸ªæ ·æœ¬\\(\\mathcal{X}=\\{\\boldsymbol x_1,\\boldsymbol x_2,\\cdots,\\boldsymbol x_N,\\boldsymbol x_{N+1},\\cdots,\\boldsymbol x_{N+K}\\}\\)ï¼Œå…¶ä¸­\\(\\boldsymbol x_i\\in\\mathbb{R}^D\\)ï¼Œæ— æ ‡ç­¾æ ·æœ¬é›†\\(\\mathcal{U}=\\{\\boldsymbol x_1,\\boldsymbol x_2,\\cdots,\\boldsymbol x_N\\}\\)ï¼Œæœ‰æ ‡ç­¾æ ·æœ¬é›†\\(\\mathcal{K}=\\{\\boldsymbol x_{N+1},\\cdots,\\boldsymbol x_{N+K}\\}\\)ï¼Œä¸”\\(K\\ll N\\)ã€‚å¼‚å¸¸æ£€æµ‹çš„ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªanomaly scoring function\\(\\phi:\\mathcal{X}\\mapsto\\mathbb{R}\\)ä½¿å¾—\\(\\phi(\\boldsymbol x_i)&gt;\\phi(\\boldsymbol x_j)\\)ï¼Œå…¶ä¸­\\(\\boldsymbol x_i\\)ä¸ºå¼‚å¸¸æ ·æœ¬ï¼Œ\\(\\boldsymbol x_j\\)ä¸ºæ­£å¸¸æ ·æœ¬ã€‚ The Proposed Framework ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ–‡ä¸­æå‡ºäº†ä¸€ç§é€šç”¨å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œæ¨¡å‹æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š æ¨¡å‹æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼š anomaly scoring network. å›¾ä¸­å·¦è¾¹çš„éƒ¨åˆ†ï¼Œä¸€ä¸ªå‡½æ•°\\(\\phi\\)ï¼Œè¾“å…¥æ ·æœ¬\\(\\mathbf{x}\\)ï¼Œè¾“å‡ºanomaly score reference score generator. å›¾ä¸­å³è¾¹çš„éƒ¨åˆ†ã€‚åªæœ‰ä¸€ä¸ªanomaly scoring networkå¹¶ä¸èƒ½è¿›è¡Œè®­ç»ƒï¼Œéœ€è¦è®­ç»ƒçš„ç›®æ ‡ã€‚ä¸ºæ­¤åŠ å…¥reference score generatorï¼Œè¾“å…¥ä¸ºéšæœºé€‰æ‹©çš„\\(l\\)ä¸ªæ­£å¸¸æ ·æœ¬ï¼Œè¾“å‡ºreference scoreï¼ˆè¿™\\(l\\)ä¸ªæ­£å¸¸æ ·æœ¬anomaly scoreçš„å‡å€¼ï¼Œè®°ä¸º\\(\\mu_\\mathcal{R}\\)ï¼‰ deviation loss. \\(\\phi(\\mathbf{x})\\)ï¼Œ\\(\\mu_\\mathcal{R}\\)åŠå¯¹åº”çš„æ ‡å‡†å·®\\(\\sigma_\\mathcal{R}\\)ä½œä¸ºdeviation losså‡½æ•°çš„è¾“å…¥ã€‚å› ä¸º\\(\\mu_\\mathcal{R}\\)å’Œ\\(\\sigma_\\mathcal{R}\\)å¯¹åº”æ­£å¸¸æ ·æœ¬é›†çš„å‡å€¼å’Œæ–¹å·®ï¼Œé‚£ä¹ˆå¼‚å¸¸æ ·æœ¬çš„anomaly scoreåº”è¯¥å’Œ\\(\\mu_\\mathcal{R}\\)å·®åˆ«æ¯”è¾ƒå¤§ï¼Œè€Œæ­£å¸¸æ ·æœ¬åˆ™åº”è¯¥æ¥è¿‘\\(\\mu_\\mathcal{R}\\)ã€‚ Deviation Networks ä¸‹é¢æ˜¯ä¸Šè¿°ä¸‰ä¸ªéƒ¨ä»¶çš„å…·ä½“å®ç°ã€‚ End-To-End Anomaly Scoring Network è®°\\(\\mathcal{Q}\\in\\mathbb{R}^M\\)ä¸ºä¸­é—´è¡¨ç¤ºç©ºé—´ï¼Œanomaly scoring network\\(\\phi(\\cdot;\\Theta):\\mathcal{X}\\mapsto\\mathbb{R}\\)å¯ä»¥å®šä¹‰ä¸ºæ•°æ®è¡¨ç¤ºå­¦ä¹ \\(\\psi(\\cdot;\\Theta_t):\\mathcal{X}\\mapsto\\mathcal{Q}\\)å’Œå¼‚å¸¸åˆ†æ•°å­¦ä¹ \\(\\eta(\\cdot;\\Theta_s):\\mathcal{Q}\\mapsto\\mathbb{R}\\)ä¸¤é˜¶æ®µçš„ç»„åˆï¼Œå…¶ä¸­\\(\\Theta=\\{\\Theta_t,\\Theta_s\\}\\)ã€‚ \\(\\psi(\\cdot;\\Theta_t)\\)å¯ä»¥ç”¨ä¸€ä¸ª\\(H\\)å±‚ç¥ç»ç½‘ç»œæ¥å®ç°ï¼š \\[ \\mathrm{q}=\\psi(\\mathbf{x};\\Theta_t) \\] å…¶ä¸­\\(\\mathbf{x}\\in\\mathcal{X}\\)ï¼Œ\\(\\mathrm{q}\\in\\mathcal{Q}\\)ã€‚ \\(\\eta(\\cdot;\\Theta_s)\\)å¯ä»¥ç”¨ä¸€ä¸ªå•å±‚çš„ç¥ç»ç½‘ç»œæ¥å®ç°ï¼š \\[ \\eta(\\mathrm q;\\Theta_s)=\\sum\\limits_{i=1}^M w_i^oq_i+w_{M+1}^o \\] å…¶ä¸­\\(\\mathrm q\\in\\mathcal Q\\)ï¼Œ\\(\\Theta_s=\\{\\mathbf{w}^o\\}\\)ã€‚ æ‰€ä»¥æœ‰ï¼š \\[ \\phi(\\mathbf{x};\\Theta)=\\eta(\\psi(\\mathbf{x};\\Theta_t);\\Theta_s) \\] Gaussian Prior-based Reference Scores æœ‰ä¸¤ç§æ–¹æ³•æ¥è·å¾—\\(\\mu_\\mathcal{R}\\)ï¼Œä¸€ç§æ˜¯data-drivenï¼Œä¸€ç§æ˜¯prior-drivenã€‚å¦‚æœæ˜¯data-drivençš„è¯åˆ™é‡‡ç”¨å¦ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œæ–‡ä¸­è¡¨ç¤ºä¸ºäº†æ›´å¥½çš„è§£é‡Šæ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œæ‰€ä»¥é‡‡ç”¨çš„æ˜¯prior-drivenã€‚ \\[ \\begin{align} r_1,r_2,\\cdots,r_l\\sim \\mathcal{N}(\\mu,\\sigma^2),\\\\ \\mu_\\mathcal{R}=\\frac{1}{l}\\sum\\limits_{i=1}^l r_i \\end{align} \\] åœ¨æ–‡ä¸­ï¼Œé‡‡ç”¨çš„prioræ˜¯æ ‡å‡†é«˜æ–¯åˆ†å¸ƒã€‚ Z-Score Based Deviation Loss anomaly scoring networkçš„ä¼˜åŒ–ç›®æ ‡å¯ä»¥å®šä¹‰ä¸ºZ-Scoreçš„æ–¹å¼ï¼š \\[ dev(\\boldsymbol x)=\\frac{\\phi(\\boldsymbol x;\\Theta)-\\mu_{\\mathcal{R}}}{\\sigma_{\\mathcal{R}}} \\] \\(dev(\\boldsymbol x)\\)å¯ä»¥çœ‹ä½œæ˜¯æ ·æœ¬åç¦»æ ‡å‡†çš„ç¨‹åº¦ï¼Œè€Œæˆ‘ä»¬è‚¯å®šå¸Œæœ›å¼‚å¸¸æ ·æœ¬åç¦»æ ‡å‡†è¶Šå¤§ï¼Œæ­£å¸¸æ ·æœ¬è¶Šæ¥è¿‘æ ‡å‡†ã€‚æ–‡ä¸­é‡‡ç”¨çš„æŸå¤±å‡½æ•°æ˜¯Contrastive Lossï¼š \\[ L(\\phi(\\boldsymbol x;\\Theta),\\mu_\\mathcal{R},\\sigma_\\mathcal{R})=(1-y)|dev(\\boldsymbol x)| + y \\max(0, a - dev(\\boldsymbol x)) \\] Contrastive Lossçš„ç›´è§‚è§£é‡Šå¯ä»¥çœ‹ä¸‹å›¾ï¼š å¯¹äºè´Ÿä¾‹ï¼ˆæ­£å¸¸ï¼‰ï¼Œä¼˜åŒ–è¿‡ç¨‹å°†ä»–ä»¬å°½é‡å‘åŸç‚¹é è¿‘ï¼Œå¯¹äºæ­£ä¾‹ï¼ˆå¼‚å¸¸ï¼‰ï¼Œä¼˜åŒ–è¿‡ç¨‹å°†ä»–ä»¬æ‹‰å‘è¾¹ç•Œã€‚ The DevNet Algorithm DevNetçš„ç®—æ³•æµç¨‹å›¾å¦‚ä¸‹ï¼š Interpretability of Anomaly Scores å› ä¸ºreference score generatoré€‰æ‹©çš„æ˜¯ç¡®å®šçš„é«˜æ–¯åˆ†å¸ƒï¼Œäºæ˜¯å¯ä»¥ç”¨æ¦‚ç‡è®ºç»™å‡ºä¸€äº›è§£é‡Šæ€§ã€‚ä½œè€…ç»™å‡ºäº†ä¸€ä¸ªç»“è®ºï¼Œ PROPOSITIONï¼š è®¾\\(\\boldsymbol x\\in\\mathcal{X}\\)ï¼Œ\\(z_p\\)ä¸º\\(\\mathcal{N}(\\mu,\\sigma^2)\\)çš„åˆ†ä½æ•°ï¼Œé‚£ä¹ˆ\\(\\phi(\\boldsymbol x)\\)åœ¨åŒºé—´\\(\\mu\\pm z_p\\sigma\\)çš„æ¦‚ç‡ä¸º\\(2(1-p)\\)ã€‚ ä¾‹å¦‚ï¼Œå‡è®¾\\(p=0.95\\)ï¼Œé‚£ä¹ˆ\\(z_{0.95}=1.96\\)ï¼Œè¡¨ç¤ºå¼‚å¸¸åˆ†æ•°é«˜äº1.96çš„æ ·æœ¬å°†ä»¥0.95çš„ç½®ä¿¡åº¦ä¸ºå¼‚å¸¸ã€‚ Experiment å®éªŒç”¨åˆ°äº†9ä¸ªæ•°æ®é›†ï¼Œ4ä¸ªBaseline (REPENï¼ŒDSVDDï¼ŒFSNETï¼ŒiForest)ï¼Œä»¥åŠROCå’ŒPRæ›²çº¿ä¸¤ç§è¯„æµ‹æ ‡å‡†ã€‚ Effectiveness in Real-world Data Sets Experiment Settings è¿™ä¸€ä¸ªå®éªŒä¸»è¦æ˜¯ä¸ºäº†éªŒè¯ç®—æ³•åœ¨çœŸå®åœºæ™¯ä¸‹çš„æ•ˆæœï¼Œå³å¤§é‡æ— æ ‡ç­¾æ•°æ®å’Œæå°‘é‡æ ‡ç­¾æ•°æ®ã€‚è®­ç»ƒé›†åŒ…å«ä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ˜¯æ— æ ‡ç­¾æ•°æ®\\(\\mathcal{U}\\),åŒ…å«\\(2\\%\\)çš„å¼‚å¸¸æ ·æœ¬ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯æœ‰æ ‡ç­¾æ•°æ®\\(\\mathcal{K}\\)ï¼Œç”±éšæœºé‡‡æ ·\\(0.005\\%-1\\%\\)çš„è®­ç»ƒæ•°æ®å’Œ\\(0.08\\%-6\\%\\)çš„å¼‚å¸¸æ ·æœ¬ç»„æˆã€‚ Findings å®éªŒç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š ä»ç»“æœä¸Šçœ‹æ¥ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½æ¯”Baselineå¥½ï¼Œè¯´æ˜DevNetç«¯åˆ°ç«¯ç›´æ¥ä¼˜åŒ–Anomaly Scoreçš„æ–¹å¼æ˜¯æœ‰æ•ˆçš„ã€‚ Data Efficiency Experiment Settings è¿™ä¸€ä¸ªå®éªŒä¸»è¦æ˜¯ä¸ºäº†æ¢ç©¶åŸºäºæ·±åº¦çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•çš„data efficiencyã€‚å’Œä¸Šä¸€ä¸ªå®éªŒä¸€æ ·ï¼Œæ— æ ‡ç­¾æ•°æ®é›†åŒ…å«\\(2\\%\\)çš„å¼‚å¸¸ï¼Œè€Œæœ‰æ ‡ç­¾çš„å¼‚å¸¸æ•°é‡ä»\\(5\\)åˆ°\\(120\\)ä¸ç­‰ã€‚æœ¬å®éªŒè¯•å›¾å›ç­”ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼š DevNetçš„data efficiencyå¦‚ä½•ï¼Ÿ åŸºäºæ·±åº¦çš„æ–¹æ³•åœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿåˆ©ç”¨æ ‡ç­¾ä¿¡æ¯ï¼Ÿ Findings åœ¨å‡ ä¸ªåŸºäºæ·±åº¦çš„Baselineä¸­ï¼ŒDevNetçš„æ•ˆæœæ˜¯æœ€å¥½çš„ï¼ŒåŒæ—¶åœ¨æœ‰æ ‡ç­¾å¼‚å¸¸éå¸¸æœ‰é™çš„æƒ…å†µä¸‹ï¼ŒDevNetä¹Ÿèƒ½å¾ˆå¥½çš„åˆ©ç”¨æ ‡ç­¾ä¿¡æ¯ï¼Œè¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚ Robustness w.r.t. Anomaly Contamination Experiment Settings åœ¨ç¬¬ä¸€ä¸ªå®éªŒä¸­ï¼Œæ— æ ‡ç­¾æ•°æ®é›†\\(\\mathcal{U}\\)åŒ…å«çš„æ˜¯å›ºå®šçš„å¼‚å¸¸æ¯”ä¾‹\\(2\\%\\)ï¼Œè€Œåœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œä½œè€…æµ‹è¯•äº†ä»\\(0\\%\\)åˆ°\\(20\\%\\)ä¹‹é—´ä¸åŒå¼‚å¸¸æ¯”ä¾‹æ¥æµ‹è¯•ç®—æ³•çš„é²æ£’æ€§ï¼ˆå³ä½¿\\(\\mathcal{U}\\)ä¸­åŒ…å«å¼‚å¸¸ï¼Œç”±äºæ²¡æœ‰æ ‡ç­¾ï¼Œåœ¨è®­ç»ƒçš„æ—¶å€™ä»ç„¶å‡è®¾éƒ½ä¸ºæ­£å¸¸æ¥è¿›è¡Œè®­ç»ƒï¼‰ã€‚æœ¬å®éªŒè¯•å›¾å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š åŸºäºæ·±åº¦çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•çš„é²æ£’æ€§å¦‚ä½•ï¼Ÿ å½“è®­ç»ƒé›†ä¸­å¼‚å¸¸æ±¡æŸ“çš„æ¯”ä¾‹è¾ƒé«˜çš„æ—¶å€™åŸºäºæ·±åº¦çš„æ–¹æ³•èƒ½å¦æ‰“è´¥æ— ç›‘ç£çš„æ–¹æ³•ï¼Ÿ Findings ä¸‹å›¾ä¸ºå®éªŒç»“æœï¼š ä»ç»“æœä¸Šæ¥çœ‹ï¼ŒDevNetæ¯”å…¶ä»–åŸºäºæ·±åº¦çš„æ–¹æ³•é²æ£’æ€§æ›´å¥½ï¼ŒåŒæ—¶åœ¨é«˜å¼‚å¸¸æ±¡æŸ“çš„æƒ…å†µä¸‹ä»ç„¶æ¯”çº¯æ— ç›‘ç£æ–¹æ³•æ•ˆæœè¦å¥½ã€‚ Ablation Study æœ¬å®éªŒè®¾ç½®äº†DevNetçš„ä¸‰ä¸ªå˜ä½“ï¼ˆé»˜è®¤çš„DevNet-Defä¸ºå•å±‚éšå±‚åŠ ä¸Šä¸€ä¸ªè¾“å‡ºå±‚ï¼‰æ¥è¿›è¡Œæ¶ˆèå®éªŒï¼Œåˆ†åˆ«æ˜¯ï¼š DevNet-Repï¼Œå»æ‰äº†anomaly scoring networkç½‘ç»œçš„è¾“å‡ºå±‚ï¼Œå¯¹åº”end-to-end learning of anomaly scoreså’Œdeviation lossï¼› DevNet-Linearï¼Œå»æ‰äº†ç½‘ç»œä¸­çš„éçº¿æ€§å±‚ï¼Œå¯¹åº”learning of non-linear featuresï¼› DevNet-3HLï¼Œéšå±‚æ•°é‡ä¸º3å±‚ã€‚ å¯¹æ¯”ç»“æœå¦‚ä¸‹ï¼š é€šè¿‡å®éªŒå¯ä»¥å‘ç°ï¼ŒDevNet-Repè¯´æ˜äº†end-to-end learning of anomaly scoreså’Œdeviation lossçš„æœ‰æ•ˆæ€§ï¼Œè€ŒDevNet-Linearè¯´æ˜äº†learning of non-linear featuresçš„é‡è¦æ€§ã€‚DevNet-3HLè¯´æ˜äº†åŠ æ·±ç½‘ç»œå¹¶ä¸æ€»èƒ½å¸¦æ¥æ€§èƒ½çš„æå‡ã€‚ Scalability Test è¿™ä¸€ä¸ªå®éªŒä½¿ç”¨åˆæˆçš„æ•°æ®æ¥æµ‹è¯•ç®—æ³•å¯¹å¤§è§„æ¨¡æ•°æ®çš„å¤„ç†èƒ½åŠ›ï¼Œåˆ†åˆ«ä»Data Sizeå’ŒData Dimensionalityä¸¤æ–¹é¢æ¥æµ‹è¯•ã€‚ç»“æœå¦‚ä¸‹ï¼š å¯ä»¥çœ‹å‡ºï¼ŒDevNetå¯¹Data Sizeå¹¶ä¸æ•æ„Ÿï¼ŒåŒæ—¶ï¼Œé¢å¯¹é«˜ç»´æ•°æ®ï¼ŒDevNetä¹Ÿæ²¡æœ‰è¡¨ç°å‡ºåŠ£åŠ¿ã€‚","link":"/2020/02/24/Deep-Anomaly-Detection-with-Deviation-Networks/"},{"title":"Geant4 å®‰è£…æ•™ç¨‹ä¸è°ƒè¯•ç¯å¢ƒé…ç½®","text":"Introduction Geant4å®‰è£…çš„æ•™ç¨‹å¾ˆå¤šï¼Œç‰ˆæœ¬éƒ½å¾ˆæ—§äº†ï¼Œè¿™é‡Œå†™ä¸€ä¸ªæ–°ç‰ˆæœ¬ï¼ˆ10.6ï¼‰åŸºäºUbuntuçš„å®‰è£…æ•™ç¨‹ï¼Œå¹¶ä¸”å¼€å¯CLion IDEè°ƒè¯•ã€‚ Step 1: Download Packages é¦–å…ˆè¿›å…¥å®˜ç½‘(http://geant4.web.cern.ch/support/download)ä¸‹è½½æºä»£ç ï¼ˆæ¨ètar.gzæ ¼å¼ï¼‰åŠæ•°æ®æ–‡ä»¶ï¼Œè§£å‹ã€‚æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ä¸“é—¨ç”¨æ¥æ”¾Geant4ç›¸å…³æ–‡ä»¶ï¼Œæ–°å»ºdataï¼Œsourceï¼Œbuildæ–‡ä»¶å¤¹ï¼Œå°†Geant4çš„æ–‡ä»¶å¤åˆ¶è¿›æ¥å¹¶æŒ‰å¦‚ä¸‹ç»“æ„ç»„ç»‡ï¼š 1234567891011121314151617.â”œâ”€â”€ buildâ”œâ”€â”€ dataâ”‚ â”œâ”€â”€ G4ABLA3.1â”‚ â”œâ”€â”€ G4EMLOW7.9â”‚ â”œâ”€â”€ G4ENSDFSTATE2.2â”‚ â”œâ”€â”€ G4INCL1.0â”‚ â”œâ”€â”€ G4NDL4.6â”‚ â”œâ”€â”€ G4PARTICLEXS2.1â”‚ â”œâ”€â”€ G4PII1.3â”‚ â”œâ”€â”€ G4SAIDDATA2.0â”‚ â”œâ”€â”€ G4TENDL1.3.2â”‚ â”œâ”€â”€ PhotonEvaporation5.5â”‚ â”œâ”€â”€ RadioactiveDecay5.4â”‚ â””â”€â”€ RealSurface2.1.1â””â”€â”€ source â””â”€â”€ geant4.10.06 Step 2: Install Dependencies å®‰è£…ç¼–è¯‘æ‰€éœ€ç¯å¢ƒï¼š 1sudo apt-get install build-essential cmake å®‰è£…ç›¸å…³ä¾èµ–ï¼š 1sudo apt-get install libgl1-mesa-dev libglu1-mesa-dev libxt-dev libxmu-dev libxi-dev zlib1g-dev libgl2ps-dev libexpat1-dev libxerces-c-dev å¦‚æœè¦ç”¨åˆ°QTéœ€è¦å•ç‹¬å®‰è£…QTã€‚ Step 3: Compile è¿›å…¥buildæ–‡ä»¶å¤¹ï¼Œç”¨cmakeå‘½ä»¤ï¼š 1cmake ../source/geant4.10.06/ -DCMAKE_BUILD_TYPE=DEBUG -DGEANT4_USE_GDML=ON -DGEANT4_USE_OPENGL_X11=ON -DGEANT4_USE_RAYTRACER_X11=ON -DGEANT4_BUILD_MULTITHREADED=ON å…¶ä¸­../source/geant4.10.06/æ›¿æ¢æˆæ¢æˆï¼ˆå¦‚æœç‰ˆæœ¬ä¸ä¸€æ ·ï¼‰ä½ è‡ªå·±çš„Geant4æºä»£ç æ‰€åœ¨ç›®å½•ï¼Œéœ€è¦QTåˆ™åŠ ä¸Š-DGEANT4_USE_QT=ONã€‚å¦‚æœä¸éœ€è¦è°ƒè¯•åˆ™æŠŠ-DCMAKE_BUILD_TYPE=DEBUGæ”¹æˆ-DCMAKE_BUILD_TYPE=RELEASEã€‚-DGEANT4_BUILD_MULTITHREADED=ONæ˜¯å¤šçº¿ç¨‹ï¼Œè§†æƒ…å†µå¼€å¯ã€‚ å®Œæˆä¹‹åå¼€å§‹ç¼–è¯‘ï¼š 1make -jX -jXä¸ºå¤šçº¿ç¨‹ç¼–è¯‘ï¼Œå¦‚-j8ã€‚ ç¼–è¯‘å®Œæˆä¹‹åè¿›è¡Œå®‰è£…ï¼š 1sudo make install Step 4: Configure å®‰è£…çš„é»˜è®¤è·¯å¾„åœ¨/usr/local/share/Geant4-10.6.0ï¼Œå°†ä¸‹è½½çš„æ•°æ®æ–‡ä»¶å¤åˆ¶åˆ°è¯¥æ–‡ä»¶å¤¹ï¼š 1sudo cp -r ./data/ /usr/local/share/Geant4-10.6.0/ ä¹‹åï¼Œåœ¨~/.bashrcé‡Œæ·»åŠ /usr/local/share/Geant4-10.6.0/geant4make/geant4make.shï¼Œå¦‚æœä½ çš„ç‰ˆæœ¬å’Œæˆ‘çš„ä¸ä¸€æ ·ï¼Œç›¸åº”ä¿®æ”¹å³å¯ã€‚ Step 5: CLion Configuration æœ€åæˆ‘ä»¬æ¥é…ç½®CLionç¯å¢ƒï¼Œé…å¥½ä¹‹åå¯ä»¥åœ¨IDEä¸­ç¼–å†™Geant4ä»£ç ï¼Œè¿˜å¯ä»¥æ–­ç‚¹è°ƒè¯•ï¼Œéå¸¸æ–¹ä¾¿ã€‚å®‰è£…CLionçš„è¿‡ç¨‹è¿™é‡Œçœç•¥ï¼Œæ‰“å¼€ä¸€ä¸ªGeant4è‡ªå¸¦çš„ä¾‹å­æˆ–è€…è‡ªå·±æ–°å»ºä¸€ä¸ªé¡¹ç›®ï¼Œæ‰“å¼€Edit Configurationsã€‚ éšä¾¿æ‰“å¼€ä¸€ä¸ªç»ˆç«¯ï¼Œè¾“å…¥ä¸€ä¸‹å‘½ä»¤è·å–ç¯å¢ƒå˜é‡ï¼š 1env | grep G4 åœ¨Environment variableså¡«å…¥åˆšæ‰è·å–çš„ç¯å¢ƒå˜é‡ï¼ˆå¤åˆ¶ä¹‹åæŒ‰ä¸€ä¸‹ç²˜è´´å°±å¯ä»¥äº†ï¼‰ï¼Œç„¶åæŠŠWorking directoryè®¾ç½®æˆå½“å‰æ–‡ä»¶å¤¹ã€‚ ç°åœ¨å°±å¤§åŠŸå‘Šæˆäº†ï¼","link":"/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"title":"Time Series Anomaly Detection Paper List","text":"Introduction æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹åœ¨å¾ˆå¤šé¢†åŸŸä¾‹å¦‚è¿ç»´ã€é‡‘èã€äº¤é€šéƒ½æ‰®æ¼”è€…é‡è¦çš„è§’è‰²ï¼Œå…¶å®šä¹‰å¦‚ä¸‹ï¼š ç»™å®šæ—¶é—´åºåˆ—\\(X=\\{\\mathbf{x}_1,\\mathbf{x}_2,\\cdots,\\mathbf{x}_n\\}\\in\\mathbb{R}^{m\\times n}\\)ï¼Œå¼‚å¸¸æ£€æµ‹çš„ä»»åŠ¡æ˜¯è¾“å‡ºå¼‚å¸¸æ ‡ç­¾\\(y=\\{y_1,y_2,\\cdots,y_n\\}\\in\\mathbb{R}^n\\)ï¼Œå…¶ä¸­\\(y_t=1\\)ä»£è¡¨\\(\\mathbf{x}_t\\)ä¸ºå¼‚å¸¸ï¼Œ\\(y_t=0\\)ä»£è¡¨\\(\\mathbf{x}_t\\)æ­£å¸¸ æœ¬æ–‡ç½—åˆ—äº†ä¸€äº›æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹é¢†åŸŸå€¼å¾—è¯»çš„ä¸€äº›æ–‡ç« ï¼ŒModelä¸€ç« ä¸»è¦æŒ‰æ—¶é—´åºåˆ—ã€é€šç”¨å’Œå›¾çš„å¼‚å¸¸æ£€æµ‹åˆ†ç±»ï¼ŒRelatedä¸»è¦æ˜¯ä¸€äº›éå¼‚å¸¸æ£€æµ‹ã€ä½†æ˜¯èƒ½å¤Ÿè§£å†³å¼‚å¸¸æ£€æµ‹ç ”ç©¶ä¸­çš„ä¸€äº›é—®é¢˜çš„æ–‡ç« ã€‚ Model Time Series Statistical ä¸»è¦åŒ…æ‹¬åå‘ç»Ÿè®¡æ–¹æ³•çš„æ¨¡å‹ï¼š Title Conf/Journal Description Links Temporal Anomaly Detection: Calibrating the Surprise ğŸ“ƒPaper Non-Parametric Outliers Detection in Multiple Time Series A Case Study: Power Grid Data Analysis ğŸ“ƒPaper Anomaly Detection in Streams with Extreme Value Theory KDD17 æå‡ºäº†ä»¥Extreme Value Theoryä¸ºåŸºç¡€çš„æ—¶åºå¼‚å¸¸æ£€æµ‹å’Œå‚æ•°é€‰æ‹©æ–¹æ³• ğŸ“ƒPaper Semi-Markov Switching Vector Autoregressive Model-Based Anomaly Detection in Aviation Systems ğŸ“ƒPaper Stochastic Online Anomaly Analysis for Streaming Time Series ğŸ“ƒPaper Unsupervised Real-time Anomaly Detection for Streaming Data ğŸ“ƒPaper Automatic Anomaly Detection in the Cloud Via Statistical Learning ğŸ“ƒPaper Classic Machine Learning Title Conf/Journal Description Links Semi-supervised Anomaly Detection with an Application to Water Analytics ğŸ“ƒPaper DILOF: Effective and Memory Efficient Local Outlier Detection in Data Streams ğŸ“ƒPaper Robust Random Cut Forest Based Anomaly Detection On Streams ICML16 å­¤ç«‹æ£®æ—çš„æ”¹è¿›ç‰ˆæœ¬æ¥åšæ—¶åºå¼‚å¸¸æ£€æµ‹ ğŸ“ƒPaper ğŸ“¥Code Anomaly Detection for an E-commerce Pricing System ğŸ“ƒPaper An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in Time Series ğŸ“ƒPaper Opprentice: Towards Practical and Automatic Anomaly Detection Through Machine Learning IMC15 ä»¥éšæœºæ£®æ—ä¸ºåŸºç¡€çš„æ—¶åºå¼‚å¸¸æ£€æµ‹ ğŸ“ƒPaper Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series ğŸ“ƒPaper A Self-Learning and Online Algorithm for Time SeriesAnomaly Detection, with Application in CPU Manufacturing ğŸ“ƒPaper VAE Title Conf/Journal Description Links Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications WWW18 æ™®é€šVAE ğŸ“ƒPaper ğŸ“¥Code âœBlog Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder IPCCC18 æ¡ä»¶VAE ğŸ“ƒPaper ğŸ“¥Code Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE INFOCOM19 VAEåŠ å¯¹æŠ—è®­ç»ƒ ğŸ“ƒPaper Multidimensional Time Series Anomaly Detection: A GRU-based Gaussian Mixture Variational Autoencoder Approach ğŸ“ƒPaper Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network KDD19 å¤šå˜é‡åŸºäºVAEå’ŒRNNçš„æ—¶åºå¼‚å¸¸æ£€æµ‹ ğŸ“ƒPaper ğŸ“¥Code A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-based Variational Autoencoder ğŸ“ƒPaper RNN Title Conf/Journal Description Links Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding ğŸ“ƒPaper BINet: Multivariate Business Process Anomaly Detection Using Deep Learning ğŸ“ƒPaper Outlier Detection for Time Series with Recurrent Autoencoder Ensembles ğŸ“ƒPaper LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection ğŸ“ƒPaper Detecting Anomalies in Space using Multivariate Convolutional LSTM with Mixtures of Probabilistic PCA KDD19 ğŸ“ƒPaper GAN Title Conf/Journal Description Links Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series ğŸ“ƒPaper ğŸ“¥Blog MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks ICANN19 æ™®é€šGANåšæ—¶åºå¼‚å¸¸æ£€æµ‹ï¼Œæ²¡æœ‰ç¼–ç ç»“æ„ ğŸ“ƒPaper ğŸ“¥Code BeatGAN: Anomalous Rhythm Detection using Adversarially Generated Time Series IJCAI19 ECGå¼‚å¸¸æ£€æµ‹ï¼Œæ²¡æœ‰éšå˜é‡çº¦æŸ ğŸ“ƒPaper Miscellaneous Title Conf/Journal Description Links A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data ğŸ“ƒPaper ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection Expert Systems With Applications æœ‰ç›‘ç£KPIå¼‚å¸¸æ£€æµ‹ï¼Œä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ¥æå‡æ€§èƒ½ ğŸ“ƒPaper âœBlog Time-Series Anomaly Detection Service at Microsoft KDD19 å°†è§†è§‰å¼‚å¸¸æ£€æµ‹ä¸­çš„è°±æ®‹å·®åº”ç”¨åˆ°äº†æ—¶åºå¼‚å¸¸æ£€æµ‹ ğŸ“ƒPaper ğŸ“¥Code âœBlog Outlier Detection for Multidimensional Time Series using Deep Neural Networks ğŸ“ƒPaper General Survey Deep Learning for Anomaly Detection: A Survey [Paper] Classic Machine Learning Title Conf/Journal Description Links LOF: Identifying Density-Based Local Outliers ğŸ“ƒPaper Isolation Forest ğŸ“ƒPaper Extended Isolation Forest ğŸ“ƒPaper Hidden Markov Anomaly Detection ğŸ“ƒPaper Linear-Time Outlier Detection via Sensitivity ğŸ“ƒPaper Reverse Nearest Neighbors in Unsupervised Distance-Based Outlier Detection ğŸ“ƒPaper Theoretical Foundations and Algorithms for Outlier Ensembles ğŸ“ƒPaper R1SVM: A Randomised Nonlinear Approach to Large-Scale Anomaly Detection ğŸ“ƒPaper Random Gradient Descent Tree: A Combinatorial Approach for SVM with Outliers ğŸ“ƒPaper Sparse Gaussian Markov Random Field Mixtures for Anomaly Detection ğŸ“ƒPaper Sequential Ensemble Learning for Outlier Detection: A Bias-Variance Perspective ğŸ“ƒPaper Sparse Modeling-Based Sequential Ensemble Learning for Effective Outlier Detection in High-Dimensional Numeric Data ğŸ“ƒPaper Contextual Spatial Outlier Detection with Metric Learning ğŸ“ƒPaper Human-Assisted Online Anomaly Detection with Normal Outlier Retraining ğŸ“ƒPaper Efficient Anomaly Detection via Matrix Sketching ğŸ“ƒPaper Dual-Regularized Multi-View Outlier Detection ğŸ“ƒPaper Deep Anomaly Detection Using Geometric Transformations ğŸ“ƒPaper Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models ğŸ“ƒPaper Partial Multi-View Outlier Detection Based on Collective Learning ğŸ“ƒPaper Multi-View Anomaly Detection: Neighborhood in Locality Matters ğŸ“ƒPaper Latent Discriminant Subspace Representations for Multi-View Outlier Detection ğŸ“ƒPaper Anomaly Detection with Partially Observed Anomalies ğŸ“ƒPaper One-Class Active Learning for Outlier Detection with Multiple Subspaces ğŸ“ƒPaper Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection NIPS19 ğŸ“ƒPaper SNIPER: Few-shot Learning for Anomaly Detection to Minimize False-negative Rate with Ensured True-positive Rate ICASSP19 ğŸ“ƒPaper AE/VAE Title Conf/Journal Description Links Estimation of Dimensions Contributing to Detected Anomalies with Variational Autoencoders ğŸ“ƒPaper Anomaly Detection with Robust Deep Autoencoders ğŸ“ƒPaper Complementary Set Variational Autoencoder for Supervised Anomaly Detection ğŸ“ƒPaper A Two-class Hyper-spherical Autoencoder for Supervised Anomaly Detection ğŸ“ƒPaper GAN Title Conf/Journal Description Links Adversarially Learned Anomaly Detection ğŸ“ƒPaper AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and Time-Evolving Categorical Data ğŸ“ƒPaper Adversarially Learned One-Class Classifier for Novelty Detection ğŸ“ƒPaper ğŸ“¥Code Generative Probabilistic Novelty Detection with Adversarial Autoencoders ğŸ“ƒPaper ğŸ“¥Code OCGAN: One-class Novelty Detection Using GANs with Constrained Latent Representations ğŸ“ƒPaper Fence GAN: Towards Better Anomaly Detection Arxiv ğŸ“ƒPaper Anomaly Detection via Minimum Likelihood Generative Adversarial Networks Arxiv ğŸ“ƒPaper DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN ICDM18 ğŸ“ƒPaper Learning Competitive and Discriminative Reconstructions for Anomaly Detection AAAI19 ğŸ“ƒPaper Miscellaneous Title Conf/Journal Description Links Deep Structured Energy Based Models for Anomaly Detection ğŸ“ƒPaper Anomaly Detection using One-Class Neural Networks ğŸ“ƒPaper ğŸ“¥Code High-dimensional and large-scale anomaly detection using a linear one-class SVM with deep learning ğŸ“ƒPaper Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection ğŸ“ƒPaper Deep Anomaly Detection with Outlier Exposure ğŸ“ƒPaper Are Generative Deep Models for Novelty Detection Truly Better? KDD18 Workshop ğŸ“ƒPaper Probabilistic-Mismatch Anomaly Detection: Do one's Medications Match with the Diagnoses? ICDM16 ğŸ“ƒPaper Deep Anomaly Detection with Deviation Networks KDD19 ğŸ“ƒPaper Weakly-supervised Deep Anomaly Detection with Pairwise Relation Learning AAAI20 ğŸ“ƒPaper Transfer Anomaly Detection by Inferring Latent Domain Representations NIPS19 ğŸ“ƒPaper Multi-view Anomaly Detection via Robust Probabilistic Latent Variable Models NIPS16 ğŸ“ƒPaper Continual Learning for Anomaly Detection with Variational Autoencoder ICASSP19 ğŸ“ƒPaper AdaFlow: Domain-adaptive Density Estimator with Application to Anomaly Detection and Unpaired Cross-domain Translation ICASSP19 ğŸ“ƒPaper Graph AddGraph: Anomaly Detection in Dynamic Graph Using Attention-based Temporal GCN [Paper] Outlier Detection in Graph Streams [Paper] NetWalk: A Flexible Deep Embedding Approach for Anomaly Detection in Dynamic Networks [Paper] Anomaly Detection in Dynamic Networks using Multi-view Time-Series Hypersphere Learning [Paper] Related è¿™ä¸€éƒ¨åˆ†ä¸»è¦æ˜¯ä¸€äº›éå¼‚å¸¸æ£€æµ‹æ–‡ç« ï¼Œä½†æ˜¯å¯ä»¥ç”¨æ¥è§£å†³å¼‚å¸¸æ£€æµ‹ä¸­çš„é—®é¢˜çš„ç›¸å…³æ–‡ç« ã€‚ Infrastructure GAN Generative Adversarial Networks [Paper] VAE &amp; GAN Combination Variational Approaches for Auto-Encoding Generative Adversarial Networks [Paper] Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks [Paper] On Unifying Deep Generative Models [Paper] Bidirectional GANs Adversarial Feature Learning [Paper] Adversarially Learned Inference [Paper] It Takes (Only) Two: Adversarial Generator-Encoder Networks [Paper] VAE Auto-Encoding Variational Bayes [Paper] Class Imbalance Focal Loss for Dense Object Detection [Paper] Gradient Harmonized Single-stage Detector [Paper] Stochastic Temporal Modeling Sequential Neural Models with Stochastic Layers [Paper] A Recurrent Latent Variable Model for Sequential Data [Paper] Deep State Space Models for Time Series Forecasting [Paper] Bayesian Recurrent Neural Networks [Paper] Detection without Closed-form Likelihood Reconstruction Adversarially Learned One-Class Classifier for Novelty Detection [Paper] Generative Adversarial Network Based Novelty Detection Using Minimized Reconstruction Error [Paper] Learning Discriminative Reconstructions for Unsupervised Outlier Removal [Paper] Discriminator A Lipschitz-constrained Anomaly Discriminator Framework [Paper] Out-of-distribution Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks [Paper] Learning Confidence for Out-of-Distribution Detection in Neural Networks [Paper] A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks [Paper] A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks [Paper] GANs for Incomplete Data AmbientGAN: Generative Models From Lossy Measurements [Paper] MisGAN: Learning from Incomplete Data with Generative Adversarial Networks [Paper] Dataset è¯¦è§http://qfxiao.me/2020/02/03/Datasets-for-Time-Series-Anomaly-Detection/ã€‚","link":"/2020/01/08/Time-Series-Anomaly-Detection-Paper-List/"},{"title":"Recurrent Neural Networks for Multivariate Time Series with Missing Values","text":"Abstract æ–‡ä¸­æå‡ºäº†ä¸€ç§å¯ä»¥å¤„ç†å¸¦ç¼ºå¤±å€¼å¤šä¸ºæ—¶é—´åºåˆ—çš„GRUæ¨¡å‹ï¼šGRU-Dã€‚æœ¬æ¨¡å‹ä¸ä»…å¯ä»¥æ•æ‰æ—¶é—´åºåˆ—ä¸­çš„é•¿æœŸä¾èµ–æ¨¡å¼ï¼Œå¹¶ä¸”è¿˜èƒ½åˆ©ç”¨æ—¶é—´åºåˆ—ä¸­çš„ç¼ºå¤±æ¨¡å¼æ¥è¾¾åˆ°æ›´å¥½çš„æ—¶é—´åºåˆ—é¢„æµ‹æ•ˆæœã€‚ åŸæ–‡ Methodology Notations è®°åŒ…å«\\(D\\)ä¸ªå˜é‡çš„å¤šå˜é‡æ—¶é—´åºåˆ—ä¸º\\(X=(x_1,x_2,\\cdots,x_T)^T\\in\\mathbb{R}^{T\\times D}\\)ï¼Œå…¶ä¸­å¯¹äºæ¯ä¸ª\\(t\\in\\{1,2,\\cdots,T\\},x_t\\in\\mathbb{R}^D\\)è¡¨ç¤ºæ—¶é—´åºåˆ—åœ¨æ—¶é—´\\(t\\)çš„è§‚æµ‹å€¼ï¼Œ\\(x_t^d\\)è¡¨ç¤º\\(x_t\\)çš„ç¬¬\\(d\\)ä¸ªæˆåˆ†ã€‚è®°\\(s_t\\in\\mathbb{R}\\)ä¸º\\(t\\)æ—¶åˆ»çš„æ—¶é—´æˆ³ï¼Œå¹¶å‡è®¾ç¬¬ä¸€ä¸ªè§‚æµ‹å€¼çš„æ—¶é—´æˆ³ä¸º\\(0\\)ã€‚å¯¹äºåŒ…å«ç¼ºå¤±å€¼çš„æ—¶é—´åºåˆ—ï¼Œæˆ‘ä»¬ç”¨Masking Vector \\(m_t\\in\\{0,1\\}\\)è¿›è¡Œæ ‡è®°ï¼ŒåŒæ—¶å¯¹æ¯ä¸ª\\(x_t^d\\)ç»´æŠ¤è·ç¦»ä¸Šä¸€ä¸ªè§‚æµ‹å€¼çš„Time Interval \\(\\delta_t^d\\in\\mathbb{R}\\)ï¼Œå…¬å¼å¦‚ä¸‹ï¼š \\[ m_t^d=\\begin{cases}1, &amp;\\text{if }x_t^d\\text{ is observed}\\\\0, &amp;\\text{otherwise}\\end{cases} \\] \\[ \\delta_t^d=\\begin{cases}s_t-s_{t-1}+\\delta_{t-1}^d, &amp;t&gt;1,m_{t-1}^d=0\\\\s_t-s_{t-1}, &amp;t&gt;1, m_{t-1}^d=1\\\\0, &amp;t=1\\end{cases} \\] ä¸‹å›¾æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨æ—¶é—´åºåˆ—çš„åˆ†ç±»é—®é¢˜ï¼Œå³ç»™å®šæ•°æ®é›†\\(\\mathcal{D}=\\{(X_n,s_n,M_n)\\}_{n=1}^N\\)ï¼Œæˆ‘ä»¬è¦å¯¹æ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«è¿›è¡Œé¢„æµ‹\\(l_n\\in\\{1,\\cdots,L\\}\\)ã€‚ GRU-RNN for Time Series Classification GRUæ˜¯ä¸€ç§æ”¹è¿›ç‰ˆæœ¬çš„RNNï¼Œå…¶æœ€å¤§ä¸åŒæ˜¯åŠ å…¥äº†é—¨æ§æœºåˆ¶ã€‚GRUå•å…ƒçš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š GRUåŒ…å«äº†é‡ç½®é—¨å’Œæ›´æ–°é—¨ï¼Œå…¶ä¸­é‡ç½®é—¨\\(R_t\\)è´Ÿè´£æ§åˆ¶ä¸Šä¸€æ—¶é—´çš„éšçŠ¶æ€\\(h_{t-1}\\)æœ‰å¤šå°‘éƒ¨åˆ†éœ€è¦ä¿ç•™ï¼Œè€Œæ›´æ–°é—¨åˆ™å†³å®šç”±\\(R_t\\)è®¡ç®—å‡ºæ¥çš„å€™é€‰éšçŠ¶æ€\\(\\tilde{h}_t\\)æœ‰å¤šå°‘éƒ¨åˆ†éœ€è¦ä¿ç•™ã€‚æœ€åå½“å‰æ—¶é—´çš„éšçŠ¶æ€ç”±\\(h_{t-1}\\)å’Œ\\(\\tilde{h}_t\\)å…±åŒç®—å‡ºã€‚GRUçš„çŠ¶æ€æ›´æ–°å…¬å¼å¦‚ä¸‹ï¼š \\[ \\begin{align} R_t&amp;=\\sigma(W_rx_t+U_rh_{t-1}+b_r)\\\\ Z_t&amp;=\\sigma(W_zx_t+U_zh_{t-1}+b_z)\\\\ \\tilde{h}_t&amp;=\\text{tanh}(Wx_t+U(R_t\\odot h_{t-1})+b)\\\\ h_t&amp;=(1-Z_t)\\odot h_{t-1}+Z_t\\odot \\tilde{h}_t \\end{align} \\] æ–‡ä¸­æå‡ºäº†ä¸€äº›å¤„ç†ç¼ºå¤±å€¼çš„ç®€å•æ–¹æ³•ï¼š ç›´æ¥ç”¨å‡å€¼æ›¿ä»£ï¼š\\(x_t^d\\leftarrow m_t^dx_t^d+(1-m_t^d)\\tilde{x}^d\\)ï¼Œå…¶ä¸­\\(\\tilde{x}^d=\\frac{\\sum_{n=1}^N\\sum_{t=1}^{T_n}m_{t,n}^d x_{t,n}^d}{\\sum_{n=1}^N\\sum_{t=1}^{T_n}m_{t,n}^d\\tilde{x}^d}\\)ã€‚è¿™ç§æ–¹æ³•ç§°ä¸ºGRU-Meanï¼› ç”¨ä¸Šä¸€ä¸ªè§‚æµ‹å€¼æ›¿ä»£ï¼š\\(x_t^d\\leftarrow m_t^d x_t^d+(1-m_t^d)x_{t^\\prime}^d\\)ã€‚è¿™ç§æ–¹æ³•ç§°ä¸ºGRU-Forwardï¼› ä¸å¡«å……ï¼Œå°†æ˜¯å¦ç¼ºå¤±ï¼Œè·ç¦»ä¸Šä¸€ä¸ªè§‚æµ‹å€¼çš„æ—¶é—´ä½œä¸ºé¢å¤–ä¿¡æ¯è¾“å…¥ï¼š\\(x_t^{(n)}\\leftarrow[x_t^{(n)};m_t^{(n)};\\delta_t^{(n)}]\\)ã€‚è¿™ç§æ–¹æ³•ç§°ä¸ºGRU-Simpleã€‚ GRU-D: Model with Trainable Decays æ–‡ä¸­æå‡ºäº†æ—¶é—´åºåˆ—ç¼ºå¤±å€¼çš„ä¸¤ä¸ªæ€§è´¨ï¼šä¸€ä¸ªæ˜¯åœ¨ä¸Šä¸€ä¸ªè§‚æµ‹å€¼è·ç¦»å¾ˆè¿œçš„æƒ…å†µä¸‹ç¼ºå¤±å€¼å€¾å‘äºæ¥è¿‘ä¸€ä¸ªé»˜è®¤çš„å€¼ï¼Œç¬¬äºŒä¸ªæ˜¯ç¼ºå¤±å€¼çš„å½±å“ä¼šéšç€æ—¶é—´å‡å¼±ã€‚ä¸ºäº†ä½“ç°ä¸Šè¿°ä¸¤ç‚¹ï¼Œæ–‡ä¸­æå‡ºäº†GPU-Dæ¨¡å‹ï¼Œæ¨¡å‹æ¡†æ¶å¦‚ä¸‹ï¼š åœ¨æ¨¡å‹ä¸­ï¼ŒDecay Ratesè¢«è®¾å®šä¸ºä¸€ä¸ªå¸¦å‚æ•°çš„å‡½æ•°å’ŒGRUä¸€èµ·è®­ç»ƒï¼š \\[ \\gamma_t=\\exp\\{-\\max(0,W_\\gamma\\delta_t+b_\\gamma)\\} \\] \\[ \\hat{x}_t^d=m_t^dx_t^d+(1-m_t^d)(\\gamma_{x_t}^dx_{t^\\prime}^d+(1-\\gamma_{x_t}^d)\\tilde{x}^d) \\] å…¶ä¸­\\(x_{t^\\prime}^d\\)æ˜¯ç¬¬\\(d\\)ä¸ªå˜é‡çš„ä¸Šä¸€ä¸ªè§‚æµ‹å€¼ï¼Œ\\(\\tilde{x}^d\\)æ˜¯ç¬¬\\(d\\)ä¸ªå˜é‡çš„ç»éªŒå‡å€¼ã€‚è¿™æ ·\\(\\hat{x}_t^d\\)å°±ä»£è¡¨ç»è¿‡Input Decayçš„è¾“å…¥ã€‚ æ–‡ä¸­æåˆ°åªç”¨Input Decayæ˜¯ä¸å¤Ÿçš„ï¼Œé™¤æ­¤ä¹‹å¤–ä½œè€…è¿˜ä½¿ç”¨äº†Hidden State Decayï¼Œå³å¯¹\\(h_{t-1}\\)è¿›è¡ŒDecayï¼Œå…¬å¼å¦‚ä¸‹ï¼š \\[ \\hat{h}_{t-1}=\\gamma_{h_t}\\odot h_{t-1} \\] ç”¨Decayä¹‹åçš„\\(\\hat{x}_t\\)å’Œ\\(\\hat{h}_{t-1}\\)æ›¿æ¢åŸå§‹çš„GRUå…¬å¼å°±å¾—åˆ°äº†GRU-Dæ¨¡å‹ï¼š \\[ \\begin{align} R_t&amp;=\\sigma(W_r\\hat{x}_t-U_r\\hat{h}_{t-1}+V_rm_t+b_r)\\\\ Z_t&amp;=\\sigma(W_z\\hat{x}_t+U_z\\hat{h}_{t-1}+V_zm_t+b_z)\\\\ \\tilde{h}_t&amp;=\\text{tanh}(W\\hat{x}_t+U(R_t\\odot \\hat{h}_{t-1})+Vm_t+b)\\\\ h_t&amp;=(1-z_t)\\odot \\hat{h}_{t-1}+z_t\\odot\\tilde{h}_t \\end{align} \\] Experiments Baseline Imputation Methods ä¸‹å›¾ä¸ºæ–‡ä¸­æ¯”è¾ƒä¸­ç”¨åˆ°çš„Baselineï¼š Baseline Prediction Methods ä¸‹å›¾ä¸ºæ–‡ä¸­ç”¨åˆ°çš„ç”¨æ¥é¢„æµ‹çš„Baselineï¼š Results æ–‡ä¸­ç”¨åˆ°çš„æ•°æ®é›†å¦‚ä¸‹ï¼š Gesture phase segmentation dataset (Gesture). PhysioNet Challenge 2012 dataset (PhysioNet). MIMIC-â…¢ dataset (MIMIC-â…¢). ä¸‹å›¾å±•ç¤ºäº†ä¸åŒæ–¹æ³•åœ¨äººå·¥åˆæˆæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š ä¸‹è¡¨å±•ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨é¢„æµ‹ä»»åŠ¡è¡¨ç°çš„å¯¹æ¯”ï¼š ä¸‹è¡¨å±•ç¤ºäº†ä¸åŒæ–¹æ³•åœ¨MIMIC-â…¢å’ŒPhysioNetæ•°æ®é›†ä¸Šçš„å¤šä»»åŠ¡è¡¨ç°ï¼š ä¸‹å›¾åˆ†åˆ«å±•ç¤ºäº†æ¨¡å‹å­¦åˆ°çš„Input Decayå’ŒHidden State Decayï¼š","link":"/2019/10/18/Recurrent-Neural-Networks-for-Multivariate-Time-Series-with-Missing-Values/"},{"title":"Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network","text":"Abstract æœ¬æ–‡æå‡ºäº†OmniAnomalyï¼šä¸€ç§é’ˆå¯¹å¤šå˜é‡æ—¶é—´åºåˆ—çš„éšæœºå¾ªç¯ç¥ç»ç½‘ç»œå¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚è¯¥æ¨¡å‹è¿ç”¨äº†ä¸€ç³»åˆ—æŠ€æœ¯æ¥æ•æ‰å¤šå˜é‡æ—¶é—´åºåˆ—çš„æ­£å¸¸æ¨¡å¼ï¼Œå¹¶åœ¨æ£€æµ‹é˜¶æ®µåŸºäºé‡æ„è¯¯å·®æ¥æ£€æµ‹å¼‚å¸¸ï¼ŒåŒæ—¶æœ¬æ–‡è¿˜æä¾›äº†ä¸€å®šçš„ç†è®ºè§£é‡Šã€‚ åŸæ–‡ Contribution æå‡ºäº†OmniAnomalyï¼Œä¸€ç§åŸºäºéšæœºå¾ªç¯ç¥ç»ç½‘ç»œçš„å¤šå˜é‡æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼› æå‡ºäº†é’ˆå¯¹å¤šå˜é‡æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„è§£é‡Šæ–¹æ³•ï¼› é€šè¿‡å®éªŒè¯æ˜äº†OmniAnomalyä¸­æ‰€ç”¨çš„å…³é”®æŠ€æœ¯çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬GRUï¼Œplanar NF, stochastic variable connectionå’Œadjusted Peaks-Over-Threshold methodï¼› é€šè¿‡å¤§é‡çš„å®éªŒæˆ‘ä»¬è¯æ˜äº†OmniAnomalyçš„æœ‰æ•ˆæ€§ï¼› å‘å¸ƒäº†ä»£ç å’Œæ•°æ®é›†ã€‚ Background Linear Gaussian State Space Model çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆState Space Model, SSMï¼‰çš„æ¦‚å¿µæ¥è‡ªäºæ§åˆ¶ç†è®ºï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä¸»è¦è®¨è®ºå…¶åœ¨æ—¶é—´åºåˆ—ä¸­çš„åº”ç”¨ã€‚å…¶å¤§æ¦‚æ€æƒ³æ˜¯æˆ‘ä»¬è®¤ä¸ºæ—¶é—´åºåˆ—åœ¨æ—¶åˆ»\\(t\\)çš„è§‚æµ‹å€¼\\(z_t\\)æ˜¯ä¸€ä¸ªéšå«çŠ¶æ€\\(\\boldsymbol{l}_t\\)çš„æ¡ä»¶åˆ†å¸ƒ\\(p(z_t|\\boldsymbol{l}_t)\\)ï¼Œè€Œè¿™ä¸ªéšå«çŠ¶æ€\\(\\boldsymbol{l}_t\\)åˆ»ç”»äº†æ—¶é—´åºåˆ—çš„å†…åœ¨è§„å¾‹ï¼ŒåŒæ—¶éšå«çŠ¶æ€ä¼šéšç€æ—¶é—´æ›´æ–°ï¼Œå³æœä»æ¡ä»¶åˆ†å¸ƒ\\(p(\\boldsymbol{l}_t|\\boldsymbol{l}_{t-1})\\)ã€‚ åœ¨çº¿æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆLinear State Space Modelï¼‰ä¸­æˆ‘ä»¬ä»¥å¦‚ä¸‹çš„æ–¹å¼åˆ»ç”»éšå«çŠ¶æ€çš„æ›´æ–°ï¼š \\[ \\boldsymbol{l}_t=\\boldsymbol{F}_t\\boldsymbol{l}_{t-1}+\\boldsymbol{g}_t\\varepsilon_t, \\space\\space\\space\\varepsilon_t\\sim\\mathcal{N}(0,1) \\] \\(\\boldsymbol{F}_t\\)ä¸ºç¡®å®šçš„çŠ¶æ€è½¬ç§»çŸ©é˜µï¼Œè€Œ\\(\\boldsymbol{g}_t\\varepsilon_t\\)åˆ™è¡¨ç¤ºäº†çŠ¶æ€è½¬ç§»çš„éšæœºæ€§ã€‚ è§‚æµ‹å€¼\\(z_t\\)ä»éšå«çŠ¶æ€\\(\\boldsymbol{l}_t\\)è®¡ç®—è€Œæ¥ï¼š \\[ \\begin{align} z_t&amp;=y_t+\\sigma_t\\epsilon_t,\\\\ y_t&amp;=\\boldsymbol{a}_t^\\top\\boldsymbol{l}_{t-1}+b_t,\\\\ \\epsilon_t&amp;\\sim\\mathcal{N}(0,1) \\end{align} \\] å…¶ä¸­\\(\\boldsymbol{a}_t\\in\\mathbb{R}^L,\\sigma_t\\in \\mathbb{R},b_t\\in\\mathbb{R}\\)éƒ½æ˜¯é¢å¤–çš„å‚æ•°ã€‚åˆå§‹çŠ¶æ€\\(\\boldsymbol{l}_0\\)åˆ™ä»ä¸€ä¸ªç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒå¾—æ¥ï¼Œå³\\(\\boldsymbol{l}_0\\sim N(\\boldsymbol\\mu_0,\\text{diag}(\\boldsymbol{\\sigma}_0^2))\\)ã€‚ ä»¤å‚æ•°é›†åˆ\\(\\Theta_t=(\\boldsymbol{\\mu}_0,\\boldsymbol{\\Sigma}_0,\\boldsymbol{F}_t,\\boldsymbol{g}_t,\\boldsymbol{a}_t,b_t,\\sigma_t),\\forall t&gt;0\\)ï¼Œä¸€èˆ¬æ¥è¯´å‚æ•°é›†åˆä¸ä¼šéšç€æ—¶é—´å˜åŒ–ï¼Œå³æ¯ä¸ªæ—¶åˆ»\\(t\\)å…±äº«åŒæ ·çš„å‚æ•°\\(\\Theta_t=\\Theta,\\forall t&gt;0\\)ã€‚å¯¹å‚æ•°çš„ä¼°è®¡å¯ä»¥é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ï¼š \\[ \\begin{align} \\Theta^*_{1:T}&amp;=\\arg\\max_{\\Theta_{1:T}}p(z_{1:T}|\\Theta_{1:T}),\\\\ \\end{align} \\] å…¶ä¸­ï¼š \\[ \\begin{align} p(z_{1:T}|\\Theta_{1:T})&amp;=p(z_1|\\Theta_1)\\prod\\limits_{t=2}^T p(z_t|z_{1:t-1},\\Theta_{1:t})\\\\ &amp;=\\int p(\\boldsymbol{l}_0)\\left[\\prod\\limits_{t=1}^T p(z_t|\\boldsymbol{l}_t)p(\\boldsymbol{l}_t|\\boldsymbol{l}_{t-1})\\right]\\mathrm{d}\\boldsymbol{l}_{0:T} \\end{align} \\] Planar Normalizing Flow Normalizing Flows VAEé‡‡ç”¨ä¸€ä¸ªå˜åˆ†åˆ†å¸ƒ\\(q_\\phi(z|x)\\)æ¥è¿‘ä¼¼çœŸå®çš„åéªŒåˆ†å¸ƒ\\(p(z|x)\\)ï¼Œå¹¶æ¨å¯¼å‡º\\(\\log p_\\theta(x)\\)çš„ä¸‹ç•Œï¼ˆç§°ä¸ºELBOï¼‰æ¥ä½œä¸ºä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼š \\[ \\begin{align} \\log p_\\theta(x)&amp;=\\log \\int p_\\theta(x|z)p(z)\\mathrm{d}z\\\\ &amp;=\\log\\int\\frac{q_\\phi(z|x)}{q_\\phi(z|x)}p_\\theta(x|z)p(z)\\mathrm{d}z\\\\ &amp;\\geq-D_{KL}[q_\\phi(z|x)\\parallel p(z)]+\\mathbb{E}_q[\\log p_\\theta(x|z)] \\end{align} \\] \\(\\log p_\\theta(x)\\)ä¸ELBOå–ç­‰çš„æ¡ä»¶æ˜¯\\(D_{KL}[q_\\phi(z|x)\\parallel p(z)]\\)ï¼Œè¡¨æ˜å˜åˆ†åˆ†å¸ƒå®Œå…¨åŒ¹é…äº†çœŸå®çš„åéªŒåˆ†å¸ƒã€‚ä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒçœŸå®çš„åéªŒåˆ†å¸ƒå¯èƒ½ä¼šéå¸¸å¤æ‚ï¼Œè€Œæˆ‘ä»¬çš„å˜åˆ†åˆ†å¸ƒé€šå¸¸æ˜¯ä¸€ä¸ªç¡®å®šçš„è¾ƒä¸ºç®€å•çš„åˆ†å¸ƒï¼Œå¦‚é«˜æ–¯åˆ†å¸ƒã€‚è¿™æ ·å˜åˆ†åˆ†å¸ƒå¯èƒ½å¾ˆéš¾å¯¹çœŸå®åéªŒåˆ†å¸ƒå¾—åˆ°ä¸€ä¸ªå¾ˆå¥½çš„æ‹Ÿåˆã€‚ ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨æ ‡å‡†åŒ–æµï¼ˆNormalizing Flowsï¼‰ã€‚æ ‡å‡†åŒ–æµæ˜¯ä»ä¸€ä¸ªç›¸å¯¹ç®€å•çš„åˆ†å¸ƒå‡ºå‘ï¼Œæ‰§è¡Œä¸€ç³»åˆ—å¯é€†çš„æ˜ å°„ï¼Œå°†åŸå§‹ç®€å•çš„åˆ†å¸ƒè½¬åŒ–ä¸ºä¸€ä¸ªå¤æ‚çš„åˆ†å¸ƒã€‚ é¦–å…ˆè€ƒè™‘ä¸€ä¸ªå…‰æ»‘çš„ã€å¯é€†çš„æ˜ å°„\\(f:\\mathbb{R}^d\\mapsto \\mathbb{R}^d\\)ï¼Œè®°\\(g=f^{-1}\\)ï¼Œé‚£ä¹ˆ\\(g\\circ f(\\mathbf{z})=\\mathbf{z}\\)ã€‚ä»¤\\(\\mathbf{z}^\\prime=f(\\mathbf{z})\\)ï¼Œé‚£ä¹ˆ\\(\\mathbf{z}^\\prime\\)çš„åˆ†å¸ƒä¸ºï¼š \\[ q(\\mathbf{z}^\\prime)=q(\\mathbf{z})\\left|\\text{det}\\frac{\\partial f^{-1}}{\\partial \\mathbf{z}^\\prime}\\right|=q(z)\\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|^{-1} \\] å¼ä¸­\\(q(\\mathbf{z}^\\prime)=q(z)\\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|^{-1}\\)è¯´æ˜äº†\\(\\mathbf{z}^\\prime\\)çš„åˆ†å¸ƒç­‰äº\\(\\mathbf{z}\\)çš„åˆ†å¸ƒä¹˜ä¸Š\\(f\\)çš„JacobiançŸ©é˜µçš„è¡Œåˆ—å¼çš„å€’æ•°ã€‚é‚£ä¹ˆå¯¹äºæ˜ å°„å¤šæ¬¡çš„æƒ…å†µï¼š \\[ \\mathbf{z}_K=f_K\\circ\\cdots\\circ f_2\\circ f_1(\\mathbf{z}_0) \\] \\(\\mathbf{z}_K\\)çš„åˆ†å¸ƒå¯ä»¥é€šè¿‡é“¾å¼è®¡ç®—å¾—åˆ°ï¼š \\[ \\ln q_K(\\mathbf{z}_K)=\\ln q_0(\\mathbf{z}_0)-\\sum\\limits_{k=1}^K\\ln\\left|\\text{det}\\frac{\\partial f_k}{\\partial \\mathbf{z}_{k-1}}\\right| \\] Planar Flows è€ƒè™‘ä¸€ä¸ªå˜æ¢æ—ï¼š \\[ f(\\mathbf{z})=\\mathbf{z}+\\mathbf{u}h(\\mathbf{w}^\\top\\mathbf{z}+b) \\] å…¶ä¸­\\(\\lambda=\\{\\mathbf{w}\\in \\mathbb{R}^d,\\mathbf{u}\\in\\mathbb{R}^d,b\\in\\mathbb{R}\\}\\)ä¸ºå‚æ•°é›†åˆï¼Œ\\(h(\\cdot)\\)ä¸ºå…ƒç´ çº§çš„éçº¿æ€§å‡½æ•°ï¼ˆå¦‚å„ç§æ¿€æ´»å‡½æ•°ï¼‰ã€‚ä»¤\\(\\psi(\\mathbf{z})=h^\\prime(\\mathbf{w}^\\top\\mathbf{z}+b)\\mathbf{w}\\)ï¼Œåˆ™\\(f\\)çš„JacobiançŸ©é˜µè¡Œåˆ—å¼ç»å¯¹å€¼ç­‰äºï¼š \\[ \\left|\\text{det}\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|=\\left|\\text{det}(\\mathbf{I}+\\mathbf{u}\\psi(\\mathbf{z})^\\top)\\right|=\\left|1+\\mathbf{u}^\\top\\psi(\\mathbf{z})\\right| \\] ä½†æ˜¯\\(f\\)å¹¶ä¸ä¿è¯æ€»æ˜¯å¯é€†çš„ï¼Œå¦‚\\(h(x)=\\tanh(x)\\)æ—¶ï¼Œ\\(f\\)å¯é€†çš„æ¡ä»¶æ˜¯\\(\\mathbf{w}^\\top \\mathbf{u}\\geq-1\\)ã€‚ ä¸‹é¢è®¨è®ºå¦‚ä½•ä¿è¯å¯é€†çš„æ¡ä»¶ã€‚è€ƒè™‘å°†\\(\\mathbf{z}\\)åˆ†è§£ä¸º\\(\\mathbf{z}=\\mathbf{z}_\\bot+\\mathbf{z}_\\parallel\\)ï¼Œå…¶ä¸­\\(\\mathbf{z}_\\bot\\)ä¸\\(\\mathbf{w}\\)æ­£äº¤ï¼Œ\\(\\mathbf{z}_\\parallel\\)ä¸\\(\\mathbf{w}\\)å¹³è¡Œï¼Œé‚£ä¹ˆï¼š \\[ f(z)=\\mathbf{z}_\\bot+\\mathbf{z}_\\parallel+\\mathbf{u}h(\\mathbf{w}^\\top \\mathbf{z}_\\parallel +b) \\] å®é™…ä¸Šå¾—åˆ°\\(\\mathbf{z}_\\parallel\\)ä¹‹åå¯ä»¥å¾ˆå®¹æ˜“çš„å¾—åˆ°\\(\\mathbf{z}_\\bot\\)ï¼Œä»¤\\(\\mathbf{y}=f(\\mathbf{z})\\)ï¼Œæœ‰ï¼š \\[ \\mathbf{z}_\\bot=\\mathbf{y}-\\mathbf{z}_\\parallel-\\mathbf{u}h(\\mathbf{w}^\\top\\mathbf{z}_\\parallel+b) \\] è€Œ\\(\\mathbf{z}_\\parallel\\)ä¸\\(\\mathbf{w}\\)å¹³è¡Œï¼Œæ˜“çŸ¥\\(\\mathbf{z}_\\parallel=\\alpha\\frac{\\mathbf{w}}{\\parallel\\mathbf{w}\\parallel^2}\\)ï¼Œå…¶ä¸­\\(\\alpha\\in\\mathbb{R}\\)ã€‚ å¯¹å¼(16)ä¸¤è¾¹åŒæ—¶ä¹˜ä»¥\\(\\mathbf{w}^\\top\\)å¯å¾—ï¼š \\[ \\mathbf{w}^\\top f(\\mathbf{z})=\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b) \\] å½“\\(\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b)\\)å¯¹äº\\(\\alpha\\)æ˜¯éé€’å‡å‡½æ•°çš„æ—¶å€™ï¼Œ\\(f\\)æ˜¯å¯é€†çš„ã€‚å› ä¸º\\(\\alpha+\\mathbf{w}^\\top\\mathbf{u} h(\\alpha+b)\\)æ˜¯éé€’å‡å‡½æ•°æ—¶æœ‰\\(1+\\mathbf{w}^\\top\\mathbf{u}h^\\prime(\\alpha+b)\\geq 0\\equiv \\mathbf{w}^\\top \\mathbf{u}\\geq -\\frac{1}{h^\\prime(\\alpha + b)}\\)ï¼Œè€Œ\\(0\\leq h^\\prime(\\alpha + b) \\leq 1\\)ï¼ˆ\\(\\tanh\\)å‡½æ•°çš„æ€§è´¨ï¼‰ï¼Œæ‰€ä»¥æ€»æ˜¯æœ‰\\(\\mathbf{w}^\\top \\mathbf{u}\\geq-1\\)ã€‚ å¯¹äºä»»æ„ä¸€ä¸ª\\(\\mathbf{u}\\)ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç‰¹å®šçš„æ–¹å¼æ„é€ ä¸€ä¸ª\\(\\hat{\\mathbf{u}}\\)ä½¿å¾—\\(\\mathbf{w}^\\top\\hat{\\mathbf{u}}&gt;-1\\)ï¼Œå³ä»¤\\(\\hat{\\mathbf{u}}(\\mathbf{w},\\mathbf{u})=\\mathbf{u}+[m(\\mathbf{w}^\\top\\mathbf{u})-(\\mathbf{w}^\\top\\mathbf{u})]\\frac{\\mathbf{w}}{\\parallel\\mathbf{w}\\parallel^2}\\)ï¼Œå…¶ä¸­\\(m(x)=-1+\\log(1+e^x)\\)ã€‚ Methodology Problem Statement æœ¬æ–‡é’ˆå¯¹çš„æ˜¯å¤šå˜é‡æ—¶é—´åºåˆ—\\(x=\\{x_1,x_2,\\cdots,x_N\\}\\in R^{M\\times N}\\)ï¼Œ\\(N\\)ä¸ºæ—¶é—´é•¿åº¦ï¼Œå…¶ä¸­æŸä¸€æ—¶åˆ»çš„è§‚æµ‹å€¼\\(x_t\\in R^M\\)ä¸ºä¸€ä¸ª\\(M\\)ç»´çš„å‘é‡ã€‚ä½œè€…ä½¿ç”¨\\(x_{t-T:t}\\in R^{M\\times(T+1)}\\)æ¥è¡¨ç¤º\\(t-T\\)åˆ°\\(t\\)ä¹‹é—´çš„æ—¶é—´åºåˆ—ã€‚ Overall Structure ç®—æ³•çš„æ€»ä½“æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š é¢„å¤„ç†æ¨¡å—ä¸»è¦æ˜¯å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ä»¥åŠçª—å£åˆ‡åˆ†ã€‚è®­ç»ƒæ¨¡å—åˆ™æ ¹æ®è¾“å…¥çš„æ•°æ®å¯¹æ­£å¸¸æ¨¡å¼è¿›è¡Œæ•æ‰ï¼Œè¾“å‡ºå¼‚å¸¸åˆ†æ•°ã€‚åœ¨çº¿æ£€æµ‹æ¨¡å—åˆ™ä¼šå®šæœŸæ‰§è¡Œã€‚ Network Architecture æ¨¡å‹çš„æ€»ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š åœ¨qnetä¸­ï¼Œé¦–å…ˆGRUè¢«ç”¨æ¥å»ºæ¨¡æ ·æœ¬çš„æ—¶é—´ä¾èµ–å…³ç³»ï¼Œä¹‹åVAEå°†æ ·æœ¬\\(\\mathbf{x}\\)æ˜ å°„åˆ°éšç©ºé—´\\(\\mathbf{z}\\)ã€‚æ–‡ä¸­ä½¿ç”¨äº†Linear Gaussian State Space Modelæ¥å»ºæ¨¡éšå˜é‡ä¹‹é—´çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä½œè€…è¿˜ä½¿ç”¨äº†Planar Normalizing Flowæ¥å°†éšå˜é‡æ˜ å°„åˆ°å¤æ‚çš„éé«˜æ–¯åˆ†å¸ƒã€‚åœ¨pnetä¸­ï¼Œéšå˜é‡\\(\\mathbf{z}_{t-T:t}\\)è¢«ç”¨æ¥é‡å»º\\(\\mathbf{x}_{t-T:t}\\)ï¼Œç›´è§‚ä¸Šæ¥è¯´ï¼Œå¯¹æ ·æœ¬çš„å¥½çš„éšå˜é‡è¡¨ç¤ºå¯ä»¥å¸¦æ¥æ›´å¥½çš„é‡æ„æ•ˆæœã€‚ ä»ç»†èŠ‚ä¸Šæ¥è¯´ï¼Œåœ¨æ—¶é—´\\(t\\)ï¼Œqnetçš„è¾“å…¥ä¸º\\(\\mathbf{x}_t\\)å’Œ\\(\\mathbf{e}_{t-1}\\)ï¼Œä¸¤è€…ç»è¿‡GRU Cellä¹‹åä¼šäº§ç”Ÿ\\(t\\)æ—¶é—´çš„\\(\\mathbf{e_t}\\)ã€‚\\(\\mathbf{e}_t\\)æ˜¯GRUæ•æ‰æ—¶é—´ä¾èµ–æ€§çš„å…³é”®ï¼Œå¯ä»¥è®¤ä¸ºå®ƒåŒ…å«äº†\\(\\mathbf{x}_{1:t}\\)çš„ä¿¡æ¯ã€‚ä¹‹å\\(\\mathbf{e}_t\\)ä¼šå’Œ\\(\\mathbf{z}_{t-1}\\)è¿›è¡Œæ‹¼æ¥ï¼Œè¿›å…¥æ ‡å‡†çš„VAEå˜åˆ†ç½‘ç»œç»“æ„ï¼Œé€šè¿‡ç½‘ç»œè¾“å‡ºçš„å‚æ•°\\(\\mu_{z_t},\\sigma_{z_t}\\)é‡‡æ ·å¾—åˆ°éšå˜é‡\\(\\mathbf{z}_t^0\\)ï¼Œæ­¤æ—¶éšå˜é‡å¯ä»¥è¯´æ•æ‰äº†æ—¶é—´ä¾èµ–æ€§ã€‚ ç½‘ç»œä¸­æ¶‰åŠåˆ°çš„å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š \\[ \\begin{align} e_t&amp;=(1-c_t^e)\\circ\\text{tanh}(w^ex_t+u^e(r_t^e\\circ e_{t-1})+b^e)+c_t^e\\circ e_{t-1}\\\\ \\mu_{z_t}&amp;=w^{\\mu_z}h^\\phi([z_{t-1},e_t])+b^{\\mu_z}\\\\ \\sigma_{z_t}&amp;=\\text{softplus}(w^{\\sigma_z}h^\\phi([z_{t-1},e_t])+b^{\\sigma_z})+\\epsilon^{\\sigma_z} \\end{align} \\] å…¶ä¸­\\(r_t^e=\\text{sigmoid}(\\mathbf{w}^{r^e}\\mathbf{x}_t+\\mathbf{u}^{r^e}\\mathbf{e}_{t-1}+b^{r^e})\\)æ˜¯GRUä¸­çš„é‡ç½®é—¨ï¼Œ\\(c_t^e=\\text{sigmoid}(\\mathbf{w}^{c^e}\\mathbf{x}_t+\\mathbf{u}^{c^e}\\mathbf{e}_{t-1}+b^{c^e})\\)æ˜¯GRUä¸­çš„æ›´æ–°é—¨ã€‚ æ­¤æ—¶\\(\\mathbf{z}_t^0\\)æœä»é«˜æ–¯åˆ†å¸ƒï¼Œä¸ºäº†æ‹Ÿåˆå¤æ‚çš„åéªŒåˆ†å¸ƒï¼Œæˆ‘ä»¬ä½¿ç”¨Planar Normalizing Flowæ¥å¯¹\\(\\mathbf{z}_t^0\\)è¿›è¡Œå˜æ¢ï¼Œæœ€åå¾—åˆ°ç»\\(K\\)æ¬¡å˜æ¢åçš„éšæœºå˜é‡\\(\\mathbf{z}_t^K\\)ã€‚ åœ¨æ—¶é—´\\(t\\)ï¼Œpnetè¯•å›¾é€šè¿‡\\(\\mathbf{z}_t^K\\)æ¥é‡æ„\\(\\mathbf{x}_t\\)ã€‚é¦–å…ˆ\\(\\mathbf{z}\\)ç©ºé—´ä¸­çš„å˜é‡ä¼šæ ¹æ®Linear Gaussian State Space Modelæ¥è¿›è¡Œâ€œè¿æ¥â€œï¼Œå…¬å¼ä¸º\\(\\mathbf{z}_t=\\mathbf{O}_\\theta(\\mathbf{T}_\\theta\\mathbf{z}_{t-1}+\\mathbf{v}_t)+\\boldsymbol{\\epsilon}_t\\)ï¼Œå…¶ä¸­\\(\\mathbf{O}_\\theta\\)å’Œ\\(\\mathbf{T}_\\theta\\)ä¸ºçŠ¶æ€è½¬ç§»çŸ©é˜µï¼Œ\\(\\mathbf{v}_t\\)å’Œ\\(\\boldsymbol{\\epsilon}_t\\)ä¸ºéšæœºå™ªå£°ã€‚ä¹‹å\\(\\mathbf{z}_t\\)å’Œ\\(\\mathbf{d}_{t-1}\\)ä¼šä½œä¸ºGRUçš„è¾“å…¥ï¼Œäº§ç”Ÿ\\(\\mathbf{d}_t\\)ã€‚ä¹‹å\\(\\mathbf{d}_t\\)ä¼šç»è¿‡æ ‡å‡†VAEä¸­çš„ç”Ÿæˆç½‘ç»œï¼Œé€šè¿‡ç½‘ç»œè¾“å‡ºçš„é«˜æ–¯åˆ†å¸ƒå‚æ•°\\(\\mu_{x_t},\\sigma_{x_t}\\)é‡‡æ ·å¾—åˆ°é‡æ„åçš„æ ·æœ¬\\(\\mathbf{x}^\\prime_t\\)ã€‚pnetä¸­æ¶‰åŠåˆ°çš„å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š \\[ \\begin{align} d_t&amp;=(1-c_t^d)\\circ\\text{tanh}(w^dz_t+u^d(r_t^d\\circ d_{t-1})+b^d)+c_t^d\\circ d_{t-1}\\\\ \\mu_{x_t}&amp;=w^{\\mu_x}h^\\theta(d_t)+b^{\\mu_x}\\\\ \\sigma_{x_t}&amp;=\\text{softplus}(w^{\\sigma_x}h^\\theta(d_t)+b^{\\sigma_x})+\\epsilon^{\\sigma_x} \\end{align} \\] å…¶ä¸­\\(r_t^d=\\text{sigmoid}(\\mathbf{w}^{r^d}\\mathbf{x}_t+\\mathbf{u}^{r^d}\\mathbf{d}_{t-1}+b^{r^d})\\)æ˜¯GRUä¸­çš„é‡ç½®é—¨ï¼Œ\\(c_t^d=\\text{sigmoid}(\\mathbf{w}^{c^d}\\mathbf{x}_t+\\mathbf{u}^{c^d}\\mathbf{d}_{t-1}+b^{c^d})\\)æ˜¯GRUä¸­çš„æ›´æ–°é—¨ã€‚ Offline Model Training å’Œä¼ ç»ŸVAEç±»ä¼¼ï¼Œæ¨¡å‹çš„è®­ç»ƒå¯ä»¥é€šè¿‡ä¼˜åŒ–ELBOæ¥å®Œæˆã€‚è®°é•¿åº¦ä¸º\\(T+1\\)çš„è¾“å…¥åºåˆ—ä¸º\\(\\mathbf{x}_{t-T:t}\\)ï¼Œéšç©ºé—´å˜é‡é‡‡æ ·æ¬¡æ•°ä¸º\\(L\\)ï¼Œç¬¬\\(l\\)ä¸ªéšç©ºé—´å˜é‡ä¸º\\(\\mathbf{l}^{(l)}_{t-T:t}\\)ï¼ŒæŸå¤±å‡½æ•°å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š \\[ \\tilde{\\mathcal{L}}(\\mathbf{x}_{t-T:t})\\approx\\frac{1}{L}\\sum_{t=1}^L[\\log(p_\\theta(\\mathbf{x}_{t-T:t}|\\mathbf{z}_{t-T:t}^{(l)}))+\\log(p_\\theta(\\mathbf{z}_{t-T:t}^{(l)}))-\\log(q_\\phi(\\mathbf{z}_{t-T:t}^|\\mathbf{x}_{t-T:t}))] \\] ç¬¬ä¸€é¡¹\\(\\log(p_\\theta(\\mathbf{x}_{t-T:t}|\\mathbf{z}_{t-T:t}^{(l)}))\\)å¯ä»¥çœ‹ä½œæ˜¯é‡æ„è¯¯å·®ï¼›ç¬¬äºŒé¡¹\\(\\log(p_\\theta(\\mathbf{z}_{t-T:t}))=\\sum_{i=t-T}^t \\log(p_\\theta(\\mathbf{z}_i|\\mathbf{z}_{i-1}))\\)é€šè¿‡Linear Gaussian State Space Modelè®¡ç®—ï¼›ç¬¬ä¸‰é¡¹\\(-\\log(q_\\phi(\\mathbf{z}_{t-T:t}|\\mathbf{x}_{t-T:t}))=-\\sum_{i=t-T}^t\\log(q_\\phi(\\mathbf{z}_i|\\mathbf{z}_{i-1},\\mathbf{x}_{t-T:i}))\\)ä¸ºéšå˜é‡\\(\\mathbf{z}\\)åéªŒåˆ†å¸ƒçš„ä¼°è®¡ï¼ŒåŒæ—¶\\(\\mathbf{z}_i\\)æ˜¯ç»Planar Normalizing Flowè½¬æ¢è¿‡çš„ã€‚ Online Detection åœ¨è®­ç»ƒå¥½æ¨¡å‹ä¹‹åï¼Œå°±å¯ä»¥è¿›è¡Œå¼‚å¸¸æ£€æµ‹äº†ã€‚åœ¨æ—¶é—´\\(t\\)ï¼Œæˆ‘ä»¬é€šè¿‡æ ¹æ®é•¿åº¦ä¸º\\(T+1\\)çš„åºåˆ—\\(\\mathbf{x}_{t-T:t}\\)æ¥é‡æ„\\(\\mathbf{x}_t\\)ï¼Œå¹¶æ ¹æ®é‡æ„æ¦‚ç‡\\(\\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))\\)æ¥åˆ¤å®šå¼‚å¸¸ã€‚å®šä¹‰\\(\\mathbf{x}_t\\)å¯¹åº”çš„å¼‚å¸¸åˆ†æ•°\\(S_t=\\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))\\)ï¼Œé«˜å¼‚å¸¸åˆ†æ•°ä»£è¡¨æ ·æœ¬\\(\\mathbf{x}_t\\)èƒ½å¤Ÿä»¥å¤§æ¦‚ç‡é‡æ„ï¼ˆå› ä¸ºæ¨¡å‹æ˜¯ç”¨æ­£å¸¸æ ·æœ¬è®­ç»ƒï¼Œå¯ä»¥è®¤ä¸ºæ¨¡å‹å»ºæ¨¡çš„æ˜¯æ­£å¸¸æ ·æœ¬çš„åˆ†å¸ƒï¼Œé‡æ„æ¦‚ç‡é«˜å°±ä»£è¡¨ç¬¦åˆæ­£å¸¸åˆ†å¸ƒï¼‰ã€‚ç»™å®šé˜ˆå€¼ä¹‹åä¾¿å¯æ ¹æ®å¼‚å¸¸åˆ†æ•°æ¥è¿›è¡Œå¼‚å¸¸çš„åˆ¤å®šã€‚ Automatic Threshold Selection åœ¨å¼‚å¸¸æ£€æµ‹é˜¶æ®µï¼Œéœ€è¦æ ¹æ®è®¾å®šçš„é˜ˆå€¼å’Œæ¯ä¸ªæ ·æœ¬çš„å¼‚å¸¸åˆ†æ•°æ¥åˆ¤æ–­è¯¥æ ·æœ¬æ˜¯å¦ä¸ºå¼‚å¸¸ï¼Œæ‰€ä»¥é˜ˆå€¼çš„é€‰æ‹©ååˆ†é‡è¦ã€‚æ–‡ä¸­ç”¨åˆ°äº†ä¸€ç§æ ¹æ®Extreme Value Theoryè‡ªåŠ¨é€‰æ‹©é˜ˆå€¼çš„ç®—æ³•ã€‚å¯¹äºä¸€ä¸ªåˆ†å¸ƒï¼Œå…¶ä¸­çš„æç«¯äº‹ä»¶å¾€å¾€ä½äºåˆ†å¸ƒçš„æœ«å°¾ï¼Œè€ŒExtreme Value Theoryç¬¬ä¸€å®šç†ç»™å‡ºä¸ç®¡åŸå§‹åˆ†å¸ƒå¦‚ä½•ï¼Œè¿™äº›æç«¯äº‹ä»¶çš„åˆ†å¸ƒæœä»ä¸€ä¸ªå¸¦å‚çš„åˆ†å¸ƒæ—ã€‚å› æ­¤ï¼Œå¯ä»¥åœ¨å¯¹æ•°æ®åˆ†å¸ƒæœªçŸ¥çš„æƒ…å†µä¸‹ä¼°è®¡æç«¯äº‹ä»¶çš„åˆ†å¸ƒã€‚ é™¤äº†Extreme Value Theoryç¬¬ä¸€å®šç†ä¹‹å¤–ï¼ŒExtreme Value Theoryç¬¬äºŒå®šç†ç»™å‡ºéšæœºå˜é‡å¤§äºç‰¹å®šé˜ˆå€¼\\(t\\)çš„åˆ†å¸ƒå¯ä»¥ç”¨Generalized Pareto Distributionæ¥æè¿°ã€‚ä½œè€…ä½¿ç”¨äº†åŸºäºExtreme Value Theoryç¬¬äºŒå®šç†çš„Peaks-Over-Thresholdç®—æ³•æ¥è¿›è¡Œé˜ˆå€¼çš„é€‰æ‹©ã€‚å› ä¸ºExtreme Value Theoryç¬¬äºŒå®šç†ç»™å‡ºéšæœºå˜é‡å¤§äºç‰¹å®šé˜ˆå€¼\\(t\\)çš„åˆ†å¸ƒï¼Œè€Œåœ¨æœ¬æ–‡çš„åœºæ™¯ä¸­æˆ‘ä»¬éœ€è¦åˆ»ç”»çš„å¼‚å¸¸ç‚¹çš„åˆ†å¸ƒåº”è¯¥æ˜¯å°äºä¸€ä¸ªç»™å®šé˜ˆå€¼çš„åˆ†å¸ƒï¼Œæ‰€ä»¥éœ€è¦ä¿®æ”¹ä¸€ä¸‹å…¬å¼ã€‚ å¯¹äºç»™å®šçš„æ•°æ®ï¼Œæ¨¡å‹ä¼šç»™å‡ºå¯¹åº”çš„å¼‚å¸¸åˆ†æ•°åºåˆ—\\(\\{S_1,S_2,\\cdots,S_{N^\\prime}\\}\\)ï¼Œç»™å®šé¢„å…ˆè®¾å®šçš„é˜ˆå€¼\\(th\\)ï¼Œ\\(S_i\\)æç«¯éƒ¨åˆ†ï¼ˆå³å°äº\\(th\\)çš„éƒ¨åˆ†ï¼‰çš„åˆ†å¸ƒç¬¦åˆGeneralized Pareto Distributionï¼Œå…¬å¼å¦‚ä¸‹ï¼š \\[ \\bar{F}(s)=P(th-S&gt;s|S&lt;th)\\sim(1+\\frac{\\gamma s}{\\beta})^{-\\frac{1}{\\gamma}} \\] å…¶ä¸­\\(\\gamma\\)å’Œ\\(\\beta\\)ä¸ºåˆ†å¸ƒçš„å½¢çŠ¶å‚æ•°ï¼Œæœ¬æ–‡ä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ¥å¯¹å‚æ•°è¿›è¡Œä¼°è®¡ã€‚è®¾å‚æ•°çš„ä¼°è®¡å€¼åˆ†åˆ«ä¸º\\(\\hat{\\gamma}\\)å’Œ\\(\\hat{\\beta}\\)ï¼Œæœ€ç»ˆçš„é˜ˆå€¼\\(th_F\\)ç”±æ‹Ÿåˆå¾—åˆ°çš„åˆ†å¸ƒçš„åˆ†ä½æ•°ç¡®å®šï¼š \\[ th_F\\simeq th-\\frac{\\hat{\\beta}}{\\hat{\\gamma}}((\\frac{qN^\\prime}{N^\\prime_{th}})^{-\\hat{\\gamma}}-1) \\] å…¶ä¸­\\(q\\)ä¸ºæœŸæœ›\\(S&lt;th\\)çš„æ¦‚ç‡ï¼Œ\\(N^\\prime\\)ä¸ºè§‚æµ‹å€¼çš„æ•°é‡ï¼Œ\\(N^\\prime_{th}\\)ä¸º\\(S_i&lt;th\\)çš„ä¸ªæ•°ã€‚ Anomaly Interpretation \\[ \\log(p_\\theta(\\mathbf{x}_t|\\mathbf{z}_{t-T:t}))=\\sum_{i=1}^M\\log(p_\\theta(x_t^i|\\mathbf{z}_{t-T:t})) \\] Experiments Datasets and Metrics Overall Performance Effects of Major Techniques Visualization on Z-Space Representations","link":"/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/"},{"title":"Transfer Anomaly Detection by Inferring Latent Domain Representations","text":"Introduction ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨è¿ç§»å­¦ä¹ æå‡target domainå¼‚å¸¸æ£€æµ‹æ€§èƒ½çš„ç®—æ³•ã€‚æ–‡ä¸­æŒ‡å‡ºç°æœ‰çš„åŸºäºè¿ç§»å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•éœ€è¦å¯¹æ¯ä¸ª target domain è¿›è¡Œå•ç‹¬è®­ç»ƒï¼Œè¿™æ ·åšä¼šå¸¦æ¥å¾ˆå¤§çš„è®¡ç®—å¼€é”€ã€‚æœ¬æ–‡é€šè¿‡latent domain vectorsæ¥å®ç°æ— éœ€é‡æ–°è®­ç»ƒçš„å¼‚å¸¸æ£€æµ‹ã€‚latent domain vectorsæ˜¯domainçš„ä¸€ç§éšå«è¡¨ç¤ºï¼Œé€šè¿‡è¯¥domainä¸­çš„æ­£å¸¸æ ·æœ¬å¾—åˆ°ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œanomaly score functioné€šè¿‡Auto-encoderå¾—åˆ°ã€‚ Proposed Method Task ä»¤\\(\\mathbf{X}_d^+:=\\{\\mathbf{x}^+_{dn}\\}^{N^+_d}_{n=1}\\)ä¸ºç¬¬\\(d\\)ä¸ªdomainçš„å¼‚å¸¸æ ·æœ¬é›†ï¼Œ\\(\\mathbf{x}_{dn}^+\\in\\mathbb{R}^M\\)ä¸ºå…¶ä¸­ç¬¬\\(n\\)ä¸ªæ ·æœ¬çš„\\(M\\)ç»´ç‰¹å¾å‘é‡ï¼Œ\\(N^+_d\\)ä¸ºç¬¬\\(d\\)ä¸ªdomainå¼‚å¸¸æ ·æœ¬çš„æ•°é‡ã€‚ ç±»ä¼¼çš„ï¼Œä»¤\\(\\mathbf{X}_d^-:=\\{\\mathbf{x}^-_{dn}\\}^{N^-_d}_{n=1}\\)ä¸ºç¬¬\\(d\\)ä¸ªdomainçš„æ­£å¸¸æ ·æœ¬é›†ã€‚æˆ‘ä»¬å‡è®¾å¯¹äºæ¯ä¸ªdomainéƒ½æœ‰\\(N^+_d\\ll N^-_d\\)ï¼Œä¸”ç‰¹å¾å‘é‡ç»´åº¦éƒ½ä¸º\\(M\\)ã€‚ å‡è®¾åœ¨ source domain \\(D_S\\)éƒ½æœ‰æ­£å¸¸æ ·æœ¬å’Œå¼‚å¸¸æ ·æœ¬ï¼Œè®°ä¸º\\(\\{\\mathbf{X}^+_d\\cup\\mathbf{X}_d^-\\}^{D_S}_{d=1}\\)ï¼Œåœ¨ target domain \\(D_T\\)åªæœ‰æ­£å¸¸æ ·æœ¬\\(\\{\\mathbf{X}_d^-\\}^{D_S+D_T}_{d=D_S+1}\\)ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¾—åˆ°ä¸€ä¸ªå¯¹äº target domain åˆé€‚çš„ domain-specific çš„å¼‚å¸¸æ‰“åˆ†å‡½æ•°ã€‚ Domain-specific Anomaly Score Function æˆ‘ä»¬åŸºäºAuto-encoderå®šä¹‰å¼‚å¸¸æ‰“åˆ†å‡½æ•°ã€‚å¯¹äºæ¯ä¸ªdomainï¼Œæˆ‘ä»¬å‡è®¾å­˜åœ¨ä¸€ä¸ª\\(K\\)ç»´çš„éšå˜é‡\\(\\mathbf{z}_d\\in\\mathbb{R}^K\\)ã€‚å¯¹äºç¬¬\\(d\\)ä¸ª domainï¼Œå¼‚å¸¸æ‰“åˆ†å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š \\[ s_\\theta(\\mathbf{x}_{dn}|\\mathbf{z}_d):=\\parallel\\mathbf{x}_{dn}-G_{\\theta_G}(F_{\\theta_F}(\\mathbf{x}_{dn},\\mathbf{z}_d))\\parallel^2 \\] å…¶ä¸­å‚æ•°\\(\\theta:=(\\theta_G,\\theta_F)\\)åœ¨æ‰€æœ‰ domain ä¹‹é—´å…±äº«ã€‚ Models for Latent Domain Vectors éšå˜é‡\\(\\mathbf{z}_d\\)æ˜¯æ— æ³•è§‚æµ‹åˆ°çš„ï¼Œåªèƒ½é€šè¿‡æ•°æ®æ¥ä¼°è®¡ã€‚é¦–å…ˆ\\(\\mathbf{z}_d\\)åœ¨\\(\\mathbf{X}_d^-\\)æ¡ä»¶ä¸‹çš„æ¡ä»¶åˆ†å¸ƒå‡è®¾ä¸ºé«˜æ–¯åˆ†å¸ƒï¼š \\[ q_\\theta(\\mathbf{z}_d|\\mathbf{X}_d^-):=\\mathcal{N}(\\mathbf{z}_d|\\mu_\\phi(\\mathbf{X}_d^-),\\text{diag}(\\sigma_\\phi^2(\\mathbf{X}_d^-))) \\] å…¶ä¸­å‡å€¼\\(\\mu_\\phi(\\mathbf{X}_d^-)\\in\\mathbb{R}^K\\)å’Œæ–¹å·®\\(\\sigma^2_\\phi(\\mathbf{X}_d^-)\\in\\mathbb{R}^K_+\\)ç”±ç¥ç»ç½‘ç»œå»ºæ¨¡ï¼Œä¸”åœ¨æ‰€æœ‰ domain ä¹‹é—´å…±äº«ã€‚åœ¨\\(\\mathbf{X}_d^-\\)ç»™å®šçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¾¿èƒ½å¤Ÿæ¨æ–­å‡ºè¯¥ domain å¯¹åº”çš„éšå˜é‡ï¼Œ \\(q_\\phi\\)çš„è¾“å…¥ä¸ºæ­£å¸¸æ ·æœ¬çš„é›†åˆï¼Œæ•…ç¥ç»ç½‘ç»œéœ€è¦æ»¡è¶³permutation invariantã€‚\\(\\tau(\\mathbf{X}_d^-)=\\rho(\\sum_{n=1}^{N_d^-}\\eta(\\mathbf{x}_{dn}^-))\\)ï¼Œå…¶ä¸­\\(\\tau(\\mathbf{X}_d^-)\\)è¡¨ç¤º\\(\\mu_\\phi(\\mathbf{X_d^-})\\)æˆ–\\(\\ln\\sigma_\\phi^2(\\mathbf{X}_d^-)\\)ï¼Œ\\(\\rho\\)å’Œ\\(\\eta\\)ä¸ºç¥ç»ç½‘ç»œï¼Œ Objective Function ç›®æ ‡å‡½æ•°ç”±anomaly scoreå‡½æ•°å’Œéšå˜é‡ç»„æˆã€‚ç¬¬\\(d\\)ä¸ªdomainåœ¨å¯¹åº”çš„éšå˜é‡\\(\\mathbf{z}_d\\)æ¡ä»¶ä¸‹çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š \\[ L_d(\\theta|\\mathbf{z}_d):=\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)-\\frac{\\lambda}{N_d^-N_d^+}\\sum\\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)-s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)) \\] å…¶ä¸­\\(\\lambda\\geq 0\\)ä¸ºè¶…å‚æ•°ï¼Œ\\(f\\)ä¸ºsigmoidå‡½æ•°ã€‚å…¬å¼çš„ç¬¬ä¸€é¡¹è¡¨ç¤ºç¬¬\\(d\\)ä¸ªdomainæ­£å¸¸æ ·æœ¬å¯¹åº”çš„anomaly scoreã€‚ç¬¬äºŒé¡¹ä¸ºå¯å¾®åˆ†çš„AUCã€‚å¼‚å¸¸æ ·æœ¬çš„anomaly scoreåº”å½“å¤§äºæ­£å¸¸æ ·æœ¬ï¼Œæ‰€ä»¥å¯¹ä»»ä½•\\(\\mathbf x_{dm}^+\\in\\mathbf X_d^+, \\mathbf x_{dn}^-\\in\\mathbf X_d^-\\)æœ‰\\(s_\\theta(\\mathbf x_{dm}^+|\\mathbf z_d)&gt;s_\\theta(\\mathbf x_{dn}^-|\\mathbf z_d)\\)ã€‚ç¬¬äºŒé¡¹\\(\\frac{\\lambda}{N_d^-N_d^+}\\sum\\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)-s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d))\\)çš„å–å€¼èŒƒå›´æ˜¯\\([0,1]\\)ï¼Œå½“æ‰€æœ‰çš„\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\gg s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)æ—¶è¯¥é¡¹ä¸º1ï¼Œå½“æ‰€æœ‰çš„\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\ll s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)æ—¶è¯¥é¡¹ä¸º0ï¼Œæ‰€ä»¥æœ€å°åŒ–è¯¥é¡¹çš„ç›¸åæ•°ç›¸å½“äºé¼“åŠ±\\(s_\\theta(\\mathbf{x}_{dm}^+|\\mathbf{z}_d)\\gg s_\\theta(\\mathbf{x}_{dm}^-|\\mathbf{z}_d)\\)ã€‚ å› ä¸ºéšå˜é‡\\(\\mathbf z_d\\)åŒ…å«ä¸ç¡®å®šæ€§ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ç›®æ ‡å‡½æ•°é‡Œè€ƒè™‘è¿™ä¸€ç‚¹ï¼š \\[ \\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z_d})) \\] ç¬¬ä¸€é¡¹æ˜¯\\(L_d(\\theta|\\mathbf z_d)\\)å…³äº\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)çš„æœŸæœ›ï¼Œç¬¬äºŒé¡¹æ˜¯\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)å’Œ\\(p(\\mathbf z_d):=\\mathcal{N}(\\boldsymbol 0,\\boldsymbol I)\\)çš„KLæ•£åº¦ã€‚ç¬¬ä¸€é¡¹å¯ä»¥ç”¨monte carloä¼°è®¡\\(\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]\\approx\\frac{1}{L}\\sum_{\\ell=1}^L L_d(\\theta|\\mathbf z_d^{(\\ell)})\\)ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜éœ€è¦ç”¨åˆ°reparametrization trickã€‚ å¯¹äºç¬¬\\(d\\)ä¸ªtarget domainï¼Œå› ä¸ºæ²¡æœ‰å¼‚å¸¸æ ·æœ¬ï¼ˆå‡è®¾ï¼‰ï¼Œæ‰€ä»¥\\(L_d(\\theta|\\mathbf{z}_d):=\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)\\)ï¼Œæœ‰ï¼š \\[ \\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[\\frac{1}{N_d^-}\\sum\\limits_{n=1}^{N_d^-}s_\\theta(\\mathbf{x}_{dn}^-|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z}_d)) \\] æ‰€ä»¥æ€»çš„æŸå¤±å‡½æ•°ä¸ºå„domainå¯¹åº”çš„æŸå¤±å‡½æ•°ä¹‹å’Œ\\(\\mathcal{L}(\\theta,\\phi):=\\sum_{d=1}^{D_S+D_T}\\alpha_d\\mathcal{L}_d(\\theta,\\phi)\\)ã€‚ Inference è®­ç»ƒå¥½ä¹‹åï¼Œdomain-specificçš„anomaly scoreå¯ä»¥ç”±ä¸‹å¼è®¡ç®—å‡ºï¼š \\[ s(\\mathbf{x}_{d^\\prime}):=\\int s_{\\theta_*}(\\mathbf{x_{d^\\prime}}|\\mathbf{z}_{d^\\prime})q_{\\phi_*}(\\mathbf{z}_{d^\\prime}|\\mathbf{X}_{d^\\prime}^-)\\mathrm{d}\\mathbf{z}_{d^\\prime}\\approx\\frac{1}{L}\\sum\\limits_{\\ell=1}^L s_{\\theta_*}(\\mathbf{x}_{d^\\prime}|\\mathbf{z}_{d^\\prime}^{(\\ell)}) \\] Experiments Data å®éªŒåŒ…å«äº”ä¸ªæ•°æ®é›†ï¼Œç¬¬ä¸€ä¸ªæ˜¯åˆæˆæ•°æ®é›†ã€‚å¦‚ä¸‹å›¾(a)æ‰€ç¤ºï¼Œå›´ç»•\\((0,0)\\)æœ‰\\(8\\)ä¸ªåœˆï¼Œæ¯ä¸ªåœˆåŒ…å«äº†ä¸€ä¸ªå†…åœˆä½œä¸ºå¼‚å¸¸æ ·æœ¬ï¼Œç¬¬\\(7\\)ä¸ªåœˆè¢«é€‰ä¸ºtarget domainï¼Œå…¶ä½™çš„ä¸ºsource domainã€‚ç¬¬äºŒä¸ªæ˜¯MNIST-rï¼Œæ˜¯åŠ å…¥æ—‹è½¬çš„MNISTï¼ŒåŒ…å«6ä¸ªdomainï¼Œå…¶ä¸­æ•°å­—â€œ4â€è¢«é€‰ä¸ºå¼‚å¸¸æ ·æœ¬ï¼Œå…¶ä½™ä¸ºæ­£å¸¸ã€‚ç¬¬ä¸‰ä¸ªä¸ºAnuran Callsï¼ŒåŒ…å«5ä¸ªdomainã€‚ç¬¬å››ä¸ªæ˜¯Landmineï¼Œä¸»è¦ç”¨åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­ã€‚ç¬¬äº”ä¸ªæ˜¯IoTï¼Œç½‘ç»œæµé‡æ•°æ®ï¼ŒåŒ…å«8ä¸ªdomainã€‚ Comparison Methods å¯¹æ¯”çš„baselineåŒ…æ‹¬NNï¼ˆæ™®é€šå¤šå±‚ç¥ç»ç½‘ç»œï¼‰ï¼ŒNNAUCï¼ˆåŠ å…¥å¯å¾®åˆ†AUCä½œä¸ºæŸå¤±å‡½æ•°ï¼‰ï¼ŒAEï¼ˆæ™®é€šAutoencoerï¼‰ï¼ŒAEAUCï¼ˆåŠ å…¥å¯å¾®åˆ†AUCçš„AEï¼‰ï¼ŒOSVMï¼ˆå•ç±»æ”¯æŒå‘é‡æœºï¼‰ï¼ŒCCSAï¼ŒTOSVMå’ŒOTLã€‚ Results 4ä¸ªçœŸå®æ•°æ®é›†çš„ç»“æœå¦‚ä¸‹ï¼š è¡¨5ä¸ºè€ƒè™‘éšå˜é‡ä¸ç¡®å®šæ€§çš„ablation studyã€‚å°†åŸæ¥çš„å…¬å¼\\(\\mathcal{L}_d(\\theta,\\phi):=\\mathbb{E}_{q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)}\\left[L_d(\\theta|\\mathbf{z}_d)\\right]+\\beta D_\\text{KL}(q_\\phi(\\mathbf{z}_d|\\mathbf{X}_d^-)\\parallel p(\\mathbf{z_d}))\\)ä¸­\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)\\)ç”¨è¿ªåˆ©å…‹é›·åˆ†å¸ƒ\\(q_\\phi(\\mathbf z_d|\\mathbf X_d^-)=\\delta(\\mathbf z_d-\\mu_\\phi(\\mathbf X_d^-))\\)ä»£æ›¿å¹¶ä¸”å»æ‰KLæ•£åº¦ã€‚ è¡¨6å±•ç¤ºäº†ä¸åŒå¼‚å¸¸æ¯”ä¾‹å¯¹æ•ˆæœçš„å½±å“ã€‚","link":"/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/"},{"title":"Time-Series Anomaly Detection Service at Microsoft","text":"Abstract æœ¬æ–‡å€Ÿé‰´è®¡ç®—æœºè§†è§‰ä¸­çš„æ˜¾è‘—æ€§æ£€æµ‹ï¼Œæå‡ºäº†ä¸€ç§åŸºäºSpectral Residualçš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ç®—æ³•ã€‚ åŸæ–‡ è¿™ç¯‡æ–‡ç« è¿˜æå‡ºäº†å‡ ä¸ªæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹è½åœ°çš„éš¾ç‚¹ï¼š Lack of Labels. åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ä¼šäº§ç”Ÿå¤§é‡çš„KPIï¼Œè€Œå¾ˆéš¾å¯¹æ¯ä¸ªKPIè¿›è¡Œäººå·¥æ ‡æ³¨ã€‚ Generalization. ä¸åŒKPIæ‰€è¡¨ç°å‡ºæ¥çš„æ¨¡å¼ä¹Ÿä¸å°½ç›¸åŒï¼Œå¦‚Figure 1æ‰€ç¤ºã€‚ç°æœ‰æ–¹æ³•å¾ˆéš¾åœ¨æ‰€æœ‰æ¨¡å¼çš„KPIä¸Šéƒ½è¡¨ç°è‰¯å¥½ã€‚ Efficiency. åœ¨å®é™…åœºæ™¯ä¸­ï¼Œä¼šäº§ç”Ÿå¤§é‡çš„æ—¶é—´åºåˆ—æ•°æ®ï¼ŒåŒæ—¶å¯¹å¼‚å¸¸æ£€æµ‹ç®—æ³•çš„æ—¶é—´æ•ˆç‡æœ‰è¦æ±‚ã€‚ Contribution å°†Visual Saliency Detectionçš„æ–¹æ³•å¼•å…¥äº†æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ã€‚ ç»“åˆSpectral Residualå’ŒCNNæé«˜äº†å¼‚å¸¸æ£€æµ‹çš„æ•ˆæœã€‚ ç®—æ³•å…·æœ‰è‰¯å¥½çš„æ—¶é—´æ•ˆç‡å’Œé€šç”¨æ€§ã€‚ Background Spectral Residual SR(Spectral Residual)ç®—æ³•ä¸»è¦åŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼š é€šè¿‡å‚…é‡Œå¶å˜æ¢å¾—åˆ°log amplitude spectrumï¼› è®¡ç®—spectral residualï¼› é€šè¿‡å‚…é‡Œå¶é€†å˜æ¢å›åˆ°æ—¶é—´åŸŸã€‚ æ›´å½¢å¼åŒ–çš„è¡¨è¿°ä¸ºå¦‚ä¸‹ï¼š ç»™å®šä¸€ä¸ªåºåˆ—\\(\\mathbb{x}\\)ï¼Œåˆ™æœ‰ï¼š \\[A(f)=Amplitude(\\mathscr{F}(\\mathbb{x}))\\] \\[P(f)=Phrase(\\mathscr{F}(\\mathbb{x}))\\] \\[L(f)=\\log(A(f))\\] \\[AL(F)=h_1(f)\\cdot L(f)\\] \\[R(f)=L(f)-AL(f)\\] \\[S(\\mathbb{x})=\\parallel\\mathscr{F}^{-1}(\\exp(R(f)+iP(f)))\\parallel\\] å…¶ä¸­\\(\\mathscr{F}\\)å’Œ\\(\\mathscr{F}^{-1}\\)åˆ†åˆ«è¡¨ç¤ºå‚…é‡Œå¶å˜æ¢å’Œå‚…é‡Œå¶é€†å˜æ¢ï¼›\\(\\mathbb{x}\\in \\mathbb{R}^{n\\times 1}\\)è¡¨ç¤ºè¾“å…¥åºåˆ—ï¼›\\(A(f)\\)ä¸ºå¹…åº¦è°±ï¼Œ\\(P(f)\\)ä¸ºç›¸ä½è°±ï¼Œ\\(L(f)\\)ä¸ºå¯¹æ•°å¹…åº¦è°±ï¼Œ\\(AL(F)\\)ä¸ºå‡å€¼æ»¤æ³¢åçš„å¯¹æ•°å¹…åº¦è°±ï¼›\\(R(f)\\)ä¸ºspectral residualï¼›\\(S(\\mathbb{x})\\)ç§°ä¸ºsaliency mapã€‚Figure 4ä¸ºæ–‡ä¸­ç»™å‡ºçš„Saliency Mapç¤ºæ„å›¾ã€‚ Methodology Problem Definition ç»™å®šä¸€ç³»åˆ—å®æ•°å€¼\\(\\mathbb{x}=x_1,x_2,\\cdots,x_n\\)ï¼Œæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„ä»»åŠ¡æ˜¯äº§ç”Ÿä¸€ä¸ªè¾“å‡ºåºåˆ—\\(\\mathbb{y}=y_1,y_2,\\cdots,y_n\\)å…¶ä¸­\\(y_i\\in\\{0,1\\}\\)è¡¨ç¤º\\(x_i\\)æ˜¯å¦ä¸ºå¼‚å¸¸ç‚¹ã€‚ SR å¯¹äºç»™å®šåºåˆ—\\(\\mathbb{x}\\)ï¼Œè®¡ç®—Saliency Map \\(S(\\mathbb{x})\\)ï¼Œè¾“å‡ºåºåˆ—\\(O(\\mathbb{x})\\)å®šä¹‰ä¸ºï¼š \\[O(x_i)=\\begin{cases}1,\\quad \\text{if}\\frac{S(x_i)-\\overline{S(x_i)}}{\\overline{S(x_i)}}&gt;\\tau\\\\\\\\0,\\quad \\text{otherwise}\\end{cases}\\] å…¶ä¸­\\(S(x_i)\\)ä¸º\\(x_i\\)å¯¹åº”çš„Saliency Mapçš„å€¼ï¼Œ\\(\\overline{S(x_i)}\\)ä¸º\\(x_i\\)é™„è¿‘Saliency Mapå±€éƒ¨å‡å€¼ã€‚ åœ¨å®é™…æ“ä½œä¸­ï¼ŒFFTæ˜¯åœ¨ä¸€ä¸ªæ»‘åŠ¨çª—å£ä¸­è¿›è¡Œçš„ï¼Œæ–‡ä¸­æåˆ°SRæ–¹æ³•åœ¨ç‚¹ä½äºçª—å£ä¸­å¤®æ—¶æ•ˆæœæ›´å¥½ï¼Œæ‰€ä»¥åœ¨è¿›è¡Œæµ‹è¯•çš„æ—¶å€™ï¼ŒæŒ‰ç…§å¦‚ä¸‹æ–¹æ³•å¯¹å½“å‰ç‚¹\\(x_n\\)(ä¹Ÿå°±æ˜¯å½“å‰åºåˆ—æœ€åä¸€ä¸ªç‚¹)ä¹‹åçš„ç‚¹è¿›è¡Œé¢„æµ‹ï¼š \\[\\overline{g}=\\frac{1}{m}\\sum_{i=1}^m g(x_n,x_{n-i})\\] \\[x_{n+1}=x_{n-m+1}+\\overline{g}\\cdot m\\] å…¶ä¸­\\(g(x_i,x_j)\\)ä»£è¡¨\\(x_i\\)å’Œ\\(x_j\\)ä¸¤ç‚¹æ„æˆçš„ç›´çº¿çš„æ¢¯åº¦ï¼›\\(\\overline{g}\\)ä»£è¡¨æ‰€å¤„ç†çš„ç‚¹çš„å¹³å‡æ¢¯åº¦ï¼›\\(m\\)ä¸ºæ‰€å¤„ç†çš„ç‚¹çš„æ•°é‡ã€‚åœ¨æœ¬æ–‡ä¸­è®¾ç½®\\(m=5\\)ã€‚æ–‡ä¸­å‘ç°ç¬¬ä¸€ä¸ªé¢„æµ‹çš„å€¼å¾ˆé‡è¦ï¼Œæ‰€ä»¥ç›´æ¥æŠŠ\\(x_{n+1}\\)èµ‹å€¼\\(k\\)æ¬¡æ·»åŠ åˆ°åºåˆ—çš„æœ«å°¾ã€‚ SR-CNN æœ¬æ–‡æåˆ°ï¼Œä»…ä»…ä½¿ç”¨ä¸€ä¸ªé˜ˆå€¼æ¥è¿›è¡Œå¼‚å¸¸çš„åˆ¤æ–­å¤ªè¿‡ç®€å•ï¼Œäºæ˜¯æå‡ºä½¿ç”¨ä¸€ä¸ªåˆ¤åˆ«æ¨¡å‹æ¥è¿›è¡Œå¼‚å¸¸çš„åˆ¤æ–­ã€‚ç”±äºè®­ç»ƒæ•°æ®æ²¡æœ‰æ ‡ç­¾ï¼Œæ‰€ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼äººå·¥åŠ å…¥å¼‚å¸¸ï¼š \\[x=(\\overline{x}+mean)(1+var)\\cdot r+x\\] å…¶ä¸­\\(\\overline{x}\\)æ‰€å¤„ç†çš„ç‚¹çš„å±€éƒ¨å‡å€¼ï¼›\\(mean\\)å’Œ\\(var\\)ä¸ºå½“å‰æ»‘åŠ¨çª—å£ç‚¹çš„å‡å€¼å’Œæ–¹å·®ï¼›\\(r\\sim \\mathcal{N}(0,1)\\)ä¸ºæœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„å™ªå£°ã€‚ å¯¹äºåˆ¤åˆ«æ¨¡å‹ä½¿ç”¨çš„æ˜¯CNNï¼Œä¸»è¦åŒ…å«ä¸¤ä¸ª1ç»´å·ç§¯å±‚(kernel sizeç­‰äºçª—å£å¤§å°\\(w\\))å’Œä¸¤ä¸ªå…¨è¿æ¥å±‚ã€‚ä¸¤ä¸ªå·ç§¯å±‚çš„channel sizeåˆ†åˆ«ä¸º\\(w\\)å’Œ\\(2w\\)ã€‚ Experiments Datasets æ‰€ç”¨æ•°æ®é›†åŒ…å«æ¸…åAIOpsç«èµ›æ•°æ®ã€Yahooå’ŒMicrosoftçš„KPIæ•°æ®ã€‚ Evaluation Metrics ç®—æ³•å‡†ç¡®ç‡æ–¹é¢ç”¨äº†precisionï¼Œrecallå’Œ\\(F_1\\)-scoreã€‚ ç”±äºåœ¨å®é™…åœºæ™¯ä¸­KPIçš„å¼‚å¸¸å¾€å¾€æ˜¯ä»¥ä¸€æ®µä¸€æ®µçš„å½¢å¼å‡ºç°ï¼Œä¸”å¹¶ä¸è¦æ±‚æŸä¸€ä¸ªæ—¶é—´ç‚¹å‡ºç°å¼‚å¸¸ç®—æ³•å°±é©¬ä¸Šæ£€æµ‹å‡ºæ¥ï¼Œåªè¦æ£€æµ‹å‡ºæ¥çš„æ—¶é—´åœ¨ä¸€å®šçš„å®¹å¿èŒƒå›´å†…å³å¯ã€‚æœ¬æ–‡ä½¿ç”¨äº†ä¸€äº›è°ƒæ•´çš„æ‰‹æ®µï¼Œå¦‚Figure 6ã€‚å¯¹äºæŸä¸€æ®µå¼‚å¸¸ï¼Œè®¾æ®µé¦–çš„å¼‚å¸¸ä½äºæ—¶é—´ç‚¹\\(t_{truth}\\)ï¼Œé¢„æµ‹ä¸ºå¼‚å¸¸çš„ç»“æœä¸­æ—¶é—´åœ¨\\(t_{truth}\\)ä¹‹åä¸”è·\\(t_{truth}\\)æœ€è¿‘çš„æ—¶é—´ç‚¹è®¾ä¸º\\(t_{predict}\\)ï¼Œé‚£ä¹ˆå¯¹äºä¸€ä¸ªé¢„å…ˆè®¾å®šçš„å®¹å¿èŒƒå›´\\(k\\)ï¼Œåªè¦\\(t_{predict}-t_{truth}\\leq k+1\\)é‚£ä¹ˆåœ¨é¢„æµ‹ç»“æœä¸­æ•´æ®µå¼‚å¸¸å°±ä¼šé‡ç½®ä¸º\\(1\\)ï¼Œå¦åˆ™å…¨éƒ¨é‡ç½®ä¸º\\(0\\)ã€‚ Results å®éªŒéƒ¨åˆ†ä½¿ç”¨äº†ä¸¤ç§è®­ç»ƒæ–¹å¼ï¼Œä¸€ç§æ˜¯cold-startï¼Œå³æŠŠæ‰€æœ‰æ•°æ®éƒ½ç”¨æ¥æµ‹è¯•ï¼Œå¦ä¸€ç§æ˜¯æŠŠæ•°æ®åˆ†ä¸ºè®­ç»ƒæµ‹è¯•ä¸¤éƒ¨åˆ†ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒï¼Œæœ€ååœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚ä¸¤ç§æ–¹æ³•é€‚ç”¨çš„baselineä¸åŒï¼Œæœ€åç»“æœå¦‚Table 2å’ŒTable 3æ‰€ç¤ºï¼š åœ¨SRçš„å‚æ•°è®¾ç½®ä¸Šï¼Œ\\(h_q(f)\\)ä¸­çš„\\(q\\)ä¸º3ï¼Œå±€éƒ¨å¹³å‡æ‰€ç”¨çš„ç‚¹æ•°ç›®\\(z\\)ä¸º21ï¼Œé˜ˆå€¼\\(\\tau\\)ä¸º3ï¼Œä¼°è®¡ç‚¹çš„æ•°é‡\\(k\\)ä¸º5ï¼Œæ»‘åŠ¨çª—å£çš„å¤§å°\\(w\\)åœ¨KPIã€Yahooã€Microsoftä¸‰ä¸ªæ•°æ®é›†ä¸Šåˆ†åˆ«ä¸º1440ã€64å’Œ30ã€‚SR-CNNçš„\\(q\\)ï¼Œ\\(z\\)ï¼Œ\\(k\\)ï¼Œ\\(w\\)è®¾ç½®ä¸SRç›¸åŒã€‚ Additional Experiments with DNN æ–‡ä¸­è¿˜å¯¹æœ‰ç›‘ç£çš„æƒ…å†µè¿›è¡Œäº†æµ‹è¯•ï¼Œå…·ä½“åšæ³•æ˜¯ä»æ—¶é—´åºåˆ—æå–ç‰¹å¾ï¼Œç„¶åå°†Saliency Mapä¹Ÿä½œä¸ºç‰¹å¾å¼•å…¥ï¼Œæ„é€ ä¸€ä¸ªæœ‰ç›‘ç£çš„Neural Networkè¿›è¡Œæµ‹è¯•ã€‚ æå–çš„ç‰¹å¾å¦‚Table 5æ‰€ç¤ºï¼š ç¥ç»ç½‘ç»œçš„ç»“æ„ä¸ºä¸¤å±‚å…¨è¿æ¥å±‚ï¼Œå¹¶æ·»åŠ äº†Dropout Ratioä¸º0.5çš„Dropout Layerã€‚ä¸¤ä¸ªLayerä½¿ç”¨äº†\\(L_1=L_2=0.0001\\)çš„æ­£åˆ™åŒ–ã€‚åŒæ—¶ä¸ºäº†å¤„ç†æ ·æœ¬ä¸å¹³è¡¡çš„æƒ…å†µä½¿ç”¨äº†è¿‡é‡‡æ ·æ¥ä½¿æ­£è´Ÿæ ·æœ¬çš„æ¯”ä¾‹ä¸º\\(1:2\\)ã€‚ç»“æ„å¦‚Figure 7æ‰€ç¤ºï¼š è®­ç»ƒæµ‹è¯•é›†çš„æƒ…å†µå¦‚Table 6æ‰€ç¤ºï¼Œæœ€ç»ˆç»“æœå¦‚Table 7æ‰€ç¤ºï¼ŒP-Ræ›²çº¿å¦‚Figure 8æ‰€ç¤ºã€‚å¯ä»¥çœ‹åˆ°ä½¿ç”¨äº†SRç‰¹å¾çš„DNNæ•ˆæœç”±äºæ²¡æœ‰ä½¿ç”¨SRç‰¹å¾çš„DNNã€‚","link":"/2019/09/22/Time-Series-Anomaly-Detection-Service-at-Microsoft/"},{"title":"Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications","text":"Abstract æœ¬æ–‡æå‡ºäº†Donutï¼Œä¸€ä¸ªåŸºäºVAEçš„æ— ç›‘ç£æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿã€‚ åŸæ–‡ Contribution Donutä¸­ä½¿ç”¨åˆ°äº†ä¸‰ä¸ªæŠ€å·§ï¼ŒåŒ…æ‹¬æ”¹è¿›åçš„ELBOã€ç¼ºå¤±æ•°æ®æ³¨å…¥å’ŒMCMCæ’å€¼ï¼› æå‡ºåŸºäºVAEçš„å¼‚å¸¸æ£€æµ‹è®­ç»ƒæ—¢éœ€è¦æ­£å¸¸æ ·æœ¬ä¹Ÿéœ€è¦å¼‚å¸¸æ ·æœ¬ï¼› å¯¹Donutæå‡ºäº†åœ¨z-ç©ºé—´ä¸­åŸºäºKDEçš„ç†è®ºè§£é‡Šã€‚ Background Anomaly Detection å¯¹äºä»»æ„æ—¶é—´\\(t\\)ï¼Œç»™å®šå†å²è§‚å¯Ÿå€¼\\(x_{t-T+1},\\cdots,x_t\\)ï¼Œç¡®å®šå¼‚å¸¸æ˜¯å¦å‘ç”Ÿ(è®°ä¸º\\(y_t=1\\))ã€‚é€šå¸¸æ¥æ”¶å¼‚å¸¸æ£€æµ‹ç®—æ³•ç»™å‡ºçš„æ˜¯å‘ç”Ÿå¼‚å¸¸çš„å¯èƒ½æ€§ï¼Œå¦‚\\(p(y_t=1|x_{t-T+1},\\cdots,x_t)\\)ã€‚ Methodology Problem Statement æœ¬æ–‡çš„ç›®çš„æ˜¯åŸºäºæ·±åº¦ç”Ÿæˆç½‘ç»œå¼€å‘å…·æœ‰ç†è®ºè§£é‡Šæ€§çš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼Œå¹¶ä¸”åœ¨æœ‰æ ‡ç­¾çš„æƒ…å†µä¸‹èƒ½åˆ©ç”¨æ ‡ç­¾ä¿¡æ¯æå‡æ€§èƒ½ã€‚æœ¬æ–‡åŸºäºVAEæ¥æ„å»ºæ¨¡å‹ã€‚ Network Structure ç®—æ³•çš„æ€»ä½“æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä¸€å…±åŒ…å«äº†é¢„å¤„ç†ã€è®­ç»ƒå’Œæ£€æµ‹ä¸‰ä¸ªéƒ¨åˆ†ã€‚ ä¸‹å›¾ä¸ºæ¨¡å‹çš„æ¦‚ç‡å›¾æ¨¡å‹ï¼š å›¾ä¸­åŒå®çº¿çš„æ¡†ä¸ºæœ¬æ–‡æ¨¡å‹æœ‰åˆ«äºä¼ ç»ŸVAEçš„åœ°æ–¹ï¼Œå…¶ä½™åœ°æ–¹å’ŒVAEä¸€æ ·ã€‚å…ˆéªŒæ¦‚ç‡\\(p_\\theta(z)\\)é€‰ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒ\\(\\mathcal{N}(0,I)\\)ï¼ŒåéªŒæ¦‚ç‡\\(x\\)å’Œ\\(z\\)éƒ½æ˜¯å¯¹è§’åŒ–é«˜æ–¯åˆ†å¸ƒï¼Œå³\\(p_\\theta(x|z)=\\mathcal{N}(\\mu_x,\\sigma_x^2 I),q_\\phi(z|x)=\\mathcal{N}(\\mu_z,\\sigma_z^2 I)\\)ã€‚å¦‚Figure 4æ‰€ç¤ºï¼Œæ¨æ–­ç½‘ç»œå’Œç”Ÿæˆç½‘ç»œä¸­åˆ†åˆ«éƒ½æœ‰éšå«å±‚\\(f_\\phi(x)\\)å’Œ\\(f_\\theta(z)\\)å¯¹ç½‘ç»œçš„è¾“å…¥è¿›è¡Œç‰¹å¾æŠ½å–ã€‚é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°å³ä»è¿™äº›æŠ½å–å‡ºæ¥çš„ç‰¹å¾ä¸Šå¾—åˆ°ã€‚å‡å€¼é€šè¿‡çº¿æ€§å±‚å¾—åˆ°ï¼š\\(\\mu_x=W^T_{\\mu_x}f_\\theta(z)+b_{\\mu_x}, \\mu_z=W^T_{\\mu_z}f_\\theta(x)+b_{\\mu_z}\\)ã€‚æ ‡å‡†å·®é€šè¿‡Soft Pluså±‚åŠ ä¸€ä¸ªé«˜æ–¯å™ªå£°å¾—åˆ°ï¼š\\(\\sigma_x=\\text{SoftPlus}[W^T_{\\sigma_x}f_\\theta(z)+b_{\\sigma_x}]+\\varepsilonï¼Œ\\sigma_x=\\text{SoftPlus}[W^T_{\\sigma_z}f_\\theta(x)+b_{\\sigma_z}]+\\varepsilon\\)ã€‚ æ–‡ä¸­æåˆ°å› ä¸ºKPIçš„å±€éƒ¨æ–¹å·®éå¸¸å°ï¼Œæ‰€ä»¥é‡‡ç”¨ç›´æ¥å»ºæ¨¡\\(\\sigma_x,\\sigma_z\\)çš„æ–¹å¼è€Œä¸æ˜¯é‡‡ç”¨å¯¹æ•°ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä¸ºäº†ç†è®ºä¸Šçš„è§£é‡Šæ€§ï¼Œæ–‡ä¸­çš„ç¥ç»ç½‘ç»œåªä½¿ç”¨äº†å…¨è¿æ¥å±‚ã€‚ Training è®­ç»ƒå¯ä»¥ç›´æ¥é‡‡ç”¨ç»å…¸çš„SGVBæ¥ä¼˜åŒ–ELBOï¼š \\[ \\begin{align} \\log p_\\theta(x)&amp;\\geq\\log p_\\theta(x)-\\text{KL}[q_\\phi(z|x)\\parallel p_\\theta(z|x)]\\\\ &amp;=\\mathcal{L}\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x)+\\log p_\\theta(z|x)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x,z)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)+\\log p_\\theta(z)-\\log q_\\phi(z|x)] \\end{align} \\] ä½†æ˜¯åœ¨å®é™…çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒæ•°æ®éœ€è¦ä¿è¯éƒ½æ˜¯æ­£å¸¸æ ·æœ¬ï¼Œä½†å®é™…ä¸Šè®­ç»ƒæ ·æœ¬æœ‰å¯èƒ½ä¼šåŒ…å«å¼‚å¸¸æˆ–è€…æ˜¯ç¼ºå¤±å€¼ã€‚ä¸€ç§åšæ³•æ˜¯ç”¨ç¼ºå¤±å€¼å¡«å……çš„ç®—æ³•æ¥å¡«å……è¿™äº›å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ï¼Œä½†ä½œè€…è®¤ä¸ºä½¿ç”¨ç¼ºå¤±å€¼å¡«å……ç®—æ³•å¹¶ä¸èƒ½å¾ˆå¥½çš„è¿˜åŸæ•°æ®çš„æ­£å¸¸æ¨¡å¼ï¼Œä»è€Œä¿è¯ç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨æ–‡ä¸­ä½œè€…é‡‡ç”¨äº†ä¿®æ”¹ELBOçš„æ–¹æ³•ï¼Œå¹¶å°†å…¶ç§°ä¹‹ä¸ºModified ELBO (M-ELBO)ï¼Œå…¬å¼å¦‚ä¸‹ï¼š \\[ \\tilde{\\mathcal{L}}=\\mathbb{E}_{q_\\phi(z|x)}[\\sum\\limits_{w=1}^W{\\alpha_w\\log p_\\theta(x_w|z)+\\beta\\log p_\\theta(z)-\\log q_\\phi(z|x)}] \\] å…¶ä¸­\\(\\alpha_w\\)ä¸ºæŒ‡ç¤ºæ ‡è®°ï¼Œ\\(\\alpha_w=1\\)ä»£è¡¨ä¸æ˜¯å¼‚å¸¸ä¹Ÿä¸æ˜¯ç¼ºå¤±ã€‚\\(\\beta\\)å®šä¹‰ä¸º\\(\\beta=\\frac{\\sum_{w=1}^W\\alpha_w}{W}\\)ã€‚ åœ¨M-ELBOä¸­ï¼Œå¼‚å¸¸æˆ–ç¼ºå¤±å€¼å¯¹åº”çš„\\(\\log p_\\theta(x_w|z)\\)çš„è´¡çŒ®ä¼šè¢«æ’é™¤ï¼ŒåŒæ—¶\\(\\log p_\\theta(z)\\)åœ¨ä¹˜ä»¥\\(\\beta\\)åä¼šç›¸åº”ç¼©å°ã€‚ä½œè€…æ²¡æœ‰ä¿®æ”¹\\(\\log q_\\phi(z|x)\\)è¿™ä¸€é¡¹çš„åŸå› æœ‰äºŒï¼šä¸€æ˜¯\\(q_\\phi(z|x)\\)ä»…ä»…æ˜¯ä»\\(x\\)åˆ°\\(z\\)çš„æ˜ å°„ï¼Œå¹¶ä¸éœ€è¦è€ƒè™‘â€œæ­£å¸¸æ¨¡å¼â€ï¼›äºŒæ˜¯\\(\\mathbb{E}_{q_\\phi(z|x)}[-\\log q_\\phi(z|x)]\\)å°±æ˜¯\\(q_\\phi(z|x)\\)çš„ç†µï¼Œè€Œè¿™ä¸ªåœ¨åé¢çš„ç†è®ºåˆ†æä¸­æœ‰ç‰¹åˆ«çš„å«ä¹‰ã€‚ é™¤æ­¤ä¹‹å¤–è¿˜æœ‰ä¸€ç§è§£å†³æ–¹æ³•å°±æ˜¯æŠŠæ‰€æœ‰åŒ…å«å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼çš„çª—å£å»é™¤ï¼Œè¿™ç§æ–¹æ³•çš„æ€§èƒ½åœ¨å®éªŒä¸­ä¼šè¿›è¡Œè®¨è®ºã€‚ åœ¨æ–‡ä¸­ä½œè€…è¿˜ä½¿ç”¨äº†ä¸€ç§Missing Data InjectionæŠ€æœ¯ï¼Œå³åœ¨æ¯ä¸ªEpochéšæœºçš„æŒ‰ç…§ä¸€ä¸ªé¢„è®¾æ¯”ä¾‹\\(\\lambda\\)å°†æ­£å¸¸çš„æ•°æ®è®¾ä¸ºç¼ºå¤±ã€‚ä½œè€…è®¤ä¸ºè¿™æ ·æœ‰åŠ©äºæ€§èƒ½çš„æå‡ã€‚ Detection åœ¨æ£€æµ‹é˜¶æ®µï¼Œå¯¹äºä¸€ä¸ªè¾“å…¥æ ·æœ¬ï¼Œæˆ‘ä»¬éœ€è¦æ¨¡å‹è¾“å‡ºå…¶å¼‚å¸¸çš„æ¦‚ç‡ã€‚å› ä¸ºæˆ‘ä»¬å»ºæ¨¡äº†\\(p_\\theta(x|z)\\)ï¼Œä¸€ç§æ–¹æ³•æ˜¯é‡‡æ ·è®¡ç®—\\(p_\\theta(x)=\\mathbb{E}_{p_\\theta(z)}[p_\\theta(x|z)]\\)ï¼Œä½†è¿™ç§æ–¹æ³•è®¡ç®—ä»£ä»·ååˆ†æ˜‚è´µã€‚å…¶ä»–çš„ä¸€äº›æ–¹æ¡ˆæœ‰è®¡ç®—\\(\\mathbb{E}_{q_\\phi(z|x)}[p_\\theta(x|z)]\\)æˆ–\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)ï¼Œå…¶ä¸­åè€…è¢«ç§°ä¸º&quot;Reconstruction Probability&quot;ï¼Œä½œè€…ä¾¿é‡‡ç”¨äº†è¿™ç§æ–¹æ¡ˆã€‚ åŒæ—¶ï¼Œä½œè€…è®¤ä¸ºè¾“å…¥çš„æ£€æµ‹æ ·æœ¬çš„ç¼ºå¤±å€¼ä¼šå¯¹ç»“æœé€ æˆè¾ƒå¤§åå·®ï¼Œäºæ˜¯ä½¿ç”¨äº†ä¸€ç§MCMC-based Missing Data Imputationçš„æ–¹æ³•æ¥å¯¹æ£€æµ‹æ ·æœ¬çš„ç¼ºå¤±å€¼è¿›è¡Œå¡«å……ã€‚å…·ä½“åšæ³•æ˜¯å°†æµ‹è¯•æ ·æœ¬åˆ†ä¸ºå·²è§‚æµ‹å’Œç¼ºå¤±ä¸¤éƒ¨åˆ†\\(x=(x_o,x_m)\\)ï¼Œç„¶åä½¿ç”¨è®­ç»ƒå¥½çš„VAEè¿›è¡Œé‡æ„å¾—åˆ°\\((x^\\prime_o,x^\\prime_m)\\)ï¼Œç„¶åç”¨\\(x^\\prime_m\\)æ›¿æ¢\\(x_m\\)ï¼Œè¿™æ ·ä¸æ–­å¾ªç¯å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä½œè€…ä½¿ç”¨äº†\\(L\\)ä¸ªæ ·æœ¬æ¥è®¡ç®—Reconstruction Probabilityï¼Œè™½ç„¶å¾—åˆ°çš„è¾“å‡ºæ˜¯é’ˆå¯¹æ•´ä¸ªçª—å£æ¯ä¸ªç‚¹çš„ï¼Œä½†ä½œè€…åªä½¿ç”¨æœ€åä¸€ä¸ªç‚¹ã€‚ Experiments Datasets ä½œè€…é€‰æ‹©äº†ä¸‰æ¡KPIä½œä¸ºæµ‹è¯•æ•°æ®ï¼Œåˆ†åˆ«è®°ä¸º\\(\\mathcal{A}\\)ï¼Œ\\(\\mathcal{B}\\)ï¼Œ\\(\\mathcal{C}\\)ï¼Œå…¶åŸºæœ¬æ•°æ®å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š Metrics å› ä¸ºå¼‚å¸¸æ£€æµ‹ç±»åˆ«çš„æä¸å‡è¡¡æ€§ï¼Œä¼ ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡å¹¶ä¸å¤ªåˆé€‚ï¼ˆå¼‚å¸¸æ ·æœ¬æå°‘ï¼Œä¸”å¼‚å¸¸ä¸€èˆ¬å‘ˆè¿ç»­çš„ç‰‡æ®µï¼‰ã€‚ä½œè€…è®¤ä¸ºåœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­è¿ç»´äººå‘˜éœ€è¦å°½é‡æ—©çš„è·çŸ¥å¼‚å¸¸çš„å‘ç”Ÿï¼Œäºæ˜¯æå‡ºäº†æ–°çš„è¯„æµ‹æœºåˆ¶ã€‚ å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç¬¬ä¸€è¡Œä¸ºçœŸå®çš„æ ‡ç­¾ï¼Œç¬¬äºŒè¡Œä¸ºé¢„æµ‹çš„å¼‚å¸¸æ¦‚ç‡ï¼Œç¬¬ä¸‰è¡Œä¸ºé¢„æµ‹çš„æ ‡ç­¾ã€‚ç¬¬ä¸€è¡Œä¸­å¼‚å¸¸ç‰‡æ®µè¢«åŠ ç²—è¡¨ç¤ºï¼Œå¯¹äºæ¯ä¸€ä¸ªå¼‚å¸¸ç‰‡æ®µçš„ç¬¬ä¸€ä¸ªä½ç½®\\({y}_{t^\\prime}\\)ï¼Œå¦‚æœé¢„æµ‹çš„æ ‡ç­¾ä¸­å­˜åœ¨\\(\\hat{y}_{t}\\)æ»¡è¶³\\(t^\\prime&lt;t\\)ä¸”\\(|t-t^\\prime|\\)å°äºç­‰äºé¢„è®¾çš„é˜ˆå€¼\\(T\\)ï¼Œé‚£ä¹ˆ\\(y_{t^\\prime}\\)å¯¹åº”çš„æ•´æ®µå¼‚å¸¸éƒ½è¢«è®¤ä¸ºæ­£ç¡®æ£€æµ‹ï¼Œå¦åˆ™æ•´æ®µå¼‚å¸¸éƒ½è®¤ä¸ºæ²¡æœ‰è¢«æ­£ç¡®æ£€æµ‹ã€‚ç„¶ååœ¨æ­¤åŸºç¡€ä¸Šè®¡ç®—F1-scoreï¼ŒAUCç­‰æŒ‡æ ‡ä½œä¸ºè¯„æµ‹æ‰‹æ®µã€‚ Results Overall Performance ä¸‹å›¾å±•ç¤ºäº†ä¸åŒæ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼š Effects of Donut Techniques ä¸ºäº†æ¢ç©¶Donutä¸­æ‰€åšçš„å„ç§æ”¹è¿›çš„å®é™…ä½œç”¨ï¼Œä½œè€…åšäº†å¤§é‡å¯¹æ¯”å®éªŒï¼Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š M-ELBO ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºM-ELBOå¯¹æ€§èƒ½æå‡æœ€å¤§ã€‚ä½œè€…åœ¨æ–‡ä¸­æåˆ°ä¸€å¼€å§‹å¹¶æ²¡æœŸæœ›M-ELBOèƒ½å¸¦æ¥æ€§èƒ½çš„æå‡ï¼Œåªæ˜¯å¸Œæœ›å®ƒèƒ½å¤ŸWorkã€‚è¿™è¡¨æ˜åœ¨VAEçš„è®­ç»ƒä¸­ï¼Œåªä½¿ç”¨æ­£å¸¸æ ·æœ¬æ˜¯ä¸å¤Ÿçš„ï¼Œä¹Ÿéœ€è¦åŠ å…¥éæ­£å¸¸çš„ä¿¡æ¯ï¼› Missing Data Injection è¯¥æŠ€å·§çš„ä¸»è¦ä½œç”¨æ˜¯å¢å¼ºM-ELBOçš„æ•ˆæœã€‚ä»ç»“æœä¸Šæ¥çœ‹ä½œç”¨å¹¶ä¸æ˜¯ååˆ†çš„æ˜¾è‘—ï¼Œåªæ˜¯åœ¨ä¸€äº›æƒ…å†µä¸‹è·å¾—äº†å°‘é‡çš„æå‡ï¼› MCMC Imputation ä½œè€…è®¤ä¸ºè™½ç„¶è¯¥æŠ€å·§åªåœ¨ä¸€éƒ¨åˆ†æƒ…å†µä¸‹æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œä½†æ€»ä½“æ¥è¯´å€¼å¾—ä½¿ç”¨ã€‚ Impact of K è¯¥éƒ¨åˆ†ä½œè€…æ¢ç©¶äº†éšå˜é‡\\(z\\)çš„ç»´åº¦\\(K\\)å¯¹æ€§èƒ½çš„å½±å“ï¼Œç»“æœå¦‚ä¸‹å›¾ï¼š ä»å›¾ä¸Šæ¥çœ‹ï¼Œå¯¹æ•°æ®é›†\\(\\mathcal{A}\\)ï¼Œ\\(\\mathcal{B}\\)ï¼Œ\\(\\mathcal{C}\\)æœ€ä½³çš„\\(K\\)åˆ†åˆ«æ˜¯\\(5\\)ï¼Œ\\(4\\)å’Œ\\(3\\)ï¼Œä½†æ˜¯è®¾å®šè¾ƒå¤§çš„\\(K\\)å¹¶ä¸ä¼šå¯¹æ€§èƒ½æœ‰ä¸¥é‡çš„æŸå®³ã€‚ä½œè€…è¿˜å‘ç°å¯¹äºè¾ƒä¸ºå¹³æ»‘çš„KPIéœ€è¦è¾ƒå¤§çš„\\(K\\)ã€‚ Analysis KDE Interpretation åœ¨è¿™ä¸€èŠ‚ä½œè€…å¯¹Reconstruction Probabilityçš„æ„ä¹‰è¿›è¡Œäº†æ·±å…¥çš„æ¢è®¨ã€‚é¦–å…ˆä½œè€…å¯¹\\(q_\\phi(z|x)\\)è¿›è¡Œäº†å¯è§†åŒ–ï¼Œåœ¨å›¾ä¸­ä½œè€…å°†æ—¶é—´ç»´åº¦ç”¨é¢œè‰²æ¥è¡¨ç¤ºã€‚å¦‚Figure 11(a) æ‰€ç¤ºï¼Œ\\(z\\)å‡ ä¹æ˜¯æŒ‰ç…§\\(x\\)å¯¹åº”çš„æ—¶é—´å‘ˆä¸€ä¸ªè¿ç»­çš„æµå½¢åˆ†å¸ƒï¼Œä½œè€…å°†è¿™ç§ç°è±¡ç§°ä¸ºTime Gradientã€‚å³ä½¿Donutæ²¡æœ‰æ˜¾å¼çš„ç”¨åˆ°æ—¶é—´ä¿¡æ¯ï¼Œä¸è¿‡å› ä¸ºå®éªŒç”¨åˆ°çš„æ•°æ®åŸºæœ¬æ˜¯å¹³æ»‘çš„ï¼Œæ‰€ä»¥è¯´ç›¸é‚»çš„\\(x\\)ä¼šæ¯”è¾ƒç›¸ä¼¼ï¼Œå› æ­¤ç»è¿‡æ˜ å°„åçš„\\(z\\)ä¹Ÿä¼šæ¯”è¾ƒç›¸ä¼¼ã€‚ä½œè€…æ®æ­¤æå‡ºDonutçš„ä¸€ä¸ªä¼˜åŠ¿ä¾¿æ˜¯å¯¹äºæ²¡æœ‰è§è¿‡çš„åéªŒåˆ†å¸ƒ\\(q_\\phi(z|x)\\)ï¼Œåªè¦å…¶ä½äºè®­ç»ƒè¿‡çš„ä¸¤ä¸ªåéªŒä¹‹é—´ï¼Œä¹Ÿä¼šäº§ç”Ÿåˆç†çš„åˆ†å¸ƒã€‚ å¯¹äºå¼‚å¸¸çš„æ ·æœ¬\\(x\\)ï¼Œå‡è®¾å…¶å¯¹åº”çš„æ­£å¸¸æ¨¡å¼ä¸º\\(\\tilde{x}\\)ï¼Œä½œè€…è®¤ä¸º\\(q_\\phi(z|x)\\)ä¼šåœ¨æŸç§ç¨‹åº¦ä¸Šå¯¹æ­£å¸¸çš„\\(q_\\phi(z|\\tilde{x})\\)è¿›è¡Œè¿‘ä¼¼ã€‚å› ä¸ºæ¨¡å‹æ˜¯ç”¨æ­£å¸¸æ ·æœ¬è¿›è¡Œè®­ç»ƒçš„ï¼Œéšå˜é‡\\(z\\)çš„ç»´åº¦é€šå¸¸æ¥è¯´å°äºæ ·æœ¬\\(x\\)ï¼Œè¿™å°±å¯¼è‡´\\(z\\)åªä¼šä¿ç•™ä¸€éƒ¨åˆ†ä¸»è¦çš„ä¿¡æ¯ã€‚å¯¹äºå¼‚å¸¸æ ·æœ¬ï¼Œå…¶å¼‚å¸¸æ¨¡å¼åœ¨ç¼–ç æ—¶å°±è¢«ä¸¢æ‰äº†ã€‚ä½œè€…è¿˜æŒ‡å‡ºå¦‚æœ\\(x\\)åŒ…å«çš„å¼‚å¸¸å¤ªå¤šï¼Œé‚£ä¹ˆæ¨¡å‹å°†éš¾ä»¥å¯¹\\(x\\)è¿›è¡Œè¿˜åŸã€‚ åŸºäºä¸Šè¿°è®¨è®ºï¼Œä½œè€…å¯¹ä½¿ç”¨\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)ä½œä¸ºReconstruction Probabilityçš„æ„ä¹‰è¿›è¡Œäº†é˜é‡Šã€‚è®¾è¾“å…¥æ ·æœ¬ä¸º\\(x\\)ï¼Œå¦‚æœå…¶åŒ…å«å¼‚å¸¸ï¼Œå‡è®¾å…¶å¯¹åº”çš„æ­£å¸¸æ ·æœ¬ä¸º\\(\\tilde{x}\\)ï¼Œé‚£ä¹ˆ\\(q_\\phi(z|x)\\)éƒ¨åˆ†åœ°å’Œ\\(q_\\phi(z|\\tilde{x})\\)ç›¸ä¼¼ã€‚å¦‚æœ\\(x\\)å’Œ\\(\\tilde{x}\\)ç›¸ä¼¼ç¨‹åº¦é«˜ï¼Œé‚£ä¹ˆ\\(\\log p_\\theta(x|z)\\)å°±ä¼šå¾ˆå¤§ï¼ˆå…¶ä¸­\\(z\\sim q_\\phi(z|\\tilde{x})\\)ï¼‰ã€‚\\(\\log p_\\theta(x|z)\\)ç±»ä¼¼äºä¸€ä¸ªå¯†åº¦ä¼°è®¡å™¨ï¼Œä»£è¡¨\\(x\\)åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¸\\(\\tilde{x}\\)æ¥è¿‘ï¼Œ\\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)ç›¸å½“äºå¯¹æ¯ä¸€ä¸ª\\(z\\)å¯¹åº”çš„\\(\\log p_\\theta(x|z)\\)ä¹˜ä»¥ä¸€ä¸ªæƒé‡\\(q_\\phi(z|x)\\)ç„¶åç›¸åŠ ã€‚äºæ˜¯ä½œè€…æå‡ºäº†Reconstruction Probabilityçš„KDE Interpretation:åœ¨Donutæ¨¡å‹ä¸­ï¼ŒReconstruction Probability \\(\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)]\\)å¯ä»¥çœ‹ä½œæ˜¯ä»¥\\(q_\\phi(z|x)\\)ä¸ºæƒé‡ï¼Œ\\(\\log p_\\theta(x|z)\\)ä¸ºæ ¸çš„æ ¸å¯†åº¦ä¼°è®¡ (Kernel Density Estimation)ã€‚ ä¸‰ç»´å¯è§†åŒ–å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä½œè€…è¿˜å¯¹ç›´æ¥è®¡ç®—\\(p_\\theta(x)=\\mathbb{E}_{p_\\theta(z)}[p_\\theta(x|z)]\\)è¿›è¡Œäº†è´¨ç–‘ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•ç›´æ¥æ±‚\\(x\\)çš„å…ˆéªŒï¼Œä»…ä»…è€ƒè™‘äº†\\(x\\)çš„æ€»ä½“æ¨¡å¼ï¼Œè€Œå¿½ç•¥äº†\\(x\\)çš„ä¸ªä½“æ¨¡å¼ã€‚ Find Good Posteriors for Abnormal \\(x\\) é€šè¿‡ä¸Šé¢çš„è®¨è®ºæˆ‘ä»¬çŸ¥é“äº†Donuté€šè¿‡æ‰¾åˆ°\\(x\\)çš„æ­£å¸¸åéªŒæ¥ä¼°è®¡\\(x\\)åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¸\\(\\tilde{x}\\)ç›¸ä¼¼ï¼Œåœ¨è¿™ä¸€èŠ‚ä½œè€…è®¨è®ºäº†æ–‡ä¸­ä½¿ç”¨çš„ä¸åŒæŠ€å·§å¯¹æ‰¾åˆ°\\(x\\)çš„åéªŒçš„ä½œç”¨ã€‚å¯¹äºMissing Data Injectionä½œè€…è®¤ä¸ºè¯¥æŠ€å·§å¢å¼ºäº†M-ELBOçš„æ•ˆæœã€‚å¯¹äºMCMC Imputationï¼Œä½œè€…è®¤ä¸ºè¯¥æŠ€å·§ä¸»è¦æ˜¯åœ¨æ£€æµ‹é˜¶æ®µé€šè¿‡ä¸æ–­è¿­ä»£æä¾›äº†æ›´å¥½çš„åéªŒï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ä½œè€…è®¤ä¸ºï¼Œè™½ç„¶å¯¹äºåŒ…å«å¤§é‡å¼‚å¸¸çš„æ ·æœ¬ï¼ŒDonutä¸èƒ½å¾ˆå¥½çš„è¿˜åŸï¼Œä½†åœ¨è¿ç»´åœºæ™¯ä¸­ï¼Œåªè¦å¯¹å¤§æ®µå¼‚å¸¸çš„å¼€å§‹é˜¶æ®µè¿›è¡Œå‡†ç¡®é¢„æµ‹å³å¯ã€‚ Causes of Time Gradient åœ¨è¿™ä¸€èŠ‚ä½œè€…è®¨è®ºäº†Time Gradientå‡ºç°çš„åŸå› ã€‚é¦–å…ˆå‡è®¾\\(x\\)éƒ½æ˜¯æ­£å¸¸ç‚¹ï¼Œè¿™æ—¶\\(x\\)çš„ELBOä¸ºï¼š \\[ \\begin{align} \\mathcal{L}(x)&amp;=\\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)+\\log p_\\theta(z)-\\log q_\\phi(z|x)]\\\\ &amp;=\\mathbb{E}[\\log p_\\theta(x|z)]+\\mathbb{E}[\\log p_\\theta(z)]+\\text{H}[z|x] \\end{align} \\] ç¬¬ä¸€é¡¹è¡¨æ˜åœ¨\\(z\\sim q_\\phi(z|x)\\)ä¸‹å°½å¯èƒ½é‡æ„\\(x\\)ã€‚ç¬¬äºŒé¡¹è¡¨æ˜\\(q_\\phi(z|x)\\)å°½é‡ä¸\\(z\\)çš„å…ˆéªŒ\\(\\mathcal{N}(0,I)\\)æ¥è¿‘ã€‚ç¬¬ä¸‰é¡¹ä¸º\\(q_\\phi(z|x)\\)çš„ç†µï¼Œè¡¨æ˜\\(q_\\phi(z|x)\\)åº”å°½é‡åˆ†æ•£ã€‚ç„¶è€Œç¬¬äºŒé¡¹åˆé™åˆ¶äº†è¿™ç§åˆ†æ•£çš„åŒºåŸŸï¼Œå¦‚ Figure 11(c) æ‰€ç¤ºã€‚åŒæ—¶è€ƒè™‘è¿™ä¸‰é¡¹çš„è¯ï¼Œç¬¬ä¸€é¡¹ä½¿å¾—\\(z\\)ä¸èƒ½è‡ªç”±åœ°åˆ†æ•£ï¼Œå¯¹äºä¸ç›¸ä¼¼çš„\\(x\\)å…¶å¯¹åº”çš„\\(z\\)ä¹Ÿæ˜¯ä¸ç›¸ä¼¼çš„ï¼Œå› ä¸ºè¦æœ€å¤§åŒ–\\(x\\)çš„é‡æ„æ¦‚ç‡ã€‚ç„¶è€Œå¯¹äºç›¸ä¼¼çš„\\(x\\)æ¥è¯´ï¼Œå…¶å¯¹åº”çš„\\(q_\\phi(z|x)\\)ä¼šå‡ºç°å¾ˆå¤šé‡å¤çš„éƒ¨åˆ†ã€‚å½“è¾¾åˆ°å¹³è¡¡æ—¶ï¼ŒTime Gradientå°±å‡ºç°äº†ã€‚ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“\\(x\\)è¶Šä¸ç›¸ä¼¼ï¼Œ\\(q_\\phi(z|x)\\)å°±ä¼šç›¸è·è¶Šè¿œï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚ç„¶è€Œåœ¨ä¸€å¼€å§‹ï¼Œå‚æ•°ç»è¿‡éšæœºåˆå§‹åŒ–ï¼Œ\\(q_\\phi(z|x)\\)éƒ½æ˜¯éšæœºæ•£ä¹±çš„ï¼Œå¦‚ Figure 11(b) æ‰€ç¤ºã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œ\\(q_\\phi(z|x)\\)å°†ä¼šä¸æ–­ä¼˜åŒ–ã€‚ç”±äºKPIæ•°æ®å¾€å¾€æ˜¯å…‰æ»‘çš„ï¼Œé‚£ä¹ˆåœ¨æ—¶é—´ä¸Šç›¸è·è¶Šè¿œçš„æ ·æœ¬å°±ä¼šè¶Šä¸ç›¸ä¼¼ï¼Œå¯¹åº”çš„\\(q_\\phi(z|x)\\)ä¹Ÿä¼šç›¸è·æ›´è¿œã€‚è¿™ä¹Ÿè¯´æ˜äº†ï¼Œè®­ç»ƒç»“æŸåï¼Œæ—¶é—´ä¸Šç›¸è·è¶Šè¿œçš„ï¼Œ\\(q_\\phi(z|x)\\)ä¹Ÿä¼šç›¸è·è¶Šè¿œï¼Œåä¹‹äº¦ç„¶ã€‚åŒæ—¶è¿™ä¹Ÿè¡¨æ˜å­¦ä¹ ç‡çš„è®¾ç½®å¯¹æœ¬æ¨¡å‹çš„ç¨³å®šæ€§æœ‰è‡³å…³é‡è¦çš„ä½œç”¨ã€‚ Sub-Optimal Equilibrium ä¸Šé¢æˆ‘ä»¬è®¨è®ºäº†éšç€è®­ç»ƒè¿›è¡Œ\\(q_\\phi(z|x)\\)çš„æ¼”å˜ï¼Œä½œè€…æå‡ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½ä¼šé‡åˆ°æ¨¡å‹æ”¶æ•›åˆ°æ¬¡ä¼˜çš„æƒ…å†µï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ç¬¬ä¸€è¡Œå±•ç¤ºçš„æ˜¯æ”¶æ•›åˆ°æœ€ä¼˜çš„æƒ…å†µï¼Œç¬¬äºŒè¡Œå±•ç¤ºçš„æ˜¯æ”¶æ•›åˆ°æ¬¡ä¼˜çš„æƒ…å†µã€‚ä»ç¬¬äºŒè¡Œçš„ç¬¬ä¸€ä¸ªå›¾ï¼ˆStep 100ï¼‰æ¥çœ‹ï¼Œç´«è‰²çš„ç‚¹å¼€å§‹ç©¿è¿‡ç»¿è‰²çš„ç‚¹ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œç´«è‰²çš„ç‚¹å¼€å§‹å°†ç»¿è‰²çš„ç‚¹æ¨å¼€ã€‚åˆ°Step 5000çš„æ—¶å€™ï¼Œç»¿è‰²çš„ç‚¹å·²ç»è¢«åˆ†æˆäº†ä¸¤åŠã€‚ä¸‹å›¾å±•ç¤ºäº†å¯¹åº”çš„è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®ï¼š è¿™æ ·çš„ç°è±¡ä¼šå¯¼è‡´åœ¨ä¸¤åŠç»¿è‰²åŒºåŸŸä¹‹é—´çš„æµ‹è¯•æ ·æœ¬ä¼šè¢«è¯†åˆ«ä¸ºç´«è‰²ï¼Œä»è€Œé™ä½æ€§èƒ½ã€‚ä½œè€…æå‡ºåœ¨\\(K\\)è¾ƒå¤§çš„æ—¶å€™è¿™ç§ç°è±¡ä¸å®¹æ˜“å‘ç”Ÿï¼Œä½†è¿™æ—¶è®­ç»ƒçš„æ”¶æ•›åˆä¼šæˆä¸ºä¸€ä¸ªé—®é¢˜ã€‚","link":"/2019/09/22/Unsupervised-Anomaly-Detection-via-Variational-Auto-Encoder-for-Seasonal-KPIs-in-Web-Applications/"},{"title":"GAIN: Missing Data Imputation using Generative Adversarial Nets","text":"Abstract æœ¬æ–‡åŸºäºGANæå‡ºäº†ä¸€ç§æ—¶é—´åºåˆ—ç¼ºå¤±å€¼å¡«å……ï¼ˆTime Series Imputationï¼‰çš„æ–¹æ³•ã€‚å…¶ä¸»è¦çš„æ€è·¯ä¸ºç”Ÿæˆå™¨\\(G\\)ä»éšç©ºé—´\\(Z\\)ç”Ÿæˆå®Œæ•´çš„æ ·æœ¬ï¼Œè€Œåˆ¤åˆ«å™¨\\(D\\)åˆ™è¾“å‡ºæ ·æœ¬ä¸­ä¸åŒéƒ¨åˆ†ä¸ºçœŸå®çš„æ¦‚ç‡ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä½œè€…æå‡ºäº†ä½¿ç”¨Hint Vectoræ¥æ­ç¤ºåŸå§‹æ•°æ®ä¸­ç¼ºå¤±éƒ¨åˆ†çš„ä¿¡æ¯ï¼Œæ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚ åŸæ–‡ Methodology Problem Formulation è€ƒè™‘ä¸€ä¸ª\\(d\\)ç»´çš„ç©ºé—´\\(\\mathcal{X}=\\mathcal{X}_1\\times \\cdots\\times \\mathcal{X}_d\\)ï¼Œè®¾\\(\\mathbf{X}=(X_1,\\cdots,X_d)\\)ç»´ç©ºé—´\\(\\mathcal{X}\\)ä¸Šçš„éšæœºå‘é‡ï¼ˆå³ç†æƒ³çš„å®Œæ•´çš„æ—¶é—´åºåˆ—ï¼‰ï¼Œè®°å…¶åˆ†å¸ƒä¸º\\(P(\\mathbf{X})\\)ã€‚è®¾\\(\\mathbf{M}=(M_1,\\cdots,M_d)\\)ä¸ºMaskå‘é‡è¡¨ç¤º\\(\\mathbf{X}\\)ä¸­è¢«è§‚å¯Ÿåˆ°çš„éƒ¨åˆ†ã€‚ï¼ˆå³æ ‡è¯†æ—¶é—´åºåˆ—å“ªäº›éƒ¨åˆ†æœ‰ç¼ºå¤±ï¼‰ï¼Œå–å€¼ä¸º\\(\\{0,1\\}^d\\)ã€‚ å¯¹äºæ¯ä¸€ä¸ª\\(i\\in\\{1,\\cdots,d\\}\\)ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ–°ç©ºé—´\\(\\tilde{\\mathcal{X}}=\\mathcal{X}\\cup\\{*\\}\\)ï¼Œå…¶ä¸­\\(*\\)è¡¨ç¤ºä¸å±äºä»»æ„\\(\\mathcal{X}_i\\)çš„ä¸€ä¸ªç‚¹ã€‚ä»¤\\(\\tilde{\\mathcal{X}}=\\tilde{\\mathcal{X}_1}\\times\\cdots\\times\\tilde{\\mathcal{X}_d}\\)ï¼ŒåŒæ—¶å®šä¹‰ä¸€ä¸ªæ–°çš„éšæœºå˜é‡ï¼ˆå³æˆ‘ä»¬è§‚æµ‹åˆ°çš„å«æœ‰ç¼ºå¤±å€¼çš„æ—¶é—´åºåˆ—ï¼‰\\(\\tilde{\\mathbf{X}}=(\\tilde{X}_1,\\cdots,\\tilde{X}_d)\\in \\tilde{\\mathcal{X}}\\)ï¼š \\[ \\tilde{X}_i=\\begin{cases}X_i,&amp;\\text{if } M_i=1\\\\*,&amp;\\text{otherwise}\\end{cases} \\] å‡è®¾æ•°æ®é›†çš„å½¢å¼ä¸º\\(\\mathcal{D}=\\{(\\tilde{x}^i,m^i)\\}^n_{i=1}\\)ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ä»\\(P(\\mathbf{X}|\\tilde{\\mathbf{X}}=\\tilde{x}^i)\\)ä¸Šé‡‡æ ·æ¥å¯¹ç¼ºå¤±å€¼è¿›è¡Œå¡«å……ã€‚ Model Architecture æ¨¡å‹çš„æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š Generator ç”Ÿæˆå™¨çš„è¾“å…¥æœ‰ä¸‰é¡¹ï¼š\\(\\tilde{\\mathbf{X}}\\)ï¼Œ\\(\\mathbf{M}\\)å’Œéšæœºå™ªå£°\\(\\mathbf{Z}\\)ï¼Œè¾“å‡ºè®¾ä¸º\\(\\bar{\\mathbf{X}}\\)ã€‚è®¾ç”Ÿæˆå™¨ä¸ºæ˜ å°„\\(G: \\tilde{\\mathcal{X}}\\times\\{0,1\\}^d\\times[0,1]^d\\rightarrow \\mathcal{X}\\)ï¼Œè€Œ\\(\\mathbf{Z}\\)ä¸º\\(d\\)ç»´çš„é«˜æ–¯å™ªå£°ã€‚ç”Ÿæˆå™¨çš„è¾“å‡ºå’Œå¡«å……åçš„æ—¶é—´åºåˆ—å®šä¹‰ä¸ºï¼š \\[ \\begin{align} \\bar{\\mathbf{X}}&amp;=G(\\tilde{\\mathbf{X}},\\mathbf{M},(1-\\mathbf{M})\\odot\\mathbf{Z})\\\\ \\hat{\\mathbf{X}}&amp;=\\mathbf{M}\\odot\\tilde{\\mathbf{X}}+(1-\\mathbf{M})\\odot\\bar{\\mathbf{X}} \\end{align} \\] \\(\\bar{\\mathbf{X}}\\)å³ä¸ºç”Ÿæˆå™¨çš„ç›´æ¥è¾“å‡ºï¼Œå› ä¸ºå…¶å®æœ‰äº›éƒ¨åˆ†æ²¡æœ‰ç¼ºå¤±ï¼Œç”Ÿæˆå™¨è¿˜æ˜¯ä¼šä¸ºæ¯ä¸ªéƒ¨åˆ†è¾“å‡ºå€¼ã€‚ \\(\\hat{\\mathbf{X}}\\)ä¸ºå¡«å……åçš„æ—¶é—´åºåˆ—ï¼Œå¯¹äºç¼ºå¤±çš„éƒ¨åˆ†é‡‡ç”¨ç”Ÿæˆå™¨çš„è¾“å‡ºè¿›è¡Œå¡«å……ã€‚ Discriminator å’ŒåŸå§‹çš„GANä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦åˆ¤æ–­æ•´ä¸ªæ ·æœ¬æ˜¯çœŸå®çš„æˆ–è€…æ˜¯ç”Ÿæˆçš„ï¼Œè€Œæ˜¯éœ€è¦åˆ¤æ–­æ ·æœ¬çš„é‚£äº›éƒ¨åˆ†æ˜¯çœŸå®çš„æˆ–è€…æ˜¯ç”Ÿæˆçš„ï¼Œæ‰€ä»¥åˆ¤åˆ«å™¨ä¸ºæ˜ å°„\\(D: \\mathcal{X}\\rightarrow[0,1]^d\\)ã€‚åˆ¤åˆ«å™¨çš„å…·ä½“ç›®æ ‡å‡½æ•°å°†åœ¨åé¢è®¨è®ºã€‚ Hint Hintæ˜¯ä¸€ç§æç¤ºæœºå€¼ï¼Œæ˜¯ä¸€ä¸ªå’Œ\\(\\mathbf{X}\\)ç›¸åŒç»´åº¦çš„éšæœºå˜é‡\\(\\mathbf{H}\\)ï¼Œå…¶åˆ†å¸ƒä¾èµ–äº\\(\\mathbf{M}\\)ã€‚\\(\\mathbf{H}\\)æ˜¯ç”±ç”¨æˆ·è‡ªå·±å®šä¹‰çš„ï¼Œç›¸å½“äºä¸€ç§ä¸å®Œæ•´çš„\\(\\mathbf{M}\\)ï¼Œç”¨æ¥ä½œä¸ºåˆ¤åˆ«å™¨çš„é¢å¤–è¾“å…¥ã€‚ Objective æˆ‘ä»¬è®­ç»ƒåˆ¤åˆ«å™¨æœ€å¤§åŒ–æ­£ç¡®é¢„æµ‹\\(\\mathbf{M}\\)çš„æ¦‚ç‡ï¼Œè€Œç”Ÿæˆå™¨æœ€å°åŒ–åˆ¤åˆ«å™¨æ­£ç¡®é¢„æµ‹\\(\\mathbf{M}\\)çš„æ¦‚ç‡ï¼Œç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š \\[ \\begin{align} V(D,G)=&amp;\\mathbb{E}_{\\hat{X},M,H}[\\mathbf{M}^T\\log D(\\hat{\\mathbf{X}},\\mathbf{H})\\\\&amp;+(1-\\mathbf{M})^T\\log(1-D(\\hat{\\mathbf{X}},\\mathbf{H}))] \\end{align} \\] æŒ‰ç…§æ ‡å‡†çš„GANå¯ä»¥å°†ä¼˜åŒ–å‡½æ•°å†™æˆä»¥ä¸‹çš„å½¢å¼ï¼š \\[ \\min_G\\max_D V(D,G) \\] åœ¨è¿™é‡Œåˆ¤åˆ«å™¨çš„ä»»åŠ¡å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªäºŒåˆ†ç±»ï¼Œè€Œç›®æ ‡å‡½æ•°å°±æ˜¯äºŒå€¼äº¤å‰ç†µçš„å®šä¹‰ï¼Œå› æ­¤å¯ä»¥å†™ä¸ºï¼š \\[ \\mathcal{L}(a,b)=\\sum\\limits_{i=1}^d[a_i\\log(b_i)+(1-a_i)\\log(1-b_i)] \\] \\(\\mathbf{M}\\)å¯ä»¥çœ‹ä½œGround Truthï¼Œè®°\\(\\hat{\\mathbf{M}}=D(\\hat{\\mathbf{X},\\mathbf{H}})\\)ï¼Œå³åˆ¤åˆ«å™¨è¾“å‡ºçš„é¢„æµ‹ï¼Œå› æ­¤ä¼˜åŒ–å‡½æ•°å¯ä»¥ç®€è®°ä¸ºï¼š \\[ \\min_G\\max_D\\mathbb{E}[\\mathcal{L}(\\mathbf{M},\\hat{\\mathbf{M}})] \\] GAIN Algorithm ä¸‹é¢è®¨è®ºGAINç®—æ³•çš„è®­ç»ƒæµç¨‹ã€‚ æœ¬æ–‡é€šè¿‡ç†è®ºè®¨è®ºï¼Œç»™å‡ºäº†ç”ŸæˆHint Vectorçš„ä¸€ä¸ªæ–¹æ³•ï¼Œé¦–å…ˆå®šä¹‰éšæœºå˜é‡\\(\\mathbf{B}=(B_1,\\cdots,B_d)\\in\\{0,1\\}^d\\)ï¼Œ\\(\\mathbf{B}\\)é€šè¿‡ä»\\(\\{1,\\cdots,d\\}\\)éšæœºå‡åŒ€é‡‡æ ·ä¸€ä¸ª\\(k\\)ï¼Œç„¶åç”±ä¸‹åˆ—å…¬å¼å¾—åˆ°ï¼š \\[ B_j=\\begin{cases}1, &amp;\\text{if }j\\neq k\\\\0, &amp;\\text{if }j=k\\end{cases} \\] å®šä¹‰ç©ºé—´\\(\\mathcal{H}=\\{0,0.5,1\\}^d\\)ï¼ŒHint Vectorä¸º\\(\\mathbf{H}=\\mathbf{B}\\odot\\mathbf{M}+0.5(1-\\mathbf{B})\\in\\mathcal{H}\\)ã€‚ åˆ¤åˆ«å™¨çš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼šå›ºå®šç”Ÿæˆå™¨\\(G\\)ï¼Œå¯¹ä¸€ä¸ªå¤§å°ä¸º\\(k_D\\)çš„mini-batchï¼Œç‹¬ç«‹åŒåˆ†å¸ƒé‡‡æ ·\\(k_D\\)ä¸ª\\(z\\)å’Œ\\(b\\)ï¼Œç”¨æ¥è®¡ç®—\\(\\mathbf{Z}\\)å’Œ\\(\\mathbf{B}\\)ã€‚åˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š \\[ \\mathcal{L}_D(m,\\hat{m},b)=\\sum\\limits_{i:b_i=0}[m_i\\log(\\hat{m}_i)+(1-m_i)\\log(1-\\hat{m}_i)] \\] åˆ¤åˆ«å™¨çš„ä¼˜åŒ–å‡½æ•°ä¸ºï¼š \\[ \\min_D-\\sum\\limits_{j=1}^{k_D}\\mathcal{L}_D(m(j),\\hat{m}(j),b(j)) \\] å…¶ä¸­\\(\\hat{m}(j)=D(\\hat{x}(j),m(j))\\)ã€‚ åœ¨ä¼˜åŒ–äº†åˆ¤åˆ«å™¨ä¹‹åï¼Œéœ€è¦ä¼˜åŒ–ç”Ÿæˆå™¨ï¼Œå¯¹ä¸€ä¸ªå¤§å°ä¸º\\(k_G\\)çš„mini-batchï¼Œç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯åœ¨ç¼ºå¤±éƒ¨åˆ†çš„æŸå¤±ï¼š \\[ \\mathcal{L}_G(m,\\hat{m},b)=-\\sum\\limits_{i:b_i=0}(1-m_i)\\log(\\hat{m}_i) \\] ä¸€ä¸ªæ˜¯æœªç¼ºå¤±éƒ¨åˆ†çš„æŸå¤±ï¼š \\[ \\mathcal{L}_M(x,x^\\prime)=\\sum\\limits_{i=1}^d m_iL_M(x_i,x_i^\\prime) \\] å…¶ä¸­ï¼š \\[ L_M(x_i,x_i^\\prime)=\\begin{cases}(x_i^\\prime-x_i)^2, &amp;\\text{if }x_i\\text{ is continuours},\\\\-x_i\\log(x_i^\\prime), &amp;\\text{if }x_i\\text{ is binary}.\\end{cases} \\] æœ€ç»ˆçš„ä¼˜åŒ–å‡½æ•°ä¸ºï¼š \\[ \\min_G\\sum\\limits_{j=1}^{k_G}\\mathcal{L}_G(m(j),\\hat{m}(j),b(j))+\\alpha\\mathcal{L}_M(\\tilde{x}(j),\\hat{x}(j)) \\] ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š Experiments ä¸‹è¡¨ä¸ºåœ¨5ä¸ªä¸åŒæ•°æ®é›†ä¸Šå®éªŒï¼Œä¸å…¶ä»–5ç§æ–¹æ³•å¯¹æ¯”çš„ç»“æœï¼š ä¸Šå›¾ä¸ºGAINã€MissForestå’ŒAutoencoderä¸‰ç§æ¨¡å‹åœ¨ä¸åŒç¼ºå¤±æ¯”ä¾‹ã€æ ·æœ¬æ•°é‡ã€ç‰¹å¾ç»´åº¦ä¸‹çš„å¯¹æ¯”æ›²çº¿å›¾ã€‚ ä¸‹è¡¨ä¸ºä½¿ç”¨ä¸åŒæ¨¡å‹å¯¹æ—¶é—´åºåˆ—è¿›è¡Œå¡«å……ä¹‹åï¼Œä½¿ç”¨é€»è¾‘å›å½’è¿›è¡Œå›å½’ä»»åŠ¡çš„æ€§èƒ½ï¼š ä¸‹å›¾ä¸ºGAINã€MissForestå’ŒAutoencoderä¸‰ç§æ¨¡å‹åœ¨ä¸åŒç¼ºå¤±æ¯”ä¾‹ä¸‹çš„AUROCæ›²çº¿å›¾ï¼š ä¸‹è¡¨å±•ç¤ºçš„æ˜¯ä½œè€…å¯¹æ—¶é—´åºåˆ—å¡«å……ç®—æ³•ä¿æŒç‰¹å¾-æ ‡ç­¾å…³ç³»çš„èƒ½åŠ›ã€‚ä½œè€…åˆ†åˆ«ç”¨å®Œæ•´çš„æ•°æ®å’Œå¡«å……åçš„æ•°æ®ç”¨é€»è¾‘å›å½’æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå°†ä¸¤è€…çš„æƒé‡æ±‚ç»å¯¹å€¼å’Œå‡æ–¹æ ¹çš„ç»“æœã€‚","link":"/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"},{"title":"Variational Approaches for Auto-Encoding Generative Adversarial Networks","text":"Abstract æœ¬æ–‡æ­ç¤ºäº†å¯¹æŠ—ç”Ÿæˆç½‘ç»œï¼ˆGenerative Adversarial Networks, GANï¼‰å’Œå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Auto-encoders, VAEï¼‰ä¹‹é—´çš„è”ç³»ï¼Œå¹¶æ®æ­¤æå‡ºäº†ä¸€ç§å°†ä¸¤è€…ç»“åˆçš„æ–°æ¨¡å‹ã€‚æ–‡ä¸­ä¸»è¦æ˜¯å°†ä¸å¯è§£çš„ä¼¼ç„¶å‡½æ•°å’ŒæœªçŸ¥çš„åéªŒåˆ†å¸ƒç”¨ä¸€ä¸ªéç¡®å®šçš„åˆ†å¸ƒï¼ˆImmplicit Distributionï¼‰æ›¿ä»£ï¼Œå¹¶åŠ å…¥åˆ¤åˆ«å™¨æ¥ä½¿å¾—è¯¥åˆ†å¸ƒé€¼è¿‘çœŸå®çš„åˆ†å¸ƒã€‚é€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œä½œè€…å°†VAEä¸­çš„æŸå¤±å‡½æ•°è¿›è¡Œäº†æ›¿æ¢ï¼Œå˜æˆäº†GANä¸­çš„â€œç”Ÿæˆ-åˆ¤åˆ«â€æ¨¡å¼ã€‚ åŸæ–‡ Contribution æœ¬æ–‡æœ‰å¦‚ä¸‹è´¡çŒ®ï¼š æœ¬æ–‡æå‡ºå˜åˆ†æ¨æ–­ï¼ˆVariational Inferenceï¼‰ä¹Ÿèƒ½é€šè¿‡å¯¹éç¡®å®šåˆ†å¸ƒçš„ä¼°è®¡åº”ç”¨åœ¨GANä¸­ï¼› åŸºäºä¼¼ç„¶çš„æ¨¡å‹ï¼ˆLikelihood-based Modelsï¼‰å’Œéä¼¼ç„¶æ¨¡å‹ï¼ˆLikelihood-free Modelsï¼‰èƒ½å¤Ÿé€šè¿‡å¯¹æŠ—å­¦ä¹ ç»“åˆèµ·æ¥ï¼› ä½œè€…æ ¹æ®æ–‡ä¸­æå‡ºçš„æ–°è§‚ç‚¹ä¿®æ”¹äº†VAEçš„æŸå¤±å‡½æ•°ï¼Œå°†å…¶ç§°ä¹‹ä¸ºAuto-encoding GAN (\\(\\alpha\\)-GAN)ï¼Œå¹¶æå‡ºäº†å¯¹åº”çš„å®ç”¨çš„æ”¹è¿›ï¼› æœ¬æ–‡ä¸ä¼—å¤šState-of-Artæ¨¡å‹è¿›è¡Œäº†å¯¹æ¯” Methodology Overcoming Intractability in Generative Models Latent Variable Models éšå˜é‡æ¨¡å‹é€šè¿‡éšå˜é‡çš„å½¢å¼æè¿°äº†æ•°æ®çš„äº§ç”Ÿè¿‡ç¨‹ã€‚æœ€ç®€å•çš„å½¢å¼æ˜¯å‡è®¾éšå˜é‡\\(\\mathbf{z}\\)æœä»ä¸€ä¸ªå…ˆéªŒåˆ†å¸ƒ\\(\\mathbf{z}\\sim p(\\mathbf{z})\\)ï¼Œè€Œæ•°æ®\\(\\mathbf{x}\\)ä»æ¡ä»¶åˆ†å¸ƒ\\(p(\\mathbf{x}|\\mathbf{z})\\)æŠ½æ ·äº§ç”Ÿã€‚é€šå¸¸æ¥è¯´æè¿°\\(p(\\mathbf{x}|\\mathbf{z})\\)çš„æ¨¡å‹ç§°ä¸ºç”Ÿæˆå™¨\\(\\mathcal{G}_\\theta(\\mathbf{z})\\)ï¼Œå¸¦æœ‰å¯ä¼˜åŒ–çš„å‚æ•°\\(\\theta\\)ï¼Œè€Œ\\(\\mathbf{z}\\)é€šå¸¸å‡è®¾ä¸ºæ­£æ€åˆ†å¸ƒ\\(\\mathbf{z}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})\\)ã€‚ æ–‡ä¸­åŒºåˆ†äº†ä¸¤ç§éšå˜é‡æ¨¡å‹ï¼Œä¸€ç§æ˜¯Implicit Latent Variable Modelsï¼Œä¸€ç§æ˜¯Prescribed Latent Variable Modelsã€‚æ–‡ä¸­çš„æè¿°ä¸å¤ªæ¸…æ¥šï¼Œä¸ªäººè®¤ä¸ºä¸¤è€…çš„åŒºåˆ«æ˜¯å‰è€…å›¾æ¨¡å‹ä¸­çš„\\(\\mathbf{x}\\)ä¸æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼Œåœ¨ä¼˜åŒ–çš„æ—¶å€™éœ€è¦ç”¨ä¸€ä¸ªåˆ»ç”»ç”Ÿæˆçš„\\(\\mathbf{x}\\)å’ŒçœŸå®çš„\\(\\mathbf{x}\\)çš„å·®åˆ«çš„å‡½æ•°\\(\\delta(\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z}))\\)ï¼Œè€Œåè€…å›¾æ¨¡å‹ä¸­\\(\\mathbf{x}\\)æ˜¯ä¸€ä¸ªéšæœºå˜é‡ï¼Œè¿™æ ·å¯ä»¥å†™å‡ºä¼¼ç„¶å‡½æ•°ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ã€‚ æ— è®ºæ˜¯GANè¿˜æ˜¯VAEéƒ½éœ€è¦é€šè¿‡è¾¹ç¼˜åˆ†å¸ƒ\\(p_\\theta(\\mathbf{x})\\)æ¥åˆ»ç”»å»ºæ¨¡çš„å¥½åï¼Œæ¯”å¦‚è¯´æ ¹æ®\\(p_\\theta(\\mathbf{x})\\)ä¸çœŸå®åˆ†å¸ƒ\\(p^*_\\theta(\\mathbf{x})\\)ä¹‹é—´çš„KLæ•£åº¦\\(\\text{KL}\\left[p_\\theta(\\mathbf{x})\\parallel p_\\theta^*(\\mathbf{x})\\right]\\)ã€‚ä½†é€šå¸¸æƒ…å†µä¸‹\\(p_\\theta(\\mathbf{x})\\)éƒ½æ˜¯ä¸å¯è§£çš„ï¼Œè€ŒGANå’ŒVAEé€šè¿‡ä¸åŒçš„é€”å¾„è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚ Generative Adversarial Networks GANæ²¡æœ‰ç›´æ¥è®¡ç®—\\(p_\\theta(\\mathbf{x})\\)ï¼Œè€Œæ˜¯ä½¿ç”¨äº†ä¸€ä¸ªåˆ¤åˆ«å™¨æ¥åˆ¤åˆ«æ ·æœ¬æ˜¯ä»\\(p_\\theta(\\mathbf{x})\\)è¿˜æ˜¯\\(p_\\theta^*(\\mathbf{x})\\)é‡‡æ ·å¾—åˆ°çš„ï¼Œå¦‚æœåˆ¤åˆ«å™¨æ— æ³•è¿›è¡ŒåŒºåˆ†ï¼Œé‚£æˆ‘ä»¬è®¤ä¸ºæ­¤æ—¶\\(p_\\theta(\\mathbf{x})\\approx p_\\theta^*(\\mathbf{x})\\)ã€‚ ä»¤éšæœºå˜é‡\\(y\\in\\{0,1\\}\\)ï¼Œ\\(y=1\\)è¡¨ç¤ºæ ·æœ¬\\(\\mathbf{x}\\)æ¥è‡ªçœŸå®åˆ†å¸ƒï¼Œ\\(y=0\\)è¡¨ç¤ºæ ·æœ¬\\(\\mathbf{x}\\)æ¥è‡ªç”Ÿæˆåˆ†å¸ƒï¼Œè€Œåˆ¤åˆ«å™¨çš„è¾“å‡ºä¸º\\(\\mathbf{x}\\)æ¥è‡ªçœŸå®åˆ†å¸ƒçš„æ¦‚ç‡\\(\\mathcal{D}_\\phi(\\mathbf{x})=p(y=1|\\mathbf{x})\\)ã€‚GANé€šè¿‡å¯¹æ¥è‡ªçœŸå®åˆ†å¸ƒå’Œç”Ÿæˆåˆ†å¸ƒçš„æ ·æœ¬æ±‚äºŒå…ƒäº¤å‰ç†µæ¥ä½œä¸ºåˆ¤åˆ«å™¨æŸå¤±å‡½æ•°ï¼š \\[ \\textbf{Discriminator Loss: }\\mathbb{E}_{p^*(\\mathbf{x})}[-\\log\\mathcal{D}_\\phi(\\mathbf{x})]+\\mathbb{E}_{p_\\theta(\\mathbf{x})}[-\\log(1-\\mathcal{D}_\\phi(\\mathbf{x}))] \\] ç”Ÿæˆå™¨å°†æœ€å¤§åŒ–åˆ¤åˆ«å™¨å¯¹ç”Ÿæˆæ ·æœ¬åˆ¤å®šä¸ºçœŸçš„æ¦‚ç‡ä½œä¸ºæŸå¤±å‡½æ•°ï¼ŒåŒæ—¶è¿˜æœ‰ä¸€ä¸ªç­‰ä»·çš„ä½†åœ¨å®è·µä¸­è¡¨ç°æ›´å¥½çš„æ›¿ä»£ç‰ˆæœ¬ï¼š \\[ \\textbf{Generator Loss: }\\mathbb{E}_{p_\\theta(\\mathbf{x})}[\\log(1-\\mathcal{D}_\\phi(\\mathbf{x}))];\\textbf{ Alternative Loss: }\\mathbf{E}_{p_\\theta(\\mathbf{x})}[-\\log\\mathcal{D}_\\phi(\\mathbf{x})] \\] The Density Ratio Trick ä»¤\\(p^*(\\mathbf{x})=p(\\mathbf{x}|y=1)\\)ï¼Œ\\(p_\\theta(\\mathbf{x})=p(\\mathbf{x}|y=0)\\)ã€‚å®šä¹‰Density Ratio \\(r_\\phi(\\mathbf{x})\\)ä¸ºçœŸå®åˆ†å¸ƒå’Œç”Ÿæˆåˆ†å¸ƒä¹‹é—´çš„æ¯”ä¾‹ï¼š \\[ r_\\phi(\\mathbf{x})=\\frac{p^*(\\mathbf{x})}{p_\\theta(\\mathbf{x})}=\\frac{p(\\mathbf{x}|y=1)}{p(\\mathbf{x}|y=0)}=\\frac{p(y=1|\\mathbf{x})}{p(y=0|\\mathbf{x})}=\\frac{\\mathcal{D}_\\phi(\\mathbf{x})}{1-\\mathcal{D}_\\phi(\\mathbf{x})} \\] ä¸Šå¼è¡¨æ˜äº†Density Ratioçš„è®¡ç®—å¯ä»¥ä»…é€šè¿‡ä»ä¸¤ä¸ªåˆ†å¸ƒä¸Šé‡‡æ ·å¾—åˆ°çš„æ ·æœ¬åŠ ä¸Šä¸€ä¸ªäºŒåˆ†ç±»å™¨\\(\\mathcal{D}_\\phi(\\mathbf{x})\\)å®ç°ï¼ˆå‡è®¾\\(p(y=0)=p(y=1)\\)ï¼‰ã€‚æ›´æ·±å…¥çš„è¯´ï¼Œå¯¹äºä¸å¯è§£çš„åˆ†å¸ƒ\\(p_\\theta^*(\\mathbf{x})\\)ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—Density Ratioæ¥äº†è§£æˆ‘ä»¬è¿‘ä¼¼çš„åˆ†å¸ƒ\\(p_\\theta(\\mathbf{x})\\)å’ŒçœŸå®çš„\\(p_\\theta^*(\\mathbf{x})\\)ä¹‹é—´çš„ç›¸å¯¹æ€§ã€‚è€Œä¸”æˆ‘ä»¬åªéœ€è¦èƒ½å¤Ÿåœ¨ä¸¤ä¸ªåˆ†å¸ƒä¸Šè¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä¸”è®­ç»ƒä¸€ä¸ªåˆ¤åˆ«å™¨å³å¯ã€‚å› ä¸ºåˆ¤åˆ«å™¨æ˜¯ä¸€ä¸ªæ™®é€šçš„åˆ†ç±»å™¨ï¼Œæ‰€ä»¥å¤§é‡çš„ä¸»æµåˆ†ç±»å™¨éƒ½å¯ä»¥ä½¿ç”¨ã€‚ Variational Inference ç°åœ¨æ¥çœ‹VAEï¼Œå¦ä¸€ç§è§£å†³ä¸å¯è§£åˆ†å¸ƒçš„æ–¹æ³•æ˜¯è¿‘ä¼¼ã€‚Variational Inferenceé€šè¿‡å¼•å…¥ä¸€ä¸ªå˜åˆ†åˆ†å¸ƒ\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)æ¨å‡ºäº†ä¸å¯è§£çš„\\(\\mathbf{x}\\)çš„å¯¹æ•°ä¼¼ç„¶çš„ä¸‹ç•Œï¼ˆå¸¸è¢«ç§°ä¸ºè¯æ®ä¸‹ç•ŒELBOï¼‰ï¼š \\[ \\log p_\\theta(\\mathbf{x})=\\log\\int p_\\theta(\\mathbb{x}|\\mathbb{z})p(\\mathbf{z})\\text{d}\\mathbf{z}\\geq \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})\\right]-\\text{KL}\\left[q_\\eta(\\mathbf{z}|\\mathbf{x})\\parallel p(\\mathbf{z})\\right]=\\mathcal{F}(\\boldsymbol{\\theta}, \\boldsymbol{\\eta}) \\] VAEæ˜¯Variational Inferenceçš„ä¸€ç§å®ç°ï¼Œå˜åˆ†åˆ†å¸ƒé€šè¿‡ä¸€ä¸ªç¥ç»ç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä¸”å»ºç«‹èµ·äº†å®Œæ•´çš„å¯ä¼˜åŒ–çš„æ¨¡å‹ã€‚ Synthetic Likelihood å½“ä¼¼ç„¶å‡½æ•°æœªçŸ¥ï¼ˆGANä¸­æ²¡æœ‰æ˜¾å¼çš„ä¼¼ç„¶å‡½æ•°ï¼Œè€ŒVAEä¸­æœ‰ï¼‰çš„æ—¶å€™ï¼ŒVariational Inferenceä¾¿æ— æ³•ç›´æ¥ä½¿ç”¨ã€‚å¯¹äºæ²¡æœ‰æ˜¾å¼çš„ä¼¼ç„¶å‡½æ•°çš„æƒ…å†µï¼Œä»¥VAEçš„ELBOçš„ç¬¬ä¸€é¡¹ä¸ºä¾‹ï¼Œå‡è®¾\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)åˆ†å¸ƒçš„å…·ä½“å½¢å¼æœªçŸ¥ï¼Œæˆ‘ä»¬åªæœ‰ä»\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)é‡‡æ ·å¾—åˆ°çš„æ ·æœ¬ï¼Œå¦‚ä½•è®¡ç®—\\(\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]\\)å‘¢ï¼Ÿä¸€ä¸ªæ–¹æ³•æ˜¯ä¹˜ä»¥\\(p_\\theta^*(\\mathbf{x})\\)å†é™¤ä»¥\\(p_\\theta^*(\\mathbf{x})\\)ï¼š \\[ \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z})}{p^*(\\mathbf{x})}\\right]+\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}[\\log p^*(\\mathbf{x})] \\] å…¬å¼(5)ä¸­çš„ç¬¬ä¸€é¡¹åŒ…æ‹¬äº†åˆæˆä¼¼ç„¶\\(R(\\theta)=\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z})}{p^*(\\mathbf{x})}\\)ï¼Œä¼˜åŒ–\\(R(\\theta)\\)ç›¸å½“äºä¼˜åŒ–\\(\\log p_\\theta(\\mathbf{x}|\\mathbf{z})\\)ã€‚ç¬¬äºŒé¡¹ä¸ç”Ÿæˆç½‘ç»œçš„å‚æ•°\\(\\theta\\)æ— å…³ï¼Œæ‰€ä»¥åœ¨ä¼˜åŒ–çš„æ—¶å€™å¯ä»¥å¿½ç•¥ã€‚ A Fusion of Variational and Adversarial Learning GANå’ŒVAEåˆ†åˆ«ä»ä¸åŒçš„è§’åº¦è§£å†³äº†ç”Ÿæˆæ¨¡å‹çš„æ¨æ–­é—®é¢˜ï¼Œæˆ‘ä»¬ä¸‹é¢ä»VAEå‡ºå‘ï¼Œè€ƒè™‘å°†ä¸¤è€…ç»“åˆèµ·æ¥ã€‚ Implicit Variational Distributions å˜åˆ†æ¨æ–­Variational Inferenceçš„ä¸»è¦ä»»åŠ¡å°±æ˜¯ç¡®å®š\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)ï¼Œé€šå¸¸çš„åšæ³•å¦‚Mean-field Variational Inferenceä¼šå‡è®¾ä¸€ä¸ªç®€å•çš„åˆ†å¸ƒï¼Œå¦‚é«˜æ–¯åˆ†å¸ƒã€‚åœ¨æœ¬æ–‡ä¸­ä¸å¯¹\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)çš„å½¢å¼ä½œå‡è®¾ï¼Œä»…å‡è®¾å…¶ä¸ºä¸€ä¸ªéšå«çš„åˆ†å¸ƒã€‚è¿ç”¨ä¸Šæ–‡æåˆ°çš„Density Ratio Trickï¼Œæˆ‘ä»¬å¯ä»¥å°†VAEæŸå¤±å‡½æ•°ä¸­çš„ç¬¬äºŒé¡¹æ”¹å†™ä¸ºï¼š \\[ -\\text{KL}[q_\\eta(\\mathbf{z}|\\mathbf{x})\\parallel p(\\mathbf{z})]=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{p(\\mathbf{z})}{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\right]\\approx\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}{1-\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}\\right] \\] æ–‡ä¸­å¼•å…¥äº†ä¸€ä¸ªéšå˜é‡åˆ†ç±»å™¨ï¼ˆLatent Classifierï¼‰\\(\\mathcal{C}_{\\boldsymbol{\\omega}}(\\mathbf{z})\\)ï¼Œç”¨æ¥åˆ¤åˆ«\\(\\mathbf{z}\\)æ˜¯ä»ç¼–ç ç½‘ç»œè¿˜æ˜¯ä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°çš„ï¼ˆçŒœæµ‹è¿™æ ·åšçš„å¥½å¤„æ˜¯ä¸ç”¨å†å¯¹\\(\\mathbf{z}\\)çš„åéªŒåšé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾äº†ï¼Œä¹Ÿä¸éœ€è¦åœ¨å˜åˆ†ç½‘ç»œè¾“å‡ºå½¢æˆçš„é«˜æ–¯åˆ†å¸ƒä¸Šé‡‡æ ·å¾—åˆ°\\(\\mathbf{z}\\)äº†ï¼Œè¿™æ ·é‡å‚æ•°æŠ€å·§ä¹Ÿçœäº†ï¼‰ã€‚å…·ä½“å®ç°ä¸Šï¼ŒæœŸæœ›å¯ä»¥ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ï¼ˆé‡‡æ ·å¤šæ¬¡å–å‡å€¼ï¼‰è¿›è¡Œè®¡ç®—ã€‚ Likelihood Choice å¯¹äºVAEæŸå¤±å‡½æ•°ç¬¬ä¸€é¡¹ï¼Œå¯¹åº”ç”Ÿæˆç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å¯¹\\(p(\\mathbf{x}|\\mathbf{z})\\)åˆ†å¸ƒçš„å…·ä½“å½¢å¼åšå‡è®¾ï¼Œ è¿™æ ·å¯¹åº”Likelihood-basedçš„æƒ…å†µã€‚æ–‡ä¸­é€‰æ‹©çš„æ˜¯Zero-mean Laplace Distribution \\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\propto\\exp(-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1)\\)ï¼ˆä¸å°±æ˜¯\\(L_1\\) Losså—ï¼Ÿï¼Ÿï¼Ÿï¼‰ã€‚ å¯¹äºLikelihood-freeçš„æƒ…å†µï¼Œå¯ä»¥ç»§ç»­ä½¿ç”¨ä¸Šé¢æåˆ°çš„Density Ratio Trickï¼Œè¿™æ—¶éœ€è¦åŠ ä¸€ä¸ªä¸€ä¸ªåˆ¤åˆ«å™¨ã€‚ \\[ \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1\\right]\\space\\space\\text{ or }\\space\\space\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\log\\frac{\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}{1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}\\right] \\] å¯¹äºä¸¤ç§é€‰æ‹©ï¼Œå‰è€…å¯¹åº”VAEï¼Œå¥½å¤„æ˜¯ä¸ä¼šå‡ºç°æ¨¡å¼å´©æºƒçš„æƒ…å†µï¼Œåè€…å¯¹åº”GANï¼Œå®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒçš„æƒ…å†µï¼Œä½†æ˜¯å¯ä»¥ä½¿ç”¨å¯¹æŠ—å­¦ä¹ çš„æ–¹å¼ï¼ˆè¿™æ˜¯ä¼˜ç‚¹ï¼Ÿï¼Ÿï¼Ÿï¼‰ï¼Œæœ¬æ–‡é€‰æ‹©ä¸¤ç§éƒ½ç”¨ï¼ˆæˆ‘å…¨éƒ½è¦.jpgï¼‰ã€‚ Hybrid Loss Functions å°†å‰é¢çš„è®¨è®ºç»“åˆèµ·æ¥ï¼Œæœ€åçš„æŸå¤±å‡½æ•°å°±æ˜¯ï¼š \\[ \\mathcal{L}(\\boldsymbol{\\theta},\\boldsymbol{\\eta})=\\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[-\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1+\\log\\frac{\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}{1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))}+\\log\\frac{\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}{1-\\mathcal{C}_\\boldsymbol{\\omega}(\\mathbf{z})}\\right] \\] æœ€åæ¨¡å‹åŒ…å«å››ä¸ªç½‘ç»œï¼šç”Ÿæˆç½‘ç»œ\\(p_\\theta(\\mathbf{x}|\\mathbf{z})\\)ã€æ¨æ–­ç½‘ç»œ\\(q_\\eta(\\mathbf{z}|\\mathbf{x})\\)ä»¥åŠä¸¤ä¸ªåˆ¤åˆ«å™¨\\(\\mathcal{C}_{\\boldsymbol{\\omega}}\\)å’Œ\\(\\mathcal{D}_\\phi\\)ï¼Œä½œè€…å°†å…¶å‘½åä¸º\\(\\alpha\\)-GANã€‚ ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š Improved Techniques ä½œè€…ä¸ºäº†æ”¹è¿›æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ•ˆç‡ï¼Œå°†ç”Ÿæˆå™¨çš„Lossä¸­çš„\\(-\\log(1-\\mathcal{D}_\\phi)\\)ä¿®æ”¹ä¸ºäº†\\(\\log\\mathcal{D}_\\phi-\\log(1-\\mathcal{D}_\\phi)\\)ï¼Œå¹¶å£°ç§°è¿™æ ·èƒ½æä¾›éé¥±å’Œï¼ˆNon-saturatingï¼‰çš„æ¢¯åº¦ï¼š \\[ \\textbf{Generator Loss: } \\mathbb{E}_{q_\\eta(\\mathbf{z}|\\mathbf{x})}\\left[\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1-\\log\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z}))+\\log(1-\\mathcal{D}_\\phi(\\mathcal{G}_\\theta(\\mathbf{z})))\\right] \\] ä½œè€…è®¤ä¸ºåœ¨ç”Ÿæˆå™¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥\\(\\lambda\\parallel\\mathbf{x}-\\mathcal{G}_\\theta(\\mathbf{z})\\parallel_1\\)èƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦é˜²æ­¢æ¨¡å¼å´©æºƒã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œä½œè€…å‘ç°å°†çœŸå®æ ·æœ¬ï¼ˆåŸæ–‡æ˜¯The Samplesï¼‰ä½œä¸ºç”Ÿæˆçš„æ ·æœ¬è¾“å…¥åˆ°åˆ¤åˆ«å™¨ä¸­èƒ½å¤Ÿæå‡æ€§èƒ½ã€‚ä½œè€…ç»™å‡ºçš„è§£é‡Šæ˜¯æ ¹æ®Jensenä¸ç­‰å¼ï¼š\\(\\log p_\\theta(\\mathbf{x})=\\log\\int p_\\theta(\\mathbf{x}|\\mathbf{z})p(\\mathbf{z})\\text{d}\\mathbf{z}\\geq \\mathbb{E}_{p(\\mathbf{z})}[\\log p_\\theta(\\mathbf{x}|\\mathbf{z})]\\)ï¼Œ [TODO] Related Work [TODO] Experiments [TODO] Metrics æœ¬æ–‡ä½¿ç”¨äº†å‡ ç§ä¸åŒçš„è¯„æµ‹ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ï¼š Inception Score: Multi-scale Structural Similarity (MS-SSIM): Independent Wasserstein Critic: Results on ColorMNIST Results on CelebA Results on CIFAR-10","link":"/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/"},{"title":"Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE","text":"Introduction è®ºæ–‡ğŸ“ƒ ä»£ç ğŸ“¥ æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åˆ©ç”¨å¯¹æŠ—è®­ç»ƒæ¥è¿›è¡Œæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„æ–¹æ³•Buzzã€‚ä½œè€…è®¤ä¸ºåœ¨ç°å®ä¸­å¤æ‚çš„KPIæ•°æ®å¤§é‡å­˜åœ¨ï¼Œè¿™ç§æ•°æ®é€šå¸¸å¸¦æœ‰éé«˜æ–¯åˆ†å¸ƒçš„å™ªå£°ï¼ŒåŒæ—¶æ•°æ®åˆ†å¸ƒå¤æ‚ï¼Œå¯¼è‡´ä¸€èˆ¬çš„ç”Ÿæˆå¼æ¨¡å‹æ— æ³•å¯¹æ•°æ®è¿›è¡Œå¾ˆå¥½çš„å»ºæ¨¡ï¼Œæ‰€ä»¥ä½œè€…æå‡ºäº†åŸºäºå¯¹æŠ—è®­ç»ƒçš„æ¨¡å‹ã€‚åœ¨æ–‡ä¸­ï¼Œä½œè€…çš„åˆ›æ–°ç‚¹ä¸»è¦æœ‰ä¸‰ä¸ªï¼š ä¸ºäº†å¤„ç†å¤æ‚æ•°æ®ï¼Œå°†æ•°æ®ç©ºé—´åˆ†ä¸ºå¤šä¸ªå­ç©ºé—´ï¼Œåœ¨æ¯ä¸ªå­ç©ºé—´ä¸Šè¿›è¡Œè·ç¦»çš„åº¦é‡ï¼› é‡‡ç”¨Wassersteinè·ç¦»åº¦é‡æ¨¡å‹å»ºæ¨¡çš„åˆ†å¸ƒå’ŒçœŸå®åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼› å»ºç«‹äº†åŸºäºå¯¹æŠ—è®­ç»ƒçš„Buzzçš„æŸå¤±å‡½æ•°å’ŒVAEä¹‹é—´çš„å…³ç³»ã€‚ Background Anomaly Detection å¯¹äºä»»æ„æ—¶é—´\\(t\\)ï¼Œç»™å®šå†å²è§‚å¯Ÿå€¼\\(x_{t-T+1},\\cdots,x_t\\)ï¼Œç¡®å®šå¼‚å¸¸æ˜¯å¦å‘ç”Ÿ(è®°ä¸º\\(y_t=1\\))ã€‚é€šå¸¸æ¥æ”¶å¼‚å¸¸æ£€æµ‹ç®—æ³•ç»™å‡ºçš„æ˜¯å‘ç”Ÿå¼‚å¸¸çš„å¯èƒ½æ€§ï¼Œå¦‚\\(p(y_t=1|x_{t-T+1},\\cdots,x_t)\\)ã€‚ VAE Model Latent Data Auto-encoder (AE) None L1Loss Variational Auto-encoder (VAE) KL Divergence Log Likelihood Adversarial Auto-encoder (AAE) Discriminator L1Loss Wasserstein Auto-encoder (WAE) MaxMeanDiscrepancy or Discriminator L1Loss AlphaGAN Discriminator Discriminator+L1Loss GAN and WGAN-GP åŸå§‹GANç­‰ä»·äºä¼˜åŒ–ï¼š \\[ \\mathbb{E}_{x\\sim P_r}\\log{\\frac{P_r(x)}{\\frac{1}{2}\\left[P_r(x)+P_g(x)\\right]}}+\\mathbb{E}_{x\\sim P_g}\\log{\\frac{P_g(x)}{\\frac{1}{2}\\left[P_r(x)+P_g(x)\\right]}} \\] æ ¹æ®KLæ•£åº¦å’ŒJSæ•£åº¦çš„å®šä¹‰ï¼š \\[ \\text{KL}(P_1\\parallel P_2)=\\mathbb{E}_{x\\sim P_1}\\log{\\frac{P_1}{P_2}} \\] \\[ \\text{JS}(P_1\\parallel P_2)=\\frac{1}{2}\\text{KL}(P_1\\parallel \\frac{P_1+P_2}{2})+\\frac{1}{2}\\text{KL}(P_2\\parallel \\frac{P_1+P_2}{2}) \\] å¯é‡å†™ä¸ºï¼š \\[ 2\\text{JS}(P_r\\parallel P_g)-2\\log 2 \\] å½“\\(P_r\\)ä¸\\(P_g\\)çš„æ”¯æ’‘é›†ï¼ˆsupportï¼‰æ˜¯é«˜ç»´ç©ºé—´ä¸­çš„ä½ç»´æµå½¢ï¼ˆmanifoldï¼‰æ—¶ï¼Œ\\(P_r\\)ä¸\\(P_g\\)é‡å éƒ¨åˆ†æµ‹åº¦ï¼ˆmeasureï¼‰ä¸º0çš„æ¦‚ç‡ä¸º1ã€‚ æ”¯æ’‘é›†ï¼ˆsupportï¼‰å…¶å®å°±æ˜¯å‡½æ•°çš„éé›¶éƒ¨åˆ†å­é›†ï¼Œæ¯”å¦‚ReLUå‡½æ•°çš„æ”¯æ’‘é›†å°±æ˜¯[å…¬å¼]ï¼Œä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„æ”¯æ’‘é›†å°±æ˜¯æ‰€æœ‰æ¦‚ç‡å¯†åº¦éé›¶éƒ¨åˆ†çš„é›†åˆã€‚ æµå½¢ï¼ˆmanifoldï¼‰æ˜¯é«˜ç»´ç©ºé—´ä¸­æ›²çº¿ã€æ›²é¢æ¦‚å¿µçš„æ‹“å¹¿ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä½ç»´ä¸Šç›´è§‚ç†è§£è¿™ä¸ªæ¦‚å¿µï¼Œæ¯”å¦‚æˆ‘ä»¬è¯´ä¸‰ç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªæ›²é¢æ˜¯ä¸€ä¸ªäºŒç»´æµå½¢ï¼Œå› ä¸ºå®ƒçš„æœ¬è´¨ç»´åº¦ï¼ˆintrinsic dimensionï¼‰åªæœ‰2ï¼Œä¸€ä¸ªç‚¹åœ¨è¿™ä¸ªäºŒç»´æµå½¢ä¸Šç§»åŠ¨åªæœ‰ä¸¤ä¸ªæ–¹å‘çš„è‡ªç”±åº¦ã€‚åŒç†ï¼Œä¸‰ç»´ç©ºé—´æˆ–è€…äºŒç»´ç©ºé—´ä¸­çš„ä¸€æ¡æ›²çº¿éƒ½æ˜¯ä¸€ä¸ªä¸€ç»´æµå½¢ã€‚ æµ‹åº¦ï¼ˆmeasureï¼‰æ˜¯é«˜ç»´ç©ºé—´ä¸­é•¿åº¦ã€é¢ç§¯ã€ä½“ç§¯æ¦‚å¿µçš„æ‹“å¹¿ï¼Œå¯ä»¥ç†è§£ä¸ºâ€œè¶…ä½“ç§¯â€ã€‚ Wassersteinè·ç¦»å®šä¹‰å¦‚ä¸‹ï¼š \\[ W(P_r,P_g)=\\inf\\limits_{\\gamma\\sim\\prod(P_r,P_g)}\\mathbb{E}_{(x,y)\\sim \\gamma}\\left[\\parallel x-y\\parallel\\right] \\] ä¸‹ç¡®ç•Œ\\(\\inf\\)æ²¡æ³•ç›´æ¥æ±‚è§£ï¼Œä¸è¿‡æ ¹æ®ç›¸å…³å®šç†å…¶ç­‰ä»·äºï¼š \\[ W(P_r,P_g)=\\frac{1}{K}\\sup\\limits_{\\parallel f\\parallel_L\\leq K}\\mathbb{E}_{x\\sim P_r}[f(x)]-\\mathbb{E}_{x\\sim P_g}[f(x)] \\] Lipschitzè¿ç»­æ˜¯æŒ‡å­˜åœ¨ä¸€ä¸ªå¸¸æ•°\\(K\\geq 0\\)ä½¿å¾—å®šä¹‰åŸŸå†…ä»»æ„ä¸¤ä¸ªå…ƒç´ \\(x_1\\)å’Œ\\(x_2\\)éƒ½æ»¡è¶³ï¼š \\[ |f(x_1)-f(x_2)|\\leq K|x_1-x_2| \\] WANçš„æŸå¤±å‡½æ•°ï¼š \\[ \\mathcal{L}=\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_g}\\left[D({\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] \\] WGAN-GPçš„æŸå¤±å‡½æ•°ä¸ºï¼š \\[ \\mathcal{L}=\\mathop{\\mathbb{E}}\\limits_{\\tilde{\\mathbf{x}}\\sim\\mathbb{P}_g}\\left[D(\\tilde{\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] + \\lambda\\mathop{\\mathbb{E}}\\limits_{\\hat{\\mathbf{x}}\\sim\\mathbb{P}_{\\hat{\\mathbf{x}}}}\\left[(\\parallel\\nabla_{\\hat{\\mathbf{x}}}D(\\hat{\\mathbf{x}})\\parallel_2-1)^2\\right] \\] Proposed Method ä¸‹å›¾ä¸ºBuzzçš„æ€»ä½“æµç¨‹ï¼š æ•°æ®ä¼šé¦–å…ˆè¿›è¡Œä¸€äº›é¢„å¤„ç†ï¼Œä¹‹åè¿›è¡Œè®­ç»ƒã€‚åœ¨æ£€æµ‹é˜¶æ®µä¼šæ ¹æ®å¼‚å¸¸åˆ†æ•°æ¥åˆ¤å®šå¼‚å¸¸ã€‚ Motivation åœ¨æ–‡ä¸­ï¼Œæœ€å…³é”®çš„ä¸¤ä¸ªåˆ›æ–°ç‚¹åˆ†åˆ«æ˜¯Wassersteinè·ç¦»å’Œå¯¹æ•°æ®åˆ†å¸ƒè¿›è¡Œåˆ†åŒºçš„æ–¹æ³•ã€‚ åœ¨ä½¿ç”¨è·ç¦»åº¦é‡æ–¹é¢ï¼Œ å› ä¸ºWassersteinåœ¨WGANä¸­å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œæ˜¯ä¸€ç§é²æ£’çš„è·ç¦»åº¦é‡ï¼Œæ‰€ä»¥ä½œè€…åœ¨æ–‡ä¸­é‡‡ç”¨äº†Wassersteinè·ç¦»æ¥è¡¡é‡ç”Ÿæˆçš„åˆ†å¸ƒå’ŒçœŸå®çš„åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼Œå¹¶ç”±æ­¤å¼•å…¥äº†å¯¹æŠ—è®­ç»ƒï¼› åœ¨åˆ†åŒºæ–¹æ³•æ–¹é¢ï¼Œä½œè€…è®¤ä¸ºåŸå§‹æ•°æ®è¿‡äºå¤æ‚ï¼Œæ‰€ä»¥å°†æ•°æ®ç©ºé—´\\(\\mathcal{X}\\)è¿›è¡Œåˆ’åˆ†ï¼Œç„¶ååœ¨æ¯ä¸ªå­ç©ºé—´ä¸Šä½¿ç”¨Wassersteinåº¦é‡è·ç¦»ï¼Œè€Œæ€»ä½“çš„è·ç¦»ç”±æ¯ä¸ªåˆ†åŒºçš„è·ç¦»çš„æœŸæœ›æ±‚å¾—ã€‚ ä½œè€…è¿˜å‘ç°ï¼Œå½“åˆ’åˆ†åœ°è¶Šæ¥è¶Šç»†æ—¶ï¼Œæ€»ä½“è·ç¦»æ¥è¿‘äºç‰¹å®šå½¢å¼çš„VAEçš„é‡æ„è¯¯å·®é¡¹ã€‚ Network Structure ä¸‹å›¾ä¸ºæ¨¡å‹çš„ç½‘ç»œç»“æ„ï¼š Training Objective Function å…ˆå®šä¹‰ä¸€äº›ç¬¦å·ï¼š \\(b\\)å’Œ\\(s\\)åˆ†åˆ«ä¸ºBatchçš„å¤§å°å’Œé‚»å±…çš„å¤§å°ï¼Œæ•°æ®é›†æŒ‰\\(s\\)è¿›è¡Œåˆ‡åˆ†ï¼Œç„¶åéšæœºæ‰“ä¹±ï¼Œæ¯ä¸ªBatchåŒ…å«\\(b\\)ä¸ª\\(s\\)ï¼Œä¹‹å\\(s/=2,b*=2\\)ï¼› \\(\\mathcal{W}=\\{w_1,w_2,\\cdots,w_b\\}\\)ä¸ºä¸€ä¸ªBatchï¼Œä¸”æ»¡è¶³æ¯ä¸ª\\(w_i\\)æ˜¯\\(s\\)çš„å€æ•°ï¼› \\(w\\in\\mathcal{W}\\)çš„é‚»åŸŸé›†(neighborhood set)ä¸ºä¸€ä¸ªæ—¶é—´ä¸Šçš„partitionï¼Œè®°ä¸º\\(\\{w,w+1,\\cdots,w+s-1\\}\\) \\(\\mathbf{x}^{(w)},\\mathbf{x}^{(w+1)},\\cdots,\\mathbf{x}^{(w+s-1)}\\)ä¸ºåœ¨ç©ºé—´\\(\\mathcal{X}\\)ä¸Šçš„ä¸€ä¸ªpartitionï¼Œè®°ä¸º\\(S_w\\)ï¼Œå…¶ä¸­\\(\\mathbf{x}^{(w)}\\)è¡¨ç¤ºä»¥\\(w\\)ä¸ºç»“å°¾çš„æ—¶é—´çª—å£ã€‚ Buzzçš„æŸå¤±å‡½æ•°å’ŒWGAN-GPç±»ä¼¼ï¼Œä½†åšäº†ä¸€äº›æ”¹è¿›ï¼Œç”±ä¸‹é¢å››éƒ¨åˆ†ç»„æˆï¼Œä¸‹é¢åˆ†åˆ«è§£é‡Šã€‚ ç¬¬ä¸€ä¸ªæ˜¯æ¯ä¸€ä¸ªpartitionçš„\\(\\mathbf{z}\\)åéªŒçš„KLæ•£åº¦ï¼š \\[ \\mathcal{K} = \\frac{1}{bs}\\sum\\limits_{w\\in\\mathcal{W}}\\sum\\limits_{i=1}^{s-1}\\text{KL}\\left[q_\\phi(\\mathbf{z}|\\mathbf{x})\\parallel\\mathcal{N}(\\mathbf{0},\\mathbf{1})\\right] \\] ç¬¬äºŒä¸ªåœ¨è®­ç»ƒæ—¶æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼š \\[ Z(\\lambda) = \\frac{\\Gamma(W)}{\\Gamma(\\frac{W}{2})}2\\pi^{\\frac{W}{2}}\\lambda^{-W} \\] å…¶ä¸­\\(\\Gamma\\)æ˜¯Gammaå‡½æ•°ã€‚ ç¬¬ä¸‰ä¸ªæ˜¯Wassersteinè·ç¦»ï¼š \\[ \\mathcal{T}(F,w)=\\frac{1}{bs}\\sum\\limits_{i=1}^{s-1}\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x}^{w+i})}\\left[F(\\mathbf{x}^{(w+i)})-F(G(\\mathbf{z}))\\right] \\] ç¬¬å››ä¸ªæ˜¯Gradient Penaltyï¼š \\[ \\mathcal{R}(F,w)=\\frac{1}{bs}\\sum\\limits_{i=1}^{s-1}\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x}^{(w+i)})}\\left[\\mathbb{E}_{\\varepsilon\\sim[0,1]}(\\parallel\\nabla_{\\hat{\\mathbf{x}}}(\\hat{\\mathbf{x}})\\parallel-\\mathbf{1})^2\\right] \\] å…¶ä¸­\\(\\hat{\\mathbf{x}}=\\varepsilon \\mathbf{x}^{w+i}+(1-\\varepsilon)G(\\mathbf{z})\\)ä¸ºç”Ÿæˆæ•°æ®ä¸çœŸå®æ•°æ®çš„æ’å€¼ã€‚ åŸå§‹çš„WGAN-GPçš„æŸå¤±å‡½æ•°ä¸ºï¼š \\[ L=\\mathop{\\mathbb{E}}\\limits_{\\tilde{\\mathbf{x}}\\sim\\mathbb{P}_g}\\left[D(\\tilde{\\mathbf{x}})\\right]-\\mathop{\\mathbb{E}}\\limits_{\\mathbf{x}\\sim\\mathbb{P}_r}\\left[D(\\mathbf{x})\\right] + \\lambda\\mathop{\\mathbb{E}}\\limits_{\\hat{\\mathbf{x}}\\sim\\mathbb{P}_{\\hat{\\mathbf{x}}}}\\left[(\\parallel\\nabla_{\\hat{\\mathbf{x}}}D(\\hat{\\mathbf{x}})\\parallel_2-1)^2\\right] \\] å…¶ä¸­\\(\\mathbb{P}_g\\)ä¸ºç”Ÿæˆå™¨çš„åˆ†å¸ƒï¼Œ\\(\\mathbb{P}_r\\)ä¸ºçœŸå®åˆ†å¸ƒï¼Œ\\(\\mathbb{P}_{\\hat{\\mathbf{x}}}\\)ä¸ºçœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®æ’å€¼å¾—åˆ°çš„åˆ†å¸ƒã€‚ \\[ \\hat{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_F\\left[\\sum\\limits_{w\\in\\mathcal{W}}(\\left|\\mathcal{T}(F,w)\\right|-\\eta\\mathcal{R}(F,w))\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] Training Procedure Buzzçš„è®­ç»ƒè¿‡ç¨‹ä¸WGAN-GPç±»ä¼¼ï¼Œ Detection æ–‡ä¸­å‡è®¾è§£ç å™¨çš„è¾“å‡ºæœä»å¦‚ä¸‹åˆ†å¸ƒï¼š \\[ p_\\theta(\\mathbf{x}|\\mathbf{z})=\\frac{1}{Z(\\lambda)}\\exp\\{-\\lambda\\parallel\\mathbf{x}-G(\\mathbf{z})\\parallel\\} \\] ä½œè€…å®šä¹‰å¼‚å¸¸åˆ†æ•°ä¸ºï¼š \\[ \\mathcal{S}=\\log p_\\theta(\\mathbf{x})-\\log p_\\theta(\\bar{\\mathbf{x}}) \\] å…¶ä¸­\\(\\bar{\\mathbf{x}}\\)ä¸ºç»è¿‡MCMCå¡«å……åçš„æ ·æœ¬ã€‚ å¼‚å¸¸åˆ†æ•°ä¹Ÿå¯ä»¥å±•å¼€ä¸ºï¼š \\[ \\log\\frac{1}{L}\\sum\\limits_{l=1}^L\\left[\\frac{p_\\theta(\\mathbf{x}|\\mathbf{z^{(l)}})p_\\theta(\\mathbf{z}^{(l)})}{q_\\phi(\\mathbf{z}^{(l)}|\\bar{\\mathbf{x}})}\\right]-\\log\\frac{1}{L}\\sum\\limits_{l=1}^L\\left[\\frac{p_\\theta(\\bar{\\mathbf{x}}|\\mathbf{z}^{(l)})p_\\theta(\\mathbf{z}^{(l)})}{q_\\phi(\\mathbf{z}^{(l)}|\\bar{\\mathbf{x}})}\\right] \\] æœ€ç»ˆç®—æ³•æµç¨‹å›¾ä¸ºï¼š Theoretical Analysis åœ¨ç†è®ºåˆ†æä¸­ï¼Œä½œè€…ä¸»è¦æ˜¯æƒ³å»ºç«‹\\(\\mathcal{L}_{Buzz}\\)å’ŒVAEçš„æŸå¤±å‡½æ•°\\(\\mathcal{L}_{vae}\\)ä¹‹é—´çš„è”ç³»ï¼ŒæŸå¤±å‡½æ•°\\(\\mathcal{\\hat{L}}_{Buzz}\\)ä¸ºï¼š \\[ \\hat{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_F\\left[\\sum\\limits_{w\\in\\mathcal{W}}(\\left|\\mathcal{T}(F,w)\\right|-\\eta\\mathcal{R}(F,w))\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] ä¸ºäº†ä¾¿äºåˆ†æï¼Œå»æ‰Gradient Penaltyçš„éƒ¨åˆ†ï¼Œå…¬å¼å¯ç®€åŒ–ä¸ºï¼š \\[ \\mathcal{L}_{Buzz}=-\\lambda\\mathbb{E}_{p(w)}W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]-\\mathcal{K}-\\log Z(\\lambda) \\] å®é™…ä¸Š\\(Z(\\lambda)=\\mathfrak{S}_W\\Gamma(W)\\lambda^{-W}\\)ï¼Œå…¶ä¸­\\(\\mathfrak{S}_W\\)ä¸º\\(W\\)ç»´å•ä½çƒçš„è¡¨é¢ç§¯ã€‚ \\(n\\)ç»´ç©ºé—´å•ä½çƒè¡¨é¢ç§¯å…¬å¼ï¼š \\[ \\omega_n=\\frac{2\\pi^{\\frac{n}{2}}}{\\Gamma(\\frac{n}{2})} \\] è€Œ\\(W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]\\)ä¸ºWassersteinè·ç¦»ï¼š \\[ W^1\\left[P(\\mathbf{x}|w)\\parallel P(\\mathbf{y}|w)\\right]=\\sup\\limits_{Lip(f)\\leq 1}\\left\\{\\int_\\mathcal{X}f(\\mathbf{x})p(\\mathbf{x}|w)\\mathrm{d}\\mathbf{x}-\\int_\\mathcal{X}f(\\mathbf{y})p(\\mathbf{y}|w)\\mathrm{d}\\mathbf{y}\\right\\} \\] Lemma 1 é€šè¿‡è®¾å®šå…·ä½“å½¢å¼çš„åéªŒåˆ†å¸ƒï¼ŒVAEçš„æŸå¤±å‡½æ•°å¯ä»¥å†™ä¸ºï¼š è®¾\\(\\mathbf{x}\\)çš„åéªŒåˆ†å¸ƒ\\(p(\\mathbf{x}|\\mathbf{z})=\\frac{1}{Z(\\lambda)}\\exp\\{-\\lambda\\parallel\\mathbf{x}-G(\\mathbf{z})\\parallel\\}\\)ï¼Œé‚£ä¹ˆVAEçš„æŸå¤±å‡½æ•°ä¸ºï¼š \\[ \\mathcal{L}_{vae}=\\lambda\\mathbb{E}_{p(w)}\\left[\\mathbb{E}_{p(\\mathbf{x}|w)}\\mathbb{E}_{p_G(\\mathbf{y}|\\mathbf{x})}-\\parallel\\mathbf{x}-\\mathbf{y}\\parallel\\right]-\\mathcal{K}-\\log{Z(\\lambda)} \\] åéªŒåˆ†å¸ƒå®é™…ä¸Šæ˜¯ä¸€ä¸ªLaplaceåˆ†å¸ƒï¼š Laplace Distribution: \\[ f(x|\\theta,\\lambda)=\\frac{1}{2\\lambda}\\exp{\\left(-\\frac{|x-\\theta|}{\\lambda}\\right)} \\] å¯ä»¥ç›´æ¥æŠŠåéªŒåˆ†å¸ƒå¸¦å…¥VAEçš„æŸå¤±å‡½æ•°å°±å¾—åˆ°äº†ã€‚ Lemma 2 \\(S_w\\)å®šä¹‰ä¸ºæ•°æ®ç©ºé—´\\(\\mathcal{X}\\)çš„ä¸€ä¸ªpartitionï¼Œè€Œ\\(S=\\{(\\mathbf{x}_1,\\mathbf{x}_2)|\\exist w, \\mathbf{x}_1\\in S_w,\\mathbf{x}_2\\in S_w\\}\\)ã€‚ å½“\\(G,\\phi,\\lambda\\)å›ºå®šæ—¶ï¼Œ\\(S\\downarrow\\)æœ‰\\(\\mathcal{L}_{Buzz}\\downarrow\\) Lemma 3 \\(\\max\\mathcal{L}_{Buzz}\\geq\\max{\\mathcal{L}_{vae}}\\)ï¼ŒåŒæ—¶ï¼Œå½“\\(S\\downarrow\\text{diag}{\\mathcal{X}}\\)æ—¶\\(\\max\\mathcal{L}_{Buzz}\\downarrow\\max\\mathcal{L}_{vae}\\) Lemma 4 ä»¤\\(p^\\prime_G(\\mathbf{y}|\\mathbf{x})\\)è¡¨ç¤º\\(\\mathbb{E}_{q_{\\phi^\\prime}}\\left[p_G(\\mathbf{y}|\\mathbf{z})\\right]\\)ã€‚å¦‚æœ\\((G,\\phi,\\lambda)\\)æ˜¯ä¸€ä¸ªè§£ï¼Œé‚£ä¹ˆå­˜åœ¨\\((G,\\phi^\\prime,\\lambda)\\)ä½¿å¾—ï¼š \\[ \\mathbb{E}_{p(\\mathbf{x}|w)}\\mathbb{E}_{p_G^\\prime(\\mathbf{y}|\\mathbf{x})}\\parallel\\mathbf{x}-\\mathbf{y}\\parallel=W^1\\left[P(\\mathbf{x}|w)\\parallel P_G(\\mathbf{y}|w)\\right] \\] æ­¤æ—¶\\(\\mathcal{L}_{Buzz}-\\mathcal{L}_{vae}^\\prime=\\mathcal{K}^\\prime-\\mathcal{K}\\)ï¼Œå…¶ä¸­\\(\\mathcal{L}^\\prime,\\mathcal{K}^\\prime\\)åˆ†åˆ«ä¸º\\((G,\\phi^\\prime,\\lambda)\\)æ—¶çš„\\(\\mathcal{L}\\)å’Œ\\(\\mathcal{K}\\)ã€‚ \\[ \\mathcal{L}^\\dagger_{Buzz}=\\mathbb{E}_{p(\\mathbf{x})}\\left[\\mathbb{E}_{q_{\\phi^\\prime}(\\mathbf{z}|\\mathbf{x})}\\log_{p_\\theta}(\\mathbf{x}|\\mathbf{z})\\right]-\\min\\limits_{\\bar{\\phi}\\sim\\phi^\\prime}\\bar{\\mathcal{K}} \\] Lemma 5 è¿™é‡Œä¸»è¦æ˜¯æƒ³è¯æ˜ å¯¹äºå›ºå®šçš„\\(w\\)ï¼Œä»¤ï¼š \\[ \\mathcal{F}=\\{f|Lip(f)\\leq 1\\}, \\space \\mathcal{F}^*=\\left\\{f|_{S_w}\\bigg|Lip(f|_{S_w})\\leq 1\\right\\} \\] æœ‰\\(\\sup_{f\\in\\mathcal{F}}\\mathcal{T}(f)=\\sup_{f|_{S_w}\\in\\mathcal{F}^*}\\mathcal{T}^*\\left(f|_{S_w}\\right)\\)ã€‚ Theorem 6 \\(\\mathcal{L}_{Buzz}\\)çš„å¯¹å¶å½¢å¼ä¸ºï¼š \\[ \\mathcal{L}_{Buzz}=-\\lambda\\sup\\limits_{Lip(F;S)\\leq 1}\\mathbb{E}_{p(w)}\\mathcal{T}^*(F)-\\mathcal{K}-\\log Z(\\lambda) \\] è¿‘ä¼¼çš„\\(\\mathcal{L}_{Buzz}\\)çš„å¯¹å¶å½¢å¼ä¸ºï¼š \\[ \\bar{\\mathcal{L}}_{Buzz}=-\\lambda\\sup\\limits_{Lip(F;S)\\leq 1}\\mathbb{E}_{p(w)}\\mathcal{T}(F)-\\mathcal{K}-\\log Z(\\lambda) \\] Experiment","link":"/2020/01/06/Unsupervised-Anomaly-Detection-for-Intricate-KPIs-via-Adversarial-Training-of-VAE/"},{"title":"ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection","text":"Introduction æœ¬æ–‡é’ˆå¯¹é¢å‘åŒºé—´çš„KPIå¼‚å¸¸æ£€æµ‹æå‡ºäº†Label Screeningæ–¹æ³•å’ŒRelearning Algorithm. åŸæ–‡ Contribution æå‡ºäº†ä¸€ç§Label Screeningæ–¹æ³•æ¥å¯¹åŒºé—´å†…ä¸åŒé‡è¦æ€§è¿›è¡Œè¿‡æ»¤ æå‡ºäº†ä¸€ç§Relearning Algorithmæ¥å¯¹FPå’ŒTPè¿›è¡ŒRelearningï¼Œåœ¨ä¸å‡å°‘Recallçš„æ¡ä»¶ä¸‹å¢å¤§Precision Methodology Overall Structure ç®—æ³•çš„æ•´ä½“æ¡†æ¶å¦‚ä¸‹ï¼š Label Screening Model é¢„è®­ç»ƒçš„ç»“æœè¢«åˆ†ä¸º\\(TP_{po},FP_{po},TN_{po},FN_{po}\\)å››ç±»ï¼Œ\\(TP_{po}\\)å’Œ\\(FN_{po}\\)å¯ä»¥è¢«ç»†åˆ†å¦‚ä¸‹ï¼š \\[ \\begin{align}TP_{po}&amp;=TP_{po,withinT}+TP_{po,afterT}\\\\&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+TP_{po,after,fnl}\\end{align} \\] \\[ \\begin{align}FN_{po}&amp;=FN_{po,withinT}+FN_{po,afterT}\\\\&amp;=FN_{po,withinT,tpl}+FN_{po,,withinT,fnl}+FN_{po,afterT,tpl}+FN_{po,afterT,fnl}\\end{align} \\] å…¶ä¸­ä¸‹æ ‡\\({}_{withinT}\\)ä»£è¡¨åœ¨å¼‚å¸¸ç‰‡æ®µç¬¬ä¸€ä¸ªç‚¹\\(T\\)è·ç¦»å†…çš„æ‰€æœ‰ç‚¹ï¼Œä¸‹æ ‡\\({}_{afterT}\\)ä»£è¡¨\\(T\\)è·ç¦»ä¹‹åã€‚ä¸‹æ ‡\\({}_{tpl}\\)å’Œ\\({}_{fnl}\\)åˆ†åˆ«ä»£è¡¨åœ¨å¼‚å¸¸ç‰‡æ®µä¸­ï¼ŒåŒ…å«å’Œä¸åŒ…å«\\(TP_{po,withinT}\\)çš„ç‚¹ã€‚ ä»¥TPä¸ºä¾‹ï¼ŒPoint-basedçš„TPåŒ…å«äº†åœ¨TèŒƒå›´ä¹‹å†…çš„ï¼ˆå³åœ¨Interval-basedçš„æ ‡å‡†ä¸­ä¹Ÿä¼šè¢«è®¤ä¸ºæ˜¯TPçš„ç‚¹ï¼‰å’ŒTèŒƒå›´ä¹‹å¤–çš„ç‚¹ï¼ˆå³åœ¨Interval-basedçš„æ ‡å‡†ä¸­ä¸è®¤ä¸ºæ˜¯TPçš„ç‚¹ï¼‰ã€‚è€Œåœ¨TèŒƒå›´ä¹‹å¤–çš„ç‚¹åˆå¯ä»¥ç»†åˆ†ä¸ºè¯¥å¼‚å¸¸ç‰‡æ®µæ˜¯å¦åŒ…å«\\(TP_{po,withinT}\\)çš„ç‚¹ï¼ˆå³è¯¥ç‚¹åœ¨Interval-basedçš„æ ‡å‡†ä¸­ä¸ä¼šè¢«åˆ¤å®šä¸ºTPï¼Œä½†è¯¥å¼‚å¸¸ç‰‡æ®µæœ‰å…¶ç‚¹ä¼šè¢«åˆ¤å®šä¸ºTPï¼‰ã€‚ ç±»ä¼¼çš„ï¼Œ\\(TP_{io}\\)å’Œ\\(FN_{io}\\)å¯ä»¥è¢«åˆ†è§£ä¸ºï¼š \\[ \\begin{align}TP_{io}&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}\\\\&amp;=TP_{po}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}-TP_{po,afterT,fnl}\\end{align} \\] \\[ \\begin{align}FN_{io}&amp;=FN_{po,withinT,fnl}+FN_{po,afterT,fnl}+TP_{po,afterT,fnl}\\\\&amp;=FN_{po}+TP_{po,afterT,fnl}-FN_{po,withinT,tpl}-FN_{po,afterT,tpl}\\end{align} \\] æ–‡ä¸­å¯¹è¯¥éƒ¨åˆ†çš„åˆ†æå¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š åœ¨Interval-orientedçš„æ ‡å‡†ä¸­ï¼Œ\\(FN_{po,tpl}\\)çš„ç‚¹ä»ä¼šè¢«è®¤ä¸ºæ˜¯\\(TP_{io}\\)ï¼Œè€Œ\\(TP_{po,afterT}\\)ï¼ˆä¸å¸¦\\({}_{tpl}\\)ï¼‰ä¸ä¼šè¢«è®¤ä¸ºæ˜¯\\(TP_{io}\\)ï¼Œæ‰€ä»¥æœ€ç»ˆ\\(TP_{io}\\)ç”±æ‰€æœ‰\\(TP_{po}\\)åŠ ä¸Šé‚£äº›ä¼šè¢«è®¤ä¸ºæ˜¯\\(TP_{io}\\)çš„\\(FN_{po,tpl}\\)å†å»æ‰ä¸å¸¦\\({}_{tpl}\\)çš„\\(TP_{po,afterT}\\)ç»„æˆï¼Œå³å…¬å¼(6) åŒæ—¶ï¼Œæ ¹æ®å…¬å¼(6)ï¼Œå¦‚æœ\\(TP_{po}\\)å˜ä¸º\\(FN_{po,tpl}\\)ï¼Œä¹Ÿä¸ä¼šå¯¹æœ€ç»ˆç»“æœé€ æˆå½±å“ã€‚ä½†æ˜¯æ ¹æ®å…¬å¼(5)å’Œå…¬å¼(7)ï¼Œ\\(TP_{po,withinT}\\)å˜æˆ\\(FN_{po,withinT,fnl}\\)ä¼šå‡å°\\(TP_{io}\\)åŒæ—¶å¢å¤§\\(FN_{io}\\) æ–‡ç« æŒ‡å‡ºï¼Œè™½ç„¶\\(FN_{po,withinT,tpl}\\)å’Œ\\(FN_{po,afterT,tpl}\\)æœ€åéƒ½ä¼šè¢«è®¤ä¸ºæ˜¯\\(TP_{io}\\)ï¼Œä½†ä½œè€…å‡è®¾\\(FN_{po,withinT,tpl}\\)æ›´éš¾æ£€æµ‹ï¼Œæ‰€ä»¥åº”è¯¥ä¿ç•™ï¼Œè€Œ\\(FN_{po,afterT,tpl}\\)åº”è¯¥å‰Šå‡ Label Screeningæ–¹æ³•å»é™¤äº†\\(FN_{po,afterT}\\)çš„ç‚¹ Screenedä¹‹åçš„è®­ç»ƒé›†è¢«ç”¨æ¥è®­ç»ƒDNNä¸»æ¨¡å‹ï¼Œä½†Label Screeningçš„é¢„æµ‹ç»“æœä¹Ÿä¼šè¢«ä¿ç•™ï¼Œå’ŒDNNä¸»æ¨¡å‹çš„ç»“æœè¿›è¡Œç»„åˆ ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š Relearning Algorithm Relearning Modelçš„è¾“å…¥æ˜¯DNNä¸»æ¨¡å‹é¢„æµ‹å‡ºæ¥çš„å¼‚å¸¸ï¼Œå…¶ä¸­åŒ…æ‹¬TPå’ŒFPã€‚Relearning Modelé‡‡ç”¨çš„æ˜¯éšæœºæ£®æ—ï¼Œå…¶è¾“å…¥çš„æ ·æœ¬é€šè¿‡é‡‡æ ·å¾—åˆ°ï¼š \\[ \\begin{align} \\text{relearning}\\space&amp;\\text{training set}=\\\\&amp; shuffle\\{4C\\ast\\text{randomof}(TP_{po})\\\\&amp;+C\\cdot\\text{randomof}(FP_{po})+C\\cdot\\text{randomof}(TN_{po})\\} \\end{align} \\] å…¶ä¸­\\(C\\)ä¸ºå¸¸æ•°ã€‚TNå’ŒFPéƒ½çœ‹ä½œæ˜¯è´Ÿä¾‹(æ­£å¸¸æ ·æœ¬)ï¼ŒTPçœ‹ä½œæ˜¯æ­£ä¾‹ã€‚ Detection å¯¹äºä¸€ä¸ªæ»‘åŠ¨çª—å£\\(x_t=\\{x_{t-w+1},\\cdots,x_t\\}\\)ï¼Œå¼‚å¸¸æ£€æµ‹ç®—æ³•çš„ç›®æ ‡æ˜¯è¾“å‡ºæ£€æµ‹ç»“æœ\\(y_t\\in\\{0,1\\}\\)æ¥è¡¨ç¤ºæ—¶é—´\\(t\\)æ˜¯å¦å‘ç”Ÿå¼‚å¸¸ã€‚å®é™…ä¸Šç®—æ³•è¾“å‡ºçš„æ˜¯\\(p_{y_t}\\in[0,1]\\)æ¦‚ç‡å€¼æ¥è¡¨ç¤ºåœ¨æ—¶é—´\\(t\\)å‘ç”Ÿå¼‚å¸¸çš„æ¦‚ç‡ã€‚æ–‡ä¸­ä¸‰ä¸ªæ¨¡å‹ä¼šå¾—åˆ°ä¸‰ä¸ªè¾“å‡ºï¼š\\(y_{t,ls},y_{t,main},y_{t,re}\\)ã€‚æœ€ç»ˆç»“æœä¸ºï¼š \\[ y_t=y_{t,ls}\\space\\&amp;\\space y_{t,main}\\space\\&amp; \\space y_{t,re} \\] åœ¨ç»˜åˆ¶PRæ›²çº¿æ—¶ï¼Œé‡‡ç”¨çš„å…¬å¼ä¸ºï¼š \\[ \\begin{align} p_{y_t}(th)=&amp;(1-sig(p_{y_t,ls},th))\\cdot(p_{y_t,ls})\\\\ &amp;+sig(p_{y_t,ls},th)\\cdot(1-sig(p_{y_t,main},th))\\cdot p_{y_t,main}\\\\ &amp;+sig(p_{y_t,ls},th)\\cdot sig(p_{y_t,main},th)\\cdot p_{y_t,re}\\\\ \\end{align} \\] \\[ y_t(th)=sig(p_{y_t}(th),th) \\] ç®—æ³•æµç¨‹å¦‚ä¸‹ï¼š Experiments Datasets æ¸…åAIOpsæ•°æ®é›†ï¼Œé€‰å–äº†25æ¡KPIã€‚ Preprocessing Missing Data. å»é™¤ã€‚ Standardization. Minmax Standardizationï¼ŒFeature Extractionä½¿ç”¨çš„æ˜¯Standardizationåçš„æ•°æ®ã€‚ Feature Extraction. ä½¿ç”¨äº†12ç§ç‰¹å¾ã€‚ Group Feature Name Values The original values standardized Statistical Features Mean, Standard Deviation, Range, Difference... Fitting Features EWMA, AR Wavelet Features Db2 wavelet decomposition Results AUCPR F1 Remark è¿™ç¯‡æ–‡ç« çš„Label Screeningæ–¹æ³•å®é™…ä¸Šæ˜¯åœ¨å¤„ç†æ ·æœ¬åˆ†ç±»éš¾æ˜“åº¦çš„é—®é¢˜ï¼Œå°†å¼‚å¸¸åŒºé—´å†…å®¹æ˜“çš„æ ·æœ¬å»é™¤äº† å¯¹äºæ—¶é—´åºåˆ—çš„å¼‚å¸¸æ£€æµ‹é—®é¢˜ï¼Œæˆ‘ä»¬çš„ç›®æ ‡ä¸€èˆ¬æ˜¯Point-basedçš„å¼‚å¸¸æ ‡ç­¾ï¼Œä¸€ä¸ªæ—¶é—´ç‚¹çš„ç‰¹å¾æ˜¯æœ‰é™çš„ã€‚å¦‚æœç”¨çª—å£çš„æ–¹å¼ï¼Œä»¥\\(\\{x_{t-w+1},\\cdots,x_t\\}\\)ä½œä¸ºæ—¶é—´\\(t\\)çš„è¾“å…¥ï¼ˆå½“ç„¶æ¯ä¸ª\\(x_t\\)å¯ä»¥æœ‰å¤šä¸ªChannelï¼‰ï¼Œç„¶åæŠŠé¢„æµ‹ç»“æœä½œä¸ºæ—¶é—´\\(t\\)çš„è¾“å‡º","link":"/2019/09/22/ALSR-An-adaptive-label-screening-and-relearning-approach-for-interval-oriented-anomaly-detection/"},{"title":"Anomaly Detection in Streams with Extreme Value Theory","text":"Introduction æœ¬æ–‡åŸºäºExtreme Value Theoryæå‡ºäº†ä¸€ç§ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®é˜ˆå€¼ä¹Ÿä¸éœ€è¦å¯¹æ•°æ®åˆ†å¸ƒä½œä»»ä½•å‡è®¾çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæœ¬æ–¹æ³•å¯ä»¥ç”¨åœ¨é€šç”¨çš„è‡ªåŠ¨é˜ˆå€¼é€‰æ‹©çš„åœºåˆä¸­ã€‚ åŸæ–‡ Background åœ¨å¾ˆå¤šæƒ…å†µä¸‹æˆ‘ä»¬éœ€è¦è¿›è¡Œé˜ˆå€¼çš„é€‰æ‹©ã€‚é˜ˆå€¼çš„é€‰æ‹©å¯ä»¥é€šè¿‡å®éªŒçš„æ–¹æ³•æˆ–è€…å¯¹æ•°æ®åˆ†å¸ƒè¿›è¡Œå‡è®¾çš„æ–¹æ³•æ¥å¾—åˆ°ï¼Œä¸è¿‡è¿™æ ·åšé€šå¸¸ä¸å‡†ç¡®ã€‚å€ŸåŠ©Extreme Value Theoryæˆ‘ä»¬å¯ä»¥åœ¨ä¸éœ€è¦å¯¹åŸå§‹æ•°æ®çš„åˆ†å¸ƒä½œå¾ˆå¼ºçš„å‡è®¾çš„æƒ…å†µä¸‹ï¼Œæ¨æ–­æˆ‘ä»¬æƒ³è¦çš„æç«¯äº‹ä»¶çš„åˆ†å¸ƒï¼ˆåœ¨å¼‚å¸¸æ£€æµ‹ä¸­å°±æ˜¯å¼‚å¸¸å€¼ï¼‰ã€‚ ä¸‹é¢ç»™å‡ºä¸€äº›æ•°å­¦ç¬¦å·ï¼Œ\\(X\\)ä¸ºéšæœºå˜é‡ï¼Œ\\(F\\)ä¸ºç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼Œå³\\(F(x)=\\mathbb{P}(X\\leq x)\\)ã€‚è®°\\(F\\)çš„â€œæœ«å°¾â€åˆ†å¸ƒ\\(\\bar{F}(x)=1-F(x)=\\mathbb{P}(X&gt;x)\\)ã€‚å¯¹äºä¸€ä¸ªéšæœºå˜é‡\\(X\\)å’Œç»™å®šçš„æ¦‚ç‡\\(q\\)ï¼Œè®°\\(z_q\\)ä¸ºåœ¨\\(1-q\\)æ°´å¹³çš„åˆ†ä½æ•°ï¼Œå³\\(z_q\\)ä¸ºæ»¡è¶³\\(\\mathbb{P}(X\\leq z_q)\\geq 1-q\\)æœ€å°çš„å€¼ã€‚ Extreme Value Distributions Extreme Value Theoryä¸»è¦æ˜¯ä¸ºäº†æ‰¾å‡ºæç«¯äº‹ä»¶å‘ç”Ÿçš„è§„å¾‹ï¼Œæœ‰å­¦è€…è¯æ˜ï¼Œåœ¨å¾ˆå¼±çš„æ¡ä»¶ä¸‹ï¼Œæ‰€æœ‰æç«¯äº‹ä»¶éƒ½æœä»ä¸€ä¸ªç‰¹å®šçš„åˆ†å¸ƒï¼Œè€Œä¸ç®¡åŸå§‹åˆ†å¸ƒå¦‚ä½•ã€‚å…·ä½“å½¢å¼å¦‚ä¸‹ï¼š \\[ G_\\gamma:x\\mapsto \\exp(-(1+\\gamma x)^{-\\frac{1}{\\gamma}}), \\space\\space\\space\\space\\space\\gamma\\in\\mathbb{R}, \\space\\space\\space\\space\\space 1+\\gamma x&gt;0 \\] å…¶ä¸­\\(\\gamma\\)ç§°ä¸ºExtreme Value Indexï¼Œç”±åŸå§‹åˆ†å¸ƒå†³å®šã€‚ æ›´ä¸¥è°¨çš„è¯´æ³•æ˜¯Fisher-Tippett-Gnedenkoå®šç†ï¼ˆæå€¼ç†è®ºç¬¬ä¸€å®šç†ï¼‰ï¼š THEOREM: (Fisher-Tippett-Gnedenko). ä»¤\\(X_1,X_2,\\cdots,X_n,\\cdots\\)ä¸ºç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡åºåˆ—ï¼Œ\\(M_n=\\max \\{X_1,\\cdots,X_n\\}\\)ã€‚å¦‚æœå®æ•°å¯¹åºåˆ—\\((a_n,b_n)\\)å­˜åœ¨ä¸”æ»¡è¶³\\(a_n&gt;0\\)å’Œ\\(\\lim\\limits_{n\\rightarrow \\infty}P\\left(\\frac{M_n-b_n}{a_n}\\leq x\\right)=F(x)\\)ï¼Œå…¶ä¸­\\(F\\)ä¸ºéé€€åŒ–åˆ†å¸ƒå‡½æ•°ï¼Œé‚£ä¹ˆ\\(F\\)å±äºGumbelã€FrÃ©chetæˆ–Weibullåˆ†å¸ƒæ—ï¼ˆæˆ–æ€»ç§°Generalized Extreme Value Distributionï¼‰ä¸­çš„ä¸€ç§ã€‚ è¿™æ˜¯ä¸€ä¸ªåç›´è§‰çš„ç»“è®ºï¼Œä½†æ˜¯æƒ³åˆ°å½“äº‹ä»¶å‘ç”Ÿå˜å¾—æç«¯æ—¶ï¼Œå³\\(\\mathbb{P}(X&gt;x)\\rightarrow 0\\)ï¼Œ\\(\\bar{F}(x)=\\mathbb{P}(X&gt;x)\\)åˆ†å¸ƒçš„å½¢çŠ¶å…¶å®å¹¶æ²¡æœ‰å¾ˆå¤šç§é€‰æ‹©ã€‚Table 1å±•ç¤ºäº†å‡ ç§ä¸åŒåˆ†å¸ƒå¯¹åº”çš„\\(\\gamma\\)ï¼š Figure 1å±•ç¤ºäº†å‡ ç§ä¸åŒ\\(\\gamma\\)æƒ…å†µä¸‹çš„â€œæœ«å°¾â€åˆ†å¸ƒï¼š Power of EVT æ ¹æ®Extreme Value Theoryï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åŸå§‹åˆ†å¸ƒæœªçŸ¥çš„æƒ…å†µä¸‹è®¡ç®—æç«¯äº‹ä»¶çš„æ¦‚ç‡ã€‚ä½†æ˜¯\\(\\bar{G}_\\gamma\\)åˆ†å¸ƒä¸­å‚æ•°\\(\\gamma\\)æ˜¯æœªçŸ¥çš„ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§é«˜æ•ˆçš„æ–¹æ³•æ¥è¿›è¡Œä¼°è®¡ã€‚The Peaks-Over-Threshold (POT) æ–¹æ³•æ˜¯æœ¬æ–‡ä»‹ç»çš„ä¸€ç§æ–¹æ³•ã€‚ Peaks-Over-Threshold Approach POTæ–¹æ³•ä¾èµ–äºPickands-Balkema-De Haanå®šç†ï¼ˆæå€¼ç†è®ºç¬¬äºŒå®šç†ï¼‰ï¼Œç»´åŸºç™¾ç§‘ç‰ˆï¼š è€ƒè™‘ä¸€ä¸ªæœªçŸ¥åˆ†å¸ƒ\\(F\\)å’Œéšæœºå˜é‡\\(X\\)ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¼°è®¡\\(X\\)åœ¨è¶…è¿‡ç¡®å®šé˜ˆå€¼\\(u\\)ä¸‹çš„æ¡ä»¶åˆ†å¸ƒ\\(F_u\\)ï¼Œå®šä¹‰ä¸ºï¼š \\[ F_u(y)=P(X-u\\leq y|X&gt;u)=\\frac{F(u+y)-F(u)}{1-F(u)} \\] å…¶ä¸­\\(0\\leq y\\leq x_F-u\\)ï¼Œ\\(x_F\\)ä¸º\\(F\\)çš„å³ç«¯ç‚¹ã€‚\\(F_u\\)æè¿°äº†è¶…è¿‡ç‰¹å¾é˜ˆå€¼\\(u\\)çš„åˆ†å¸ƒï¼Œç§°ä¸ºConditional Excess Distribution Functionã€‚ STATEMENT: (Pickands-Balkema-De Haan). è®¾\\((X_1,X_2,\\cdots)\\)ä¸ºç‹¬ç«‹åŒåˆ†å¸ƒéšæœºå˜é‡åºåˆ—ï¼Œ\\(F_u\\)ä¸ºç›¸åº”çš„Conditional Excess Distribution Functionã€‚å¯¹äºä¸€å¤§ç±»çš„\\(F\\)å’Œå¾ˆå¤§çš„\\(u\\)ï¼Œ\\(F_u\\)èƒ½å¤Ÿå¾ˆå¥½çš„è¢«Generalized Pareto Distributionæ‰€æ‹Ÿåˆï¼š \\[ F_u(y)\\rightarrow G_{k,\\sigma}(y),\\space\\space \\text{as } u\\rightarrow \\infty \\] å…¶ä¸­ï¼š \\[ G_{k,\\sigma}(y)= \\begin{cases} 1-(1+ky/\\sigma)^{-1/k}, &amp;\\text{if }k\\neq 0\\\\ 1-e^{-y/\\sigma}, &amp;\\text{if }k=0 \\end{cases} \\] å½“\\(k\\geq 0\\)æ—¶\\(\\sigma&gt;0, y\\geq 0\\)ï¼Œ\\(k&lt;0\\)æ—¶\\(0\\leq y\\leq -\\sigma/k\\)ã€‚ è®ºæ–‡ä¸­ç»™å‡ºçš„å®šç†å¦‚ä¸‹ï¼š THEOREM: (Pickands-Balkema-De Haan). ç´¯ç§¯æ¦‚ç‡å¯†åº¦å‡½æ•°\\(F\\in\\mathcal{D}_\\gamma\\)å½“ä¸”ä»…å½“å‡½æ•°\\(\\sigma\\)å­˜åœ¨æ—¶ï¼Œå¯¹æ‰€æœ‰\\(x\\in\\mathbb{R}\\)åœ¨\\(1+\\gamma x&gt;0\\)çš„æ¡ä»¶ä¸‹æœ‰ï¼š \\[ \\frac{\\bar{F}(t+\\sigma(t)x)}{\\bar{F}(t)}\\mathop{\\rightarrow}\\limits_{t\\rightarrow\\tau}(1+\\gamma x)^{-\\frac{1}{\\gamma}} \\] ä¸Šå¼å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š \\[ \\bar{F}_t(x)=\\mathbb{P}(X-t&gt;x|X&gt;t)\\mathop{\\sim}\\limits_{t\\rightarrow\\tau}\\left(1+\\frac{\\gamma x}{\\sigma(t)}\\right)^{-\\frac{1}{\\gamma}} \\] è¯¥å¼è¡¨æ˜\\(X\\)è¶…è¿‡é˜ˆå€¼\\(t\\)çš„æ¦‚ç‡ï¼ˆå†™ä¸º\\(X-t\\)ï¼‰æœä»Generalized Pareto Distribution (GPD)ï¼Œå‚æ•°ä¸º\\(\\gamma\\)å’Œ\\(\\sigma\\)ã€‚POTä¸»è¦æ˜¯æ‹ŸåˆGPDè€Œä¸æ˜¯EVTåˆ†å¸ƒã€‚ å¦‚æœæˆ‘ä»¬è¦ä¼°è®¡å‚æ•°\\(\\hat{\\gamma}\\)å’Œ\\(\\hat{\\sigma}\\)ï¼Œåˆ†ä½æ•°å¯ä»¥é€šè¿‡ä¸‹å¼è®¡ç®—å¾—åˆ°ï¼š \\[ z_q\\simeq t+\\frac{\\hat{\\sigma}}{\\hat{\\gamma}}\\left(\\left(\\frac{qn}{N_t}\\right)^{-\\hat{\\gamma}}-1\\right) \\] å…¶ä¸­\\(t\\)æ˜¯ä¸€ä¸ªâ€œå¾ˆé«˜â€çš„é˜ˆå€¼ï¼Œ\\(q\\)æ˜¯ç»™å®šçš„æ¦‚ç‡å€¼ï¼Œ\\(n\\)æ˜¯æ‰€æœ‰è§‚æµ‹æ ·æœ¬çš„æ•°é‡ï¼Œ\\(N_t\\)æ˜¯peaksçš„æ•°é‡ï¼Œå³\\(X_i&gt;t\\)çš„æ•°é‡ã€‚ä¸ºäº†è¿›è¡Œé«˜æ•ˆçš„å‚æ•°ä¼°è®¡ï¼Œæ–‡ä¸­ä½¿ç”¨äº†æå¤§ä¼¼ç„¶ä¼°è®¡ã€‚ Maximum Likelihood Estimation è®¾\\(X_1,\\cdots,X_n\\)ä¸ºç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œæ¦‚ç‡å¯†åº¦å‡½æ•°è®°ä¸º\\(f_\\theta\\)ï¼Œ\\(\\theta\\)ä¸ºåˆ†å¸ƒä¸­çš„å‚æ•°ï¼Œé‚£ä¹ˆä¼¼ç„¶å‡½æ•°å¯ä»¥å†™ä¸ºï¼š \\[ \\mathcal{L}(X_1,\\cdots,X_n;\\theta)=\\prod\\limits_{i=1}^n f_\\theta(X_i) \\] åœ¨æå¤§ä¼¼ç„¶ä¼°è®¡ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°åˆé€‚çš„å‚æ•°ä½¿å¾—ä¼¼ç„¶å‡½æ•°æœ€å¤§åŒ–ã€‚åœ¨æˆ‘ä»¬çš„é—®é¢˜ä¸­ï¼Œä¼¼ç„¶å‡½æ•°å¦‚ä¸‹ï¼š \\[ \\log\\mathcal{L}(\\gamma,\\sigma)=-N_t\\log\\sigma-\\left(1+\\frac{1}{\\gamma}\\right)\\sum\\limits_{i=1}^{N_t}\\log\\left(1+\\frac{\\gamma}{\\sigma}Y_i\\right) \\] å…¶ä¸­\\(Y_i&gt;0\\)è¡¨ç¤º\\(X_i\\)è¶…è¿‡é˜ˆå€¼\\(t\\)çš„éƒ¨åˆ†ã€‚ æ–‡ä¸­ä½¿ç”¨äº†Grimshaw's Trickæ¥å°†å«ä¸¤ä¸ªå‚æ•°çš„ä¼˜åŒ–é—®é¢˜è½¬æ¢ä¸ºåªå«ä¸€ä¸ªå‚æ•°çš„ä¼˜åŒ–é—®é¢˜ã€‚è®°\\(\\ell(\\gamma,\\sigma)=\\log\\mathcal{L}(\\gamma,\\sigma)\\)ï¼Œå¯¹äºæ‰€æœ‰æå€¼æ¥è¯´æœ‰\\(\\nabla \\ell(\\gamma, \\sigma)=0\\)ã€‚Grimshaw's Trickè¡¨æ˜å¯¹äºæ»¡è¶³\\(\\nabla \\ell(\\gamma, \\sigma)=0\\)çš„ä¸€å¯¹\\((\\gamma^*,\\sigma^*)\\)ï¼Œ\\(x^*=\\frac{\\gamma^*}{\\sigma^*}\\)ä¸ºç­‰å¼\\(u(X)v(X)=1\\)çš„è§£ï¼Œå…¶ä¸­ï¼š \\[ \\begin{align} u(x)&amp;=\\frac{1}{N_t}\\sum\\limits_{i=1}^{N_t}\\frac{1}{1+xY_i}\\\\ v(x)&amp;=1+\\frac{1}{N_t}\\sum\\limits_{i=1}^{N_t}\\log(1+xY_i) \\end{align} \\] åœ¨æ‰¾åˆ°æ»¡è¶³è¯¥ç­‰å¼çš„è§£\\(x^*\\)åï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°\\(\\gamma^*=v(x^*)-1\\)å’Œ\\(\\sigma^*=\\gamma^*/x^*\\)ï¼Œäºæ˜¯é—®é¢˜å°±å˜æˆäº†å¦‚ä½•å¯»æ‰¾æ–¹ç¨‹çš„æ‰€æœ‰æ ¹ã€‚ å› ä¸º\\(\\log\\)çš„å­˜åœ¨ï¼Œæ‰€ä»¥æœ‰\\(1+xY_i&gt;0\\)ã€‚è€Œ\\(Y_i\\)æ˜¯æ­£æ•°ï¼Œæ‰€ä»¥\\(x^*\\)çš„èŒƒå›´ä¸€å®šåœ¨\\(\\left(-\\frac{1}{Y^M},+\\infty\\right)\\)ï¼Œå…¶ä¸­\\(Y^M=\\max Y_i\\)ã€‚ Grimshawï¼ˆä½œè€…å‚è€ƒçš„ä¸€ç¯‡è®ºæ–‡ï¼‰è¿˜ç»™å‡ºäº†ä¸€ä¸ªä¸Šç•Œï¼š \\[ x^*_{\\text{max}}=2\\frac{\\bar{Y}-Y^m}{(Y^m)^2} \\] å…¶ä¸­\\(Y^m=\\min Y_i\\)ï¼Œ\\(\\bar{Y}\\)ä¸º\\(Y_i\\)çš„å‡å€¼ã€‚è¯¦ç»†çš„ä¼˜åŒ–æ–¹æ³•ä¼šåœ¨ä¸‹æ–‡è®¨è®ºã€‚ èƒŒæ™¯éƒ¨åˆ†åˆ°æ­¤ç»“æŸï¼Œæ¥ä¸‹æ¥çš„éƒ¨åˆ†å°±æ˜¯ä½œè€…æå‡ºçš„æ–°æ–¹æ³•ã€‚ Methodology Extreme Value Theoryç»™å‡ºäº†åœ¨å¯¹åŸå§‹åˆ†å¸ƒæœªçŸ¥çš„æƒ…å†µä¸‹ä¼°è®¡ä½¿å¾—\\(\\mathbb{P}(X&gt;z_q)&lt;q\\)çš„\\(z_q\\)çš„æ–¹æ³•ã€‚ æœ¬æ–‡æ®æ­¤æå‡ºäº†æ—¶é—´åºåˆ—æµçš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚é¦–å…ˆæ ¹æ®å·²çŸ¥çš„è§‚æµ‹å€¼\\(X_1,\\cdots,X_n\\)å¾—åˆ°é˜ˆå€¼\\(z_q\\)ï¼Œç„¶åæ ¹æ®æ•°æ®çš„ç‰¹æ€§è¿ç”¨ä¸¤ç§ä¸åŒæ–¹æ³•æ¥æ›´æ–°\\(z_q\\)ã€‚å¯¹äºå¹³ç¨³æ—¶é—´åºåˆ—ï¼Œä½¿ç”¨SPOTï¼›å¯¹äºéå¹³ç¨³æ—¶é—´åºåˆ—ï¼Œä½¿ç”¨DSPOTã€‚ Initialization Step åœ¨è¿›è¡Œå¼‚å¸¸æ£€æµ‹ä¹‹å‰ï¼Œéœ€è¦æ ¹æ®å·²æœ‰çš„è§‚æµ‹æ•°æ®è¿›è¡Œ\\(z_q\\)çš„ä¼°è®¡ã€‚ç»™å®š\\(n\\)ä¸ªè§‚æµ‹å€¼\\(X_1,\\cdots,X_n\\)å’Œä¸€ä¸ªå›ºå®šçš„æ¦‚ç‡å€¼\\(q\\)ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¼°è®¡é˜ˆå€¼\\(z_q\\)ä½¿å¾—\\(\\mathbb{P}(X&gt;z_q)&lt;q\\)ã€‚å…¶ä¸»è¦æµç¨‹æ˜¯é¦–å…ˆè®¾å®šä¸€ä¸ªè¾ƒå¤§çš„é˜ˆå€¼\\(t\\)ï¼Œç„¶åé€šè¿‡æ‹ŸåˆGPDåˆ†å¸ƒæ¥è®¡ç®—\\(z_q\\)ã€‚è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ç®—æ³•æµç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š \\(Y_t\\)ä»£è¡¨å¤§äº\\(t\\)çš„è§‚æµ‹å€¼çš„é›†åˆï¼ŒGPDåˆ†å¸ƒçš„æ‹Ÿåˆä½¿ç”¨äº†å‰æ–‡æåˆ°çš„Grimshaw's Trickã€‚ Finding Anomalies in a Stream é€šè¿‡Initialization Stepä½¿ç”¨POTç®—æ³•å¾—åˆ°çš„\\(z_q\\)ï¼Œæˆ‘ä»¬å®šä¹‰å…¶ä¸º&quot;Normality Bound&quot;ï¼Œç”¨äºåé¢çš„æ£€æµ‹ã€‚åœ¨åé¢çš„æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬ä¼šæ ¹æ®æ–°å¾—åˆ°çš„è§‚æµ‹å€¼æ¥æ›´æ–°\\(z_q\\)ã€‚ Stationary Case æˆ‘ä»¬é¦–å…ˆæ¥è®¨è®ºæ—¶é—´åºåˆ—æ²¡æœ‰æ—¶é—´ä¾èµ–æ€§çš„æƒ…å†µï¼ˆ\\(X_1,\\cdots,X_n\\)ä¹‹é—´ç‹¬ç«‹åŒåˆ†å¸ƒï¼‰ã€‚é€šè¿‡POTç®—æ³•å¯¹æ‰€æœ‰è§‚æµ‹å€¼å¾—åˆ°\\(z_q\\)ä¹‹åï¼ŒStreaming POT (SPOT) ç®—æ³•ä¼šæ£€æŸ¥\\(X_n\\)ä¹‹åçš„å€¼ï¼ˆæ•°æ®æµåœºæ™¯ï¼Œ\\(X_1,\\cdots,X_n\\)æ˜¯å†å²æ•°æ®ï¼Œè¿˜ä¼šæœ‰æ–°çš„æ•°æ®è¿›æ¥ï¼‰ï¼Œå¦‚æœå¤§äº\\(z_q\\)ï¼Œåˆ™å°†\\(X_i\\)åŠ å…¥å¼‚å¸¸ç‚¹é›†åˆä¸­ï¼›å¦‚æœå¤§äº\\(t\\)ä½†å°äº\\(z_q\\)ï¼Œåˆ™å°†\\(X_i\\)åŠ å…¥è§‚æµ‹å€¼é›†åˆä¸­ï¼Œæ›´æ–°\\(z_q\\)ï¼›å…¶ä»–æƒ…å†µæˆ‘ä»¬\\(X_i\\)æ˜¯æ­£å¸¸æƒ…å†µã€‚ç®—æ³•æµç¨‹å›¾å¦‚ä¸‹ï¼š Drifting Case SPOTç®—æ³•åªé€‚ç”¨äºå¹³ç¨³åˆ†å¸ƒçš„æƒ…å†µï¼Œä½†åœ¨ç°å®ç”Ÿæ´»ä¸­è¿™æ ·çš„å‡è®¾è¿‡å¼ºäº†ã€‚äºæ˜¯ä½œè€…æå‡ºäº†èƒ½å¤„ç†æ—¶é—´ä¾èµ–æ€§çš„Streaming POT with Drift (DSPOT) ç®—æ³•ã€‚ åœ¨DSPOTä¸­ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨\\(X_i\\)çš„ç»å¯¹å€¼ï¼Œè€Œæ˜¯ç”¨ç›¸å¯¹å€¼\\(X^\\prime_i=X_i-M_i\\)ï¼Œå…¶ä¸­\\(M_i\\)æ˜¯\\(i\\)æ—¶åˆ»çš„å±€éƒ¨ç‰¹å¾ï¼Œå¦‚Figure 4æ‰€ç¤ºã€‚æœ€ç®€å•çš„å®ç°æ˜¯ä½¿ç”¨å±€éƒ¨å‡å€¼ï¼Œå³\\(M_i=(1/d)\\cdot\\sum\\limits_{k=1}^d X_{i-k}^*\\)ï¼Œ\\(X_{i-1}^*,\\cdots,X_{i-d}^*\\)æ˜¯é•¿åº¦ä¸º\\(d\\)çš„çª—å£ã€‚æˆ‘ä»¬å‡è®¾\\(X^\\prime_i\\)æœä»å¹³ç¨³åˆ†å¸ƒçš„å‡è®¾ã€‚ ç®—æ³•æµç¨‹å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š Numerical Optimization ç°åœ¨å‰©ä¸‹çš„é—®é¢˜å°±æ˜¯ä¼˜åŒ–äº†ï¼Œå‰æ–‡å·²ç»æåˆ°å¯¹GPDçš„æ‹Ÿåˆå·²ç»è¢«ä¼˜åŒ–æˆä¸€ä¸ªå‚æ•°çš„ä¼˜åŒ–é—®é¢˜ï¼Œä¸‹é¢å°†ä¼šè¯¦ç»†è®¨è®ºä¼˜åŒ–ç®—æ³•ã€‚ Reduction of the Optimal Parameters Search å‰æ–‡å·²ç»å¾—åˆ°äº†ä¸€ä¸ªåˆæ­¥çš„\\(x^*\\)çš„Boundï¼Œå³\\(x^*&gt;-\\frac{1}{Y^M}\\)å’Œ\\(x^*\\leq 2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\)ï¼Œä¸‹é¢å°†ç»™å‡ºä¸€ä¸ªæ›´ä¸¥æ ¼çš„Boundã€‚ PROPOSITION: å¦‚æœ\\(x^*\\)æ˜¯\\(u(x)v(x)=1\\)çš„è§£ï¼Œé‚£ä¹ˆï¼š \\[ x^*\\leq 0 \\text{ or } x^*\\geq 2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m} \\] è¯æ˜è§è®ºæ–‡åŸæ–‡ã€‚ è¿™æ ·\\(x^*\\)çš„èŒƒå›´å°±è¿›ä¸€æ­¥ç¼©å°äº†ï¼Œäºæ˜¯æœ‰\\(u(x)v(X)=1\\)çš„è§£\\(x^*\\)åœ¨ä»¥ä¸‹èŒƒå›´ä¹‹å†…ï¼š \\[ \\left(-\\frac{1}{Y^M},0\\right]\\text{ and }\\left[2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m},2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\right] \\] How Can We Maximize the Likelihood Function? æ¥ä¸‹æ¥æ˜¯ä¼˜åŒ–çš„å…·ä½“å®ç°é—®é¢˜ã€‚æ–‡ä¸­é¦–å…ˆè®¾å®šäº†ä¸€ä¸ªå¾ˆå°çš„å€¼\\(\\epsilon&gt;0\\space(\\sim 10^{-8})\\)ï¼Œç„¶ååœ¨ä¸‹é¢çš„èŒƒå›´å†…å¯»æ‰¾å‡½æ•°\\(w:x\\mapsto u(x)v(x)-1\\)çš„æ ¹ï¼š \\[ \\left[-\\frac{1}{Y^M}+\\epsilon,-\\epsilon\\right]\\text{ and }\\left[2\\frac{\\bar{Y}-Y^m}{\\bar{Y}Y^m},2\\frac{\\bar{Y}-Y^m}{(Y^m)^2}\\right] \\] ä½œè€…æ²¡æœ‰ä½¿ç”¨ç°æœ‰çš„å¯»æ‰¾å‡½æ•°æ ¹çš„ç®—æ³•ï¼Œè€Œæ˜¯è½¬æ¢ä¸ºå¦‚ä¸‹ä¼˜åŒ–é—®é¢˜ï¼š \\[ \\min\\limits_{x_1,\\cdots,x_k\\in I}\\sum\\limits_{i=1}^k w(x_k)^2 \\] å…¶ä¸­\\(I\\)å°±æ˜¯\\(x^*\\)çš„Boundã€‚è¯¥é—®é¢˜æ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„ä¼˜åŒ–é—®é¢˜ï¼Œå¯ä»¥è¢«å¾ˆå¤šæˆç†Ÿçš„ç®—æ³•æ‰€è§£å†³ã€‚ Initial Threshold åœ¨ç®—æ³•çš„Initialization Stepï¼Œéœ€è¦äº‹å…ˆè®¾å®šä¸€ä¸ªé˜ˆå€¼\\(t\\)ï¼Œå¦‚æœè®¾å®šçš„å¤ªå¤§ï¼Œé‚£ä¹ˆ\\(Y_t\\)çš„æ•°é‡å°±ä¼šå¾ˆå°‘ã€‚ä½œè€…ç»™å‡ºçš„å»ºè®®æ˜¯ä¿è¯\\(t&lt;z_q\\)ï¼Œå³\\(t\\)å¯¹åº”çš„æ¦‚ç‡å€¼åº”è¯¥å°äº\\(1-q\\)ã€‚ Experiments åœ¨å®éªŒéƒ¨åˆ†ï¼Œä½œè€…åœ¨åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¸Šè¯•éªŒäº†SPOTç®—æ³•å’ŒDSPOTç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚ (D)SPOT Reliability ä½œè€…é¦–å…ˆåœ¨åˆæˆæ•°æ®ä¸ŠéªŒè¯SPOTçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“åšæ³•æ˜¯ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒç”Ÿæˆæ•°æ®ï¼ˆé«˜æ–¯åˆ†å¸ƒçš„åˆ†ä½æ•°èƒ½å¤Ÿç›´æ¥è®¡ç®—ï¼‰ï¼Œç„¶åå°†SPOTå¾—å‡ºçš„\\(z_q\\)å’Œç†è®ºå€¼è¿›è¡Œå¯¹æ¯”ã€‚è¯¯å·®å®šä¹‰å¦‚ä¸‹ï¼š \\[ \\text{error rate}=\\left|\\frac{z^{\\text{SPOT}}-z^{\\text{th}}}{z^{\\text{th}}}\\right| \\] ä¸‹å›¾æ˜¯é‡‡ç”¨ä¸åŒæ•°é‡è§‚æµ‹å€¼çš„ç»“æœï¼š Finding Anomalies with SPOT åœ¨è¿™ä¸€èŠ‚ä½œè€…åœ¨çœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒä»¥éªŒè¯SPOTç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœå¦‚ä¸‹å›¾ï¼š åœ¨æ–‡ä¸­ä½œè€…è¯´ç®—æ³•çš„True Positiveè¾¾åˆ°äº†\\(86\\%\\)ï¼ŒFalse Positiveå°äº\\(4\\%\\)ã€‚ Finding Anomalies with DSPOT åœ¨è¿™ä¸€èŠ‚ä½œè€…ä½¿ç”¨DSPOTåœ¨çœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒã€‚çª—å£å¤§å°\\(d=450\\)ï¼Œé¢„è®¾çš„é£é™©æ¦‚ç‡å€¼\\(q=10^{-3}\\)ã€‚ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š åœ¨å›¾ä¸­å¯ä»¥çœ‹å‡ºåœ¨\\(8000\\) Minutesä¹‹åä¸Šç•Œæ˜¾è‘—æé«˜ï¼Œä½œè€…åˆ†æäº†åŸå› ï¼Œè®¤ä¸ºæ˜¯å› ä¸ºè¶…è¿‡é˜ˆå€¼\\(t\\)çš„ç‚¹\\(Y_t\\)çš„å­˜å‚¨æ˜¯å…¨å±€çš„ï¼Œåœ¨å‰\\(8000\\) Minutesç®—æ³•å­˜å‚¨äº†å¾ˆå¤šè¾ƒé«˜çš„\\(Y_t\\)å€¼ï¼Œè€Œåœ¨\\(8000\\) Minutesä¹‹åï¼ŒçœŸå®æ•°æ®çš„è¶‹åŠ¿å¼€å§‹ä¸‹é™ï¼Œä½†ç®—æ³•ä»æ˜¯æ ¹æ®å…¨å±€çš„\\(Y_t\\)æ¥è¿›è¡Œ\\(z_q\\)çš„è®¡ç®—ï¼ˆè¿™ä¸€æ®µæ²¡æœ‰ç‰¹åˆ«æ˜ç™½ï¼‰ã€‚ä½œè€…ç»™å‡ºçš„ä¿®æ­£æ–¹æ³•æ˜¯åªä¿å­˜å›ºå®šæ•°é‡çš„Peaksã€‚ ä¸‹å›¾æ˜¯ä½œè€…åœ¨è‚¡ç¥¨æ•°æ®ä¸Šå¾—åˆ°çš„å®éªŒç»“æœï¼š Performances ä½œè€…è¿˜éªŒè¯äº†ç®—æ³•çš„æ—¶é—´æ•ˆç‡ã€‚ è¡¨ä¸­Tä»£è¡¨çš„æ˜¯æ¯ä¸ªIterationçš„æ—¶é—´ï¼ŒMä»£è¡¨çš„æ˜¯Peaksçš„æ¯”ä¾‹ï¼Œ&quot;bi-&quot;å‰ç¼€ä»£è¡¨çš„æ˜¯åŒæ—¶è®¡ç®—ä¸Šç•Œå’Œä¸‹ç•Œã€‚","link":"/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/"},{"title":"Discovering Physical Concepts with Neural Networks","text":"Introduction å¦‚é¢˜ç›®æ‰€ç¤ºï¼Œæœ¬æ–‡çš„ç›®çš„æ˜¯åˆ©ç”¨ç¥ç»ç½‘ç»œæ¥å‘æ˜ç‰©ç†æ¦‚å¿µã€‚å…¶æ€è·¯æ˜¯ä»å®éªŒæ•°æ®å­¦åˆ°è¡¨ç¤ºï¼Œç„¶åç”¨å­¦åˆ°çš„è¡¨ç¤ºæ¥å›ç­”ç‰©ç†é—®é¢˜ï¼Œç”±æ­¤ç‰©ç†æ¦‚å¿µå¯ä»¥ä»å­¦åˆ°çš„è¡¨ç¤ºæ¥æå–å‡ºã€‚ä½œè€…è¿›è¡Œäº†4ä¸ªå®éªŒï¼š åœ¨é˜»å°¼æŒ¯åŠ¨å®éªŒä¸­ï¼Œæ¨¡å‹å­¦åˆ°äº†ç›¸å…³çš„ç‰©ç†å‚æ•°ï¼› åœ¨è§’åŠ¨é‡å®ˆæ’å®éªŒä¸­ï¼Œæ¨¡å‹é¢„æµ‹äº†è´¨ç‚¹çš„è¿åŠ¨ï¼› ç»™å®šé‡å­ç³»ç»Ÿçš„è§‚æµ‹æ•°æ®ï¼Œæ¨¡å‹æ­£ç¡®çš„è¯†åˆ«å‡ºäº†é‡å­çŠ¶æ€çš„è‡ªç”±åº¦ï¼› ç»™å®šä»åœ°çƒè§‚æµ‹çš„å¤ªé˜³å’Œç«æ˜Ÿçš„ä½ç½®æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ¨¡å‹å‘ç°äº†æ—¥å¿ƒè¯´æ¨¡å‹ã€‚ Preliminaries ä½œè€…åœ¨é™„å½•ä¸­å¯¹ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†è¿›è¡Œäº†ä»‹ç»ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ï¼Œåªæˆªå–äº†ä¸€äº›ç›¸å¯¹å‰æ²¿çš„å†…å®¹ã€‚ Variational Autoencoders æœ¬æ–‡ç”¨åˆ°çš„æ¨¡å‹åŸºç¡€æ˜¯VAEï¼š Representation Learning Representation learningçš„ä¸»è¦ç›®æ ‡æ˜¯å°†æ•°æ®æ˜ å°„åˆ°ä¸€ä¸ªéšå‘é‡ (encoder)ï¼Œä¸ºäº†ä¿è¯éšå‘é‡åŒ…å«äº†æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Œ é‚£ä¹ˆåº”è¯¥èƒ½å¤Ÿä»éšå‘é‡è¿˜åŸåŸæ•°æ® (decoder)ã€‚ä¼ ç»Ÿçš„Autoencoderæ˜¯è¿™ä¸ªæ€æƒ³çš„æœ€ç®€å•å®ç°ï¼Œè€ŒVAEåˆ™å°†AEå’ŒVariational Inferenceç»“åˆäº†èµ·æ¥ï¼Œæ˜¯ä¸€ç§ç»å…¸çš„ç”Ÿæˆå¼æ¨¡å‹ã€‚ç°åœ¨å¾ˆå¤šç ”ç©¶å…³æ³¨Disentangled Representation Learningï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å¸Œæœ›æ¨¡å‹èƒ½å¤Ÿæ— ç›‘ç£åœ°å­¦ä¹ æ•°æ®ï¼Œä»ä¸­å­¦åˆ°æœ‰æ„ä¹‰çš„è¡¨ç¤ºã€‚ \\(\\boldsymbol \\beta\\)-VAE \\(\\beta\\)-VAEæ˜¯ä¸€ç§ç‰¹æ®Šçš„VAEï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç»å…¸çš„Disentangled Representation Learningæ¨¡å‹ï¼Œå®ƒå’ŒVAEä¸»è¦çš„åŒºåˆ«æ˜¯å¯¹KLæ•£åº¦ä¸€é¡¹åŠ ä¸Šäº†æƒé‡\\(\\beta\\)è¿›è¡Œè°ƒèŠ‚ï¼š \\[ C_\\beta(x)=-\\left[\\mathbb{E}_{z\\sim p_\\phi(z|x)}\\log p_\\theta(x|z)\\right] + \\beta D_\\text{KL}\\left[p_\\phi(z|x)\\parallel h(z)\\right] \\] å¦‚æœå‡è®¾\\(p_\\phi(z|x)=\\mathcal{N}(\\mu,\\sigma)\\)ï¼Œé‚£ä¹ˆæŸå¤±å‡½æ•°å¯ä»¥è¿›è¡Œç®€åŒ–ï¼š \\[ C_\\beta(x)=\\parallel \\hat{x} - x \\parallel^2_2-\\frac{\\beta}{2}\\left(\\sum\\limits_i\\log(\\sigma_i^2)-\\mu_i^2-\\sigma_i^2\\right)+C \\] Network Structure Network Structure: SciNet æ¨¡ä»¿ç‰©ç†å­¦å®¶å»ºæ¨¡ç‰©ç†é—®é¢˜çš„è¿‡ç¨‹ï¼Œä½œè€…æå‡ºäº†SciNetï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š ç‰©ç†å­¦å®¶åœ¨å»ºæ¨¡ç‰©ç†é—®é¢˜çš„æ—¶å€™ï¼Œå¾€å¾€æ˜¯ä»ä¸€äº›å®éªŒæ•°æ®å‡ºå‘ï¼Œæ ¹æ®ç‰©ç†å¸¸è¯†æå–æ›´åŠ ç²¾ç»ƒçš„è¡¨ç¤ºï¼Œç„¶åç”¨å­¦åˆ°çš„è¡¨ç¤ºæ¥å›ç­”ç‰©ç†é—®é¢˜ã€‚ å¯¹äºå•çº¯çš„è¾“å…¥è¾“å‡ºé—®é¢˜ï¼ŒSciNetå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œ\\(F:\\mathcal{O}\\times\\mathcal{Q}\\rightarrow\\mathcal{A}\\)ã€‚\\(\\mathcal{O}\\)æ˜¯å¯èƒ½çš„å®éªŒæ•°æ®é›†åˆï¼Œ\\(\\mathcal{Q}\\)æ˜¯å¯èƒ½çš„é—®é¢˜é›†åˆï¼Œ\\(\\mathcal{A}\\)æ˜¯å¯èƒ½çš„ç­”æ¡ˆé›†åˆã€‚å¯ä»¥å°†å…¶åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šç¼–ç è¿‡ç¨‹\\(E:\\mathcal{O}\\rightarrow\\mathcal{R}\\)ä»å®éªŒæ•°æ®å­¦åˆ°è¡¨ç¤ºï¼Œè§£ç è¿‡ç¨‹\\(D:\\mathcal{R}\\times \\mathcal{Q}\\rightarrow \\mathcal{A}\\)æ ¹æ®ç»™å®šçš„é—®é¢˜ä»è¡¨ç¤ºæ¥å›ç­”é—®é¢˜ã€‚ç”±æ­¤ï¼Œ\\(F(o,q)=D(E(o),q)\\)ã€‚åœ¨å®ç°æ–¹é¢ï¼ŒSciNeté‡‡ç”¨çš„æ˜¯å…¨è¿æ¥ç½‘ç»œã€‚ Training and Testing SciNet ç”¨æ¥è®­ç»ƒçš„æ•°æ®å½¢å¼ä¸º\\((o,q,a_{cor}(o,q))\\)ï¼Œè§‚æµ‹\\(o\\)å’Œé—®é¢˜\\(q\\)åˆ†åˆ«ä»è§‚æµ‹é›†\\(\\mathcal{O}\\)å’Œé—®é¢˜é›†\\(\\mathcal{Q}\\)é€‰å‡ºï¼Œ\\(a_{cor}(o,q)\\)ä¸ºå¯¹åº”çš„æ­£ç¡®ç­”æ¡ˆã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å‡†ç¡®åº¦å°½é‡é«˜ï¼Œå¹¶ä¸”å­¦åˆ°minimal uncorrelated representationsã€‚ä¸ºæ­¤ï¼Œä½œè€…é‡‡ç”¨disentangling variational autoencoderä½œä¸ºæ¨¡å‹ã€‚ Results åœ¨æ–‡ä¸­ï¼Œä½œè€…è¿›è¡Œäº†4ä¸ªå®éªŒæ¥éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ Damped Pendulum é˜»å°¼æŒ¯åŠ¨å®éªŒï¼š ä»»åŠ¡ï¼šé¢„æµ‹ä¸€ç»´é˜»å°¼æŒ¯åŠ¨åœ¨ä¸åŒæ—¶é—´çš„ä½ç½®ã€‚ ç‰©ç†æ¨¡å‹ï¼š\\(-kx-b\\dot{x}=m\\ddot{x}\\)ï¼Œ\\(k\\)ä¸ºå¼¹æ€§æ¨¡é‡ï¼Œ\\(b\\)ä¸ºé˜»å°¼ç³»æ•°ï¼Œé€šè§£ä¸º\\(x(t)=A_0e^{-\\frac{b}{2m}t}\\cos(\\omega t+\\delta_0), \\space \\omega=\\sqrt{\\frac{k}{m}}\\sqrt{1-\\frac{b^2}{4mk}}\\) è§‚æµ‹æ•°æ®ï¼šä½ç½®æ—¶é—´åºåˆ—æ•°æ®\\(o=[x(t_i)]_{i\\in\\{1,\\cdots,50\\}}\\in\\mathbb{R}^{50}\\)ï¼Œæ—¶é—´é—´éš”ç›¸ç­‰ï¼Œè´¨é‡\\(m=1\\text{kg}\\)ï¼ŒæŒ¯å¹…\\(A_0=1\\text{m}\\)ï¼Œç›¸ä½\\(\\delta_0=0\\)ï¼Œå¼¹æ€§æ¨¡é‡\\(k\\in[5,10]\\text{kg}/\\text{s}^2\\)ï¼Œé˜»å°¼ç³»æ•°\\(b\\in[0.5,1]\\text{kg}/\\text{s}\\)ã€‚ é—®é¢˜ï¼šé¢„æµ‹\\(q=t_\\text{pred}\\in\\mathbb{R}\\) éšå˜é‡å¤§å°è®¾ç½®ä¸º3ï¼Œç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š (b)ä¸­çš„ä¸‰å¹…å›¾åˆ†åˆ«æ˜¯å­¦åˆ°çš„ä¸‰ä¸ªéšå˜é‡å’Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„å‚æ•°\\(k\\)å’Œ\\(b\\)çš„å…³ç³»å›¾ã€‚ç¬¬ä¸€å¹…å›¾ä¸­å˜é‡\\(1\\)ä¸\\(b\\)å‡ ä¹å®Œå…¨çº¿æ€§ç›¸å…³ï¼Œä¸\\(k\\)åŸºäºçº¿æ€§æ— å…³ï¼Œå˜é‡\\(2\\)åªå’Œ\\(k\\)ç›¸å…³ã€‚å˜é‡\\(3\\)å‡ ä¹ä¸ºä¸€ä¸ªå¸¸æ•°ï¼Œæ•…ä¸æä¾›é¢å¤–çš„ä¿¡æ¯ã€‚ç”±æ­¤ä½œè€…è®¤ä¸ºSciNetå­¦åˆ°äº†æˆ‘ä»¬å…³å¿ƒçš„ä¸¤ä¸ªå‚æ•°çš„çŸ¥è¯†ã€‚ Conservation of Angular Momentum è§’åŠ¨é‡å®ˆæ’å®éªŒï¼š ä»»åŠ¡ï¼šé¢„æµ‹ä¸€ä¸ªç”±é•¿åº¦ä¸º\\(r\\)çš„ç»³å­æ†ç»‘ç€çš„æ—‹è½¬è´¨ç‚¹åœ¨ä½ç½®\\((0,r)\\)ç»ä¸€ä¸ªè‡ªç”±è´¨ç‚¹æ’å‡»åçš„ä½ç½® ç‰©ç†æ¨¡å‹ï¼šç»™å®šæ’å‡»ä¹‹å‰çš„è§’åŠ¨é‡ï¼Œè‡ªç”±è´¨ç‚¹æ’å‡»ä¹‹åçš„é€Ÿåº¦ï¼Œæ—‹è½¬è´¨ç‚¹åœ¨æ’å‡»ä¹‹ååœ¨æ—¶é—´\\(t_\\text{pred}^\\prime\\)çš„ä½ç½®å¯ä»¥ç”±è§’åŠ¨é‡å®ˆæ’å®šå¾‹ç»™å‡ºï¼š \\[ J=m_\\text{rot}r^2\\omega-rm_\\text{free}(\\mathbf{v}_\\text{free})_x=m_\\text{rot}r^2\\omega^\\prime-rm_\\text{free}(\\mathbf{v}^\\prime_\\text{free})_x=J^\\prime \\] è§‚æµ‹æ•°æ®ï¼šåœ¨æ’å‡»ä¹‹å‰ä¸¤ä¸ªè´¨ç‚¹çš„ä½ç½®æ•°æ®\\(o=[(t_i^\\text{rot},q_\\text{rot}(t_i^\\text{rot})),(t_i^\\text{free},q_\\text{free}(t_i^\\text{free}))]_{i\\in\\{1,\\cdots,5\\}}\\)ï¼Œè´¨é‡ä¸ºå›ºå®šå€¼ï¼ŒåŠå¾„\\(r\\)ä¹Ÿä¸ºå›ºå®šå€¼ã€‚æ•°æ®æ·»åŠ é«˜æ–¯å™ªå£°ã€‚ é—®é¢˜ï¼šé¢„æµ‹æ’å‡»ä¹‹åè‡ªç”±è´¨ç‚¹åœ¨æ—¶é—´\\(t_\\text{pred}^\\prime\\)çš„ä½ç½® å®éªŒå®¤æ„å›¾å¦‚ä¸‹ï¼š å®éªŒç»“æœè¡¨æ˜SciNetèƒ½å¤Ÿæ­£ç¡®é¢„æµ‹è´¨ç‚¹æ’å‡»ä¹‹åçš„ä½ç½®ï¼ŒåŒæ—¶å¯¹å™ªéŸ³é²æ£’ã€‚æ ¹æ®(b)ï¼Œéšå˜é‡å’Œè§’åŠ¨é‡å­˜åœ¨çº¿æ€§ç›¸å…³å…³ç³»ï¼Œä½œè€…è®¤ä¸ºSciNetå­¦åˆ°äº†å®ˆæ’çš„åŠ¨é‡è¿™ä¸€æ¦‚å¿µã€‚ Representation of Qubits é‡å­æ¯”ç‰¹å®éªŒï¼š ä»»åŠ¡ï¼šé¢„æµ‹åœ¨\\(n=1,2\\)çš„çº¯\\(n\\)é‡å­ä½çŠ¶æ€\\(\\psi\\in\\mathbb{C}^{2^n}\\)ä¸‹ä»»ä½•äºŒè¿›åˆ¶æŠ•å½±æµ‹é‡\\(\\omega\\in\\mathbb{C}^{2^n}\\)çš„æµ‹é‡æ¦‚ç‡ã€‚ ç‰©ç†æ¨¡å‹ï¼šåœ¨æ‰§è¡Œæµ‹é‡\\(\\omega\\in\\mathbb{C}^{2^n}\\)çš„çŠ¶æ€\\(\\psi\\in\\mathbb{C}^{2^n}\\)ä¸‹æµ‹é‡0çš„æ¦‚ç‡\\(p(\\omega,\\psi)\\)ç”±\\(p(\\omega,\\psi)=|\\left&lt;\\omega,\\psi\\right&gt;|^2\\)ç»™å®š è§‚æµ‹æ•°æ®ï¼šçŠ¶æ€\\(\\psi: o=[p(\\alpha_i,\\psi)]_{i\\in\\{i,\\cdots,n_1\\}}\\)çš„æ“ä½œå‚æ•°åŒ–ï¼šè¡¨ç¤ºä¸€ç»„å›ºå®šçš„éšæœºäºŒå…ƒå°„å½±æµ‹é‡å€¼\\(\\mathcal{M}_1=\\{\\alpha_1,\\cdots,\\alpha_{n_1}\\}\\)ï¼ˆä¸€ä¸ªé‡å­ä½\\(n_1 = 10\\)ï¼Œä¸¤ä¸ªé‡å­ä½\\(n_1 = 30\\)ï¼‰ é—®é¢˜ï¼šå¯¹äºå›ºå®šçš„ä¸€ç»„éšæœºäºŒå…ƒå°„å½±æµ‹é‡\\(\\mathcal{M}_2=\\{\\beta_1,\\cdots,\\beta_{n_2}\\}\\)ï¼Œæµ‹é‡\\(\\omega:q=[p(\\beta_i,\\omega)]_{i\\in\\{1,\\cdots,n_2\\}}\\)çš„Operationalå‚æ•°åŒ–ï¼ˆä¸€ä¸ªé‡å­ä½\\(n_2 = 10\\)ï¼Œä¸¤ä¸ªé‡å­ä½\\(n_2 = 30\\)ï¼‰ å®éªŒç»“æœå¦‚ä¸‹ï¼š é€šè¿‡å®éªŒå‘ç°ï¼ŒSciNetå¯ä»¥åœ¨ä¸æä¾›å…ˆéªŒç‰©ç†çŸ¥è¯†çš„æ¡ä»¶ä¸‹ç¡®å®šè¡¨è¿°çŠ¶æ€\\(\\psi\\)æœ€å°çš„å‚æ•°æ•°é‡ã€‚åŒæ—¶ï¼ŒSciNetè¿˜èƒ½åˆ†è¾¨tomographically completeå’Œtomographically incompleteã€‚ Heliocentric Model of the Solar System æ—¥å¿ƒè¯´æ¨¡å‹ï¼š é—®é¢˜ï¼šåœ¨ç»™å®šåˆå§‹æ¡ä»¶ä¸‹é¢„æµ‹ç›¸å¯¹ä¸åœ°çƒçš„å¤ªé˜³å’Œç«æ˜Ÿçš„è§’åº¦\\(\\theta_M(t)\\)å’Œ\\(\\theta_S(t)\\) ç‰©ç†æ¨¡å‹ï¼šåœ°çƒå’Œç«æ˜Ÿå›´ç»•å¤ªé˜³ä»¥ä¸€å®šè§’é€Ÿåº¦åšè¿‘ä¼¼åœ†å‘¨è¿åŠ¨ è§‚æµ‹æ•°æ®ï¼šç»™å®šåˆå§‹è§’åº¦ï¼Œéšæœºé€‰æ‹©å‘¨å‘¨æœŸçš„å“¥ç™½å°¼çš„è§‚æµ‹æ•°æ® æ¨¡å‹çš„å®ç°ç¨æœ‰å˜åŒ–ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š è¿™æ ·ï¼Œå¯¹äºä¸åŒæ—¶é—´éƒ½å¯¹åº”ä¸€ä¸ªéšå˜é‡\\(r(t_i)\\)ï¼Œè€Œä¸”éšå˜é‡æ˜¯æ—¶é—´ä¾èµ–çš„ï¼Œå¯¹äºä¸€ä¸ªéšå˜é‡\\(r(t_i)\\)æœ‰ä¸€ä¸ªè§£ç å™¨æ¥è¾“å‡ºç­”æ¡ˆã€‚ å®éªŒç»“æœè¡¨ç¤ºï¼ŒSciNetä¸ä»…æ­£ç¡®é¢„æµ‹äº†å¤ªé˜³å’Œç«æ˜Ÿç›¸å¯¹åœ°çƒçš„è§’åº¦ï¼ŒåŒæ—¶éšå˜é‡æ­ç¤ºäº†ç«æ˜Ÿå’Œåœ°çƒç›¸å¯¹å¤ªé˜³çš„è§’åº¦ã€‚","link":"/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/"}],"tags":[{"name":"Variational Inference","slug":"Variational-Inference","link":"/tags/Variational-Inference/"},{"name":"VAE","slug":"VAE","link":"/tags/VAE/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Time Series","slug":"Time-Series","link":"/tags/Time-Series/"},{"name":"Anomaly Detection","slug":"Anomaly-Detection","link":"/tags/Anomaly-Detection/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"RNN","slug":"RNN","link":"/tags/RNN/"},{"name":"Flow-based Model","slug":"Flow-based-Model","link":"/tags/Flow-based-Model/"},{"name":"Transfer Learning","slug":"Transfer-Learning","link":"/tags/Transfer-Learning/"},{"name":"Spectral","slug":"Spectral","link":"/tags/Spectral/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"}],"categories":[{"name":"Research","slug":"Research","link":"/categories/Research/"},{"name":"Anomaly Detection","slug":"Research/Anomaly-Detection","link":"/categories/Research/Anomaly-Detection/"},{"name":"Tutorial","slug":"Research/Tutorial","link":"/categories/Research/Tutorial/"},{"name":"Technical Notes","slug":"Technical-Notes","link":"/categories/Technical-Notes/"},{"name":"RNN","slug":"Research/RNN","link":"/categories/Research/RNN/"},{"name":"Time Series Imputation","slug":"Research/Time-Series-Imputation","link":"/categories/Research/Time-Series-Imputation/"},{"name":"GAN","slug":"Research/GAN","link":"/categories/Research/GAN/"},{"name":"Misc","slug":"Technical-Notes/Misc","link":"/categories/Technical-Notes/Misc/"},{"name":"Misc","slug":"Research/Misc","link":"/categories/Research/Misc/"}]}