<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hanzawa の 部屋</title>
  
  
  <link href="http://qfxiao.me/atom.xml" rel="self"/>
  
  <link href="http://qfxiao.me/"/>
  <updated>2021-02-28T04:58:08.309Z</updated>
  <id>http://qfxiao.me/</id>
  
  <author>
    <name>Hanzawa</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Unsupervised Feature Learning via Non-Parametric Instance Discrimination</title>
    <link href="http://qfxiao.me/2020/09/23/Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination/"/>
    <id>http://qfxiao.me/2020/09/23/Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination/</id>
    <published>2020-09-23T12:36:57.000Z</published>
    <updated>2021-02-28T04:58:08.309Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文基于样本分类和噪声对比估计提出了一个无监督表示学习算法。下图展示了一个Intuition Example：</p><img src="https://i.loli.net/2020/07/28/AimfJM7gtuDsPGQ.png"  /><p>对于一个有监督的分类器，输入一张图片，作者观察到分类器的Softmax Response中较高的那些类都是在视觉上看起来比较接近的（美洲豹Leopard，美洲虎Jaguar，印度豹Cheetah），也就是说网络捕捉到了类间的视觉相似性，不过这是在有标签的情况下。对于无监督表示学习任务，作者将这个观察推广到了一个极端情况，就是把每一个样本都视作不同的类，然后让分类器来学习样本（类）间的视觉相似性。不过直接这么做会有严重的效率问题，所以作者还利用了Memory Bank机制和噪声对比估计来提高效率。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><p>学习一个嵌入表示函数$\mathbf v=f_\theta(x)$。在表示空间中$d_\theta(x,y)=\parallel f_\theta(x)-f_\theta(y)\parallel$</p><p><img src="https://i.loli.net/2020/07/26/WICKVkhrBu6Mci5.png"></p><h2 id="Non-Parametric-Softmax-Classifier"><a href="#Non-Parametric-Softmax-Classifier" class="headerlink" title="Non-Parametric Softmax Classifier"></a>Non-Parametric Softmax Classifier</h2><h3 id="Parametric-Classifier"><a href="#Parametric-Classifier" class="headerlink" title="Parametric Classifier"></a>Parametric Classifier</h3><p>在经过嵌入表示函数之后，得到表示向量$\mathbf v_i=f_\theta(\mathbf x_i)$。要基于这个向量进行分类，<br>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf w_i^\top\mathbf v)}{\sum_j\exp(\mathbf w_j^\top\mathbf v)}<br>$$</p><h3 id="Non-Parametric-Classifier"><a href="#Non-Parametric-Classifier" class="headerlink" title="Non-Parametric Classifier"></a>Non-Parametric Classifier</h3><p>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf v_i^\top\mathbf v/\tau)}{\sum_j\exp(\mathbf v_j^\top\mathbf v/\tau)}<br>$$</p><p>同时约束$\parallel \mathbf v\parallel=1$</p><p>最后的损失函数为负对数似然损失（negative log-likelihood）：<br>$$<br>J(\theta)=-\sum_{i=1}^n\log P(i|f_\theta(x_i))<br>$$</p><p>到这里，算法的大框架就确定下来了，剩下的就是解决两个效率上的问题。一个是损失函数的计算每次都需要计算整个训练集的表示，同时Softmax函数由于分母对应的项目很多（等于训练集大小）在效率上也有问题。</p><h3 id="Learning-with-A-Memory-Bank"><a href="#Learning-with-A-Memory-Bank" class="headerlink" title="Learning with A Memory Bank"></a>Learning with A Memory Bank</h3><p>这里解决第一个效率问题。要计算损失函数，需要遍历整个训练集获得对应的表示，而在训练的时候是一批一批的数据，每次重新计算表示效率很低。为了解决这个问题，作者引入了缓存机制，即加入一个memory bank $V$，用来保存计算好的表示$\mathbf f_i=f_\theta(x_i)$。一开始$V$采用单位随机向量初始化，之后在训练的时候不断更新$\mathbf f_i\rightarrow \mathbf v_i$。</p><h2 id="Noise-Contrastive-Estimation"><a href="#Noise-Contrastive-Estimation" class="headerlink" title="Noise Contrastive Estimation"></a>Noise Contrastive Estimation</h2><p>第二个效率问题很容易想到使用噪声对比估计（Noise Contrastive Estimation, NCE）来做。NCE主要是将计算复杂的分母作为一个参数来进行优化：<br>$$<br>P(i|\mathbf v)=\frac{\exp(\mathbf v^\top\mathbf f_i/\tau)}{Z_i}<br>$$</p><p>其中$Z_i=\sum_{j=1}^n\exp(\mathbf v^\top_j\mathbf f_i/\tau)$，噪声分布$P_n=1/n$，如果噪声样本数量是真实数据的$m$倍，那么随意给定一个样本，其属于真实样本的后验概率为：<br>$$<br>h(i,\mathbf v)=P(D=1|i,\mathbf v)=\frac{P(i|\mathbf v)}{P(i|\mathbf v)+mP_n(i)}=\sigma\left(s(\mathbf v)-\log {m P_n(i)}\right)<br>$$<br>其中$\Delta s=s(\mathbf v)-\log [m P_n(i)]$。这里的真实数据分布$P_d$为。NCE的损失函数就是要最大化$h(i,\mathbf v)$，最小化$h(i,\mathbf v^\prime)$<br>$$<br>J_{NCE}(\theta)=-E_{P_d}[\log h(i,\mathbf v)]-m\cdot E_{P_n}[\log(1-h(i,\mathbf v^\prime))]<br>$$<br>为了计算$Z_i$<br>$$<br>Z\simeq Z_i\simeq nE_j[\exp(\mathbf v_j^\top\mathbf f_i/\tau)]=\frac{n}{m}\sum_{k=1}^m\exp(\mathbf v_{j_k}^\top\mathbf f_i/\tau)<br>$$</p><h2 id="Proximal-Regularization"><a href="#Proximal-Regularization" class="headerlink" title="Proximal Regularization"></a>Proximal Regularization</h2><p>每个类别只有一个样本<br>$$<br>-\log h(i,\mathbf v_i^{(t-1)})+\lambda\parallel\mathbf v_i^{(i)}-\mathbf v_i^{(i-1)}\parallel^2_2<br>$$</p><p>最终的损失函数：</p><p>$$<br>J_{NCE}(\theta)=-E_{P_d}\left[\log h(i,\mathbf v_i^{(t-1)})-\lambda\parallel\mathbf v_i^{(t)}-\mathbf v_i^{(t-1)}\parallel^2_2\right]\<br>-m\cdot E_{P_n}\left[\log(1-h(i,\mathbf v^{\prime(t-1)}))\right]<br>$$</p><img src="https://i.loli.net/2020/08/06/nvS3Z7jEldVcCep.png" style="zoom:67%;" /><h2 id="Weighted-k-Nearest-Neighbor-Classifier"><a href="#Weighted-k-Nearest-Neighbor-Classifier" class="headerlink" title="Weighted k-Nearest Neighbor Classifier"></a>Weighted k-Nearest Neighbor Classifier</h2><p>$s_i=\cos(\mathbf v_i,\hat{\mathbf f})$。记$\mathcal N_k$。$w_c=\sum_{i\in\mathcal N_k}\alpha_i\cdot 1(c_i=c)$。</p><img src="https://i.loli.net/2020/07/29/Cl8xHeFZzXpvosL.png" style="zoom:67%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><img src="https://i.loli.net/2020/08/07/Zj628R7WYixJGog.png" style="zoom:67%;" /><img src="https://i.loli.net/2020/08/07/k6rx1LoaZiFYGpQ.png" style="zoom:67%;" /><p><img src="https://i.loli.net/2020/08/07/a3tNMQ7I2xmGdYA.png"></p><img src="https://i.loli.net/2020/08/07/CK7s3wHbmgnv2j4.png" style="zoom:80%;" /><img src="https://i.loli.net/2020/08/07/rM7n3jhOiBbvJXf.png" style="zoom:67%;" /><img src="https://i.loli.net/2020/08/07/PVL4nlGFtqOdyRh.png" style="zoom:67%;" /><img src="https://i.loli.net/2020/08/07/F3miMXyOqg1DUtK.png" style="zoom:67%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文基于样本分类和噪声对比估计提出了一个无监督表示学习算法。</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Self-supervised Learning" scheme="http://qfxiao.me/categories/Research/Self-supervised-Learning/"/>
    
    
    <category term="Representation Learning" scheme="http://qfxiao.me/tags/Representation-Learning/"/>
    
    <category term="Self-supervised Learning" scheme="http://qfxiao.me/tags/Self-supervised-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Representation Learning with Contrastive Predictive Coding</title>
    <link href="http://qfxiao.me/2020/09/17/Representation-Learning-with-Contrastive-Predictive-Coding/"/>
    <id>http://qfxiao.me/2020/09/17/Representation-Learning-with-Contrastive-Predictive-Coding/</id>
    <published>2020-09-17T12:08:53.000Z</published>
    <updated>2021-02-19T10:20:26.291Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这篇文章算是Contrastive Learning的开山之作之一了，本文提出了表示学习框架：Contrastive Predictive Coding（CPC）和InfoNCE Loss。</p><p><a href="https://arxiv.org/abs/1807.03748">原文</a></p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Contrastive-Predictive-Coding"><a href="#Contrastive-Predictive-Coding" class="headerlink" title="Contrastive Predictive Coding"></a>Contrastive Predictive Coding</h2><p>N-pair Loss:<br>$$<br>\mathcal L=-\log\frac{\exp(f^+\cdot f^\top)}{\exp(f^+\cdot f^\top)+\sum_{f_j\neq f^\top}\exp(f^+\cdot f_j)}<br>$$<br>你有N个样本${x_1,x_2,\cdots,x_N}$，然后对应的表示为$f_j$。假设当前样本为$f^+$，在所有的$f_j$中只有一个表示与$f^+$ match，记为$f^\top$（可以理解为属于同一类，或者两个相似），其他的都是负样本。我们优化上面的优化公式就会拉近$f^+$和$f^\top$之间的距离（拉近同类），疏远$f^+$和所有其他负样本$f_j$的距离（疏远异类）。不过在N-pair Loss中，正负样本是根据标签来选取的，然而在这里我们没有标签。</p><p>下图展示了Contrastive Predictive Coding的结构：</p><img src="https://i.loli.net/2020/07/07/mcFYnVGasjkHrw5.png" style="zoom:67%;" /><p>对比学习<br>$$<br>\mathcal L(f_i)=-\log\frac{\exp(f_i\cdot f^\top)}{\sum_j\exp(f_i\cdot f_j)}<br>$$<br>设数据集（一个Batch）为$\mathbf X={x_1,x_2,\cdots,x_N}$，正样本对为，负样本对。</p><p>至于$f(\cdot,\cdot)$的具体形式，其实$\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}$这个式子我们也是没法直接优化的，因为这个Density Ratio无法直接算出来。在这里，作者使用了一个替代的办法，就是用$\mathbf c_t$来预测未来的隐变量$\hat{\mathbf z}<em>{t+1},\hat{\mathbf z}</em>{t+2},\cdots$，而真实的隐变量$\mathbf z_{t+1},\mathbf z_{t+2},\cdots$我们是知道的。这里预测直接使用权重矩阵和$\mathbf c_t$相乘：<br>$$<br>f_k(\mathbf x_{t+k},\mathbf c_t)=\exp\left(\mathbf z_{t+k}^T \cdot \mathbf W_k\mathbf c_t\right)<br>$$</p><p>上式有点难以理解，实际上预测值$\hat{\mathbf z}<em>{t+k}=\mathbf W_k\mathbf c_t$，而$\mathbf z</em>{t+k}\hat{\mathbf z}_{t+k}$相当于计算两者的距离，即相似性。所以$f_k(\cdot,\cdot)$其实是在计算预测值和真实值的相似性。现在大家先接受这个$f(\cdot,\cdot)$的定义，因为后面会证明优化这个$f(\cdot,\cdot)$就相当于在优化Density Ratio $\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}$。</p><p>一个来自$p(x_{t+k}|c_t)$的正例和$N-1$个来自$p(x_{t+k})$的负例，目标函数（文中称为CPC Loss）为：<br>$$<br>\mathcal L_N=-\mathop{\mathbb E}\limits_X\left[\log\frac{f_k(x_{t+k},c_t)}{\sum_{x_j\in X}f_k(x_j,c_t)}\right]<br>$$</p><p>这里相当于做了个$N$分类，因为这里损失函数等价于$N$分类交叉熵损失函数。</p><blockquote><p>两个离散随机变量的交叉熵的定义为：<br>$$<br>H(p,q) = -\sum_{x\in\mathcal X}p(x)\log q(x)<br>$$<br>对于交叉熵损失函数，设$i$为真实标签，$\hat{\boldsymbol y}$为分类器的输出。$\frac{\exp(\hat y_i)}{\sum_j\exp(\hat y_j)}$为经过<code>Softmax</code>归一化之后的输出，其每个分量$\hat y_j$相当于输入样本$x$的预测类别为$j$的概率。不过由于对于真实标签$y$来说，只有$y_i=1$，其他的分量都为$0$，所以最后交叉熵只剩下一项：<br>$$<br>\mathcal L=-\log\left(\frac{\exp(\hat y_i)}{\sum_j\exp(\hat y_j)}\right)<br>$$</p></blockquote><p>$$<br>I(x;c)=\sum_{x,c}p(x,c)\log\frac{p(x|c)}{p(x)}<br>$$</p><p>编码器$g_{enc}$将观测值$\boldsymbol x_t$编码到隐变量$\boldsymbol z_t=g_\text{enc}(\boldsymbol x_t)$（对应于局部信息），之后自回归模型$g_{ar}$将所有$t$之前的（包括$t$）隐变量$z_{\leq t}$压缩到一个上下文隐变量$\boldsymbol c_t=g_\text{ar}(\boldsymbol z_{\leq  t})$（希望具有预测性质，捕获了长时依赖性）。不过本文并不是基于$\boldsymbol c_t$来预测未来的观测值$\boldsymbol x_{t+k}$，即估计分布$p_k(\boldsymbol x_{t+k}|\boldsymbol c_t)$，而这样的话又要用到MSE之类的Loss。文中利用的是最大化$\boldsymbol c_t$和$\boldsymbol x_{t+k}$之间的互信息$\log \frac{p(x_{t+k}|c_t)}{p(x_{t+k})}$（这种形式的互信息被称为是点互信息，详见<a href="https://en.wikipedia.org/wiki/Pointwise_mutual_information">维基</a>）。定义一个度量函数$f(\cdot,\cdot)$，要求其具有与$\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}$成比例的性质：<br>$$<br>f_k(x_{t+k},c_t)\propto\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}<br>$$<br>这时最大化$f(\cdot,\cdot)$就相当于最大化两者的互信息。</p><h2 id="Mutual-Information-Estimation-Explanation"><a href="#Mutual-Information-Estimation-Explanation" class="headerlink" title="Mutual Information Estimation Explanation"></a>Mutual Information Estimation Explanation</h2><p>现在回到公式$I(x;c)=\sum_{x,c}p(x,c)\log\frac{p(x|c)}{p(x)}$，</p><h2 id="Multual-Information"><a href="#Multual-Information" class="headerlink" title="Multual Information"></a>Multual Information</h2><p>互信息是衡量已知一个变量时，另一个变量不确定性的减少程度的度量。对于离散随机变量，互信息的定义为：<br>$$<br>I(X,Y)=\sum_{y\in\mathcal Y}\sum_{x\in\mathcal X}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}=\sum_{y\in\mathcal Y}\sum_{x\in\mathcal X}p(x,y)\log\frac{p(y|x)}{p(y)}<br>$$<br>对于连续随机变量，互信息的定义为：<br>$$<br>I(X,Y)=\int_{\mathcal Y}\int_{\mathcal X}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}\mathrm dx\mathrm d y=\int_{\mathcal Y}\int_{\mathcal X}p(x,y)\log\frac{p(y|x)}{p(y)}\mathrm dx\mathrm d y<br>$$<br>互信息与熵之间的关系：<br>$$<br>\begin{align}<br>I(X,Y)&amp;=H(X)-H(X|Y)\<br>&amp;=H(Y)-H(Y|X)\<br>&amp;=H(X)+H(Y)-H(X,Y)\<br>&amp;=H(X,Y)-H(X|Y)-H(Y|X)<br>\end{align}<br>$$<br>互信息与KL散之间的关系：<br>$$<br>I(X,Y)=\mathbb E_Y[D_{KL}(p(x|y)\parallel p(x))]<br>$$<br>从图中可以很容易看出互信息相当于$X$和$Y$两者的熵的“重叠”的部分：</p><img src="https://i.loli.net/2020/07/17/orRXnpugEzsZDwq.png" style="zoom:67%;" /><p>在表示学习中，互信息的应用越来越广泛。对于输入的数据$X$，表示学习的目的是尽可能学到“好“的表示$Z$，保留原始数据尽可能多的重要信息。如果使用基于重构的模型，我们就会要求最小化重构误差$\parallel X-\hat{X}\parallel^2_2$，但是这种”逐像素“式的损失函数过于严苛，不利于模型学习高层语义信息。如果加入一个判别器来自动学习一个度量，首先增大了计算开销，同时GAN本身也有诸多问题。</p><p>现阶段很多工作使用互信息来判定学到的表示$Z$的好坏，即最大化原始数据$X$与表示$Z$之间的互信息：<br>$$<br>Z^*=\mathop{\arg\max}_{p(z|x)}I(X,Z)<br>$$<br>互信息越大意味着$\log\frac{p(z|x)}{p(z)}$越大，即$p(z|x)$要大于$p(z)$。$p(z)$可以看作是$Z$的先验，而$p(z|x)\gg p(z)$可以理解为在得知输入$X$之后，我们能找到专属$X$的那个编码$Z$。</p><p>接下来作者证明优化$\mathcal L_N$会使得$f_k(\mathbf x_{t+k},\mathbf c_t)$和互信息接近。这里的$p(\mathbf x_{t+k}|\mathbf c_t)$。设$p(d=i|X,c_t)$为给定数据集（或者Batch）$X$和context向量$c_t$的条件下，样本$x_i$为正样本的概率，有：<br>$$<br>\begin{align}<br>p(d=i|X,c_t)&amp;=\frac{p(x_i|c_t)\prod_{l\neq i}p(x_l)}{\sum^N_{j=1} p(x_j|c_t)\prod_{l\neq j}p(x_l)}\<br>&amp;=\frac{\frac{p(x_i|c_t)}{p(x_i)}}{\sum^N_{j=1}\frac{p(x_j|c_t)}{p(x_j)}}<br>\end{align}<br>$$</p><p>$$<br>\begin{align}<br>\mathcal L_\text{N}^\text{opt}&amp;=-\mathop{\mathbb E}\limits_X\log\left[\frac{\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}}{\frac{p(x_{t+k}|c_t)}{p(x_{t+k})}+\sum_{x_j\in X_\text{neg}}\frac{p(x_j|c_t)}{x_j}}\right]\</p><p>\end{align}<br>$$</p><p>$$<br>I(x_{t+k},c_t)\geq \log(N)-\mathcal L_N<br>$$</p><p>可以说$\mathcal L_N$作为互信息$I(x_{t+k},c_t)$的一个下界。</p><h2 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h2><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Audio"><a href="#Audio" class="headerlink" title="Audio"></a>Audio</h2><p><img src="https://i.loli.net/2020/07/07/kWectjL27MKy1dA.png"></p><p><img src="https://i.loli.net/2020/07/07/vhBRmpntw2Xx6J9.png"></p><p><img src="https://i.loli.net/2020/07/07/5QaDOCFvxLE6wqT.png"></p><p><img src="https://i.loli.net/2020/07/07/nA49kE1WP73oGQJ.png"></p><h2 id="Vision"><a href="#Vision" class="headerlink" title="Vision"></a>Vision</h2><img src="https://i.loli.net/2020/07/07/gkNnWo4zyUeBRCa.png" style="zoom:67%;" /><img src="https://i.loli.net/2020/07/07/qH6BAJnhMcP9bKy.png" style="zoom:67%;" /><p><img src="https://i.loli.net/2020/07/07/ezO1IibwvC5Mus8.png"></p><p><img src="https://i.loli.net/2020/07/07/sWNGXqv1n38kgcf.png"></p><h2 id="Natural-Language"><a href="#Natural-Language" class="headerlink" title="Natural Language"></a>Natural Language</h2><p><img src="https://i.loli.net/2020/07/07/Ly86Xu9n4KSOJge.png"></p><h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><p><img src="https://i.loli.net/2020/07/07/92XzLqltMUfCgTs.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;这篇文章算是Contrastive Learning的开山之</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Self-supervised Learning" scheme="http://qfxiao.me/categories/Research/Self-supervised-Learning/"/>
    
    
    <category term="Deep Learning" scheme="http://qfxiao.me/tags/Deep-Learning/"/>
    
    <category term="Contrastive Learning" scheme="http://qfxiao.me/tags/Contrastive-Learning/"/>
    
    <category term="Self-supervised Learning" scheme="http://qfxiao.me/tags/Self-supervised-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Model Selection and Evaluation: Machine Learning Basics</title>
    <link href="http://qfxiao.me/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/"/>
    <id>http://qfxiao.me/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/</id>
    <published>2020-09-09T03:33:25.000Z</published>
    <updated>2021-02-19T10:21:57.175Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h1><p>我们将模型输出与真实值之间的差异称为误差，如对于分类问题，我们可以使用模型分类错误的样本数量占总样本数的比例。模型在训练集（我们收集到的数据）上的误差称作是<strong>训练误差 (training error)**，而在新样本（这里指的是新的样本而不是测试集，训练集测试集是从我们收集到的数据上人为划分出来的）上的误差称作是</strong>泛化误差 (generalization error)**。对于机器学习算法，我们希望算法能学到数据背后的普遍规律，所以我们总是希望模型的泛化误差越小越好。</p><p>不过测试集对训练过程来说是未知的，所以模型只能尽量从训练集中发掘数据的普遍规律，要是模型把训练集学得”太好“了，很可能把训练集中不属于普遍规律的部分特点作为了一般性质，这就会导致泛化性能下降，我们称这种情况为<strong>过拟合 (overfitting)**。反之，模型对训练集的特性学得不够，就会出现</strong>欠拟合 (underfitting)**。关于过拟合和欠拟合，周志华老师的《机器学习》中有一张很好的图：</p><img src="https://i.loli.net/2020/09/09/tVPeQfu9CWLaSi6.png" style="zoom:67%;" /><p>一般来说，欠拟合比较容易克服，可以通过增加模型的复杂度来实现。而过拟合则比较难解决，一般而言可以通过增加数据量、加正则化约束来改善。</p><h1 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h1><p>对于一个机器学习任务，一般我们有多种模型供我们选择，并且模型也有不同的超参数，我们希望得到泛化性能尽可能高的模型。不过根据前面的讨论，新样本是未知的，所以没法直接得到泛化误差，而过拟合的存在使得我们不能贸然的根据模型在我们收集到的数据上的表现来选择模型（训练误差低不代表泛化误差低）。</p><p>我们假设无论是我们收集到的数据还是新样本都是从数据的真实分布中独立同分布采样得来，为此我们可以从数据中划分出一部分”测试集“，然后将模型在测试集上的表现作为泛化误差的近似，而剩下的部分用来模型训练。</p><p>那么如何划分训练集和测试集呢？比较常见的方法是”$k$折交叉验证法“ ($k$-fold cross validation)，一般$k$常取$10$，其基本思想如下图所示：</p><img src="https://i.loli.net/2020/09/09/8KEWDe3qMTsQoUx.png" style="zoom: 50%;" /><p>$k$折交叉验证法首先将数据集均匀地划分为$k$个部分，然后进行$k$个循环，在每个循环中将第$k$份作为测试集，其余的作为训练集，最后得到的结果进行平均。</p><h1 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h1><p>前面我们讨论了评测的框架，但是没有说具体的评测指标。实际上评测指标要根据任务来确定，并且不同的评测指标也有自己的特点。</p><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>回归任务比较常用的评测标准是<strong>均方误差 (Mean Squared Error)**：<br>$$<br>\text{MSE}(f;D)=\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2<br>$$<br>和</strong>平均绝对误差 (Mean Absolute Error)**：<br>$$<br>\text{MAE}(f;D)=\frac{1}{m}\sum_{i=1}^m |f(x_i)-y_i|<br>$$</p><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><p>对于分类任务，最简单的想法是使用模型分类正确的比例来作为评测标准，我们称之为<strong>准确率 (Accuracy)**：<br>$$<br>\text{ACC}(f;D)=\frac{1}{m}\sum_{i=1}^m \mathbb{I}(f(x_i)=y_i)<br>$$<br>但准确率并不能满足我们的所有要求，比如说对于新冠病毒的分类任务，我们可能会更关注于对于所有患有新冠的病人，模型到底查出来了多少，而对于模型误把正常病人当作是患病的情况没有那么关注。对于二分类问题，我们可以将样例根据其真实类别与模型预测的类别划分为真正例 (true positive, TP)、假正例 (false positive, FP)、真反例 (true negative, TN) 和假反例 (false negative, FN) 四种，形成</strong>混淆矩阵 (Confusion Matrix)**：</p><p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg"></p><p>下面给一个具体的例子：</p><p><img src="https://i.loli.net/2020/09/09/tCLxvZfNoEgqWID.png"></p><p>比如我们的任务是预测一张手写数字图片是不是$5$，根据上图，右下角就是我们正确预测的是$5$的图片，左下角就是本来是$5$，但被预测成不是$5$的图片；左上角是本来不是$5$，我们也正确地预测出其不是$5$的，右上角是本来不是$5$却被预测成是$5$的。是不是有点被绕晕了😀，只要记住T和F代表的是预测结果对还是不对，P和N代表的是模型预测当前样本是正例还是负例。</p><p>基于混淆矩阵，我们可以定义<strong>查准率 (Precision)</strong> 和<strong>查全率 (Recall)</strong> 这两个评测标准。</p><p>查准率，顾名思义，对于检测出来的正例，有多少是真正的正例，即查的准不准，公式为：<br>$$<br>\text{Precision}=\frac{TP}{TP+FP}<br>$$<br>分母就是模型预测为正例的样本总数。</p><p>查全率，就对应刚才举的新冠的例子，我们比较在乎对于数据集中的正例，有多少被查出来了，公式为：<br>$$<br>\text{Recall} = \frac{TP}{TP+FN}<br>$$<br>分母就是真实类别为正例的样本总数。一般来说，查准率和查全率是相互矛盾的，除非是特别简单的任务，很难兼顾查准率和查全率。</p><p><strong>F1分数 (F1 Score)</strong> 综合了查准率和查全率：<br>$$<br>\text{F}1=\frac{2\cdot\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}<br>$$<br>查准率和查全率中任意一项较低都会导致F1分数较低。有时候我们对待查准率和查全率的权重不同，这时候可以使用F$_\beta$分数：<br>$$<br>\text{F}_\beta=\frac{(1+\beta^2)\cdot \text{Precision}\cdot\text{Recall}}{(\beta^2\cdot\text{Precision})+\text{Recall}}<br>$$<br>$\beta=1$时等价于F1分数，$\beta&gt;1$代表偏重查全率，$\beta&lt;1$代表偏重查准率。</p><h3 id="Multi-classification"><a href="#Multi-classification" class="headerlink" title="Multi-classification"></a>Multi-classification</h3><p>前面的讨论都是基于二分类任务，如果是多分类任务的话， 对于每一类，我们将该类作为正例，其他类别作为负例，都能得到一个混淆矩阵。如果我们在每个混淆矩阵上计算评测指标，然后进行平均，这样就得到宏查准率 (macro-Precision)、宏查全率 (macro-Recall) 和宏F1分数 (macro-F1)。如果我们事先将混淆矩阵的TP、FP、TN、FN先进行平均，再计算评测指标，就得到了微查准率 (micro-Precision)、微查全率 (micro-Recall) 和微F1分数 (micro-F1)。</p><h3 id="PR-Curve"><a href="#PR-Curve" class="headerlink" title="PR-Curve"></a>PR-Curve</h3><p>很多情况下模型的输出是样本为正例的“概率值”或者是分数，分数越高的样本代表越可能是正例。这种时候需要人为划定阈值，规定高于阈值的样本是正例。不过阈值的划分相当于超参数的选取，同时我们会认为一个鲁棒的模型的性能应该不受阈值选取的左右。这个时候我们可以使用**PR曲线 (Precision-Recall Curve)**，即遍历所有可能的阈值，对于每个阈值，计算其对应的Precision和Recall，然后画在图上，最后会得到一系列离散的点（理论上应该是连续曲线，不过阈值是连续值，我们只能取离散值），形成PR-曲线。</p><img src="https://i.loli.net/2020/09/09/ecP8flTYZIDUBrV.png" alt="2-class Precision-Recall curve: AP=0.88" style="zoom:67%;" /><p>模型性能越好，曲线就会越接近右上角的点，我们可以把PR曲线的曲线下面积 (PR-AUC) 作为评测标准。</p><h3 id="ROC-Curve"><a href="#ROC-Curve" class="headerlink" title="ROC-Curve"></a>ROC-Curve</h3><p>ROC全称是<strong>受试者工作特征 (Receiver Operating Characteristic) 曲线</strong>, 和PR曲线类似，ROC曲线也是遍历不同的阈值计算点，不过ROC曲线计算的是真正例率 (True Positive Rate, TPR) 和假正例率 (False Positive Rate, FPR)，两者定义分别是：<br>$$<br>\begin{align}<br>\text{TPR}=\frac{TP}{TP+FN}\<br>\text{FPR}=\frac{FP}{TN+FP}<br>\end{align}<br>$$<br>其中TPR就是查全率，而FPR是所有负例中没有检测出来的比例，这一项是越低越好。</p><img src="https://i.loli.net/2020/09/09/CdHrDaKAns4EN93.png" style="zoom:67%;" /><p>模型性能越好，曲线就会越接近左上角的点，我们可以把ROC曲线的曲线下面积 (ROC-AUC) 作为评测标准。</p><p>下面来总结一下PR曲线和ROC曲线之间的优缺点。</p><table><thead><tr><th></th><th>纵轴</th><th>横轴</th></tr></thead><tbody><tr><td><strong>PR</strong></td><td>$\text{Precision}=\frac{TP}{TP+FP}$</td><td>$\text{Recall} = \frac{TP}{TP+FN}$</td></tr><tr><td><strong>ROC</strong></td><td>$\text{TPR}=\frac{TP}{TP+FN}$</td><td>$\text{FPR}=\frac{FP}{TN+FP}$</td></tr></tbody></table><p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg"></p><p>ROC的优点：</p><ul><li>相比PR仅关注正例，ROC同时关注正例和负例</li><li>相比PR不易受到正负例相对数量的影响，ROC的两个指标的计算都只涉及到P、N中的一列，正例或负例增加对总体影响不大。而PR曲线就不一样，两个指标的计算都涉及到了P、N两列，那么正例或负例样本数量的变化会造成较大影响。如负例突然增大，那么FP也会增大，这样Precision会降低，而Recall却不变。</li></ul><p>ROC的缺点：</p><ul><li>对于类别不平衡问题，存在大量负例，这样会带来大量的FP，而ROC的FPR却不会因为FP的大幅增长而剧烈改变，结果是这一类错误很难在ROC曲线中体现出来。所以ROC会呈现出一个过于乐观的评价。</li></ul><p>我们来尝试下是否如此，下面是用随机森林分类器，测试样本正负例数量比为1:1的情况下的ROC曲线和PR曲线：</p><img src="https://i.loli.net/2020/09/10/yqMDQh5oTs96SJm.png" style="zoom:50%;" /><img src="https://i.loli.net/2020/09/10/zFW941YTMl8yxiP.png" style="zoom:50%;" /><p>在我们将正负例数量比调整为1:9之后（总数量相同），可以看到ROC曲线比较稳定，没出现较大变化，而PR曲线则出现了剧烈变化：</p><img src="https://i.loli.net/2020/09/10/HbnLtfGsiVc17q5.png" style="zoom:50%;" /><img src="https://i.loli.net/2020/09/10/FfYrb3SnkeZ9JTv.png" alt="4" style="zoom:50%;" /><h1 id="Bias-and-Variance"><a href="#Bias-and-Variance" class="headerlink" title="Bias and Variance"></a>Bias and Variance</h1><p>在机器学习中，偏差-方差分解是解释学习算法泛化性能的重要工具。假设我们要预测某一个地区的房子的房价，每一套房子都是一个样本，我们认为每个样本都是从总体分布$P(X)$独立同分布采样得来的。不过我们不可能得到所有的样本，我们采样得到的训练集只是其中一个子集。那么，即使对于同样的测试样本，使用不同的训练集（训练集大小相同）训练出来的模型对测试样本的预测也是不一样的，我们将这一部分模型自身的不稳定性用<strong>方差 (Variance) **来描述：$\text{Var}(X)=E_D\left[(\hat f(X)-E[\hat f(X)])^2\right]$，方差越小代表模型稳定性越强。模型输出的期望与真实值之间的差距我们用</strong>偏差 (Bias) **来描述：$\text{Bias}(X)=E[\hat f(X)]-f(X)$。</p><p>泛化误差与方差、偏差有下列关系：<br>$$<br>\begin{align}<br>\text{Err}(X)&amp;=E\left[(y-\hat f(X))^2\right]\<br>&amp;=E\left[(f(X)+\varepsilon-\hat f(X))^2\right]\<br>&amp;= (E[\hat f(X)]-f(X))^2 + E\left[(\hat f(X)-E[\hat f(X)])^2\right]+\sigma_{\varepsilon}^2\<br>&amp;=\text{Bias}^2 + \text{Variance} + \text{Random Error}<br>\end{align}<br>$$<br>也就是说泛化误差可以分解为方差、偏差和随机噪声之和。偏差刻画了模型的期望预测与真实值之间的偏离程度，方差刻画了不同训练集对模型性能的影响，他们之间的关系如下图所示：</p><img src="https://i.loli.net/2020/09/09/2IpmrwJGfqORU3z.png" style="zoom: 33%;" /><p>图中左上角的部分是比较理想的情况，即方差和偏差都较小。但实际上方差和偏差往往是相互冲突的，如下图所示：</p><img src="https://i.loli.net/2020/09/09/GsREiklKYfuX3Ub.png" style="zoom:67%;" /><p>模型复杂度不足的时候，模型的拟合能力不够强，偏差主导了泛化误差，而随着模型复杂度的提高，模型的拟合能力逐渐提高，训练数据的扰动会造成模型发生显著变化，这时方差逐渐主导了泛化误差。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Overfitting&quot;&gt;&lt;a href=&quot;#Overfitting&quot; class=&quot;headerlink&quot; title=&quot;Overfitting&quot;&gt;&lt;/a&gt;Overfitting&lt;/h1&gt;&lt;p&gt;我们将模型输出与真实值之间的差异称为误差，如对于分类问题，我们可以使</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Machine Learning" scheme="http://qfxiao.me/categories/Technical-Notes/Machine-Learning/"/>
    
    
    <category term="Overfitting" scheme="http://qfxiao.me/tags/Overfitting/"/>
    
    <category term="Bias" scheme="http://qfxiao.me/tags/Bias/"/>
    
    <category term="Variance" scheme="http://qfxiao.me/tags/Variance/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Classification Algorithms: Decision Trees</title>
    <link href="http://qfxiao.me/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/"/>
    <id>http://qfxiao.me/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/</id>
    <published>2020-09-02T10:47:55.000Z</published>
    <updated>2021-02-19T10:22:31.857Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>（PS：本文内容是学习高级树模型（GBDT，XGBoost）的基础，强烈建议在看那些内容之前先了解本文的内容！）</p><p>本文主要是介绍常用的三种决策树模型：ID3、C4.5和CART。决策树（Decision Tree）是一种<strong>有监督分类模型</strong>（稍加改造可进行回归任务）。</p><p>比如我们要判断一个瓜是不是好瓜，对于人来说，要判断一个瓜是不是好瓜，可能会先去看看色泽，然后看看根蒂，然后再敲一敲听听声音，这样经过一系列的决策过程。</p><img src="https://i.loli.net/2020/09/02/WuGQ79g4NcHqJDh.png" style="zoom:50%;" /><p>决策树正是模拟了这样的过程。给定数据集，决策树会不断地选择最佳的特征将数据集进行切分（如选择色泽，然后将数据分为青绿、乌黑、浅白这几个子集），然后递归地进行下去，直到达到停止条件：</p><ol><li>每个叶子节点的样本都属于同一个类别</li><li>没有可供划分的特征，或者集合中每个样本所有特征取值都相同</li><li>决策树达到预先指定的最大深度</li></ol><p>所以决策树算法要解决的关键问题就是如何去选择当前最好的划分特征。</p><h1 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h1><p>ID3算法根据信息熵来进行特征的划分。信息熵是衡量一个随机变量信息量的度量，如果把数据集的标签$y$看作是随机变量，那么$y$的熵越小代表不确定性越小（集合里几乎都是一种类别的样本），熵越大代表不确定性越大（集合包含不同类别的样本），其公式为：<br>$$<br>Ent(D)=-\sum_{k=1}^{|\mathcal Y|}p_k\log p_k<br>$$<br>$Ent(D)$代表集合$D$对应的熵，$|\mathcal Y|$是类别数量，二分类就是$|\mathcal Y|=2$，$p_k$为第$k$个类别对应的概率（频率）。很自然的，我们可以根据划分前后熵的变化来确定划分特征的选择，如果划分之后熵减小的最多，那么这个特征也是最好的。假设我们选定特征$a$来对集合进行划分，特征$a$共有$V$个离散取值，那么划分之后将会产生$V$个子集，我们记每个子集为$D^v, v=1,\cdots, V$。那么，信息增益可以写为：<br>$$<br>Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)<br>$$<br>不过，ID3存在两个致命的缺点：</p><ol><li>无法对连续取值的特征进行计算</li><li>对取值较多的特征具有很大的偏向性（极端的情况，把样本编号作为特征，由于每个样本的编号都不同，分裂之后每个自己只有一个样本/类别，熵是最小的）</li></ol><h1 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h1><p>C4.5算法在ID3的基础上做了诸多改进。C4.5解决了ID3对于取值数目较多的特征的偏向性问题，其采用的方案很直观，即对信息增益除以一个系数，特征取值数目越多的特征系数越大，该划分标准被称作是信息增益率：<br>$$<br>Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}<br>$$<br>其中$IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}\log \frac{|D^v|}{|D|}$。其实$IV(a)$可以看作是“划分之后每个样本属于集合$v$的概率”这个随机变量的熵，划分的子集越多，划分之后属于哪个集合就越不确定，所以熵就越大。</p><p>不过信息增益率反而会对特征取值数目少的特征有所偏好，所以C4.5算法是先计算信息增益，确定信息增益高于平均值的候选集，再从中选择信息增益率最高的特征。</p><p>除此之外，C4.5还能处理连续取值的特征，其做法是“离散化”，即将连续取值划分为若干个离散的区间，一般二分比较常用。设连续特征$a$，假设其出现了$n$个取值，将其排序得到${a^1,a^2,\cdots,a^n}$，我们考虑每两个相邻节点的中点集合$T_a={\frac{a^i+a^{i+1}}{2}|1\leq i \leq n-1}$，之后我们就可以像考察离散属性值一样选择最优划分。</p><p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/10/RNyxp8EM6BCsOHK.png"></p><h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p>CART (Classification and Regression Trees) 是一种应用广泛的决策树模型，既可应用于分类任务也可应用于回归任务。</p><h2 id="CART-Regression"><a href="#CART-Regression" class="headerlink" title="CART Regression"></a>CART Regression</h2><p>我们先来说说CART怎么进行回归。在回归问题中，CART使用了MSE作为划分准则：<br>$$<br>\frac{1}{N}\sum_{i=1}^N (f(x_i)-y_i)^2<br>$$<br>如果CART有$M$片叶子，那么相当于CART将输入划分成了$M$个单元$R_m, m=1,\cdots,M$，也即有$M$个输出，那么该CART在数据集上的MSE为：<br>$$<br>\frac{1}{N}\sum_{m=1}^M\sum_{x_i\in R_m} (c_m-y_i)^2<br>$$<br>这里$c_j$为叶子节点$j$的输出，一般选为对应样本的均值$c_m=\text{avg}(y_i|x_i\in R_m)$。这样，剩下的问题就是如何确定每次的切分特征和切分点了。假设选择的特征是$j$，切分点$s$，那么该划分方案对应的损失为：<br>$$<br>\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2<br>$$<br>遍历所有的$j$和$s$，我们就能找到最佳的特征和切分点：<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2\right]<br>$$</p><p>算法流程大致如下：</p><blockquote><p><strong>CART Decision Tree Algorithm</strong></p><p>INPUT: 数据集 $D={(x_1,y_1),\cdots,(x_N,y_N)}$</p><p>OUTPUT: 预测值${\hat y_1,\cdots,\hat y_N}$</p><p>PROCEDURE:</p><p><strong>1. 选取当前最优切分特征变量$j^*$与最优切分点$s^*$</strong></p><p>设当前选择的切分变量为$j$，切分点为$s$那么可以根据切分点将数据集分为两个子集，一个是$R_1(j,s)=\left{x|x^{(j)}\leq s\right}$，另一个是$R_2(j,s)=\left{x|x^{(j)}&gt; s\right}$。<br>遍历所有的$j$，求解<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum\limits_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min\limits_{c_2}\sum\limits_{x_i\in R_2(j,s)}(y_i-c_2)^2\right]<br>$$<br>注意$\hat c_1=\frac{1}{N_1}\sum\limits_{x_i\in R_1(j,s)}y_i$<br><strong>2. 用选定的$(j^*,s^*)$来划分区域并计算输出值</strong></p><p>此时，我们还需要确定这两个区域（划分到同一个区域的样本对应的输出是相同的）的输出值$c_1$和$c_2$，其确定方式是使得对应区域上的均方误差最小。这样我们相当于得到了给定$j,s$下的损失，所以只要找出使得损失最小的$j^*,s^*$即可：</p><p><strong>3. 递归地对划分出来的两个区域重复步骤1和步骤2，直到满足停止条件</strong></p><p><strong>4. 最后将输入空间划分为$M$，输出$f(x)=\sum_{m=1}^M \hat c_m I(x\in R_m)$</strong></p></blockquote><p>下图是在波士顿房价数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/09/knOHuvsfyorTpxt.png"></p><h2 id="CART-Classification"><a href="#CART-Classification" class="headerlink" title="CART Classification"></a>CART Classification</h2><p>从前面的讨论可以看到，CART回归树是一棵二叉树，对于分类任务，CART也是一棵二叉树。我们先来介绍CART的划分准则，再来介绍它是怎么进行划分的。</p><p>采用基尼系数作为准则，基尼系数的计算依赖于基尼值：<br>$$<br>\begin{align}<br>Gini(D)&amp;=1-\sum_{k=1}^{|\mathcal Y|}p_k^2<br>\end{align}<br>$$<br>直观上来说，基尼值表示随机抽取两个样本，其类别不一致的概率</p><p>如果说一个特征越好，那么划分之后其每个子集对应的基尼值应该越小越好。基尼系数的定义为：<br>$$<br>Gini_index(D,a)=\sum_{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)<br>$$</p><p>对于离散取值特征，CART不会根据不同取值个数进行划分，而是和连续值类似，会确定一个“划分点”，将样本进行二分。比如对于特征$a$，其对应取值为${a^1,a^2,\cdots,a^n}$，CART会考察每个取值，将样本集划分为特征$a$是不是等于$a^i$两部分，然后计算基尼系数，最终会采用基尼系数最小的取值作为划分点。</p><p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/10/mMf2EVkI1NaQLdS.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;（PS：本文内容是学习高级树模型（GBDT，XGBoost）</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Machine Learning" scheme="http://qfxiao.me/categories/Technical-Notes/Machine-Learning/"/>
    
    
    <category term="ID3" scheme="http://qfxiao.me/tags/ID3/"/>
    
    <category term="C4.5" scheme="http://qfxiao.me/tags/C4-5/"/>
    
    <category term="CART" scheme="http://qfxiao.me/tags/CART/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Classification Algorithms: Support Vector Machine</title>
    <link href="http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/"/>
    <id>http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/</id>
    <published>2020-08-25T18:09:24.000Z</published>
    <updated>2021-02-19T10:23:31.925Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Still working on it😅…</p><p><a href="http://blog.pluskid.org/?page_id=683">blog</a></p><h1 id="Hyperplane"><a href="#Hyperplane" class="headerlink" title="Hyperplane"></a>Hyperplane</h1><p>超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程：<br>$$<br>a_1x_1+\cdots+a_nx_n=d<br>$$<br>的所有解形成的集合，其中$a_1,\cdots,a_n$为不全为$0$的实数，$d$也是实数。</p><p>从几何上来说，超平面可以看作是除空间$R^n$自身外维度最大的仿射空间。</p><p><img src="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg"></p><h1 id="Maximum-Margin-Classifier"><a href="#Maximum-Margin-Classifier" class="headerlink" title="Maximum Margin Classifier"></a>Maximum Margin Classifier</h1><img src="https://i.loli.net/2020/08/26/vjuyCGXMr4msaUK.png" style="zoom:67%;" /><p>要谈SVM就得先谈线性分类器，其设置是这样的。对于$D$维空间，我们有一堆数据$X$，进行二分类任务，标签记为$y$，其中$y=-1$和$y=1$分别代表不同的类别。我们的任务就是找到一个超平面，将正负例切分开来（先假设数据是线性可分的），这个超平面的方程可以表示为：<br>$$<br>w^\top x+b=0<br>$$<br>我们令$f(x)=w^\top x+b$，对于$f(x)&lt;0$的样本，我们赋予其类别$-1$，对于$f(x)&gt;0$的样本，我们可以赋予其类别$1$。对于相同的分类结果，我们可以找出无限种超平面。不过，对于那些样本特别靠近超平面的情况，鲁棒性并不好。为什么呢？因为这时只要超平面有轻微的变化，样本的分类结果就会发生变化。直观上来说，我们希望样本到超平面的距离越大越好。</p><p>我们先定义函数间隔的概念，函数间隔$\hat \gamma=y(w^\top x+b)$，乘以$y$的目的主要是保持非负性，表示起来方便。可见函数间隔的大小并不能表示样本距离，因为同一个超平面，法向量$w$可以任意增大，函数间隔也会相应增大。</p><p>下面来推导点$x$到超平面的距离。设$x$在超平面上的投影为$x_0$，到超平面的距离为$\gamma$，$w$为法向量，那么有：<br>$$<br>x=x_0+\gamma\frac{w}{\parallel w\parallel}<br>$$<br>将上式带入到超平面方程可以得到<br>$$<br>\gamma=\frac{w^\top}{\parallel w\parallel}x+\frac{b}{\parallel w\parallel}<br>$$<br>我们称$\gamma$为几何间隔。</p><p><img src="https://i.loli.net/2020/08/26/b6qLJWzHwFAPDne.png"></p><p>可以很容易看出函数间隔和几何间隔的关系：<br>$$<br>\gamma = \frac{\hat \gamma}{\parallel w\parallel}<br>$$<br>前面提到我们希望几何间隔越大越好，于是可以直接最大化$\gamma$，得到：<br>$$<br>\begin{align}<br>\max \space &amp;\gamma\<br>s.t. \space &amp; y_i(w^\top x_i+b)=\hat\gamma_i\geq\hat\gamma, \space i=1,\cdots,n<br>\end{align}<br>$$<br>这里$\hat \gamma=\gamma \parallel w\parallel$，根据前面的分析我们知道，对于同一个超平面，函数间隔$\hat\gamma$可以随着$\parallel w\parallel$的变化而变化，所以为了找到最优的$\gamma$，我们可以考虑固定$\parallel w\parallel$或者$\hat\gamma$，这里我们固定$\hat \gamma=1$，所以有：<br>$$<br>\begin{align}<br>\max &amp; \space \frac{1}{\parallel w\parallel},\ s.t. \space&amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$</p><p>下面的约束条件代表前提是所有样本分类正确，而$\max\frac{1}{\parallel w\parallel}$代表最大化间隔。为了方便，我们将其化为等价的最小化形式：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中那些$y_i(w^\top x_i+b)=1$的样本就是“支持向量”。这个优化问题是典型的二次凸优化问题，可以调用现成的算法去解决。不过我们可以使用拉格朗日乘子法来更高效的解决。</p><h1 id="Dual-Problem"><a href="#Dual-Problem" class="headerlink" title="Dual Problem"></a>Dual Problem</h1><p>拉格朗日乘子法可以将有$d$个变量和$k$个约束条件的最优化问题转化成有$d+k$个变量的无约束最优化问题求解。</p><h2 id="Lagrange-Multiplier"><a href="#Lagrange-Multiplier" class="headerlink" title="Lagrange Multiplier"></a>Lagrange Multiplier</h2><p>对于以下有约束优化问题：<br>$$<br>\begin{align}<br>\min_x \space &amp; f(x)\<br>\text{s.t.} \space &amp; h_i(x)=0 \space (i=1,\cdots,m),\<br>&amp;g_j(x) \leq 0 \space (j=1,\cdots,n)<br>\end{align}<br>$$</p><p>引入拉格朗日乘子$\boldsymbol\lambda = (\lambda_1,\lambda_2,\cdots,\lambda_n)^\top$和$\boldsymbol\mu=(\mu_1,\mu_2,\cdots,\mu_m)^\top$，相应的广义拉格朗日函数 (generalized Lagrange function) 为：<br>$$<br>L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=f(\boldsymbol x)+\sum_{j=1}^n \lambda_j g_j(\boldsymbol x)+\sum_{i=1}^m \mu_i h_i(\boldsymbol x)<br>$$</p><p>其中$\lambda_j$，$\mu_i$被称作是拉格朗日乘子，$\lambda_j \geq 0$。</p><h3 id="Primal-Problem"><a href="#Primal-Problem" class="headerlink" title="Primal Problem"></a>Primal Problem</h3><p>现在我们来讨论原问题的等价性。假设给定某个$x$，如果$x$违反约束条件，即存在某个$x$使得$h_i(x)\neq 0$或者$g_j(x)&gt;0$，那么就有：<br>$$<br>\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=+\infty<br>$$<br>如果存在某个$x$使得$h_i(x)\neq 0$，那么可以令$\lambda_j \rightarrow +\infty$，如果存在$g_j(x)&gt;0$，那么可令$\mu_ih_i(x)\rightarrow +\infty$。</p><p>如果考虑以下极小化问题：<br>$$<br>p^*=\min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>他与原始带约束最优化问题是等价的（因为不符合约束时会有$+\infty$，而我们考虑的是极小化问题），我们将其记为原问题 (Primal problem)。</p><h3 id="Dual-Problem-1"><a href="#Dual-Problem-1" class="headerlink" title="Dual Problem"></a>Dual Problem</h3><p>如果先考虑最小化$x$，再考虑最大化$\boldsymbol\lambda$和$\boldsymbol\mu$，这时有：<br>$$<br>\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>对偶问题 (Dual problem)<br>$$<br>d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>原问题和对偶问题的关系<br>$$<br>d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) \leq \min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) = p^*<br>$$</p><h3 id="KKT-Condition"><a href="#KKT-Condition" class="headerlink" title="KKT Condition"></a>KKT Condition</h3><blockquote><p>对于原问题和对偶问题，设$f(x)$和$g_i(x)$为凸函数，$h_i(x)$为仿射函数，并且不等式约束$c_i(x)$是严格可行的，则$x^*$，$\lambda^*$，$\mu^*$分别是原问题和对偶问题的解的充分必要条件是满足下面的Karush-Kuhn-Tucker (KKT) 条件：<br>$$<br>\begin{cases}<br>\nabla_x L(x^*,\lambda^*,\mu^*)=0 &amp;\<br>\lambda^<em>_j g_j(x^</em>)=0 &amp; j=1,\cdots n\<br>g_j(x^*)\leq 0 &amp; j=1,\cdots n\<br>\lambda_j^<em>\geq 0 &amp; j=1,\cdots n\<br>h_i(x^</em>) = 0 &amp; i = 1, \cdots m<br>\end{cases}<br>$$</p></blockquote><p>这告诉我们</p><h2 id="Dual-Form-of-SVM-Optimization"><a href="#Dual-Form-of-SVM-Optimization" class="headerlink" title="Dual Form of SVM Optimization"></a>Dual Form of SVM Optimization</h2><p>支持向量机优化的对偶问题可以写为：<br>$$<br>L(w,b,\alpha)=\frac{1}{2}\parallel w\parallel^2-\sum_{i=1}^n \alpha_i(y_i(w^\top x_i+b)-1)<br>$$<br>我们先令：<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial w}=0&amp;\Rightarrow w=\sum_{i=1}^n\alpha_i y_i x_i\<br>\frac{\partial L}{\partial b}=0&amp;\Rightarrow \sum_{i=1}^n\alpha_i y_i =0<br>\end{align}<br>$$<br>带回到$L$得到：<br>$$<br>\begin{align}<br>L(w,b,\alpha)&amp;=\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_j y_i y_j x^\top_i x_j-\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_jx^\top_ix_j-b\sum_{i=1}^n\alpha_iy_i+\sum_{i=1}^n\alpha_i\<br>&amp;=\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j<br>\end{align}<br>$$<br>于是得到关于$\alpha$的对偶优化问题：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$</p><p>前面有提到我们根据$f(x)=w^\top x + b$的输出来判定样本类别，而刚才得到$w=\sum_{i=1}^n\alpha_i y_i x_i$，于是：<br>$$<br>\begin{align}<br>f(x) &amp;= (\sum_{i=1}^n \alpha_iy_ix_i)^\top x+b\<br>&amp;= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>\end{align}<br>$$<br>最后的$\sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b$值得特别注意，这意味着我们对于测试样本$x$的预测，只需要计算它与训练集的内积即可，同时由于所有非支持向量对应的$\alpha$都是$0$，我们只需要求一小部分内积。同时这个内积计算也是后面核方法应用的前提。</p><h1 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h1><p>到目前为止，我们的讨论都是在数据是线性可分的前提下进行讨论的，那么对于线性不可分的情况呢？答案是使用核方法。</p><p><img src="https://i.loli.net/2020/09/08/kSTVgelDjWqtu8v.png"></p><p>核方法的思想是，对于原始不可分的数据，我们假设原始数据通过一个映射$\phi(\cdot)$就变得线性可分了。核方法相当于对数据找到了一种新的表示，如上图没法用一个超平面直接分割，但通过$\phi(\cdot)$映射之后就变得可分了。原始的分类函数为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>$$<br>加上映射之后变为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle \phi(x_i), \phi(x)\rangle + b<br>$$<br>优化问题也变为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j \langle\phi(x_i), \phi(x_j)\rangle\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>我们把计算两个向量在映射后的空间中的内积的函数叫做核函数<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i k(x_i, x) + b<br>$$<br>优化问题改为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j k(\phi(x_i), \phi(x_j))\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>实际上，通过核函数，我们隐式地定义了一个映射$\phi(\cdot)$</p><p>常用核函数</p><table><thead><tr><th>名称</th><th>表达式</th><th>参数</th></tr></thead><tbody><tr><td>线性核</td><td></td><td></td></tr><tr><td>多项式核</td><td></td><td></td></tr><tr><td>RBF核</td><td></td><td></td></tr><tr><td>拉普拉斯核</td><td></td><td></td></tr><tr><td>Sigmoid核</td><td></td><td></td></tr></tbody></table><h1 id="Soft-Margin"><a href="#Soft-Margin" class="headerlink" title="Soft Margin"></a>Soft Margin</h1><p>数据线性不可分的情况，除了数据本身结构非线性的原因之外（核方法），还有可能是因为噪声或者离群点。为了处理这种情况，我们可以允许一部分点在一定程度上偏离超平面，具体来说就是原来的约束条件$y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n$变成了：<br>$$<br>y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>$$<br>其中$\xi_i\geq 0$称作是松弛变量，代表样本$i$允许的偏离程度。当然松弛变量不可能无限大，所以我们需要将$\xi_i$加入到优化目标函数中使其尽量小，于是有：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2+C\sum_{i=1}^n \xi_i,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中$C$为控制最优化$\parallel w\parallel$和松弛变量这两项的权重。这里的优化函数还是对偶问题之前的形式，我们马上会讨论对偶问题。</p><h1 id="Numerical-Optimization"><a href="#Numerical-Optimization" class="headerlink" title="Numerical Optimization"></a>Numerical Optimization</h1><p>这里讨论SVM高效求解的Sequential Minimal Optimization (SMO)算法。</p><p>坐标下降法是一种非梯度优化算法，</p><p><img src="https://i.loli.net/2020/09/08/I6AonzFRHGVBU3t.png"></p><p><img src="https://i.loli.net/2020/09/08/Hmr79nMlK4C8GeJ.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Still working on it😅…&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Machine Learning" scheme="http://qfxiao.me/categories/Technical-Notes/Machine-Learning/"/>
    
    
    <category term="SVM" scheme="http://qfxiao.me/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning Ensemble Algorithms: GBDT and XGBoost</title>
    <link href="http://qfxiao.me/2020/08/26/Machine-Learning-Ensemble-Algorithms-GBDT-and-XGBoost/"/>
    <id>http://qfxiao.me/2020/08/26/Machine-Learning-Ensemble-Algorithms-GBDT-and-XGBoost/</id>
    <published>2020-08-25T16:28:26.000Z</published>
    <updated>2021-02-28T05:38:18.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文主要介绍GBDT和XGBoost，在学习本文内容之前建议先学习<a href="http://hanzawa.me/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/">决策树相关内容</a>。</p><p>下面是一些有用的参考链接：</p><p><a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">XGBoost Documentation</a></p><p><a href="https://www.cnblogs.com/pinard/p/6133937.html">AdaBoost blog</a></p><p><a href="https://www.cnblogs.com/pinard/p/6140514.html">GBDT blog</a></p><p><a href="http://wepon.me/files/gbdt.pdf">slide</a></p><p><a href="https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf">陈天奇slide</a></p><p><a href="https://snaildove.github.io/2018/10/01/8.Booting-Methods_LiHang-Statistical-Learning-Methods/">blog</a></p><p><a href="https://snaildove.github.io/2018/10/02/get-started-XGBoost/">blog</a></p><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>实际上，GBDT和梯度下降、XGBoost和牛顿法之间是存在密切关系的，这里我们先回顾一下梯度下降算法和牛顿法的基础知识。</p><h2 id="Taylor-Formulation"><a href="#Taylor-Formulation" class="headerlink" title="Taylor Formulation"></a>Taylor Formulation</h2><p>函数$f(x)$在点$x_0$处的泰勒展开为：<br>$$<br>f(x)=\sum_{n=0}^\infty\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n<br>$$<br>特别的，一阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0)<br>$$<br>二阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0) + f^{\prime\prime}(x_0)\frac{(x-x_0)^2}{2}<br>$$<br>迭代形式：假设$x^t=x^{t-1}+\Delta x$，将$f(x)$在$x^{t-1}$处进行泰勒展开<br>$$<br>\begin{align}<br>f(x^t) &amp;= f(x^{t-1}+\Delta x)\<br>&amp;\approx f(x^{t-1})+f^\prime(x^{t-1})\Delta x + f^{\prime\prime}(x^{t-1})\frac{\Delta x^2}{2}<br>\end{align}<br>$$</p><h2 id="Gradient-Descend-Method"><a href="#Gradient-Descend-Method" class="headerlink" title="Gradient Descend Method"></a>Gradient Descend Method</h2><p>设参数$\theta$，那么参数对应的损失函数为$L(\theta)$，</p><p>设当前步数为$t$，那么$t-1$步时的参数为$\theta^{t-1}$，将$L(\theta^t)$在$\theta^{t-1}$处展开得到：</p><p>$$<br>L(\theta^t) \approx L(\theta^{t-1})+ L^\prime(\theta^{t-1})\Delta\theta<br>$$<br>我们想求的$\theta^t=\theta^{t-1}+\Delta \theta$</p><h2 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h2><p>将$L(\theta^t)$在$\theta^{t-1}$处进行二阶泰勒展开<br>$$<br>\begin{align}<br>L(\theta^t) &amp;= L(\theta^{t-1}+\Delta \theta)\<br>&amp;\approx L(\theta^{t-1})+L^\prime(\theta^{t-1})\Delta \theta + L^{\prime\prime}(\theta^{t-1})\frac{\Delta \theta^2}{2}<br>\end{align}<br>$$<br>记一阶导数和二阶导数分别为$g$和$H$，那么<br>$$<br>L(\theta^t)=L(\theta^{t-1})+g\Delta \theta + H\frac{\Delta \theta^2}{2}<br>$$<br>要使得迭代后的结果尽量小，即$g\Delta \theta + H\frac{\Delta \theta^2}{2}$尽量小，那么有$\frac{\left(g\Delta \theta + H\frac{\Delta \theta^2}{2}\right)}{\partial\Delta\theta}=0$</p><p>求得$\Delta \theta=H^{-1}g$，故$\theta^{t}=\theta^{t-1}+\Delta \theta=\theta^{t-1}-\frac{g}{h}$。如果$\theta$是一个向量，那么$\theta^{t}=\theta^{t-1}-H^{-1}g$，这里$H$为海森矩阵。</p><h1 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h1><p>我们首先来看基于树的Boosting模型中，非常经典的梯度提升树 (Gradient Boosting Decision Tree)。</p><h2 id="The-Additive-Model"><a href="#The-Additive-Model" class="headerlink" title="The Additive Model"></a>The Additive Model</h2><p>首先GBDT是一个加法模型，即最终模型由一系列树模型乘以对应权重相加得来：<br>$$<br>F_T(x;w)=\sum_{t=0}^T\alpha_t h_t(x;w_t)=\sum_{t=0}^T f_t(x;w_t)<br>$$<br>我们的目标是使得$F$的损失函数最小化：<br>$$<br>F_T^*=\mathop{\arg\min}\limits_{F}\sum_{i=1}^N L(y_i, F_T(x_i;w))<br>$$</p><p>直接优化这个损失函数复杂度是很高的，GBDT实际上运用了一种类似贪心的策略来优化这个函数，将优化过程分解成了迭代的步骤。</p><p>回想梯度下降算法进行优化的步骤，我们有参数$\theta$，损失函数$L(\theta)$是$\theta$的函数，我们希望找到最优的$\theta^*$使得$L(\theta^*)$最小，于是我们使用了迭代优化的步骤。假设迭代执行到第$t$步，也就是说我们现在的参数$\theta^{t-1}$为前面$t-1$步增量之和：$\theta^{t-1}=\sum_{j=1}^{t-1}\Delta \theta_j$，每一步的增量记为$\Delta \theta_t$。当前的增量$\Delta \theta_{t}$是怎么计算得到的呢？大家都知道是采用的损失函数在$\theta^{t-1}$的负梯度乘以一个步长，即$\Delta \theta_t=-\alpha_t \frac{\partial L(\theta)}{\partial \theta^{t-1}}$。</p><p>梯度下降相当于是在参数空间$\theta$找到最合适的参数$\theta^*$使得损失函数$L(\theta)$最小化，如果我们把模型$F_T$看作是函数空间，我们的目的是在函数空间中找到最优的$F_T^*$使得损失函数最小化，在这一个角度上GBDT和梯度下降就统一起来了。每一步的基模型$f_t$就相当于梯度下降中的增量$\Delta \theta$，所以我们就得到了GBDT每一的优化目标，即损失函数$L$对于$F_{t-1}$的负梯度。</p><table><thead><tr><th></th><th>梯度下降</th><th>GBDT</th></tr></thead><tbody><tr><td>损失函数</td><td>$L(\theta)$</td><td>$L(F_t)$</td></tr><tr><td>参数</td><td>$\theta^t$</td><td>$F_t$</td></tr><tr><td>增量</td><td>$\Delta \theta_t=-\alpha_t g_t$</td><td>$f_t=-\alpha_t g_t$</td></tr><tr><td>步长</td><td>$\alpha_t$</td><td>$\alpha_t$</td></tr><tr><td>初始值</td><td>$\theta_0$</td><td>$f_0$</td></tr></tbody></table><h2 id="Gradient-Boosting-Tree-for-Regression"><a href="#Gradient-Boosting-Tree-for-Regression" class="headerlink" title="Gradient Boosting Tree for Regression"></a>Gradient Boosting Tree for Regression</h2><p>我们先来讨论GBDT解决回归问题的算法。前面我们已经讨论过，在每一步GBDT的优化目标是损失函数的负梯度，那么现在的问题就是如何求得每一步最优的基模型（GBDT的基模型选用的是CART）。GBDT的算法步骤如下：</p><blockquote><p><strong>Gradient Boosting Tree Algorithm</strong></p><p>INPUT: 训练样本${(x_1,y_1),\cdots,(x_m,y_m)}$，迭代轮数$T$，损失函数$L$</p><p>OUTPUT: 强模型$F_T$</p><ol><li>初始化弱学习器$f_0$，直接使用一个基模型在训练集上进行训练</li><li>在步骤$t=1…T$，对于每个样本计算负梯度$r_{ti}=\left[\frac{\partial L(y_i,F_{t-1}(x_i))}{\partial F_{t-1}}\right]$</li><li>在$(x_i,r_{ti})$上训练得到一个CART回归树，确定树的结构</li><li>假设一共有$J$个叶子节点，那么对每个叶子节点计算最佳输出值$c_{tj}=\mathop{\arg\min}\limits_{c_{tj}}\sum_{x_i\in R_{tj}} L(y_i,F_{t-1}(x_i)+c_{tj})$（其中$c_{tj}$代表第$j$个叶子的输出，$R_{tj}$代表第$j$个叶子对应的样本集合），确定每个叶子节点的输出</li><li>更新强学习器$F_t=F_{t-1}+f_t$，回到步骤2直到达到迭代轮数</li><li>最终得到强学习器的表达式：$f(x)=f_0(x)+\sum\limits_{t=1}^T\sum\limits_{j=1}^J c_{tj}\mathrm I(x\in R_{tj})$</li></ol></blockquote><p>于是我们就得到了最终模型$F_T$。</p><h2 id="Gradient-Boosting-Tree-for-Classification"><a href="#Gradient-Boosting-Tree-for-Classification" class="headerlink" title="Gradient Boosting Tree for Classification"></a>Gradient Boosting Tree for Classification</h2><p>在处理分类任务时，由于输出是离散的值</p><p>一种方法是使用指数损失函数，此时GBDT退化为AdaBoost；另一种方法是借鉴逻辑回归的方法，去建模真实值的概率</p><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><h2 id="GBDT-Sumarry"><a href="#GBDT-Sumarry" class="headerlink" title="GBDT Sumarry"></a>GBDT Sumarry</h2><p>优点：</p><ol><li>可以灵活处理</li><li>相对SVM，调参较少</li><li>使用某些损失函数对异常值的鲁棒性高</li></ol><p>缺点：</p><ol><li>难以并行训练</li></ol><h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p>前面我们讲了梯度下降和牛顿法，刚才又讨论了GBDT和梯度下降的关系，那么XGBoost是否和牛顿法有什么关系呢？答案是肯定的。GBDT利用了损失函数在$F_{t-1}$的一阶展开（即一阶导数信息），而XGBoost则利用了损失函数在$F_{t-1}$的二阶展开，这也是XGBoost和GBDT最根本的区别。下面我们将详细讲解XGBoost算法。</p><table><thead><tr><th></th><th>牛顿法</th><th>XGBoost</th></tr></thead><tbody><tr><td>损失函数</td><td>$L(\theta)$</td><td>$L(F_t)$</td></tr><tr><td>参数</td><td>$\theta^t$</td><td>$F_t$</td></tr><tr><td>增量</td><td>$\Delta \theta_t=-\alpha_t H^{-1}_tg_t$</td><td>$f_t=-\alpha_t H^{-1}_tg_t$</td></tr><tr><td>步长</td><td>$\alpha_t$</td><td>$\alpha_t$</td></tr><tr><td>初始值</td><td>$\theta_0$</td><td>$f_0$</td></tr></tbody></table><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>XGBoost相比GBDT的另一大改进是加入了正则化项，即控制每个树的复杂度。衡量树的复杂度的度量有很多，XGBoost采用的是每棵树叶子节点的个数$T$和每个叶子节点输出$w$的平方和：<br>$$<br>\Omega(f)=\gamma T+\frac{1}{2}\lambda\parallel w\parallel^2<br>$$</p><p>这一步主要是为了进一步降低每个弱学习器的方差。</p><h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>加上正则项之后总的损失函数变为：<br>$$<br>L=\sum_{i=1}^N \ell(y_i, F_T(x_i))+\Omega(F_T)<br>$$<br>和GBDT类似，我们来推导第$t$步的优化公式，对于第$t$步，我们的损失函数为：<br>$$<br>\begin{align}<br>L_t&amp;=\sum_{i=1}^N \ell(y_i,F_t(x_i))+\Omega(F_t)\<br>&amp;=\sum_{i=1}^N \ell(y_i, F_{t-1}(x_i) + f_t(x_i))+\Omega(F_t)<br>\end{align}<br>$$<br>将损失函数在$F_{t-1}$处进行二阶泰勒展开，得到<br>$$<br>L_t \approx \left[\sum_{i=1}^N \ell(y_i, F_{t-1}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(F_t)<br>$$<br>其中$g_i=\frac{\partial \ell(y_i, F_{t-1})}{\partial F_{t-1}}$，$h_i=\frac{\partial \ell(y_i, F_{t-1}) ^2}{\partial^2 F_{t-1}}$，分别代表损失函数对$F_{t-1}$的一阶导和二阶导。</p><p>由于我们要优化的是本轮的基模型$f_t$，$\ell(y_i, F_{t-1})$已经是固定的了，相当于常数，把常数项去掉，得到：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(f_t)\<br>&amp;=\left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \gamma T + \frac{1}{2}\lambda \parallel w \parallel^2<br>\end{align}<br>$$<br>我们都知道样本$x_i$在树$f_t$上的输出取决于$x_i$在哪个叶子节点。假设树$f_t$一共有$J$个叶节点，记$q(x_i)=j$代表样本$x_i$经过决策树对应的叶节点是$j$，$I_j$代表叶子节点$j$的所有样本下标集合，$w_j$代表叶子节点$j$的输出，我们可以将损失函数改写为：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \sum_{j=1}^J\left[\sum_{i\in I_j}g_i w_j+\frac{1}{2}(\sum_{i\in I_j}h_i +\lambda)w_j^2\right]+\gamma T\<br>&amp;= \sum_{j=1}^J\left[G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2 \right] + \gamma T<br>\end{align}<br>$$<br>其中$G_j=\sum_{i\in I_j}g_i$和$H_j=\sum_{i\in I_j}h_i$为简记，分别代表损失函数在叶子节点$j$对应的所有样本上的一阶导之和与二阶导之和。</p><p>到现在，我们还剩两个问题需要解决，一个是确定树$f_t$的最优结构，也就是怎么去分裂节点，另一个是确定每个叶子节点的最优输出。我们可以先确定下一个问题，找到另一个问题的最优答案，再来确定剩下的问题。</p><p>这里先去寻找树$f_t$每一个叶子节点对应的最优输出。和牛顿法的推导类似，为了使损失函数下降的最快，我们令$G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2$的导数为$0$，得到：<br>$$<br>w_j^*=-\frac{G_j}{H_j + \lambda}<br>$$<br>加上正则项有：<br>$$<br>\tilde L_t^*=-\frac{1}{2}\sum_{j=1}^J\frac{G_j^2}{H_j+\lambda}+\gamma T<br>$$</p><h2 id="Splitting-Strategy"><a href="#Splitting-Strategy" class="headerlink" title="Splitting Strategy"></a>Splitting Strategy</h2><p>现在来确定树$f_t$的最优结构。最优结构的确定实际上使用了一种类似贪心的策略，和决策树类似，我们从一个只有根节点的树出发（所有样本都在根节点这一叶子节点上），不断分裂节点来降低$\tilde L_t^*$。在每一步的分裂中，我们会希望$\frac{G_j^2}{H_j+\lambda}$越大越好，于是：<br>$$<br>Gain = \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda} - \frac{(G_L+G_R)^2}{H_L+H_R+\lambda} - \gamma<br>$$</p><p>我们希望挑选能使得$Gain$最大的特征和特征分裂点，而选择的策略又有很多种，下面介绍三种。</p><h3 id="Exact-Greedy-Algorithm-for-Split-Finding"><a href="#Exact-Greedy-Algorithm-for-Split-Finding" class="headerlink" title="Exact Greedy Algorithm for Split Finding"></a>Exact Greedy Algorithm for Split Finding</h3><p>最简单的方法是枚举所有特征，然后对于这个特征下的所有可能取值进行排序，然后遍历分裂点，找到使得$gain$最高的那个。这样做的好处是找到的分裂点确定是最好的，不过坏处是时间复杂度过高。</p><h3 id="Approximate-Algorithm-for-Split-Finding"><a href="#Approximate-Algorithm-for-Split-Finding" class="headerlink" title="Approximate Algorithm for Split Finding"></a>Approximate Algorithm for Split Finding</h3><p>一个比较容易想到的优化方案是不去遍历所有可能的分裂点，而是只考察其中的分位数，如下图展示了三分位数方法：</p><p><img src="https://i.loli.net/2020/09/10/HoPR9XlpZSm1Gju.png"></p><p>这样需要考察的点就大大减少。</p><p>同时分位数的选择由有global和local之分，global是指在训练之前我们就可以提前对每个特征的分位数进行预处理，local是指每次分裂前计算分位数点。直观上来说global需要更多的分位点数，而local则需要更多的计算量。</p><p>实际上，XGBoost还会使用二阶导信息$h_i$对样本进行夹权，如下图所示：</p><p><img src="https://i.loli.net/2020/09/15/nxloKNmTHwJRqI9.png"></p><h3 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h3><p>稀疏感知分裂算法 (Sparsity-aware Split Finding) </p><h2 id="Other-Features"><a href="#Other-Features" class="headerlink" title="Other Features"></a>Other Features</h2><p>除了上面提到的之外，XGBoost还有很多工程优化。</p><h3 id="Block-Structure-and-Parallelism"><a href="#Block-Structure-and-Parallelism" class="headerlink" title="Block Structure and Parallelism"></a>Block Structure and Parallelism</h3><p>XGBoost预先对特征进行了排序，</p><p>每个特征的增益的计算可以并行进行</p><h3 id="Column-Sample"><a href="#Column-Sample" class="headerlink" title="Column Sample"></a>Column Sample</h3><p>借鉴随机森林，即每次只用一部分特征进行特征选择，进一步降低过拟合</p><h3 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h3><p>在每次迭代会对叶子节点的权总乘以一个系数，让后面的树有更大的学习空间。</p><h3 id="Custom-Loss-Function"><a href="#Custom-Loss-Function" class="headerlink" title="Custom Loss Function"></a>Custom Loss Function</h3><h3 id="Missing-Values"><a href="#Missing-Values" class="headerlink" title="Missing Values"></a>Missing Values</h3><h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h1><p><a href="https://zhuanlan.zhihu.com/p/227782064">parameter tuning</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文主要介绍GBDT和XGBoost，在学习本文内容之前建议</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Machine Learning" scheme="http://qfxiao.me/categories/Technical-Notes/Machine-Learning/"/>
    
    
    <category term="GBDT" scheme="http://qfxiao.me/tags/GBDT/"/>
    
    <category term="XGBoost" scheme="http://qfxiao.me/tags/XGBoost/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Representation Learning by Predicting Random Distances</title>
    <link href="http://qfxiao.me/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/"/>
    <id>http://qfxiao.me/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/</id>
    <published>2020-08-24T08:17:36.000Z</published>
    <updated>2020-08-24T10:25:42.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>针对高维表格数据的表示学习，作者提出了基于预测预计变换后的距离的无监督表示学习框架RDP，并进行了理论上的讨论。To be finished…</p><p><a href="https://arxiv.org/abs/1912.12186">论文地址</a>         <a href="https://github.com/billhhh/RDP">代码地址</a></p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Random-Distance-Prediction-Model"><a href="#Random-Distance-Prediction-Model" class="headerlink" title="Random Distance Prediction Model"></a>Random Distance Prediction Model</h2><p>对于很多下游任务来说，高维数据对模型效率和性能都很大，所以学习低维的有意义（能够最大限度保存原始空间的信息）的表示十分重要。本文的大致思想是给定一个确定的随机映射将样本映射到一个新的空间，然后构造数据集，输入时任意一对样本，标签是两个样本在新的空间的距离，之后训练一个模型来学习这个距离。作者认为通过该任务的训练，模型能够学到有意义的低维表示。模型的框架如下图：</p><img src="https://i.loli.net/2020/07/19/vRV32EgLiYkWaQN.png" style="zoom: 50%;" /><p>其中$\phi(\mathbf x;\Theta):\mathbb R^D\mapsto\mathbb R^M$为孪生神经网络（Siamese Neural Network），将数据映射到$M$的新空间。损失函数为：</p><p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=l(\langle \phi(\mathbf x_i;\Theta),\phi(\mathbf x_j;\Theta)\rangle,\langle\eta(\mathbf x_i),\eta(\mathbf x_j)\rangle)<br>$$</p><p>其中$\eta(\cdot)$为已知的映射，$l(\cdot)$为衡量两个输入相似程度的度量。具体的来说，文中选取了简单的实现方案，即采用内积作为映射后的样本的距离度量：</p><p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=\left(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)\right)^2<br>$$</p><p>$\eta(\cdot)$为现成的映射。至于为什么要这么做，可以先接着看下面原文给出的理论分析，然后我再说说我自己的理解。</p><h2 id="Incorporating-Task-Dependent-Complementary-Auxiliary-Loss"><a href="#Incorporating-Task-Dependent-Complementary-Auxiliary-Loss" class="headerlink" title="Incorporating Task-Dependent Complementary Auxiliary Loss"></a>Incorporating Task-Dependent Complementary Auxiliary Loss</h2><p>对于特定的下游任务，作者提出可以整合额外的误差函数来提高模型行性能。比如说针对聚类任务可以使用重构误差：</p><p>$$<br>\mathcal L_{aux}^{clu}(\mathbf x)=(\mathbf x-\phi^\prime(\phi(\mathbf x;\Theta); \Theta^\prime))^2<br>$$</p><p>其中$\phi(\cdot)$和$\phi^\prime(\cdot):\mathbb R^M\mapsto\mathbb R^D$分别为编码器和解码器。</p><p>对于异常检测任务，可以使用下式：<br>$$<br>\mathcal L_{aux}^{ad}(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2<br>$$</p><p>这一个Loss本来是出现在强化学习的论文中，用来检测一个状态$\mathbf x$出现的频率，如果预测误差较小，说明这个样本之前见过或见过类似的，否则没怎么见过，可以认为是异常。由于本文的目的主要是降维加保留原始空间信息，可以认为使用线性变换的话此目的已经达到了。</p><h2 id="Theoretical-Analysis"><a href="#Theoretical-Analysis" class="headerlink" title="Theoretical Analysis"></a>Theoretical Analysis</h2><h3 id="Using-Linear-Projection"><a href="#Using-Linear-Projection" class="headerlink" title="Using Linear Projection"></a>Using Linear Projection</h3><p>这里讨论使用线性映射的情况，设数据集$\mathcal X\subset\mathbb R^{N\times D}$，映射矩阵$\mathbf A\subset\mathbb R^{K\times D}$为一随机矩阵，映射之后的数据为$\mathbf A\mathcal X^\top$。对于$\epsilon\in(0,\frac{1}{2})$和$K=\frac{20\log n}{\epsilon^2}$，存在$f:\mathbb R^D\mapsto\mathbb R^K$使得对于所有的$\mathbf x_i,\mathbf x_j\in\mathcal X$有：</p><p>$$<br>(1-\epsilon)\parallel\mathbf x_i-\mathbf x_j \parallel^2\leq \parallel f(\mathbf x_i)-f(\mathbf x_j)\parallel^2\leq (1+\epsilon)\parallel\mathbf x_i-\mathbf x_j\parallel^2<br>$$</p><p>如果$\mathbf A$的每个元素独立采样自标准正态分布那么有：</p><p>$$<br>\text{Pr}\left((1-\epsilon)\parallel\mathbf x\parallel^2\leq\parallel\frac{1}{\sqrt{K}}\mathbf A\mathbf x\parallel^2\leq(1+\epsilon)\parallel\mathbf x\parallel^2\right)\geq 1-2e^{\frac{-(\epsilon^2-\epsilon^3)K}{4}}<br>$$</p><p>在该随机映射下有：</p><p>$$<br>\text{Pr}(|\hat{\mathbf x}_i\cdot\hat{\mathbf x}_j-f(\hat{\mathbf x}_i)\cdot f(\hat{\mathbf x}_j)|\geq\epsilon)\leq 4e^{\frac{-(\epsilon^2-\epsilon^3)\cdot K}{4}}<br>$$</p><p>直观的解释就是说使用线性映射的情况下，只要使用的变换矩阵采样自标准正态分布，那么变换之后样本对之间的距离信息能够以一定的概率保留。</p><h3 id="Using-Non-Linear-Projection"><a href="#Using-Non-Linear-Projection" class="headerlink" title="Using Non-Linear Projection"></a>Using Non-Linear Projection</h3><p>这里作者试图说明，在某些条件下，非线性随机映射的作用和核函数接近。对于一个确定的随机映射函数$g:\mathbb R^D\mapsto\mathbb R^K$，在某些特定的条件下，函数$g$和核函数存在下列关系：</p><p>$$<br>k(\mathbf x_i,\mathbf x_j)=\langle\psi(\mathbf x_i),\psi(\mathbf x_j)\rangle\approx g(\mathbf x_i)\cdot g(\mathbf x_j)<br>$$</p><p>这个条件是函数$g$为一个乘以一个线性矩阵$\mathbf A$然后在经过一个具备平移不变性的傅里叶基函数（如cosine）。由于核函数能够保留原始空间的信息，所以作者认为使用非线性函数也能保留原始空间的信息。</p><blockquote><p>PS: 感觉作者在理论部分的讨论还是有点模糊，因为把一个随机的映射作为（伪）监督信息来进行学习，神经网络学到的不也就是随机噪声信息吗？对于这个方法work的原因，我在这里不负责任的分析一下。</p></blockquote><h3 id="Learning-Class-Structure-by-Random-Distance-Prediction"><a href="#Learning-Class-Structure-by-Random-Distance-Prediction" class="headerlink" title="Learning Class Structure by Random Distance Prediction"></a>Learning Class Structure by Random Distance Prediction</h3><p>这一节主要解释为什么神经网络$\phi(\cdot)$学到的要比随机映射$\eta(\cdot)$要好。模型的优化目标可以写成如下的形式：</p><p>$$<br>\mathop{\arg\min}<em>{\Theta}\sum</em>{\mathbf x_i,\mathbf x_j\in\mathcal X}(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-y_{ij})^2<br>$$</p><p>其中$y_{ij}=\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)$。设$\mathbf Y_\eta\in\mathbb R^{N\times N}$为距离矩阵。这个目标函数是在最小化每一对样本在经过$\phi(\cdot)$和$\eta(\cdot)$映射后之间的距离的差距。通过公式(7)和公式(8)我们知道，在合适的条件下，随机映射$\eta(\cdot)$能够保留原始空间的距离信息（即原始空间相近的样本在映射后也相近）。不过，上述公式的成立都依赖于对数据分布的一定假设，当真实的数据不满足条件时，结论就会有所偏差。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Performance-Evaluation-in-Anomaly-Detection"><a href="#Performance-Evaluation-in-Anomaly-Detection" class="headerlink" title="Performance Evaluation in Anomaly Detection"></a>Performance Evaluation in Anomaly Detection</h2><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/3G7DNKjwfQkiIz4.png"></p><p>异常分数定义为$\mathcal S(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2$。</p><h3 id="Comparison-to-the-State-of-the-art-Competing-Methods"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/8Ie2Q3mpdPHtrYF.png"></p><p><img src="https://i.loli.net/2020/07/20/OEcQSvZmfBz1ACt.png"></p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p><img src="https://i.loli.net/2020/07/20/7GtKlN8q5Mvygre.png"></p><h2 id="Performance-Evaluation-in-Clustering"><a href="#Performance-Evaluation-in-Clustering" class="headerlink" title="Performance Evaluation in Clustering"></a>Performance Evaluation in Clustering</h2><h3 id="Experimental-Settings-1"><a href="#Experimental-Settings-1" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/9xW12MVkoXgFZ6J.png"></p><h3 id="Comparison-to-the-State-of-the-art-Competing-Methods-1"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods-1" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/pUZ64aX1xWiLf2q.png"></p><p><img src="https://i.loli.net/2020/07/20/VrnXuJsymiMItUf.png" alt="image-20200720014002063"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;针对高维表格数据的表示学习，作者提出了基于预测预计变换后的距</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Representation Learning" scheme="http://qfxiao.me/categories/Research/Representation-Learning/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
    <category term="Representation Learning" scheme="http://qfxiao.me/tags/Representation-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Effective End-to-end Unsupervised Outlier Detection via Linear Priority of Discriminative Network</title>
    <link href="http://qfxiao.me/2020/07/14/Effective-End-to-end-Unsupervised-Outlier-Detection-via-Linear-Priority-of-Discriminative-Network/"/>
    <id>http://qfxiao.me/2020/07/14/Effective-End-to-end-Unsupervised-Outlier-Detection-via-Linear-Priority-of-Discriminative-Network/</id>
    <published>2020-07-14T10:46:13.000Z</published>
    <updated>2020-07-21T12:35:42.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文针对无监督异常检测提出了$E^3\space{Outlier}$。作者使用自监督学习的方法，通过构建有监督任务在没有标签的情况下学习高层语义特征。PS：这篇文章的方法和NIPS18上的<em>Deep Anomaly Detection Using Geometric Transformations</em>（后面简称GEOM）颇为相似，但是不知为啥没有在实验中进行比较。后面我会分析一些两篇文章方法上的异同。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Surrogate-Supervision-Based-Effective-Representation-Learning-for-UOD"><a href="#Surrogate-Supervision-Based-Effective-Representation-Learning-for-UOD" class="headerlink" title="Surrogate Supervision Based Effective Representation Learning for UOD"></a>Surrogate Supervision Based Effective Representation Learning for UOD</h2><p>这里作者提到了使用重构的模型来进行异常检测的不足：重构模型采用像素级别的损失函数（如mean square error），而这太过于严格和细节，并不能学到高层语义特征。</p><p>为此，作者提出了<em>surrogate supervision based discriminative network</em> (SSD)。具体操作和GEOM类似，首先预定义大小为$K$的几何变换集合$\mathcal O={O(\cdot|y)}<em>{y=1}^K$。对每一个样本$\mathbf x$，在经过$K$个集合变换之后会得到$K$个变换后的样本（第$y$个变换产生的样本即记为$\mathbf x^{(y)}=O(\mathbf x|y)$），每个样本对应的pseudo label即为变换的序号或者说种类。之后在新的数据集上（大小为原来的$K$倍）训练$K$分类网络。网络的输出为$P(\mathbf x^{(y^\prime)}|\boldsymbol\theta)=[P^{(y)}(\mathbf x^{(y^\prime)}|\boldsymbol\theta)]</em>{y=1}^K$，每个维度代表输入样本对应的变换的概率。总的损失函数为：<br>$$<br>\min_\theta\frac{1}{N}\sum_{i=1}^{N}\mathcal L_{SS}(\mathbf x_i|\theta)<br>$$</p><p>其中$\mathcal L_{SS}(\mathbf x_i|\theta)$代表每个样本对应的Loss，这个Loss可以由分类器在$K$个变换上的交叉熵损失来确定：</p><p>$$<br>\mathcal L_{SS}(\mathbf x_i|\boldsymbol\theta)=-\frac{1}{K}\sum_{y=1}^K\log(P^{(y)}(\mathbf x_i^{(y)}|\boldsymbol\theta))=-\frac{1}{K}\sum_{y=1}^K\log(P^{(y)}(O(\mathbf x_i|y)|\boldsymbol\theta))<br>$$<br><img src="https://i.loli.net/2020/07/14/ULAdYpzsoGfFwtD.png"></p><p>变换集合$\mathcal O$由一系列基本变换的组合确定。作者将这些基本变换分为了：1) 旋转 2) 翻转 3) 平移，包括横向和纵向 4) Patch置换（参考图1(a)中的Patch Re-arranging）。最终的变换集合$\mathcal O$由三个子集组成，分别是$\mathcal O_{RA}$（代表Regular Affine，其中每个变换为旋转$90°$的倍数、翻转、横向平移和纵向平移这四个基本变换的叠加），$\mathcal O_{IA}$（代表Irregular Affine，其中每个变换为进行$30°$的倍数且不为$90°$的倍数角度的旋转、翻转这两个基本变换的叠加）和$\mathcal O_{PR}$（只包含Patch Re-arranging）。</p><p>为了验证SSD学到的特征的有效性，作者将CAE提取的特征和SSD提取的特征分别用孤立森林进行异常检测，发现SSD效果更好（见图1(b)）。</p><p>到这里为止本文和GEOM基本没有大的区别。值得注意的是在所采用的几何变换中，采用了非线性变换（进行$30°$的倍数且不为$90°$的倍数角度的旋转）。而在GEOM中，提到过使用非线性变换的话效果会比较差，至于具体的影响如何，可能需要实验来确定。</p><h2 id="Inlier-Priority-The-Foundation-of-End-to-end-UOD"><a href="#Inlier-Priority-The-Foundation-of-End-to-end-UOD" class="headerlink" title="Inlier Priority: The Foundation of End-to-end UOD"></a>Inlier Priority: The Foundation of End-to-end UOD</h2><p>在这里作者主要对在训练集包含少量异常的情况下做出的理论分析，作者将其称为<em>Inlier Priority</em>，原句如下：</p><blockquote><p><em>Inlier Priority</em>: Despite that inliers/outliersare indiscriminately fed into SSD for training, SSD will prioritize the minimization of inliers’ loss.</p></blockquote><h3 id="Priority-by-Gradient-Magnitude"><a href="#Priority-by-Gradient-Magnitude" class="headerlink" title="Priority by Gradient Magnitude"></a>Priority by Gradient Magnitude</h3><p>对于第$c$个类来说，设<code>softmax</code>层和倒数第二层之间的权重矩阵为$\mathbf w_c=[w_{s,c}]^{(L+1)}<em>{s=1}$，损失函数记为$\mathcal L$，梯度记为$\nabla</em>{\mathbf w_c}\mathcal L=[\nabla_{w_{s,c}}\mathcal L]^{(L+1)}<em>{s=1}$。设训练集$X^{(c)}$包含$N</em>{in}$个正常样本，$N_{out}$个异常样本。记正常样本和异常样本对应的梯度分别为$\parallel\nabla^{(in)}_{\mathbf w_c}\mathcal L\parallel$和$\parallel\nabla^{(out)}_{\mathbf w_c}\mathcal L\parallel$，在网络只有一个隐层且采用<code>Sigmoid</code>作为激活函数时，两者梯度的期望之比有如下关系：</p><p>$$<br>\frac{E(\parallel\nabla^{(in)}<em>{\mathbf w_c}\mathcal L\parallel^2)}{E(\parallel\nabla^{(out)}_{\mathbf w_c}\mathcal L\parallel^2)}\approx\frac{N^2_{in}}{N^2</em>{out}}<br>$$</p><p>在训练集中，正常样本和异常样本的数量是极不均衡的，$N_{in}\gg N_{out}$，所以有$E(\parallel\nabla^{(in)}_{\mathbf w_c}\mathcal L\parallel^2)\gg E(\parallel\nabla^{(out)}_{\mathbf w_c}\mathcal L\parallel^2)$。</p><p>在使用更复杂的网络时，作者通过实验展示了正常样本和异常样本对应的梯度大小的比较：</p><p><img src="https://i.loli.net/2020/07/16/iPa7h9HWqrnZvgx.png"></p><h3 id="Priority-by-Network-Updating-Direction"><a href="#Priority-by-Network-Updating-Direction" class="headerlink" title="Priority by Network Updating Direction"></a>Priority by Network Updating Direction</h3><p>这里作者通过梯度更新的方向来进行了理论上的解释。对于一个Batch的数据$X$，梯度为$-\nabla_\theta\mathcal L(X)=-\frac{1}{N}\sum_i\nabla_\theta\mathcal L(\mathbf x_i)$，如果将该梯度在Batch中某一样本$\mathbf x_i$对应的梯度的方向上进行分解$-\nabla_\theta\mathcal L(\mathbf x_i):d_i=-\nabla_\theta\mathcal L(X)\cdot\frac{-\nabla_\theta\mathcal L(\mathbf x_i)}{\parallel -\nabla_\theta\mathcal L(\mathbf x_i)\parallel}$，这代表了总的Loss在多大程度上减小样本$\mathbf x_i$对应的Loss，由于一个Batch即包含正常样本，也可能包含异常样本，所以作者将两者对应的梯度方向贡献进行了可视化：</p><p><img src="https://i.loli.net/2020/07/16/U5fVk8YOEGPx3Q7.png"></p><p>可以看到随着训练的进行，正常样本对应的贡献更高。</p><p>PS: 我以为作者会对基于几何变换的异常检测为什么有效做一些理论上的解释，不过却没有。这里只是对在训练集包含少量异常的情况下做出的理论分析，而这个实际上直觉上就很显然了。</p><h2 id="Scoring-Strategies-for-UOD"><a href="#Scoring-Strategies-for-UOD" class="headerlink" title="Scoring Strategies for UOD"></a>Scoring Strategies for UOD</h2><p>作者采用了三种方法来计算异常分数：</p><h3 id="Pseudo-Label-based-Score-PL"><a href="#Pseudo-Label-based-Score-PL" class="headerlink" title="Pseudo Label based Score (PL)"></a>Pseudo Label based Score (PL)</h3><p>对于一个测试样本$\mathbf x$，对其进行$K$个几何变换，通过分类器会得到$K$个输出，对于第$k$个输出，我们只取其第$k$个分量，最后把他们加起来除以$K$：</p><p>$$<br>S_{pl}(\mathbf x)=\frac{1}{K}\sum_{y=1}^K P^{(y)}(\mathbf x^{(y)}|\boldsymbol\theta)<br>$$</p><h3 id="Maximum-Probability-based-Score-MP"><a href="#Maximum-Probability-based-Score-MP" class="headerlink" title="Maximum Probability based Score (MP)"></a>Maximum Probability based Score (MP)</h3><p>这里稍有不同，对于第$k$个输出，我们取其值最大的分量，而不是第$k$个分量：</p><p>$$<br>S_{mp}(\mathbf x)=\frac{1}{K}\sum_{y=1}^K\max_t P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta)<br>$$</p><h3 id="Negative-Entropy-based-Score-NE"><a href="#Negative-Entropy-based-Score-NE" class="headerlink" title="Negative Entropy based Score (NE)"></a>Negative Entropy based Score (NE)</h3><p>作者认为，标签为One-Hot向量，分类器的输出分布越“尖峰”就越接近于正常样本，而越“平均”就越接近于异常样本，所以作者提出使用熵来描述分类器输出的“尖锐度”：<br>$$<br>S_{ne}(\mathbf x)=-\frac{1}{K}\sum_{y=1}^K H(P(\mathbf x^{(y)}|\boldsymbol\theta))=\frac{1}{K}\sum_{y=1}^K\sum_{t=1}^K P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta)\log(P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta))<br>$$<br>这里作者对第一种方法得到的结果进行了可视化：</p><p><img src="https://i.loli.net/2020/07/16/PgzqXIdJ67s3BtG.png"></p><p>PS：对比NIPS18 的Dirichlet Normality Score</p><ol><li>也用到了全部$K$个维度的信息</li><li>相当于对分类器的输出做了迪利克雷分布的先验假设，然后通过训练集的输出估计分布参数。因为直觉上对于正常分布来说，分类器的输出分布形状上都类似一个尖峰，但对于不同的数据集来说具体形状还是会有所差异</li></ol><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Experiment-Setup"><a href="#Experiment-Setup" class="headerlink" title="Experiment Setup"></a>Experiment Setup</h2><p> 数据集用到了MNIST, Fashion-MNIST (F-MNIST) , CIFAR10, SVHN和CIFAR100。为了模拟无监督异常检测的环境，人为在训练集中加入异常样本，异常的比例$\rho$从$5%$到$25%$以$5%$的步长递增。评测标准采用AUPR和AUROC。</p><h2 id="UOD-Performance-Comparison-and-Discussion"><a href="#UOD-Performance-Comparison-and-Discussion" class="headerlink" title="UOD Performance Comparison and Discussion"></a>UOD Performance Comparison and Discussion</h2><p>下表展示了模型性能对比结果：</p><p><img src="https://i.loli.net/2020/07/16/G3agKPuJBowFmIW.png"></p><p>下图展示了在不同的Outlier Ratio下的性能对比：</p><p><img src="https://i.loli.net/2020/07/16/h6iYjBkrwQdFvMJ.png"></p><p>下图展示了在不同的变换集合，网络结构，异常分数的条件下的性能：</p><p><img src="https://i.loli.net/2020/07/16/waWAi7zI3QpOcf6.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文针对无监督异常检测提出了$E^3\space{Outli</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Self-Supervised Learning" scheme="http://qfxiao.me/tags/Self-Supervised-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Probability Distributions - Binary and Multinomial Variables</title>
    <link href="http://qfxiao.me/2020/06/22/Probability-Distributions-Binary-and-Multinomial-Variables/"/>
    <id>http://qfxiao.me/2020/06/22/Probability-Distributions-Binary-and-Multinomial-Variables/</id>
    <published>2020-06-22T05:43:58.000Z</published>
    <updated>2021-02-19T10:26:08.671Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>本文主要是介绍一些机器学习中常用的分布，内容主要来自PRML (Pattern Recognition and Machine Learning) 第二章<code>Probability Distributions</code>笔记的第一部分，主要包括<code>2.1. Binary Variables</code>和<code>2.2. Multinomial Variables</code>这两节。</p><h1 id="Probability-Distributions-for-Binary-Variables"><a href="#Probability-Distributions-for-Binary-Variables" class="headerlink" title="Probability Distributions for Binary Variables"></a>Probability Distributions for Binary Variables</h1><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>这一节主要针对二值随机变量的建模，即$x\in{0,1}$。这里可以想象为我们有一个硬币，$x=1$代表正面朝上，而$x=0$代表反面朝上，并且正面朝上的概率为$\mu$，即：<br>$$<br>p(x=1|\mu)=\mu<br>$$<br>其中$0\leqslant \mu \leqslant 1$。$x$的概率分布可以写为：<br>$$<br>\text{Bern}(x|\mu)=\mu^x(1-\mu)^{1-x}<br>$$<br>也就是我们熟知的**伯努利分布 (Bernoulli Distribution)**。其均值和方差分别为：<br>$$<br>\begin{align}<br>\mathbb E[x]&amp;=\mu\<br>\text{var}[x] &amp;= \mu(1-\mu)<br>\end{align}<br>$$<br>现在来考虑参数估计任务。假设我们正在进行一个投硬币的实验，每一次投币都服从伯努利分布且相互独立，我们将每次采集到的观测值组成数据集$\mathcal D={x_1,\cdots,x_N}$，则似然函数为：<br>$$<br>p(\mathcal D|\mu)=\prod_{n=1}^N p(x_n|\mu)=\prod_{n=1}^N \mu^{x_n}(1-\mu)^{1-x_n}<br>$$<br>如果采用极大似然估计的话，我们可以最大化似然函数，这等价于最大化对数似然：<br>$$<br>\ln p(\mathcal D|\mu)=\sum_{n=1}^{N}\ln p(x_n|\mu)=\sum_{n=1}^N{x_n\ln\mu+(1-x_n)\ln(1-\mu)}<br>$$<br>令其导数为0得到极值点：<br>$$<br>\mu_{ML}=\frac{1}{N}\sum_{n=1}^N x_n<br>$$<br>这相当于样本均值，不过这样做会有严重的问题。假设我们的数据集为$\mathcal D={1,1,1}$，也就是说我们只收集到了三个样本，并且都是正例，我们会得到$\mu_{ML}=1$，而这显然是严重过拟合的。稍后我们会说说如何应对这种情况（加入先验）。</p><h2 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h2><p>我们同样可以对多次伯努利实验进行概率建模。记$m$为成功的次数，$N$为数据集大小，可知这个概率应该与$\mu^m(1-\mu)^{N-m}$成正比。乘以标准化系数后即我们熟知的**二项分布 (Binomial Distribution)**：<br>$$<br>\text{Bin}(m|N,\mu)=\binom{N}{m}\mu^m(1-\mu)^{N-m}<br>$$</p><p>其中：<br>$$<br>\binom{N}{m}=\frac{N!}{(N-m)!m!}<br>$$<br>其均值和方差分别为：<br>$$<br>\begin{align}<br>\mathbb E[m]&amp;=N\mu\<br>\text{var}[m]&amp;=N\mu(1-\mu)<br>\end{align}<br>$$</p><h2 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a>Beta Distribution</h2><p>现在我们来讨论如何解决刚才提到的最大似然估计过拟合问题。为了解决这个问题，我们使用贝叶斯的思路，对$\mu$引入了先验分布$p(\mu)$。而这个分布需要具有良好的解释性和数学性质。</p><p>根据贝叶斯定理：<br>$$<br>p(\mu|\mathcal D)=\frac{p(\mathcal D|\mu)p(\mu)}{p(\mathcal D)}<br>$$<br>而$p(\mathcal D)=\int_0^1 p(\mathcal D|\mu)p(\mu)\mathrm d\mu$只受数据集影响，而数据集是固定的，所以为常数，因此$p(\mu|\mathcal D)\propto p(\mathcal D|\mu)p(\mu)$。而似然函数为$\mu^x(1-\mu)^{1-x}$的乘积，如果先验也采用$\mu$和$1-\mu$的幂的乘积的形式，那么后验分布也将和先验形式相同，这种性质在统计学中被称为**先验共轭 (conjugacy)**。</p><p>这里我们直接给出这个先验分布，再来分析它的性质。这个分布叫做<strong>Beta分布 (Beta Distribution)</strong>$P(\mu|a,b)\sim \text{Beta}(a,b)$：<br>$$<br>\begin{align}<br>\text{Beta}(\mu|a,b) &amp;= \frac{\Gamma(a+b)}{\Gamma(a\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\ &amp;= \frac{1}{B(a,b)}\mu^{a-1}(1-\mu)^{b-1}<br>\end{align}<br>$$<br>$B(\boldsymbol \alpha,\beta)$称为B函数，为一个标准化函数：<br>$$<br>\begin{align}<br>B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}<br>\end{align}<br>$$<br>其目的是为了使整个概率分布积分等于1而存在的。Gamma函数的定义为：<br>$$<br>\Gamma(x)=\int_0^{\infty}s^{x-1}e^{-s}\mathrm d s<br>$$<br>Gamma函数有一个性质：</p><p>$$<br>\Gamma(x+1)=x\Gamma(x)<br>$$<br>证明为：<br>$$<br>\begin{align*}<br>\Gamma(x+1) &amp;= \int_{0}^{\infty} {s^{x} e^{-s} ds} \<br>&amp;= \big[s^{x} (-e^{-s})\big] \big|<em>{0}^{\infty} - \int</em>{0}^{\infty} {(x s^{x-1}) (-e^{-s}) ds} \<br>&amp;= (0 - 0) + x \int_{0}^{\infty} {s^{x-1} e^{-s} ds} \<br>&amp;= x \Gamma(x)<br>\end{align*}<br>$$</p><p>除此之外：</p><p>$$<br>\Gamma(1)=1\<br>\Gamma(\frac{1}{2})=\sqrt{\pi}<br>$$</p><p>可以验证：<br>$$<br>\int_0^1\text{Beta}(\mu|a,b)\mathrm d\mu=1<br>$$</p><p>Beta分布的均值和方差为：</p><p>$$<br>\mathbb E[\mu]=\frac{a}{a+b}\<br>\text{var}[\mu]=\frac{ab}{(a+b)^2(a+b+1)}<br>$$</p><p>因为后验分布与先验和似然函数的乘积成比例，那么：<br>$$<br>p(\mu|m,l,a,b)\propto\mu^{m+a-1}(1-\mu)^{l+b-1}<br>$$</p><p>其中$l=N-m$。乘上标准化因子，就得到：<br>$$<br>p(\mu|m,l,a,b)=\frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1}<br>$$<br>得到的仍然是Beta分布，相当于把$a\rightarrow{m+a}$，$b\rightarrow{l+b}$。同时不难发现，参数$a$和$b$都有比较直观的意义。$a$可以看作是历史记录中，成功的次数，$b$可以看作是历史记录中失败的次数，比如$a=2$，$b=3$，根据经验成功的概率应该在$\frac{2}{2+3}=0.4$左右，即我们的先验为成功的概率为$0.4$（见下图左下角的子图）。如果在实验中，又进行了$7$次实验，其中$m=6$，$l=1$，由于成功的次数变多了，$a=2+6=8$，$b=3+1=4$，直觉上来说我们对成功概率的估计应当相应提高，大概为$\frac{8}{8+4}\approx 0.67$左右。这时的Beta分布如右下角的图的样子，也印证了我们的直觉。</p><img src="https://i.loli.net/2020/06/25/3hcj18ELXl4iWy6.png" style="zoom:67%;" /><p>以下为不同参数对应的Beta分布的互动演示：</p><div><iframe width="650px" height="450px" frameborder="0" style="dispaly:block；" src="http://qfxiao.me/html/beta_distribution_vis.html"></iframe></div><p>最后，Beta还有一个有趣的应用就是，如果我们不断接收到新的观测数据，那么旧的后验分布则可以作为新的先验分布将参数更新下去 。这相当于说，基于已有的观测数据，我们提出一个先验Beta分布，然后根据新得到的一批观测数据，用先验Beta分布计算一个似然函数，将似然函数和先验Beta分布乘起来，归一化后得到了新的后验分布，只要不断有新的观测数据接收到，就可以把后验分布作为新的先验，不断更新下去。这样做的优势是对于大数据集，我们不需要整个数据集，而是只需要一批一批的更新即可。</p><h1 id="Probability-Distributions-for-Multinomial-Variables"><a href="#Probability-Distributions-for-Multinomial-Variables" class="headerlink" title="Probability Distributions for Multinomial Variables"></a>Probability Distributions for Multinomial Variables</h1><h2 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h2><p>前面我们讨论了二值随机变量，现在我们将其扩展到多值变量。设一个$K$维向量$\mathbf x$，当$x_k$为$1$的时候其他元素都为$0$，如$K=6,x_3=1$时$\mathbf x$表示为$\mathbf x=(0,0,1,0,0,0)^\top$。如果$p(x_k=1)=\mu_k$，那么$\mathbf x$的概率分布为：<br>$$<br>p(\mathbf x|\boldsymbol \mu)=\prod_{k=1}^{K}\mu_k^{x_k}<br>$$<br>$\mu_k$满足$\sum_k \mu_k=1$和$\mu_k\geqslant 0$，该分布被称作是<strong>Categorical Distribution</strong>。易知其均值为：<br>$$<br>\begin{align}<br>\mathbb E[\mathbf x|\boldsymbol \mu]=\sum_{\mathbf x}p(\mathbf x|\boldsymbol \mu)\mathbf x=\boldsymbol \mu<br>\end{align}<br>$$<br>假设我们有大小为$N$的数据集$\mathcal D$，每个样本服从该分布且相互独立，那么似然函数：<br>$$<br>p(\mathcal D|\boldsymbol \mu)=\prod_{n=1}^N\prod_{k=1}^K \mu_k^{x_{nk}}=\prod_{k=1}^K \mu_k^{\sum_n x_{nk}}=\prod_{k=1}^K\mu_k^{m_k}<br>$$<br>其中$m_k=\sum_n x_{nk}$，即$x_k=1$的数量。为了最大化对数似然同时保证$\sum_k \mu_k=1$，我们可以用拉格朗日乘子法：<br>$$<br>\sum_{k=1}^K m_k\ln \mu_k+\lambda\left(\sum_{k=1}^K\mu_k-1\right)<br>$$<br>我们得到$\mu_k=-m_k/\lambda$。通过$\sum_k \mu_k=1$得出$\lambda=-N$，故最后我们有：<br>$$<br>\mu_k^{ML}=\frac{m_k}{N}<br>$$</p><p>这相当于是$x_k=1$的数量除以总数。</p><h2 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h2><p>类似的，我们可以对多次实验进行建模，假设进行$N$次独立实验，概率分布可以写为：</p><p>$$<br>\text{Mult}(m_1,m_2,\cdots,m_K|\boldsymbol\mu,N)=\binom{N}{m_1m_2\cdots m_K}\prod_{k=1}^K\mu_k^{m_k}<br>$$</p><p>这也是我们熟知的**多项分布 (Multinomial Distribution)**，其中$\binom{N}{m_1m_2\cdots m_K}$为正则化因子：<br>$$<br>\binom{N}{m_1m_2\cdots m_K}=\frac{N!}{m_1!m_2!\cdots m_K!}<br>$$<br>注意$\sum\limits_{k=1}^K m_k=N$。</p><h2 id="Dirichlet-Distribution"><a href="#Dirichlet-Distribution" class="headerlink" title="Dirichlet Distribution"></a>Dirichlet Distribution</h2><p>有了前面Beta的启发，我们同样可以对多项分布的参数$\mu_k$建立共轭先验。首先根据似然函数，我们知道先验应当与$\mu_k$的幂的乘积成比例：</p><p>$$<br>p(\boldsymbol \mu|\boldsymbol \alpha) \propto \prod_{k=1}^{K}\mu_k^{a_{k-1}}<br>$$</p><p>其中$0\leqslant \mu_k\leqslant 1$且$\sum_k\mu_k=1$。和Beta分布不同，由于要满足$\sum\mu_k=1$，所以${\mu_k}$的取值会位于$K-1$的单纯型上，如下图所示：</p><img src="https://i.loli.net/2020/06/25/N8CSMvmlRz91Gqy.png" style="zoom:67%;" /><p>加上标准化因子，我们就得到了所谓的先验分布，称之为**迪利克雷分布 (Dirichlet Distribution)**：<br>$$<br>\text{Dir}(\boldsymbol \mu|\boldsymbol\alpha)=\frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1)\cdots\Gamma(\alpha_K)}\prod_{k=1}^K\mu_k^{a_{k-1}}<br>$$</p><p>其中$\Gamma(\cdot)$为Gamma函数，$\alpha_0=\sum\limits_{k=1}^K\alpha_k$。下图为不同条件下的迪利克雷分布的可视化：</p><p><img src="https://i.loli.net/2020/06/25/amGtuvPNoOM7kWZ.png"></p><p>$\boldsymbol \mu$的后验与先验和似然函数的乘积成正比：</p><p>$$<br>p(\boldsymbol\mu|\mathcal D,\boldsymbol\alpha)\propto p(\mathcal D|\boldsymbol\mu)p(\boldsymbol\mu|\boldsymbol\alpha)\propto\prod_{k=1}^K \mu_k^{\alpha_k+m_k-1}<br>$$</p><p>不难验证：</p><p>$$<br>\begin{align}<br>p(\boldsymbol\mu|\mathcal D,\boldsymbol\alpha) &amp;= \text{Dir}(\boldsymbol\mu|\boldsymbol\alpha+\mathbf m)\<br>&amp;=\frac{\Gamma(\alpha_0+N)}{\Gamma(\alpha_1+m_1)\cdots\Gamma(\alpha_K+m_K)}\prod_{k=1}^K\mu_k^{\alpha_k+m_k-1}<br>\end{align}<br>$$</p><p>即后验同样为迪利克雷分布。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;p&gt;本文主要是介绍一些机器学习中常用的分布，内容主要来自PRML (Pattern Recogn</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Notes" scheme="http://qfxiao.me/categories/Research/Notes/"/>
    
    
    <category term="Statistics" scheme="http://qfxiao.me/tags/Statistics/"/>
    
    <category term="Probability" scheme="http://qfxiao.me/tags/Probability/"/>
    
  </entry>
  
  <entry>
    <title>Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets</title>
    <link href="http://qfxiao.me/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/"/>
    <id>http://qfxiao.me/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/</id>
    <published>2020-06-13T08:42:04.000Z</published>
    <updated>2020-07-07T03:15:36.315Z</updated>
    
    <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1><p>本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的<em>time-aware shapelet</em>，并且定义了<em>shapelet evolution graph</em>来捕获Shapelet在时间维度上的动态变化。</p><p><a href="https://arxiv.org/abs/1911.04143">📰Get Paper</a></p><h1 id="preliminaries">Preliminaries</h1><p>时间序列集合<span class="math inline">\(T=\{t_1,\cdots,t_{|T|}\}\)</span>包含若干条时序数据<span class="math inline">\(t=\{x_1,\cdots,x_n\}\)</span>。一个<span class="math inline">\(t\)</span>的片段<span class="math inline">\(s\)</span>是<span class="math inline">\(t\)</span>的一个连续子序列。如果<span class="math inline">\(t\)</span>能被切分成<span class="math inline">\(m\)</span>个长度都为<span class="math inline">\(l\)</span>的片段，那么我们就有<span class="math inline">\(t=\{\{x_{l*k+1},\cdots,x_{l*k+l}\},0\leq k\leq m-1\}\)</span>。两个长度相等的片段之间距离很好度量，直接计算欧式距离即可，那么两个片段长度不相等的情况呢？这就需要对其（Alignment）的概念。</p><blockquote><p><strong>Definition 1 </strong> <strong><em>Alignment</em></strong>. 给定两个长度分别为<span class="math inline">\(l_i\)</span>和<span class="math inline">\(l_j\)</span>的序列<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，一个<em>alignment</em> <span class="math inline">\(a=(a_1,a_2)\)</span>是一个满足以下条件的长度为<span class="math inline">\(p\)</span>的下标序列： <span class="math display">\[1\leq a_k(1)\leq\cdots\leq a_k(p)=l_k,\\a_k(n+1)-a_k(n)\leq 1,\\\text{for }k=i,j,\text{ and }1\leq n\leq p-1\]</span></p></blockquote><p>上述公式可能比较抽象，其实看了下图就不难理解：</p><p><img src="https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png" style="zoom:67%;" /></p><p>片段<span class="math inline">\(s_i\)</span>中的某个点<span class="math inline">\(a\)</span>，与片段<span class="math inline">\(s_j\)</span>中的某个点<span class="math inline">\(b\)</span>形成对应，然后在<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>之间连一条虚拟的线（不能与已有的线交叉），一直这么做直到短的那个片段中的每个点都找到对应，就是一个合理的<em>alignment</em>。对于两个长度不一样的片段<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，会有很多种<em>alignment</em>。我们把<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>所有可能的<em>alignment</em>记为<span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>。在定义了<em>alignment</em>之后就可以定义DTW了。DTW (<em>Dynamic Time Warping</em>) 定义为在给定一个预定义的距离度量<span class="math inline">\(\tau\)</span>和所有可能的<em>alignment</em> <span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>的情况下，最小的距离<span class="math inline">\(\tau\)</span>： <span class="math display">\[d_\text{DTW}(s_i,s_j)=\min_{a\in\mathcal{A}(s_i,s_j)}\tau(s_i,s_j|a)\]</span></p><p>进一步的，因为时间序列<span class="math inline">\(t\)</span>也可以看作是一个片段，我们可以定义一个子序列<span class="math inline">\(s\)</span>和时间序列<span class="math inline">\(t\)</span>之间的距离度量： <span class="math display">\[D(s,t)=\min_{1\leq k\leq m} d(s,s_k)\]</span></p><p>这里<span class="math inline">\(\boldsymbol s_k\)</span>为时序<span class="math inline">\(\boldsymbol t\)</span>分解成的片段。之后Shapelet可以通过片段与时序的距离定义为最具有辨识度的有代表性的片段：</p><blockquote><p><strong>Definition 2 </strong> <strong>Shapelet. </strong>一个Shapelet <span class="math inline">\(\boldsymbol v\)</span>是对于特定类别时序的最具有代表性的片段。考虑时序分类任务，给定时序集合<span class="math inline">\(T\)</span>，可以通过与<span class="math inline">\(\boldsymbol v\)</span>相似或不相似而分成两个子集合，与<span class="math inline">\(\boldsymbol v\)</span>相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量小，与<span class="math inline">\(\boldsymbol v\)</span>不相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量大，此时损失函数可以形式化为： <span class="math display">\[\mathcal L=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))\]</span></p></blockquote><p><span class="math inline">\(\mathcal L\)</span>描述了在shapelet <span class="math inline">\(\boldsymbol v\)</span>下正负样本集的相异性。<span class="math inline">\(S_{*}(\boldsymbol v,T)\)</span>表示特定时序集合与<span class="math inline">\(\boldsymbol v\)</span>的距离集合，<span class="math inline">\(g(\cdot,\cdot)\)</span>为接受两个有限集合为输入的可微函数，并且能够度量两个集合的距离。</p><h1 id="framework">Framework</h1><p>本文主要是提出了一种时间序列表示学习方法。基于Shapelet在不同的时间片段上的作用是不同的观察，作者为不同的时间片段赋予了不同的Shapelet，而不是像传统方法一样整个时序对应一个Shapelet。接着基于这些Shapelet作者构造了图，并通过图嵌入得到了嵌入向量，作为时序的表示。</p><p><img src="https://i.loli.net/2020/06/25/mKJH4c2EMAljavG.png" style="zoom:80%;" /></p><h2 id="time-aware-shapelet-extraction">Time-Aware Shapelet Extraction</h2><p>第一步是捕获Shapelet在时间维度上的动态影响。我们定义了两个参数来定量的测量shapelet在不同时间上的动态性。第一个是局部因子<span class="math inline">\(\boldsymbol w_n\)</span>，用来控制shapelet内部<span class="math inline">\(n\)</span>个元素的权重，那么shapelet <span class="math inline">\(\boldsymbol v\)</span>和片段<span class="math inline">\(\boldsymbol s\)</span>的距离为： <span class="math display">\[\begin{align}\hat{d}(\boldsymbol v,\boldsymbol s|\boldsymbol w) &amp;= \tau(\boldsymbol v,\boldsymbol s|\boldsymbol a^*,\boldsymbol w)\\&amp; = \left(\sum_{k=1}^{p}\boldsymbol w_{\boldsymbol a^*_1(k)}\cdot(\boldsymbol v_{\boldsymbol a^*_1(k)}-\boldsymbol s_{\boldsymbol a^*_2(k)})^2\right)^{\frac{1}{2}}\end{align}\]</span> 其中<span class="math inline">\(\boldsymbol a^*\)</span>为DTW距离下的最佳对齐。</p><p>第二个是全局因素<span class="math inline">\(\boldsymbol u_m\)</span>，这主要是通过对不同片段<span class="math inline">\(\boldsymbol s\)</span>施加不同的权重实现的，于是shapelet <span class="math inline">\(\boldsymbol v\)</span>和时间序列<span class="math inline">\(\boldsymbol t\)</span>的距离可以重写为： <span class="math display">\[\hat{D}(\boldsymbol v,\boldsymbol t|\boldsymbol w,\boldsymbol u)=\min_{1\leq k\leq m}\boldsymbol u_k\cdot\hat{d}(\boldsymbol v,\boldsymbol s_k|\boldsymbol w)\]</span> 其中<span class="math inline">\(\boldsymbol t\)</span>被分割为<span class="math inline">\(m\)</span>个片段：<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>。对于分类任务，具体的来说，我们先生成一堆Shapelet候选集，然后通过有监督的方法来挑选最佳的Shapelet和对应的参数<span class="math inline">\(\boldsymbol w\)</span>和<span class="math inline">\(\boldsymbol u\)</span>。</p><p>计算shapelet候选集的算法如下：</p><p><img src="https://i.loli.net/2020/06/25/srW4Shk79XBFL3U.png" /></p><p>在获取了Shapelet候选集合之后，我们有带有标签的时序集合<span class="math inline">\(T\)</span>，对于每一个Shapelet我们可以优化：</p><p><span class="math display">\[\hat{\mathcal L}=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))+\lambda\parallel \boldsymbol w\parallel+\epsilon\parallel \boldsymbol u\parallel\]</span></p><p>来获取最优的<span class="math inline">\(\hat{\boldsymbol w}\)</span>和<span class="math inline">\(\hat{\boldsymbol u}\)</span>。然后，我们可以挑选出使得<span class="math inline">\(\hat{\mathcal L}\)</span>最小的前<span class="math inline">\(K\)</span>个Shapelet。整个过程的算法流程如下：</p><p><img src="https://i.loli.net/2020/06/25/5b2TcjuBzlIFrPm.png" /></p><h2 id="shapelet-evolution-graph">Shapelet Evolution Graph</h2><p>在获取了Shapelet之后，为了捕获Shapelet之间的相关性，我们定义了<em>Shapelet Evolution Graph</em>。</p><blockquote><p><strong>Definition 3 Shapelet Evolution Graph. </strong> <em>Shapelet Evolution Graph</em>为一个有向带权图<span class="math inline">\(G=(V,E)\)</span>，<span class="math inline">\(V\)</span>为<span class="math inline">\(K\)</span>个Shapelet，每条带有权重<span class="math inline">\(w_{ij}\)</span>的边<span class="math inline">\(e_{ij}\in E\)</span>代表两个Shapelet <span class="math inline">\(\boldsymbol v_i \in V\)</span>和<span class="math inline">\(\boldsymbol v_j \in V\)</span>被分配给相邻片段的概率。</p></blockquote><h3 id="graph-construction">Graph Construction</h3><p>这里来说一下，建图的具体过程。首先顶点为Shapelet，之后来进行边的构造。对于每一个片段<span class="math inline">\(\boldsymbol s_i\)</span>，我们会计算Shapelet到该片段的距离，距离越近代表这个Shapelet与片段越匹配。之后会设定一个阈值<span class="math inline">\(\delta\)</span>，然后将与片段的距离低于这个阈值的Shapelet分配给这个片段（一个Shapelet可能会分配给多个不同片段）。对于<span class="math inline">\(\boldsymbol s_i\)</span>的所有shapetlet我们记为<span class="math inline">\(\boldsymbol v_{i,*}\)</span>，我们会按照Shape到片段的距离进行归一化：</p><p><span class="math display">\[\boldsymbol p_{i,j}=\frac{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\hat{d}_{i,j}(\boldsymbol v_{i,j},\boldsymbol s_i)}{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\min(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))}\]</span></p><p>其中<span class="math inline">\(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i)=\boldsymbol u_*[i]*\hat{d}(\boldsymbol v_{i,*},\boldsymbol s_i|\boldsymbol w_*)&lt;\delta\)</span>。这样对于每个片段<span class="math inline">\(\boldsymbol s_i\)</span>所分配的Shapelet对应的<span class="math inline">\(\boldsymbol p\)</span>之和会等于<span class="math inline">\(1\)</span>。对每一对相邻的片段<span class="math inline">\((\boldsymbol s_i,\boldsymbol s_{i+1})\)</span>的Shapelet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>和<span class="math inline">\(\boldsymbol v_{i+1,k}\)</span>，我们创建一条连接<span class="math inline">\(\boldsymbol v_{*,j}\)</span>和<span class="math inline">\(\boldsymbol v_{*,k}\)</span>的边<span class="math inline">\(e_{j,k}\)</span>，权重为<span class="math inline">\(\boldsymbol p_{i,j}\cdot\boldsymbol p_{i+1,k}\)</span>。最后，所有重复的边会被合并。</p><p><img src="https://i.loli.net/2020/07/07/FzGEbWJflHmQa9R.png" style="zoom: 33%;" /></p><p>如上图所示，假设有两个片段，每个片段分配了<span class="math inline">\(3\)</span>个Shapelet，Shapelet <span class="math inline">\(B\)</span>在片段<span class="math inline">\(1\)</span>对应的概率是<span class="math inline">\(p_{12}\)</span>，Shapelet <span class="math inline">\(C\)</span>在片段<span class="math inline">\(2\)</span>对应的概率是<span class="math inline">\(p_{23}\)</span>，那么由于片段<span class="math inline">\(1\)</span>和<span class="math inline">\(2\)</span>是相邻片段，会在<span class="math inline">\(B\)</span>和<span class="math inline">\(C\)</span>之间连一条边，边的权重为<span class="math inline">\(p_{12}*p_{23}\)</span>。</p><p>建图的算法流程图如下：</p><p><img src="https://i.loli.net/2020/06/25/aq9tGuApSbiC67c.png" /></p><h2 id="representation-learning">Representation Learning</h2><p>之后，我们使用DeepWalk算法来获取获取每个结点（Shapelet）的嵌入表示。对于时序<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>即对应的Shapelet <span class="math inline">\(\{\boldsymbol v_{1,*},\cdots, v_{m,*}\}\)</span>和对应的概率<span class="math inline">\(\{\boldsymbol p_{1,*},\cdots,\boldsymbol p_{m,*}\}\)</span>，每个Shaplet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>的表示记为<span class="math inline">\(\boldsymbol \mu(\boldsymbol v_{i,j})\)</span>。片段<span class="math inline">\(\boldsymbol s_i\)</span>对应的嵌入向量为对应的Shapelet嵌入向量与对应的概率值加权求和：</p><p><span class="math display">\[\boldsymbol\Phi_i=\left(\sum_j p_{i,j}\cdot\boldsymbol \mu(\boldsymbol v_{i,j})\right),\space 1\leq i \leq m\]</span></p><p>算法流程如下：</p><p><img src="https://i.loli.net/2020/06/25/O5exTgsVLuRWQ42.png" /></p><h1 id="experiments">Experiments</h1><h2 id="experimental-setup">Experimental Setup</h2><p>文中用了<em>Earthquakes</em> (EQS)、<em>WormsTwoClass</em> (WTC)、<em>Strawberry</em> (STB)、<em>Electricity Consumption Records</em> (ECR)和<em>Network Traffic Flow</em> (NTF) 这五个数据集，其中后两个为作者自己收集的数据集。五个数据集对应的统计信息如下：</p><p><img src="https://i.loli.net/2020/06/25/zHjTKkUJB8fGwdi.png" /></p><p>文中与多个Baseline进行了比较，包括:</p><ul><li><strong>Distance-based Models: </strong>文中使用了不同的距离度量与基于1-NN的模型进行组合，包括Euclidean Distance (ED)、Dynamic Time Warping (DTW)、Weighted DTW (WDTW)、Complexity-Invariant Distance (CID) 和 Derivative DTW (DDTW)；</li><li><strong>Feature-based Models: </strong>文中分别使用了提取特征（均值、标准差等）和原始序列来训练XGBoost。除此之外，还使用了 Bag-of-Patterns (BoP)、Time Series Forest (TSF)、Elastic Ensembles (EE) 和 基于SAX的 Vector Space Model (SAXVSM)；</li><li><strong>Shapelet-based Models: </strong>这部分模型包括 Learn Time Series Shapelets (LS)、Fast Shapelets (FS)、和 Learned Pattern Similarity (LPS)；</li><li><strong>Deep Learning Models: </strong>这部分模型包括MLP、LSTM和VAE。</li></ul><h2 id="comparison-results">Comparison Results</h2><p>对于前三个公共数据集评测标准采用Accuracy，后两个数据集因为样本类比不均衡，所以采用了Precision、Recall和F1作为评测标准。结果如下：</p><p><img src="https://i.loli.net/2020/06/25/jxKFpDVXdmc5tbE.png" style="zoom:67%;" /></p><p>在EQS数据集上，Time2Graph打败了所有Baseline，而在WTC和STB这两个数据集上也达到了较好的效果。在ECR和NTF这两个真实数据集上，Time2Graph在F1上打败了所有Baseline。</p><h2 id="parameter-analysis">Parameter Analysis</h2><p>本节对Shapelet的数量<span class="math inline">\(K\)</span>、嵌入维度<span class="math inline">\(B\)</span>和片段长度<span class="math inline">\(l\)</span>进行了参数分析。结果如下：</p><p><img src="https://i.loli.net/2020/06/25/hPfqAvNnOlEBQuw.png" /></p><h2 id="case-study-of-time-aware-shapelets">Case Study of Time-Aware Shapelets</h2><p>本节作者对提出的<em>Time-Aware Shapetlet</em>进行了细致的探究。第一个问题是不同Shapelet的区分能力是否不同？下图(a)里，作者在使用Shapelet进行二分类的任务中，将Shapelet按Loss（图中灰色的线）进行排序，并且绘制了对应的正负样本距离的KL散度（橘红色的点）。可以看到，在Loss曲线和KL散度呈反比关系。KL散度越高，我们可以认为该Shapelet的区分度越高，这说明不同Shapelet的区分度的确不同，并且这会与最终效果直接挂钩。图(b)展示了不同Shapelet的均值和方差（原文没有说清楚是什么的均值和方差）。</p><p>除此之外，作者和流行的Shapelet提取算法<em>LS</em>进行了比较，如图(c)和图(d)。从图中可以看到对于不同时间，本文的算法提取的Shapelet的确是具有时间动态性的。</p><p><img src="https://i.loli.net/2020/06/25/ed5PwksC2l3OWE8.png" /></p><h2 id="case-study-of-the-shapelet-evolution-graph">Case Study of the Shapelet Evolution Graph</h2><p>本节作者对<em>Shapelet Evolution Graph</em>进行了细致的探究。下图分别为一月份和七月份的<em>Shapelet Evolution Graph</em>。在一月，45号Shapelet的度较大，而且对应的时间因素在一月和二月也较大（图中深色部分）。说明45号Shapelet在一月份具有代表性。而在七月，45号Shapelet的重要性降低，而42号Shapelet在七月的重要性很高。</p><p><img src="https://i.loli.net/2020/06/25/N2Vij8ODQaRuALJ.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapel</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Time Series Modeling" scheme="http://qfxiao.me/categories/Research/Time-Series-Modeling/"/>
    
    
    <category term="Time Series" scheme="http://qfxiao.me/tags/Time-Series/"/>
    
    <category term="Shapelet" scheme="http://qfxiao.me/tags/Shapelet/"/>
    
  </entry>
  
  <entry>
    <title>Generative Probabilistic Novelty Detection with Adversarial Autoencoders</title>
    <link href="http://qfxiao.me/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/"/>
    <id>http://qfxiao.me/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/</id>
    <published>2020-06-06T04:03:27.000Z</published>
    <updated>2020-06-25T08:14:29.250Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这篇文章介绍了一种基于概率分布的异常检测方法。其基本思想是假设正常样本服从定义在流形$M$上的分布，而对于任意一点$\bar x$，通过投影到流形$M$上$x^\parallel$，可以分解为平行于切空间的部分$x^\parallel$和正交与切空间的部分$x^\bot$。原始的坐标$\bar x$被转换到$x^\parallel$局部坐标系中，然后似然通过转换后的坐标系进行计算。</p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Generative-Probabilistic-Novelty-Detection"><a href="#Generative-Probabilistic-Novelty-Detection" class="headerlink" title="Generative Probabilistic Novelty Detection"></a>Generative Probabilistic Novelty Detection</h2><p>我们假设训练数据$x_1,\cdots,x_N$，其中$x_i\in\mathbb{R}^m$，从一个分布采样的来，并带有随机噪声$\xi$：<br>$$<br>x_i=f(z_i)+\xi_i, \space\space\space i=1,\cdots,N<br>$$<br>其中$z_i\in\mathbb{R}^n$，$f:\Omega\mapsto\mathbb{R}^m$定义了一个$n$维带参流形$\mathcal{M}\equiv f(\Omega)$。注意这里噪声的加入使得样本的值域扩展到了整个实数空间。同时假设存在$g:\mathbb{R}^m\mapsto\mathbb{R}^n$，对任意$x\in\mathcal{M}$都有$f(g(x))=x$。$f$和$g$后面会通过神经网络实现。</p><p>对于一个测试样本$\bar{x}\in\mathbb{R}^m$，我们可以得到其在$M$上的投影，这是通过逆变换$\bar z = g(\bar x)$得到对应$z$的然后再通过$\bar x^{\parallel}=f(\bar z)$得到。$f$在$\bar z$的一阶泰勒展开为：<br>$$<br>f(z)=f(\bar z)+J_f(\bar z)(z-\bar z)+O(\parallel z-\bar z\parallel ^2)<br>$$<br><img src="https://i.loli.net/2020/06/25/oi9xKMO3ID7jANJ.png" style="zoom:67%;" /></p><p>其中$J_f(\bar z)$为$f$在点$\bar z$的雅各比矩阵。$\mathcal T=\text{span}(J_f(\bar z))$代表点$\bar z$处由$J_f(\bar z)$的$n$个独立向量组成的切空间。通过对$J_f(\bar z)$进行奇异值分解$J_f(\bar z)=U^\parallel SV^\top$。<br>$$<br>\bar w=U^\top\bar x=\left[\begin{matrix}U^{\parallel^\top}\bar x\ U^{\bot^\top}\bar x\end{matrix}\right]=\left[\begin{matrix}\bar w^\parallel\ \bar w^\bot\end{matrix}\right]<br>$$<br>坐标$\bar w$可以分解为平行于$\mathcal T$和正交于$\mathcal T$两部分。</p><p>定义在施加变换前后的坐标系上的概率分布$p_X(x)$和$p_W(w)$是等价的，不过对于$p_W(w)$，我们假设平行部分和正交部分是独立的，即：<br>$$<br>p_X(x)=p_W(w)=p_W(w^\parallel,w^\bot)=p_{W^\parallel}(w^\parallel)p_{W^\bot}(w^\bot)<br>$$<br>这一假设的依据是随机噪声部分假设主要是往流形之外偏离的，即与$\mathcal T$正交，所以$W^\bot$主要是反映噪声的部分。而噪声与样本分布相独立的假设是合理的。于是，异常分数可以定义为：<br>$$<br>p_X(\bar x)=p_{W^\parallel}(\bar w^\parallel)p_{W^\bot}(\bar w^\bot)=\begin{cases}\geq \gamma \Rightarrow \text{Inlier}\&lt;\gamma\Rightarrow\text{Outlier}\end{cases}<br>$$</p><h2 id="Computing-the-Distribution-of-Data-Samples"><a href="#Computing-the-Distribution-of-Data-Samples" class="headerlink" title="Computing the Distribution of Data Samples"></a>Computing the Distribution of Data Samples</h2><p>上面的异常分数需要计算$p_{W^\parallel}(\bar w^\parallel)$和$p_{W^\bot}(\bar w^\bot)$。给定测试样本$\bar x$，投影到流形$\bar x^\parallel=f(g(\bar x))$。$\bar w^\parallel$可以重写为$\bar w^\parallel=U^{\parallel^\top}\bar x=U^{\parallel^\top}(\bar x-\bar x^{\parallel})+U^{\parallel^\top}\bar x^\parallel=U^{\parallel^\top}\bar x^\parallel$，即我们假设$U^{\parallel^\top}(\bar x-\bar x^\parallel)\approx 0$。于是有$w^\parallel(z)=U^{\parallel^\top}f(\bar z)+SV^\top(z-\bar z)+O(\parallel z-\bar z\parallel^2)$。</p><p>如果$Z$为定义在流形上的概率分布，那么：<br>$$<br>p_{W^\parallel}(w^\parallel)=|\text{det}S^{-1}|p_Z(z)<br>$$<br>$p_{W^\bot}(w^\bot)$由半径为$\parallel w^\bot\parallel$的超球体$\mathcal S^{m-n-1}$来进行估计：<br>$$<br>p_{W^\bot}(w^\bot)\approx\frac{\Gamma(\frac{m-n}{2})}{2\pi^{\frac{m-n}{2}}\parallel w^\bot\parallel^{m-n}}p_{\parallel W^\bot\parallel}(\parallel w^\bot\parallel)<br>$$</p><p>其中$\Gamma(\cdot)$代表Gamma函数。</p><h2 id="Manifold-Learning-with-Adversarial-Autoencoders"><a href="#Manifold-Learning-with-Adversarial-Autoencoders" class="headerlink" title="Manifold Learning with Adversarial Autoencoders"></a>Manifold Learning with Adversarial Autoencoders</h2><p>为了学习映射$f$和$g$，我们使用了AAE框架，如下图所示：</p><img src="https://i.loli.net/2020/06/25/sQhO3D4gKJqBPXv.png" style="zoom: 67%;" /><p>除了常规的AAE外，我们还为$x$添加了一个额外的判别器。</p><h3 id="Adversarial-Losses"><a href="#Adversarial-Losses" class="headerlink" title="Adversarial Losses"></a>Adversarial Losses</h3><p>对于隐变量$z$，对抗损失函数为：<br>$$<br>\mathcal L_{adv-d_z}(x,g,D_z)=E[\log(D_z(\mathcal N(0,1)))]+E[\log(1-D_z(g(x)))]<br>$$<br>对于样本$x$，对抗损失函数为：<br>$$<br>\mathcal L_{adv-d_x}(x,D_x,f)=E[\log(D_x(x))]+E[\log(1-D_x(f(\mathcal N(0,1))))]<br>$$</p><h3 id="Autoencoder-Loss"><a href="#Autoencoder-Loss" class="headerlink" title="Autoencoder Loss"></a>Autoencoder Loss</h3><p>$$<br>\mathcal L_\text{error}(x,g,f)=-E_z[\log(p(f(g(x))|x))]<br>$$</p><h3 id="Full-Objective"><a href="#Full-Objective" class="headerlink" title="Full Objective"></a>Full Objective</h3><p>$$<br>\mathcal L(x,g,D_z,D_x,f)=\mathcal L_{adv-d_z}+\mathcal L_{adv-d_x}+\lambda \mathcal L_\text{error}<br>$$</p><p>下图为模型重构的例子：</p><img src="https://i.loli.net/2020/06/25/i7ytlgjoIbYV6uF.png" style="zoom:67%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul><li>**MNIST. ** 手册数字识别数据集。</li><li>**The Coil-100. **包含7200张100个不同物体的不同角度的图片。</li><li>**Fashion-MNIST. ** 手册数字识别数据集彩色版。</li><li>**Others. ** 前三个数据集都是采用一个类作为inlier，而其他类作为outlier。在这一设置中inlier采样自数据集CIFAR-10(CIFAR-100)，而outlier采样自TinyImageNet、LSUN和iSUN。</li></ul><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="MNIST-Dataset"><a href="#MNIST-Dataset" class="headerlink" title="MNIST Dataset"></a>MNIST Dataset</h3><p><img src="https://i.loli.net/2020/06/25/5a71oidmK2ZGLyh.png"></p><img src="https://i.loli.net/2020/06/25/4lcGeHDrhbdKN5W.png" style="zoom:67%;" /><h3 id="Coil-100-Dataset"><a href="#Coil-100-Dataset" class="headerlink" title="Coil-100 Dataset"></a>Coil-100 Dataset</h3><img src="https://i.loli.net/2020/06/25/ofVGBgR7a3WmyvU.png" style="zoom:67%;" /><h3 id="Fashion-MNIST"><a href="#Fashion-MNIST" class="headerlink" title="Fashion-MNIST"></a>Fashion-MNIST</h3><p><img src="https://i.loli.net/2020/06/25/avURoBw6ny8SIEq.png"></p><h3 id="CIFAR-10-CIFAR-100"><a href="#CIFAR-10-CIFAR-100" class="headerlink" title="CIFAR-10 (CIFAR-100)"></a>CIFAR-10 (CIFAR-100)</h3><img src="https://i.loli.net/2020/06/25/piteKy1m9kvQ6EU.png" style="zoom: 67%;" /><h3 id="Ablation"><a href="#Ablation" class="headerlink" title="Ablation"></a>Ablation</h3><p><img src="https://i.loli.net/2020/06/25/xgni9wBtYkheGZq.png"></p><img src="https://i.loli.net/2020/06/25/idhqkCbAKvzMt68.png" style="zoom:67%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;这篇文章介绍了一种基于概率分布的异常检测方法。其基本思想是假</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
    <category term="GAN" scheme="http://qfxiao.me/tags/GAN/"/>
    
    <category term="Novelty Detection" scheme="http://qfxiao.me/tags/Novelty-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Classification-based Anomaly Detection for General Data</title>
    <link href="http://qfxiao.me/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/"/>
    <id>http://qfxiao.me/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/</id>
    <published>2020-06-02T15:01:34.000Z</published>
    <updated>2020-06-26T12:55:43.589Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文主要是对<a href="http://qfxiao.me/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/">NIPS18这篇异常检测文章</a>的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：</p><ul><li>**Reconstruction Methods： **这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误差。</li><li>**Distributional Methods： **这一部分方法将异常检测看作是密度估计问题。通过对正常样本的分布进行估计，异常样本在该正常分布下的似然将会很低。</li><li>**Classification-based Methods： **这一部分方法主要是指的单分类方法和通过几何变换构造分类任务的方法。本文使用的就是这类方法。</li></ul><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Classification-based-Anomaly-Detection"><a href="#Classification-based-Anomaly-Detection" class="headerlink" title="Classification-based Anomaly Detection"></a>Classification-based Anomaly Detection</h2><p>假设所有数据位于空间$R^L$内，而正常数据位于子空间$X\subset R^L$内。我们假设所有的异常样本位于$X$之外。为了检测异常，我们希望学习一个分类器$C$使得对于所有的$x\in X$有$C(x)=1$，而对所有的$x\in R^L\backslash X$有$C(x)=0$。</p><p>单分类方法的思想是直接学习$P(x\in X)$，代表的方法有One-Class SVM，DSVDD等。传统的OC-SVM直接在原始空间或者核空间学习分类器。比较新的方法，如Deep-SVDD则是先将样本转换到一个特征空间，然后在这个特征空间上学习使得半径$R$最小的超球体（球心$c_0$），来覆盖住所有正常样本。异常的判定则通过计算$\parallel f(x)-c_0\parallel^2-R^2$来实现。不过学习一个好的样本到特征空间的变换并不是一件容易的事情，比如说$f(x)=0, \forall x \in X$就是一个使得超球体最小的解。所以需要很多trick来避免诸如此类的情况。</p><p><em>Geometric-transformation classification</em> (GEOM) 则将数据空间$X$通过$M$个几何变换转换到一系列子空间$X_1,\cdots,X_M$。之后训练一个分类器来预测样本$T(x,m)$对应的几何变换的种类$m$。转换后的正常图片空间记为$\cup_m X_m$，所以该方法尝试估计以下条件概率：<br>$$<br>P(m^\prime|T(x,m))=\frac{P(T(x,m)\in X_{m^\prime})P(m^\prime)}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})P(\tilde{m})}-\frac{P(T(x,m)\in X_{m^\prime})}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})}<br>$$</p><p>对于异常的样本$x\in R^L\backslash X$，在经过几何变换之后，都不会位于正确的子空间中，即$T(x,m)\in R^L\backslash X_m$。之后，使用$P(m|T(x,m))$来判定异常。</p><p>作者认为，这种方法的问题是分类器$P(m^\prime|T(x,m))$只在正常数据上训练，而对于异常样本的异常分数会出现方差很大的问题。</p><p>一种解决方式是加入异常样本进行训练，但是作者认为在有的任务中标签很难获取，于是作者使用了另外一种方法来解决这个问题。</p><h2 id="Distance-based-Multiple-Transformation-Classification"><a href="#Distance-based-Multiple-Transformation-Classification" class="headerlink" title="Distance-based Multiple Transformation Classification"></a>Distance-based Multiple Transformation Classification</h2><p>和GEOM一样，先对每个样本进行$M$个几何变换，然后学习一个特征提取器$f(x)$，将$X_m$映射到特征空间。之后和OC-SVM类似，假设特征${f(x)|x\in X_m}$为球心为$c_m=\frac{1}{N}\sum_{x\in X} f(T(x,m))$的超球体。样本属于某一类$m^\prime$的概率由下式给出：</p><p>$$<br>P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2}}{\sum_{\bar m}e^{-\parallel f(T(x,m))-c_{\bar m}\parallel^2}}<br>$$</p><p>目标函数采用的是Triplet Loss：</p><p>$$<br>L=\sum_i\max(\parallel f(T(x_i,m))-c_m\parallel^2+s-\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2,0)<br>$$</p><p>$\parallel f(T(x_i,m))-c_m\parallel^2$相当于最小化了类内距离，$\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2$最大化了每个类对应的集簇间距离。在检测阶段，为了避免一些数值问题，作者做了一些平滑操作：</p><p>$$<br>\tilde P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2+\epsilon}}{\sum_{\tilde m}e^{-\parallel f(T(x,m))-c_{\tilde m}\parallel^2+M\cdot\epsilon}}<br>$$</p><p>最后的评判分数由下式给出：</p><p>$$<br>Score(x)=-\log P(x\in X)=-\sum_m\log \tilde{P}(T(x,m)\in X_m)=-\sum_m\log\tilde{P}(m|T(x,m))<br>$$</p><p>算法流程图如下：</p><img src="https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png" style="zoom:67%;" /><h2 id="Parameterizing-the-Set-of-Transformations"><a href="#Parameterizing-the-Set-of-Transformations" class="headerlink" title="Parameterizing the Set of Transformations"></a>Parameterizing the Set of Transformations</h2><p>在GEOM中，由于使用的几何变换都是针对图像的，所以对于其他类型的数据并不适用。本文中作者对非图像数据设计了以下变换：</p><p>$$<br>T(x,m)=W_mx+b_m<br>$$</p><p>不同的参数$W_m$和$b_m$即为不同的几何变换，可以考虑采用随机采样的方式。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Image-Experiments"><a href="#Image-Experiments" class="headerlink" title="Image Experiments"></a>Image Experiments</h2><p>对于图像数据的异常检测实验，作者采用了CIFAR10、FasionMNIST这两个数据集，实验结果如下：</p><img src="https://i.loli.net/2020/06/24/j4Y29tB6k1Aipgo.png" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/24/D3opwrLnSGmcsyM.png" style="zoom:67%;" /><h2 id="Tabular-Data-Experiments"><a href="#Tabular-Data-Experiments" class="headerlink" title="Tabular Data Experiments"></a>Tabular Data Experiments</h2><p>对于非图像数据，作者采用了几个小的数据集：Arrhythmia、Thyroid、KDD和KDDRev。采用的Baseline包括OC-SVM、E2E-AE、LOF、DAGMM和FB-AE (Feature Bagging Autoencoder)。对于几何变换的参数，采样自标准正态分布。结果如下：</p><img src="https://i.loli.net/2020/06/24/e6PfIDOVwlzrSWi.png" style="zoom:67%;" /><h1 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h1><p>结合<a href="https://openreview.net/forum?id=H1lK_lBtvS">OpenReview</a>上的一些讨论，这里提出一些问题和总结：</p><ul><li>KDD数据集太简单了，正常、异常样本能够很容易被分开；</li><li>对于图像数据作者只使用了CIFAR10和FashionMNIST这两个比较小的数据集，而在GEOM中还使用了CIFAR100和CatsVsDogs。并且GEOM原文中提到数据集（指图像大小）越大，GEOM的优势就越明显，所以在本文的实验中只使用这两个数据集说服力略显不够；</li><li>关于评测标准的问题，作者在图像数据中用的是AUROC，而非图像数据用的是F1 score。像AUPR、AUROC这种评测标准往往更加全面，而F1 score依赖于阈值的选取。如果是遍历阈值找到最好的那个F1 score，则无法全面考察模型的鲁棒性，模型有可能只是在特定的阈值下表现很好，而阈值稍微偏差一下性能可能就会大幅下降。我看到的大多数异常检测文章都是使用AUROC或者F1加上AUROC作为评测指标；</li><li>文中在第二节“CLASSIFICATION-BASED ANOMALY DETECTION”的末尾两段关于GEOM方法的缺点说的很模糊。异常分数的方差大到底指的是什么；</li><li>关于作者提出的变换$T(x,m)=W_mx+b_m$并没有用到图像数据的实验上，而且在实验中$b_m$这个参数实际上是被忽略掉了的，$b_m$的作用究竟如何不得而知。而且GEOM中的几何变换的Motivation在原文中是做了实验充分讨论了的，GEOM的作者认为这些几何变换保留了图像的高阶语义信息。而本文中的变换中的参数只是随机采样而来，并不存在说保留原始数据中的结构信息。如果忽略掉这一层变换，那就类似于加了神经网络提取特征的OC-SVM。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文主要是对&lt;a href=&quot;http://qfxiao.m</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
  </entry>
  
  <entry>
    <title>面向OpenPAI的Docker镜像配置及OpenPAI基本使用方法</title>
    <link href="http://qfxiao.me/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>http://qfxiao.me/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2020-06-02T04:26:13.000Z</published>
    <updated>2020-08-01T04:00:16.325Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>实验室服务器集群采用OpenPAI来进行GPU资源的管理，而OpenPAI采用了Docker作为基础，即代码都放在Docker容器中运行。由于Docker的使用、Docker镜像的配置都有一定的门槛，所以这里写一篇Tutorial来进行介绍。本文不是网上资料的拼凑，而是经过本人走弯路踩坑形成的”Best practice”。主要内容包括Docker的介绍、Docker的基本使用、如何配置自己的Docker镜像以及OpenPAI平台的基本使用，但不包括Docker和OpenPAI的安装。</p><blockquote><p>2020.8.1 Update: 加入通过HDFS读取容器保存的文件的方法</p></blockquote><h1 id="Docker-from-Scratch"><a href="#Docker-from-Scratch" class="headerlink" title="Docker from Scratch"></a>Docker from Scratch</h1><p>要理解Docker是什么，从虚拟机开始讲可能会比较好理解。虚拟机大家可能都很熟悉了，比如说我用的系统是Windows，但我需要Linux系统来作为一个Flask编写的网站的服务器，但是又不想单独安装Linux系统，于是可以使用虚拟机来解决这个问题。安装VMWare Workstation，去官网下载Ubuntu系统镜像，然后在VMWare中安装好系统，然后从头配置Flask相关环境。实际上我需要的仅仅是一个Flask运行环境而已，而使用虚拟机却需要如此“大费周章”，这时Docker出现了，网上有大量现成的Flask Docker镜像，配置好了你所需的Flask环境，你只需要下载这些镜像，然后运行它，你就得到了一个Flask运行环境，而与你当前使用的系统无关。如果你需要一个Tomcat的运行环境，那么去找一个Tomcat的Docker镜像就行。Docker将需求或者说服务绑定在了Docker镜像中（<strong>轻量化</strong>，一个需求对应一个Docker镜像，每个镜像都很小），你有什么需求，去找相应的镜像即可（或者自己写一个），镜像的运行是以虚拟机的形式存在，所以他们之间也是互不干扰的。同时，你在写好一个Docker镜像之后，你还可以<strong>分享</strong>给别人，这样其他人就不用重新配置，直接运行你给他的镜像即可。Docker有两个比较关键的概念：</p><ul><li><strong>镜像 Images：</strong> 这里的镜像不是指我们安装系统时下载的ISO镜像，Docker镜像就是把你需要的东西（一个系统+需要的服务）集中到一起，相当于做菜的菜谱；</li><li><strong>容器 Containers：</strong> 如果一个Docker镜像启动了，那么就会有一个Docker容器产生，相当于按照菜谱做出来的菜。</li></ul><img src="https://i.loli.net/2020/06/24/H2x9mnPwkVQyO6p.png" alt="img" style="zoom: 33%;" /><img src="https://i.loli.net/2020/06/24/7k6S3yecX2lbvQY.png" alt="img" style="zoom: 33%;" /><p>这一节我们先不讨论如何自己写Docker镜像，只是先讨论Docker的基本操作。</p><h2 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h2><p>Docker新安装好当然是没有什么镜像的，首先我们使用<code>docker pull hello-world</code>来下载一个测试镜像。</p><blockquote><p>拉取镜像 <code>docker pull &lt;image_name&gt;</code></p></blockquote><p>在输入之后，Docker会自动在远程服务器上查找对应的镜像进行下载。由于我的电脑上已经有这个镜像了，所以显示是下面的样子：</p><p><img src="https://i.loli.net/2020/06/24/rvqcAwzOYJtF6T8.png"></p><p>接下来，我们输入<code>docker run hello-world</code>运行这个镜像。</p><blockquote><p>运行镜像<code>docker run &lt;image_name&gt;</code></p></blockquote><p>可以看到，Docker输出了一些信息就自己退出了，这和我们理解的虚拟机不太一样。在Docker里面，我们既可以创建一个完整的系统，用户在运行之后就可以正常使用这个操作系统，也可以创建一个简单的服务，默认运行完一些指令就退出了。这里的<code>hello-world</code>镜像这是输出了一些信息后就自动退出了，因为这就是这个镜像的全部内容。</p><p><img src="https://i.loli.net/2020/06/24/Zb1VKjFyMh8gHf2.png"></p><p>我们尝试来运行一个完整的系统，先用<code>docker pull ubuntu</code>拉取Ubuntu Docker镜像：</p><p><img src="https://i.loli.net/2020/06/24/zEerb2gPwYWX8O7.png"></p><p>接下来我们使用：</p><p><img src="https://i.loli.net/2020/06/24/6cMz1WGH4fgpBsS.png"></p><blockquote><p><code>-it</code>的意思是什么？根据<code>docker run --help</code>：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">-i, --interactive                    Keep STDIN open even <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> attached<br>    --ip string                      IPv4<span class="hljs-built_in"> address </span>(e.g., 172.30.100.104)<br>    --ip6 string                    <span class="hljs-built_in"> IPv6 address </span>(e.g., 2001:db8::33)<br>    --ipc string                     IPC mode <span class="hljs-keyword">to</span> use<br>    --isolation string               Container isolation technology<br>    --kernel-memory bytes            Kernel memory limit<br>-t, --tty                            Allocate a pseudo-TTY<br>    --ulimit ulimit                  Ulimit options (default [])<br>Copy<br></code></pre></td></tr></table></figure><p>其实<code>-it</code>是<code>-i</code>和<code>-t</code>的合并写法，意思是运行后进入这个容器并且启用shell，不然运行之后就会放到后台而不会进入容器中。而<code>--rm</code>则代表容器退出之后会被删除（镜像不会被删除），每次运行实际上会创建一个新的容器，如果不加<code>--rm</code>或退出之后不手动删除的话会看到一堆停止运行的容器。</p></blockquote><p>输入<code>cat /etc/issue</code>可以看到默认拉取的是最新的Ubuntu 20.04 LTS：</p><p><img src="https://i.loli.net/2020/06/24/wldBMFtx3eIk98C.png"></p><h1 id="Build-Customized-Docker-Images"><a href="#Build-Customized-Docker-Images" class="headerlink" title="Build Customized Docker Images"></a>Build Customized Docker Images</h1><p>如果没有现成的Docker镜像能满足我们的需求，我们可以考虑自己写一个。要自定义一个Docker镜像需要两步，第一步是编写Dockerfile，第二步是使用<code>docker build</code>命令构建镜像。Dockerfile可以看作是一个脚本，描述了我们构建镜像所需要的全部命令，比如要构建一个用于Python科学计算的Docker镜像，我们需要在Dockerfile中编写安装Python的命令，安装Numpy、Scipy等常用包的命令等等。我们先来上手编写Dockerfile，这里我准备写一个包含<a href="https://hexo.io/">hexo博客框架</a>的镜像，这个框架需要node作为基础环境，不过我们不需要在Dockerfile里写安装node的命令。因为类似于<code>C++</code>或<code>Python</code>中的对象的继承，Dockerfile也可以“继承”，这意味着我们不必从头写起。我们先来看一下完整的Dockfile和效果，再来一一解释。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> node<br><br>--------------------------------------------------------------<br><br><span class="hljs-keyword">RUN</span><span class="bash"> npm install -g hexo-cli</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">4000</span><br><span class="hljs-keyword">CMD</span><span class="bash"> hexo init blog &amp;&amp; <span class="hljs-built_in">cd</span> blog &amp;&amp; hexo generate &amp;&amp; hexo serverCopy</span><br></code></pre></td></tr></table></figure><p>运行结果如下所示，可以看到Docker按照我们写的Dockerfile一行一行的进行镜像的构建：</p><p><img src="https://i.loli.net/2020/06/24/tZ3JW4SPNhxUwEn.png"></p><p>现在来解释Docerfile里的内容。<code>FROM &lt;docker image&gt;</code>表示继承其他的镜像，这里我们使用node官方的镜像。接下来是安装hexo，<code>RUN &lt;command&gt;</code>表示执行命令，这里我们直接用<code>npm install -g hexo-cli</code>进行安装。由于要浏览博客网页需要开放端口，而Docker容器运行的时候和外部主机是完全隔断的，要使外部主机访问Docker容器端口，需要暴露端口。<code>EXPOSE &lt;port&gt;</code>代表暴露端口，这里用的是4000端口。之后是创建博客和启动本地服务，<code>CMD &lt;command&gt;</code>和<code>RUN &lt;command&gt;</code>的区别是RUN会在构建的时候执行，而CMD是在容器启动之后才会执行。<code>hexo init blog &amp;&amp; cd blog &amp;&amp; hexo generate &amp;&amp; hexo server</code>分别代表初始化博客、进入博客所在文件夹、生成博客网站、启动本地服务器。更多指令可以参考<a href="https://docs.docker.com/engine/reference/builder/">官方文档</a>。</p><p>然后我们使用<code>docker build -t test_hexo .</code>命令构建镜像。</p><blockquote><p>构建镜像 <code>docker build -t &lt;image_name&gt; &lt;direcotry&gt;</code></p></blockquote><p>运行镜像：</p><p><img src="https://i.loli.net/2020/06/24/m4FSe15kMIDCHXy.png"></p><p>可以看到容器启动后开始执行博客初始化。</p><p><img src="https://i.loli.net/2020/06/24/BEdibvgPTMz4sn8.png"></p><p>最后在<code>locahost:4000</code>上启动了一个本地服务器，在浏览器中输入这个地址，可以看到刚刚构建好的博客：</p><p><img src="https://i.loli.net/2020/06/24/vmSUb5QH6l4afzF.png"></p><p>值得注意的是，在Dockerfile中我们暴露了4000端口，使用<code>-p</code>标签可以达到同样的效果：<code>docker run -p &lt;docker_port&gt;:&lt;local_port&gt; &lt;image_name&gt;</code>。比如<code>docker run -p 9999:8888 xxxx</code>代表将Docker容器中的9999端口转发到外部主机的8888端口。如果你是在远程服务器上使用的Docker，那么端口只是被转发到了远程服务器上，还得手动将远程服务器再转发到你本机上才能直接在本机浏览器上看到页面。</p><h2 id="Build-Docker-Images-with-Aliyun-Container-Registry"><a href="#Build-Docker-Images-with-Aliyun-Container-Registry" class="headerlink" title="Build Docker Images with Aliyun Container Registry"></a>Build Docker Images with Aliyun Container Registry</h2><p>因为某些原因，如果在构建镜像的时候需要通过<code>apt-get update</code>更新源，会发现无论如何都会卡住。这个时候可以使用<a href="https://cr.console.aliyun.com/">阿里云容器镜像服务</a>，在阿里的服务器上构建好镜像，再拉取到自己的机器上。注册好帐号之后，点击创建镜像仓库：</p><p><img src="https://i.loli.net/2020/06/24/u4DGHv3En1iLI5z.png"></p><p>这里仓库类型如果没有特殊需求建议使用公开，然后填写一些基本信息：</p><p><img src="https://i.loli.net/2020/06/24/Qipw5hAg136afnL.png"></p><p>之后设置代码源，其实就是告诉阿里云从哪儿获取Dockerfile，我这里用的是Github，所以需要先在阿里云中关联Github账号，然后在Github中创建一个用来放Dockerfile的仓库。构建设置里有一个“海外机器构建”，这正是我们使用阿里云容器服务的主要目的，勾选。</p><p><img src="https://i.loli.net/2020/06/24/ksvZJG9lKfdh6aR.png"></p><p>镜像仓库创建好之后，点进去，在构建页面点击添加规则：</p><p><img src="https://i.loli.net/2020/06/24/irBm3QcqjVhGMsv.png"></p><p>按下图进行设置即可，镜像版本就是你想要的镜像名字：</p><p><img src="https://i.loli.net/2020/06/24/7pAFvM8CJQbq6mU.png"></p><p>点击“立即构建”：</p><p><img src="https://i.loli.net/2020/06/24/GlMwqDInL7zVOpf.png"></p><p>等待一段时间后，如果构建成功，便可以进行拉取了，在镜像仓库的基本信息页面可以看到地址：</p><p><img src="https://i.loli.net/2020/06/24/57jmEv8PYkr2nQG.png"></p><p>将阿里云上的镜像拉取到本机之后一般会想要对镜像改名，可以使用<code>docker tag &lt;old_name&gt; &lt;new_name&gt;</code>。</p><h1 id="Build-Docker-Images-for-Deep-Learning"><a href="#Build-Docker-Images-for-Deep-Learning" class="headerlink" title="Build Docker Images for Deep Learning"></a>Build Docker Images for Deep Learning</h1><h2 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h2><p>在Docker中配置适用于OpenPAI的深度学习镜像不是一件容易的事，会有很多的坑，这里专门说一下如何配置。推荐在阿里云容器镜像服务中进行构建，会少很多麻烦。</p><p>第一步是初始镜像，由于需要用到CUDA，这里可以根据自己的需求（比如不同CUDA版本支持的GPU驱动版本不一样，还有Tensorflow不同版本对CUDA和cuDNN要求也不一样）从Nvidia的Dockerhub<a href="https://hub.docker.com/r/nvidia/cuda">官方页面</a>选择合适的CUDA和cuDNN版本：</p><p><img src="https://i.loli.net/2020/06/24/pftdhmHiWkTq8Fj.png"></p><p>这里我们选择CUDA10.1 + cuDNN7：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">FROM</span> nvidia/cuda:<span class="hljs-number">10</span>.<span class="hljs-number">1</span>-cudnn<span class="hljs-number">7</span>-devel-ubuntu<span class="hljs-number">18</span>.<span class="hljs-number">04</span>Copy<br></code></pre></td></tr></table></figure><p>这一条主要是解决乱码问题以及定义用到的软件包的版本，这里Miniconda版本设置为4.5.4的原因是这是最后一个自带Python3.6的版本，我在这儿为了稳定所以用了Python3.6，大家也可以安装最新版的Miniconda：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ENV</span> LANG=C.UTF-<span class="hljs-number">8</span> LC_ALL=C.UTF-<span class="hljs-number">8</span><br><span class="hljs-attribute">ENV</span> HADOOP_VERSION=<span class="hljs-number">2</span>.<span class="hljs-number">7</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">LABEL</span> HADOOP_VERSION=<span class="hljs-number">2</span>.<span class="hljs-number">7</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">ENV</span> MINICONDA_VERSION=<span class="hljs-number">4</span>.<span class="hljs-number">5</span>.<span class="hljs-number">4</span>Copy<br></code></pre></td></tr></table></figure><p>接下来安装必须的包，大家可以根据需求自行调整，<code>-y</code>标签代表Yes，即自动同意安装：</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs livescript">RUN DEBIAN_FRONTEND=noninteractive &amp;&amp; <span class="hljs-string">\</span><br>    apt-get -y update &amp;&amp; <span class="hljs-string">\</span><br>    apt-get -y install build-essential <span class="hljs-string">\</span><br>        wget <span class="hljs-string">\</span><br>        git <span class="hljs-string">\</span><br>        curl <span class="hljs-string">\</span><br>        unzip <span class="hljs-string">\</span><br>        automake <span class="hljs-string">\</span><br>        openjdk-<span class="hljs-number">8</span>-jdk <span class="hljs-string">\</span><br>        openssh-server <span class="hljs-string">\</span><br>        openssh-client <span class="hljs-string">\</span><br>        lsof <span class="hljs-string">\</span><br>        libcupti-dev &amp;&amp; <span class="hljs-string">\</span><br>    apt-get clean &amp;&amp; <span class="hljs-string">\</span><br>    rm -rf <span class="hljs-regexp">/var/lib/apt/lists/</span>*Copy<br></code></pre></td></tr></table></figure><p>安装Miniconda并设置环境变量，<code>-b</code>标签可以让Miniconda无交互自动安装：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">RUN wget --quiet https:<span class="hljs-regexp">//</span>repo.anaconda.com<span class="hljs-regexp">/miniconda/</span>Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh &amp;&amp; <span class="hljs-regexp">/bin/</span>bash Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh -b -p <span class="hljs-regexp">/opt/mi</span>niconda \<br>&amp;&amp; rm Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh<br>ENV PATH <span class="hljs-regexp">/opt/mi</span>niconda/bin:<span class="hljs-variable">$PATHCopy</span><br></code></pre></td></tr></table></figure><p>安装Hadoop，OpenPAI平台会用到：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">RUN wget -qO- http:<span class="hljs-regexp">//</span>archive.apache.org<span class="hljs-regexp">/dist/</span>hadoop<span class="hljs-regexp">/common/</span>hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span>/hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span>.tar.gz | \<br>    tar xz -C <span class="hljs-regexp">/usr/</span>local &amp;&amp; \<br>    mv <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoop-$&#123;HADOOP_VERSION&#125; /u</span>sr<span class="hljs-regexp">/local/</span>hadoopCopy<br></code></pre></td></tr></table></figure><p><code>ENV</code>的作用是配置环境变量。配置JAVA和Hadoop环境变量：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs routeros">ENV <span class="hljs-attribute">JAVA_HOME</span>=/usr/lib/jvm/java-8-openjdk-amd64 \<br>    <span class="hljs-attribute">HADOOP_INSTALL</span>=/usr/local/hadoop \<br>    <span class="hljs-attribute">NVIDIA_VISIBLE_DEVICES</span>=all<br><br>ENV <span class="hljs-attribute">HADOOP_PREFIX</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \<br>    <span class="hljs-attribute">HADOOP_BIN_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/bin \<br>    <span class="hljs-attribute">HADOOP_SBIN_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/sbin \<br>    <span class="hljs-attribute">HADOOP_HDFS_HOME</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \<br>    <span class="hljs-attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/lib/native \<br>    <span class="hljs-attribute">HADOOP_OPTS</span>=<span class="hljs-string">&quot;-Djava.library.path=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/lib/native&quot;</span>Copy<br></code></pre></td></tr></table></figure><p>设置PATH环境变量：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs elixir">ENV PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/nvidia/bin</span><span class="hljs-symbol">:/usr/local/cuda/bin</span><span class="hljs-symbol">:/usr/local/sbin</span><span class="hljs-symbol">:/usr/local/bin</span><span class="hljs-symbol">:/usr/sbin</span><span class="hljs-symbol">:/usr/bin</span><span class="hljs-symbol">:/sbin</span><span class="hljs-symbol">:/bin</span><span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>HADOOP_BIN_DIR&#125;<span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>HADOOP_SBIN_DIR&#125; \<br>LD_LIBRARY_PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/extras</span><span class="hljs-regexp">/CUPTI/lib</span><span class="hljs-symbol">:/usr/local/cuda/extras/CUPTI/lib64</span><span class="hljs-symbol">:/usr/local/nvidia/lib</span><span class="hljs-symbol">:/usr/local/nvidia/lib64</span><span class="hljs-symbol">:/usr/local/cuda/lib64</span><span class="hljs-symbol">:/usr/local/cuda/targets/x86_64-linux/lib/stubs</span><span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>JAVA_HOME&#125;/jre/lib/amd64/serverCopy<br></code></pre></td></tr></table></figure><p>完整的Dockerfile如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs awk">FROM nvidia/cuda:<span class="hljs-number">10.1</span>-cudnn7-devel-ubuntu18.<span class="hljs-number">04</span><br><br>ENV LANG=C.UTF-<span class="hljs-number">8</span> LC_ALL=C.UTF-<span class="hljs-number">8</span><br>ENV HADOOP_VERSION=<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span><br>LABEL HADOOP_VERSION=<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span><br>ENV MINICONDA_VERSION=<span class="hljs-number">4.5</span>.<span class="hljs-number">4</span><br><br>RUN DEBIAN_FRONTEND=noninteractive &amp;&amp; \<br>    apt-get -y update &amp;&amp; \<br>    apt-get -y install build-essential \<br>        wget \<br>        git \<br>        curl \<br>        unzip \<br>        automake \<br>        openjdk-<span class="hljs-number">8</span>-jdk \<br>        openssh-server \<br>        openssh-client \<br>        lsof \<br>        libcupti-dev &amp;&amp; \<br>    apt-get clean &amp;&amp; \<br>    rm -rf <span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/apt/</span>lists/*<br><br>RUN wget --quiet https:<span class="hljs-regexp">//</span>repo.anaconda.com<span class="hljs-regexp">/miniconda/</span>Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh &amp;&amp; <span class="hljs-regexp">/bin/</span>bash Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh -b -p <span class="hljs-regexp">/opt/mi</span>niconda \<br>&amp;&amp; rm Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh<br>ENV PATH <span class="hljs-regexp">/opt/mi</span>niconda/bin:<span class="hljs-variable">$PATH</span><br>    <br>RUN wget -qO- http:<span class="hljs-regexp">//</span>archive.apache.org<span class="hljs-regexp">/dist/</span>hadoop<span class="hljs-regexp">/common/</span>hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span>/hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span>.tar.gz | \<br>    tar xz -C <span class="hljs-regexp">/usr/</span>local &amp;&amp; \<br>    mv <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoop-$&#123;HADOOP_VERSION&#125; /u</span>sr<span class="hljs-regexp">/local/</span>hadoop<br>    <br>ENV JAVA_HOME=<span class="hljs-regexp">/usr/</span>lib<span class="hljs-regexp">/jvm/</span>java-<span class="hljs-number">8</span>-openjdk-amd64 \<br>    HADOOP_INSTALL=<span class="hljs-regexp">/usr/</span>local/hadoop \<br>    NVIDIA_VISIBLE_DEVICES=all<br><br>ENV HADOOP_PREFIX=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \<br>    HADOOP_BIN_DIR=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/bin \<br>    HADOOP_SBIN_DIR=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/sbin \<br>    HADOOP_HDFS_HOME=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \<br>    HADOOP_COMMON_LIB_NATIVE_DIR=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span><span class="hljs-regexp">/lib/</span>native \<br>    HADOOP_OPTS=<span class="hljs-string">&quot;-Djava.library.path=$&#123;HADOOP_INSTALL&#125;/lib/native&quot;</span><br><br>ENV PATH=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/nvidia/</span>bin:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>bin:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/sbin:/u</span>sr<span class="hljs-regexp">/local/</span>bin:<span class="hljs-regexp">/usr/</span>sbin:<span class="hljs-regexp">/usr/</span>bin:<span class="hljs-regexp">/sbin:/</span>bin:<span class="hljs-variable">$&#123;HADOOP_BIN_DIR&#125;</span>:<span class="hljs-variable">$&#123;HADOOP_SBIN_DIR&#125;</span>:<span class="hljs-variable">$PATH</span> \<br>LD_LIBRARY_PATH=<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>extras<span class="hljs-regexp">/CUPTI/</span>lib:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>extras<span class="hljs-regexp">/CUPTI/</span>lib64:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/nvidia/</span>lib:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/nvidia/</span>lib64:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>lib64:<span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/cuda/</span>targets<span class="hljs-regexp">/x86_64-linux/</span>lib<span class="hljs-regexp">/stubs:$&#123;JAVA_HOME&#125;/</span>jre<span class="hljs-regexp">/lib/</span>amd64/serverCopy<br></code></pre></td></tr></table></figure><p>建议先把这一部分进行构建，作为基础镜像，后面要配置其他环境（如安装Pytorch框架登），就不用重复构建这部分，还减少了出错的可能性。这里说一下，启动带CUDA的Docker镜像需要在<code>docker run</code>加上额外的参数<code>--runtime nvidia</code>。</p><p>接下来安装深度学习框架。</p><h2 id="Configure-PyTorch"><a href="#Configure-PyTorch" class="headerlink" title="Configure PyTorch"></a>Configure PyTorch</h2><p>假设上面的镜像我们命名为xiaoqinfeng/base，那么构建PyTorch的Dockerfile可以像下面这么写：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">FROM</span> xiaoqinfeng/base<br><br><span class="hljs-attribute">RUN</span> pip install -U pip<br><span class="hljs-attribute">RUN</span> pip install numpy scipy pandas matplotlib tqdm<br><span class="hljs-attribute">RUN</span> pip install torch==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">0</span>+cu<span class="hljs-number">101</span> torchvision==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span>+cu<span class="hljs-number">101</span> -f https://download.pytorch.org/whl/torch_stable.htmlCopy<br></code></pre></td></tr></table></figure><p>因为这里我用的CUDA10.1，其他版本的CUDA安装指令可能不太一样，具体可以参考<a href="https://pytorch.org/get-started/locally/">官网</a>。</p><h2 id="Configure-Tensorflow"><a href="#Configure-Tensorflow" class="headerlink" title="Configure Tensorflow"></a>Configure Tensorflow</h2><p>如果是安装Tensorflow，那么构建Tensorflow的Dockerfile可以像下面这么写：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> xiaoqinfeng/base<br><br><span class="hljs-keyword">RUN</span><span class="bash"> pip install -U pip</span><br><span class="hljs-keyword">RUN</span><span class="bash"> pip install numpy scipy pandas matplotlib tqdm tensorflow-gpuCopy</span><br></code></pre></td></tr></table></figure><p>这里会自动安装最新版本的Tensorflow2。Tensorflow不同版本对CUDA和cuDNN版本甚至Python版本的支持都不太一样，可以参考<a href="https://www.tensorflow.org/install/source#linux">官网</a>的说明。</p><h1 id="Deep-Learning-with-OpenPAI"><a href="#Deep-Learning-with-OpenPAI" class="headerlink" title="Deep Learning with OpenPAI"></a>Deep Learning with OpenPAI</h1><h2 id="What-is-OpenPAI"><a href="#What-is-OpenPAI" class="headerlink" title="What is OpenPAI"></a>What is OpenPAI</h2><p>OpenPAI是一个分布式深度学习计算资源管理平台，对于我们用户来说，只需要定义好Docker镜像，然后编写好任务设置，提交到平台之后，平台便会自动分配计算资源来运行任务。</p><p>OpenPAI界面：</p><img src="https://i.loli.net/2020/06/24/CDrZjgYR7lNcieh.png" style="zoom: 50%;" /><img src="https://i.loli.net/2020/06/24/FGJpVCbls7YP4aM.png" style="zoom: 50%;" /><p>下面我们来讲讲怎么向OpenPAI平台提交任务。</p><h2 id="Submit-Jobs-to-OpenPAI"><a href="#Submit-Jobs-to-OpenPAI" class="headerlink" title="Submit Jobs to OpenPAI"></a>Submit Jobs to OpenPAI</h2><h3 id="Pack-Code-amp-Data-Files"><a href="#Pack-Code-amp-Data-Files" class="headerlink" title="Pack Code &amp; Data Files"></a>Pack Code &amp; Data Files</h3><p>假设你已经完成了代码的编写和测试，你的目录结构可能看起来是这样：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css">.<br>├── <span class="hljs-selector-tag">README</span><span class="hljs-selector-class">.md</span><br>├── <span class="hljs-selector-tag">data</span><br>│   └── <span class="hljs-selector-tag">dataset</span><span class="hljs-selector-class">.csv</span><br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span><br>└── <span class="hljs-selector-tag">src</span><br>    ├── <span class="hljs-selector-tag">data</span><span class="hljs-selector-class">.py</span><br>    └── <span class="hljs-selector-tag">net</span><span class="hljs-selector-class">.pyCopy</span><br></code></pre></td></tr></table></figure><p>因为OpenPAI会创建一个虚拟容器来运行你的代码，所以你的数据和代码必须要以某种方式传送到OpenPAI上的虚拟容器中。我们先来打包，在代码目录下执行<code>tar -cvf files.tar ./</code>。之后，运行<code>python -m http.server &lt;port&gt;</code>。打开浏览器输入<code>&lt;server_ip&gt;:&lt;port&gt;</code>应该就能看到你的文件了：</p><p><img src="https://i.loli.net/2020/06/24/Cbgiw3XKnGYsNHp.png"></p><p>由于这个http进程需要一直运行，所以建议使用<code>screen</code>放到后台执行。</p><h3 id="Configure-Tasks"><a href="#Configure-Tasks" class="headerlink" title="Configure Tasks"></a>Configure Tasks</h3><p>像OpenPAI提交任务可以采用网页提交也可以使用VSCode插件，这里我们采用网页提交。登入OpenPAI界面，点击Submit Job：</p><p><img src="https://i.loli.net/2020/06/24/bhXAcJfOmo8RtT2.png"></p><p>可以看到提交任务的界面：</p><p><img src="https://i.loli.net/2020/06/24/KME8GuN49gyY1ph.png"></p><p>Job name大家可以自己设置。在Command一栏，是执行任务所需的全部命令，首先我们要做的就是将代码数据压缩包下载到容器中并解压：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elixir">wget &lt;server_ip&gt;<span class="hljs-symbol">:&lt;port&gt;/files</span>.tar<br><br>tar -xvf files.tarCopy<br></code></pre></td></tr></table></figure><p>然后是运行代码，假设我这里的任务比较简单，只有一行main.py的调用：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">python</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.pyCopy</span><br></code></pre></td></tr></table></figure><p>如果任务的执行比较复杂，也只需把命令填到Command里即可，OpenPAI会自动执行。接下来是设置配置，可以选GPU的数量，内存大小等等：</p><img src="https://i.loli.net/2020/06/24/T7ryOxjpJP4FWYR.png" style="zoom:67%;" /><p>然后是镜像的选择：</p><img src="https://i.loli.net/2020/06/24/3n7SpNlsLjBRvgE.png" style="zoom:67%;" /><p>要注意在本机上构建好镜像之后，需要把镜像重命名为<code>&lt;repository_address&gt;/&lt;image_name&gt;</code>的格式（我们的<code>&lt;repository&gt;</code>是<code>lin-ai-27:5000</code>，假设我的镜像名是<code>xiaoqinfeng/pytorch</code>，那就是改成<code>lin-ai-27:5000/xiaoqinfeng/pytorch</code>），然后执行<code>docker push</code>推送到Docker镜像服务器上才能在OpenPAI上使用。</p><p>提交之后，可以在Jobs界面看到任务的运行情况：</p><img src="https://i.loli.net/2020/06/24/ZD4cUgOCIqnyHdB.png" style="zoom: 50%;" /><h1 id="Misc"><a href="#Misc" class="headerlink" title="Misc"></a>Misc</h1><h2 id="Store-Files-in-Containers"><a href="#Store-Files-in-Containers" class="headerlink" title="Store Files in Containers"></a>Store Files in Containers</h2><p>我们往往需要在程序运行的时候保存文件，如checkpoints等。在OpenPAI上执行程序的话文件是保存在程序中的，如果我们想要在运行完之后把文件复制到本地电脑上呢？这个时候就需要在任务的配置文件里加上复制文件到HDFS的语句。首先确认你的HDFS的URL：如<code>hdfs://172.31.246.52:9000/你的OpenPAI用户名/</code>。</p><p>如果要创建文件夹，则可以使用<code>hdfs dfs -mkdir -p &lt;HDFS URL&gt;+&lt;New Folder&gt;</code>。这里<code>&lt;New Folder&gt;</code>是你要创建的的文件夹的路径，用起来和Linux的<code>mkdir</code>命令其实是差不多的。</p><p>要复制文件（夹）则使用<code>hdfs dfs -cp &lt;Source Dir&gt; &lt;Dest Dir&gt;</code>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;实验室服务器集群采用OpenPAI来进行GPU资源的管理，而</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Misc" scheme="http://qfxiao.me/categories/Technical-Notes/Misc/"/>
    
    
    <category term="Pytorch" scheme="http://qfxiao.me/tags/Pytorch/"/>
    
    <category term="Tensorflow" scheme="http://qfxiao.me/tags/Tensorflow/"/>
    
    <category term="Docker" scheme="http://qfxiao.me/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu20.04LTS 深度学习环境配置 CUDA11 + cuDNN8 + Tensorflow + Pytorch</title>
    <link href="http://qfxiao.me/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA11-cuDNN8-Tensorflow-Pytorch/"/>
    <id>http://qfxiao.me/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA11-cuDNN8-Tensorflow-Pytorch/</id>
    <published>2020-06-02T02:26:13.000Z</published>
    <updated>2020-12-21T14:05:52.434Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu的最新LTS版本也更新到了20.04，在给新机器配置深度学习环境的时候发现比以前容易了许多，特此写一篇Tutorial。这里的安装方法只针对Ubuntu20.04LTS，对于其他版本的系统可能不太适用。</p><h1 id="Install-GPU-Drivers"><a href="#Install-GPU-Drivers" class="headerlink" title="Install GPU Drivers"></a>Install GPU Drivers</h1><p>这里假设安装系统之后已经做好了必要的配置（安装常用软件依赖、修改国内源等）。Ubuntu20.04中GPU驱动可以直接通过GUI界面安装，十分方便，方法是找到软件与更新 (Software &amp; Updates)，在附加驱动 (additional drivers) 选项卡中选择驱动版本，一般是选择“专有，tested” (proprietary, tested) 那个，之后点Apply Changes，重启。</p><p><img src="https://i.loli.net/2020/06/24/xevtVosYOH7D68I.png"></p><p>如果是服务器的话，也可以采用命令行的安装方法。在命令行输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ubuntu-drivers devices<br></code></pre></td></tr></table></figure><p>会列出驱动信息：</p><p><img src="https://i.loli.net/2020/12/19/CGWnoRFPz23r46K.png" alt="image-20201219103330645"></p><p>可以看到推荐驱动版本是455，直接使用命令<code>ubuntu-drivers autoinstall</code>就可以自动安装推荐版本的驱动了。</p><h1 id="Install-CUDA-amp-cuDNN"><a href="#Install-CUDA-amp-cuDNN" class="headerlink" title="Install CUDA &amp; cuDNN"></a>Install CUDA &amp; cuDNN</h1><p>最常用的方式是按照[官网](<a href="https://developer.nvidia.com/cuda-11.0-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal">CUDA Toolkit 11.0 Download | NVIDIA Developer</a>)的指导来安装CUDA，之后需要设置环境变量，在<code>~/.bashrc</code>中添加下列指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> PATH=/usr/<span class="hljs-built_in">local</span>/cuda-11.0/bin<span class="hljs-variable">$&#123;PATH:+:<span class="hljs-variable">$&#123;PATH&#125;</span>&#125;</span><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="hljs-built_in">local</span>/cuda-11.0/lib64\<br>                         <span class="hljs-variable">$&#123;LD_LIBRARY_PATH:+:<span class="hljs-variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span><br></code></pre></td></tr></table></figure><p>还可以选择简单的方式，直接使用apt-get来安装CUDA：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install nvidia-cuda-toolkit<br></code></pre></td></tr></table></figure><p>不过这样会直接安装最新的CUDA版本，而PyTorch等深度学习框架不一定对最新的CUDA版本都有很好的支持，所以不推荐这种方式。</p><p>安装完CUDA之后输入<code>nvcc --version</code>可以测试是否安装成功，输入<code>nvidia-smi</code>可以看到GPU信息和CUDA版本。</p><p>之后安装cuDNN，进入<a href="https://developer.nvidia.com/cudnn">官网</a>，选择Download cuDNN：</p><p><img src="https://i.loli.net/2020/06/24/VYBRoINFDC9ObA1.png"></p><p>会要求登录，如果没有账号的注册一个即可。在这里根据CUDA版本选择适合的cuDNN，我这里是CUDA10.2。我们选择deb包的方式安装，下载下图中圈出来的三个deb包，依次用<code>sudo dpkg -i xxx.deb</code>命令安装。</p><p><img src="https://i.loli.net/2020/06/24/qcDG5t3JY6vfoQM.png"></p><h1 id="Configure-Python"><a href="#Configure-Python" class="headerlink" title="Configure Python"></a>Configure Python</h1><p>为了更好地管理Python包和虚拟环境，我们需要安装Anaconda。使用Anaconda之后，我们可以创建虚拟环境，虚拟环境之间互不干扰。做科学实验我们一般需要安装大量的Python包，有的包之间甚至还有冲突，如果我们把他们都安装在同一个环境下就会难以管理，甚至出冲突。而有了虚拟环境之后，我们可以把不同需求放在不同虚拟环境中，比如深度学习开发放在一个虚拟环境中（安装Tensorflow等），网站开发放在一个虚拟环境中（安装Flask等）。Anaconda默认自带大量的包，不过我们一般会创建新的虚拟环境去安装新的包，所以这里我们选用Miniconda。Miniconda和Anaconda唯一的区别是不会自带大量Python包，这里大家自行选择。Anaconda国内镜像下载地址为：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/%EF%BC%8CMiniconda%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%E4%B8%BA%EF%BC%9Ahttps://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/%E3%80%82">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/，Miniconda国内镜像下载地址为：https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/。</a></p><p>比如说我们下载的是<code>Miniconda3-py38_4.8.2-Linux-x86_64.sh</code>，执行<code>bash Miniconda3-py38_4.8.2-Linux-x86_64.sh</code>即可安装。显示一大屏用户协议哪儿按<code>q</code>可以直接跳过，其他选项的默认的输入<code>yes</code>即可。在提示是否需要conda init的时候记得输入<code>yes</code>。</p><p>安装成功之后，重开一个终端，可以看到现在处于<code>base</code>环境中：</p><p><img src="https://i.loli.net/2020/06/24/giml1UKzWuyqTjr.png"></p><p>我们先配置一下国内镜像，执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim ~/.condarc<br></code></pre></td></tr></table></figure><p>然后粘贴下列文本使用清华源：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs awk">channels:<br>  - defaults<br>show_channel_urls: true<br>channel_alias: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn/anaconda<br>default_channels:<br>  - https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>pkgs/main<br>  - https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>pkgs/free<br>  - https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>pkgs/r<br>  - https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>pkgs/pro<br>  - https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>pkgs/msys2<br>custom_channels:<br>  conda-forge: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br>  msys2: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br>  bioconda: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br>  menpo: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br>  pytorch: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br>  simpleitk: https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/anaconda/</span>cloud<br></code></pre></td></tr></table></figure><p>之后我们输入<code>conda create -n &lt;your_name&gt;</code>创建一个新的虚拟环境，如果需要指定Python版本，则<code>conda create --n &lt;your_name&gt; python=&lt;python_version&gt;</code>。之后输入<code>conda activate &lt;your_name&gt;</code>进入虚拟环境，如果需要退出，则使用<code>conda deactivate</code>。</p><p>安装常用包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install --yes numpy scipy pandas matplotlib tqdm pip jupyter<br></code></pre></td></tr></table></figure><p><code>--yes</code>的作用是手动输入<code>y</code>来确认是否安装，这里列出的是一些最常用的Python包，大家可以根据自己的需求自行调整。<code>conda install</code>为Anaconda中安装Python包的方式。</p><h1 id="Install-PyTorch"><a href="#Install-PyTorch" class="headerlink" title="Install PyTorch"></a>Install PyTorch</h1><p>这里来安装PyTorch环境，推荐使用<code>conda create -n pytorch</code>创建一个专有虚拟环境，然后使用<code>conda install</code>安装常用包。对于安装PyTorch，我们可以使用<code>conda</code>也可以使用<code>pip</code>安装。<code>pip</code>是另外一个安装Python包的工具，由于不检查依赖所以比<code>conda</code>安装速度快，而且包的数量比<code>conda</code>多，使用也更广泛。同样<code>pip</code>也可以使用国内镜像加速下载，详见<a href="https://mirrors.tuna.tsinghua.edu.cn/help/pypi/%E3%80%82">https://mirrors.tuna.tsinghua.edu.cn/help/pypi/。</a></p><p>对于CUDA11.0，官方给出的用<code>conda</code>安装PyTorch的命令（CUDA11.1也是这个）是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch<br></code></pre></td></tr></table></figure><p>用<code>pip</code>安装PyTorch的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html<br></code></pre></td></tr></table></figure><p>对于其他版本的CUDA安装命令可能不一样，可以去<a href="https://pytorch.org/get-started/locally/">官网</a>查看。</p><p>可以使用以下命令来测试GPU版本的PyTorch是否正常工作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -c <span class="hljs-string">&quot;import torch; print(torch.cuda.is_available())&quot;</span><br></code></pre></td></tr></table></figure><h1 id="Install-Tensorflow"><a href="#Install-Tensorflow" class="headerlink" title="Install Tensorflow"></a>Install Tensorflow</h1><p>安装Tensorflow环境同样推荐创建一个专有虚拟环境。对于Tensorflow2的安装，使用<code>pip</code>十分方便，使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install tensorflow tensorflow-gpu<br></code></pre></td></tr></table></figure><p>即可。要安装其他版本的Tensorflow可以使用<code>pip install tensorflow==&lt;tf_version&gt; tensorflow-gpu==&lt;tf_version&gt;</code>来指定版本。不过不同版本的Tensorflow要求的CUDA版本都有所不同，可以参考<a href="https://www.tensorflow.org/install/source#linux">官网</a>的说明。</p><p>可以使用以下命令来测试GPU版本的Tensorflow是否正常工作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python -c <span class="hljs-string">&quot;import tensorflow as tf; tf.config.list_physical_devices(&#x27;GPU&#x27;)&quot;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;Ubuntu的最新LTS版本也更新到了20.04，在给新机器</summary>
      
    
    
    
    <category term="Technical Notes" scheme="http://qfxiao.me/categories/Technical-Notes/"/>
    
    <category term="Misc" scheme="http://qfxiao.me/categories/Technical-Notes/Misc/"/>
    
    
    <category term="Pytorch" scheme="http://qfxiao.me/tags/Pytorch/"/>
    
    <category term="Tensorflow" scheme="http://qfxiao.me/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Deep Anomaly Detection Using Geometric Transformations</title>
    <link href="http://qfxiao.me/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/"/>
    <id>http://qfxiao.me/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/</id>
    <published>2020-06-01T15:17:03.000Z</published>
    <updated>2020-06-26T16:25:25.079Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>本文考虑针对图像的异常检测。记$\mathcal X$为所有自然图像的空间，$X\subseteq\mathcal X$为正常图像集合。给定数据集$S\subseteq X$，异常检测的目的是学习一个分类器$h_S(x):\mathcal X\rightarrow{0,1}$，其中$h_S(x)=1\Leftrightarrow x\in X$。</p><p>为了兼顾查准率和查全率，常用的设置是学习一个打分函数$n_S(x):\mathcal X\rightarrow\mathbb R$，分数越高代表样本属于$X$的概率越大。之后，通过设定阈值，便可以构建异常分类器：<br>$$<br>\begin{align}<br>h_S^\lambda(x)=<br>\begin{cases}<br>1 &amp; n_S(x)\leq\lambda\<br>0 &amp; n_S(x)&lt;\lambda<br>\end{cases}<br>\end{align}<br>$$</p><h2 id="Discriminative-Learning-of-an-Anomaly-Scoring-Function-Using-Geometric-Transformations"><a href="#Discriminative-Learning-of-an-Anomaly-Scoring-Function-Using-Geometric-Transformations" class="headerlink" title="Discriminative Learning of an Anomaly Scoring Function Using Geometric Transformations"></a>Discriminative Learning of an Anomaly Scoring Function Using Geometric Transformations</h2><p>有初始数据集$S$，几何变换集合$\mathcal T$，通过对$S$中每个样本施加这$|\mathcal T|$个几何变换得到新数据集记为$S_\mathcal{T}$，且$S_\mathcal{T}$中每个样本的标签为变换的序号。之后，在$S_\mathcal{T}$上训练一个$|\mathcal T|$分类器。在测试阶段，对测试样本同样施加$|\mathcal T|$个几何变换，分类器会给出经过$\mathrm{softmax}$的输出向量，最终的异常分数由经过输出的向量构造的分布对数似然得来。</p><h3 id="Creating-and-Learning-the-Self-Labeled-Dataset"><a href="#Creating-and-Learning-the-Self-Labeled-Dataset" class="headerlink" title="Creating and Learning the Self-Labeled Dataset"></a>Creating and Learning the Self-Labeled Dataset</h3><p>设$\mathcal T={T_0,T_1,\cdots,T_{k-1}}$为几何变换集合，$1\leq i\leq k-1,\space T_i:\mathcal X\rightarrow \mathcal X$，且$T_0(x)=x$。$S_\mathcal{T}$定义为：</p><p>$$<br>S_\mathcal T={(T_j(x),j):x\in S,T_j\in\mathcal T}<br>$$<br>对于每个$x\in S$，$j$为$T_j(x)$的标签。我们直接学习一个$K$类分类器$f_\theta$，来预测输入样本对应的几何变换种类，这相当于是一个图像分类问题。</p><img src="https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png" style="zoom:67%;" /><h3 id="Dirichlet-Normality-Score"><a href="#Dirichlet-Normality-Score" class="headerlink" title="Dirichlet Normality Score"></a>Dirichlet Normality Score</h3><p>接下来要做的是如何定义异常分数，记为$n_S(x)$，这是文中的一个重要的部分。设几何变换集合$\mathcal T={T_0,T_1,\cdots,T_{k-1}}$，且$k$分类器$f_\theta$在$S_\mathcal{T}$上完成训练。对于任意一个样本$x$，令$\mathbf y(x)=\text{softmax}(f_{\theta}(x))$，即分类器$f_\theta$输出的$\text{softmax}$之后的向量。异常分数$n_S(x)$定义为：</p><p>$$<br>n_S(x)=\sum\limits_{i=0}^{k-1}\log p(\mathbf y(T_i(x))|T_i)<br>$$</p><p>该异常分数定义为每个类别上，在几何变换$T_i$的条件下，输出的$\mathbf y$的对数似然之和。在文中，作者假设$\mathbf y(T_i(x)|T_i$服从迪利克雷分布：$\mathbf y(T_i(x))|T_i\sim\text{Dir}(\boldsymbol \alpha_i)$，其中$\boldsymbol \alpha_i\in\mathbb R^k_+$，$x\sim p_X(x)$，$i\sim\text{Uni}(0,k-1)$，而$p_X(x)$代表正常样本的真实数据分布。于是：</p><p>$$<br>n_S(x)=\sum_{i=0}^{k-1}\left[\log\Gamma(\sum_{j=0}^{k-1}[\tilde{\boldsymbol\alpha}<em>i]<em>j)-\sum</em>{j=0}^{k-1}\log\Gamma([\tilde{\boldsymbol\alpha}_i]_j)+\sum</em>{j=0}^{k-1}([\tilde{\boldsymbol\alpha}_i]_j-1)\log\mathbf y(T_i(x))_j\right]<br>$$</p><p>因为$\tilde{\alpha}<em>i$相对于$x$来说是常数，所以可以直接忽略，于是式子简化为：<br>$$<br>n_S(x)=\sum_{i=0}^{k-1}\sum</em>{j=0}^{k-1}([\tilde{\boldsymbol\alpha}_i]<em>j-1)\log\mathbf y(T_i(x))_j=\sum</em>{i=0}^{k-1}(\tilde{\boldsymbol \alpha}_i-1)\cdot\log\mathbf y(T_i(x))<br>$$</p><p>注意这里的每个$\boldsymbol \alpha_i$都是一个向量，即对于每个变换$i$，都对应一个迪利克雷分布，其参数为$\boldsymbol\alpha_i$；在对训练集进行第$i$个几何变换之后，我们得到了${T_i(x)}$，然后分类器$f_\theta(\cdot)$的输出$\mathbf y(T_i(x))$相当于迪利克雷分布的观测值，我们需要根据观测值来估计参数$\boldsymbol \alpha_i$，然后根据这个参数来计算$n_S(x)$。对于$\boldsymbol\alpha_i$，可以知道其第$i$个分量应该是相对比较大的，下面是运行官方代码得到的$\boldsymbol\alpha_i$的结果（$i=69$，$i$从$0$开始，总共为$72$维），可以看到第$69$个分量是最大的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">[INFO] value of mle_alpha_t:<br> [ 0.10228925  0.08997199  0.13083569  0.10862965  0.09811163  0.08527119<br>  0.17637901  0.27628416  0.12873376  0.19197053  0.11587154  0.09873095<br>  0.12700618  0.07688542  0.10488203  0.12499191  0.11637607  0.07739511<br>  0.13049147  0.51031647  0.20546597  0.15558449  0.09288609  0.12134945<br>  0.09324992  0.14650162  0.16281216  0.11827823  0.08214853  0.15618336<br>  0.28129761  0.45293697  0.11485838  1.78598954  0.16556983  0.1141158<br>  0.10909459  0.13916602  0.11563799  0.07309986  0.11049714  0.12974086<br>  0.15930642  0.13714361  0.13938356  0.70619553  0.11174039  0.07201538<br>  0.16626109  0.12153727  0.09548811  0.07940956  0.15832209  0.11035474<br>  0.12487912  0.16937875  0.23212662  0.37041831  0.08557451  0.0839439<br>  0.09924258  0.39766872  0.14917286  0.08704662  0.09554555  0.31047109<br>  0.24504759  0.16812463  0.11508187 63.98878807  0.12971073  0.07972932]<br></code></pre></td></tr></table></figure><p>下图也展示了对于每个变换$i$，$\mathbf y(T_i(x)|T_i$分布的情况：</p><img src="https://i.loli.net/2020/06/23/fLkst4i7Hu6PhQl.png" style="zoom:67%;" /><p>作者还给出了一种简化的形式，$\hat{n}<em>S(x)=\frac{1}{k}\sum^{k-1}</em>{j=0}[\mathbf y(T_j(x))]_j$。相当于说，对于每个变换$T_i$分类器都会给出一个$\text{softmax}$向量，取其第$i$个分量$[\mathbf y(T_j(x))]_j$，然后把每个变换对应的$[\mathbf y(T_j(x))]_j$加起来。</p><p>整个算法的流程如下：</p><img src="https://i.loli.net/2020/06/23/z8MpdeoD6ZGavlN.png" style="zoom:67%;" /><p>这里结合作者的源代码简单说一下检测阶段的流程。</p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> t_ind <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(transformer.n_transforms):<br>        observed_dirichlet = mdl.predict(transformer.transform_batch(observed_data, [t_ind] * <span class="hljs-built_in">len</span>(observed_data)), batch_size=<span class="hljs-number">1024</span>)<br></code></pre></td></tr></table></figure><p>在训练好模型之后，对于训练集的所有样本，对其进行$K$个几何变换之后，得到$K$个样本${T_i(x)}$，对于所有第$i$个几何变换对应的样本${T_i(x)}$，通过分类器$f_\theta$会给出输出$\mathbf y(T_i(x))$。这里对应算法中的第$7-8$行，这个<code>observed_dirichlet</code>就是$S_i$。</p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">log_p_hat_train = np.log(observed_dirichlet).mean(axis=<span class="hljs-number">0</span>)<br><br>alpha_sum_approx = calc_approx_alpha_sum(observed_dirichlet)<br>alpha_0 = observed_dirichlet.mean(axis=<span class="hljs-number">0</span>) * alpha_sum_approx<br></code></pre></td></tr></table></figure><p>之后这部分主要对应算法中的$9-11$行。作者把所有的第$i$个变换，分类器的输出的集合（也就是变量<code>observed_dirichlet</code>）记为$S_i$，$\bar s$为$S_i$的平均，$\bar l$为$S_i$对数的平均（变量<code>log_p_hat_train</code>），初始值$\tilde{\alpha}_i$由$\bar s\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}$给出（变量<code>alpha_0</code>）。函数<code>calc_approx_alpha_sum</code>实现的是算法中第$11$行的$\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}$，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calc_approx_alpha_sum</span>(<span class="hljs-params">observations</span>):</span><br>    N = <span class="hljs-built_in">len</span>(observations)<br>    f = np.mean(observations, axis=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">return</span> (N * (<span class="hljs-built_in">len</span>(f) - <span class="hljs-number">1</span>) * (-psi(<span class="hljs-number">1</span>))) / (<br>        N * np.<span class="hljs-built_in">sum</span>(f * np.log(f)) - np.<span class="hljs-built_in">sum</span>(f * np.<span class="hljs-built_in">sum</span>(np.log(observations), axis=<span class="hljs-number">0</span>)))<br></code></pre></td></tr></table></figure><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mle_alpha_t = fixed_point_dirichlet_mle(alpha_0, log_p_hat_train)<br></code></pre></td></tr></table></figure><p>这里对应算法中的$12-14$行，即重复$\tilde\alpha_i\leftarrow\Psi^{-1}\left(\Psi(\sum_j[\alpha_i]_j)+\bar l\right)$来估计$\alpha$，函数<code>fixed_point_dirichlet_mle</code>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fixed_point_dirichlet_mle</span>(<span class="hljs-params">alpha_init, log_p_hat, max_iter=<span class="hljs-number">1000</span></span>):</span><br>    alpha_new = alpha_old = alpha_init<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iter):<br>        alpha_new = inv_psi(psi(np.<span class="hljs-built_in">sum</span>(alpha_old)) + log_p_hat)<br>        <span class="hljs-keyword">if</span> np.sqrt(np.<span class="hljs-built_in">sum</span>((alpha_old - alpha_new) ** <span class="hljs-number">2</span>)) &lt; <span class="hljs-number">1e-9</span>:<br>            <span class="hljs-keyword">break</span><br>        alpha_old = alpha_new<br>    <span class="hljs-keyword">return</span> alpha_new<br></code></pre></td></tr></table></figure><p>$\Psi^{-1}(\cdot)$是通过数值方法来估计的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">inv_psi</span>(<span class="hljs-params">y, iters=<span class="hljs-number">5</span></span>):</span><br>    <span class="hljs-comment"># initial estimate</span><br>    cond = y &gt;= <span class="hljs-number">-2.22</span><br>    x = cond * (np.exp(y) + <span class="hljs-number">0.5</span>) + (<span class="hljs-number">1</span> - cond) * <span class="hljs-number">-1</span> / (y - psi(<span class="hljs-number">1</span>))<br><br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(iters):<br>        x = x - (psi(x) - y) / polygamma(<span class="hljs-number">1</span>, x)<br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><hr><p>最后，在得到对$\alpha$的估计之后，可以来计算测试样本的分数了。这里对应的是算法中的第$16$行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x_test_p = mdl.predict(transformer.transform_batch(x_test, [t_ind] * <span class="hljs-built_in">len</span>(x_test)), batch_size=<span class="hljs-number">1024</span>)<br><br>scores += dirichlet_normality_score(mle_alpha_t, x_test_p)<br></code></pre></td></tr></table></figure><p>函数<code>dirichlet_normality_score</code>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dirichlet_normality_score</span>(<span class="hljs-params">alpha, p</span>):</span><br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((alpha - <span class="hljs-number">1</span>) * np.log(p), axis=<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><p>文中用到了如下的Baseline：</p><ul><li><strong>One-class SVM. **单类支持向量机，作者使用了三个变体，分别为</strong>RAW-OC-SVM<strong>——使用原始数据作为输入，</strong>CAE-OC-SVM<strong>——使用一个卷积自编码器来获得低维表示作为输入和</strong>E2E-OC-SVM<strong>——全名为</strong>One-Class Deep Support Vector Data Description**；</li><li>**Deep structured energy-based models. **</li><li>**Deep Autoencoding Gaussian Mixture Model. **</li><li>**Generative Adversarial Networks. **</li></ul><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>文中用到了一下几个数据集：</p><ul><li><strong>CIFAR-10</strong></li><li><strong>CIFAR-100</strong></li><li><strong>Fashion-MNIST</strong></li><li><strong>CatsVsDogs</strong></li></ul><p>在实验中所有图片都被归一化到$[-1,1]$的范围。</p><h2 id="Experimental-Protocol"><a href="#Experimental-Protocol" class="headerlink" title="Experimental Protocol"></a>Experimental Protocol</h2><p>设数据集有$C$个类，我们会进行$C$次实验，在第$c$次实验 ($1\leq c \leq C$)中我们会将第$c$个类作为正常样本，而其他类作为异常样本。在训练阶段，训练集只包含正常样本，而在测试阶段则会有正常样本和异常样本。在获得异常分数之后，阈值$\lambda$则根据ROC曲线下面积选择。</p><p>实验中使用的几何变换基于以下三种基变换：</p><ul><li>**Horizontal flip: ** 记为$T_b^{flip}(x)$，$b\in{T,F}$代表是否翻转；</li><li>**Translation: ** 记为$T_{s_h,s_w}^{trans}(x)$，其中$s_h,s_w\in{-1,0,1}$。在长宽两个维度上位移分别为$0.25$高度和$0.25$宽度，这两个维度发生位移的方向由$s_h$和$s_w$决定，当$s_h=s_w=0$时代表不移动；</li><li>**Rotation by multiples 90 degrees: ** 记为$T_k^{rot}(x)$，$k\in{0,1,2,3}$。旋转$k\times90$度。</li></ul><p>将三种基变换叠加有：<br>$$<br>\mathcal T=\left{<br> T_k^{rot}\circ T_{s_h,s_w}^{trans}\circ T_b^{flip} : \begin{matrix}<br> b &amp;\in {T,F}\<br> s_h,s_w&amp;\in{-1,0,1}\<br> k&amp;\in{0,1,2,3}<br> \end{matrix}<br>\right}<br>$$<br>最终几何变换种数为$2\times3\times3\times4=72$种。</p><p>分类器模型使用的是<strong>Wide Residual Network</strong>，优化器为Adam，Batch size为128，训练轮数为200。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>下面是不同方法在不同数据集上的实验结果：</p><p><img src="https://i.loli.net/2020/06/24/gHZohrvz9MGYmxi.png"></p><p>评测标准使用的是AUROC。作者关于结果的分析主要有以下几点：</p><ol><li>在绝大多数情况下，我们的算法都比Baseline要好，而且是越大的数据集效果越好。CatsVsDogs数据集每张图片的大小比其他几个数据集都要大，而Baseline在这个数据集上的结果都在$50%$或不到$50%$，这基本等同于瞎猜；</li><li>在CIFAR-100数据集里，由于将这100类聚合为了20类，所以存在类内样本差异大的问题。比如在类$5$、类$7$和类$13$上，模型表现就不够好；</li><li>在Fashion-MNIST数据集上几乎所有方法（除了DAGMM）都表现很好。</li></ol><h2 id="On-the-Intuition-for-Using-Geometric-Transformations"><a href="#On-the-Intuition-for-Using-Geometric-Transformations" class="headerlink" title="On the Intuition for Using Geometric Transformations"></a>On the Intuition for Using Geometric Transformations</h2><p>这里作者对所选用的几何变换做了一些解释。实验中选用的三种基本几何变换都是可逆的线性几何变换（且为双射），作者也试过一些复杂的非线性变换，如高斯模糊、锐化、伽马校正等等，但是效果并不好。</p><p>作者认为分类器能够分辨不同变换的能力与最终性能成正比，为了验证这一点，进行了$3$个实验。从MNIST数据集选择一个数字作为正常样本，几何变换只采用两个，然后选择另一个数字作为异常样本，结果如下：</p><ul><li>**Normal digit: 8，Anomaly: 3，Transformations: Identity and horizontal flip. **由于数字$8$是对称的，所以要让分类器分辨原始的$8$和翻转之后的$8$是很难的，AUROC只有$0.646$；</li><li>**Normal digit: 3，Anomaly: 8，Transformations: Identity and horizontal flip. **这里把$3$作为正常样本，由于$3$不是对称的，所以两种变换是可以分辨的，AUROC达到了$0.957$；</li><li>**Normal digit: 8，Anomaly: 3，Transformations: Identity and translation by 7 pixels. **同样是把$8$作为正常样本，但变换用的是平移，AUROC达到了$0.919$。</li></ul><p>除此之外，作者还设计了一个实验，目的是测试什么样的图像会获得较高的分数$n_S(x)$。在给定训练好的分类器的情况下，优化输入的图像，目标函数是最大化分数$n_S(x)$。下图为实验结果：</p><p><img src="https://i.loli.net/2020/06/24/8Pi4EKCRuBXrYgp.png"></p><p>在左图中，将数字$3$作为正常样本训练的分类器、原始输入为数字$0$的图片时，随着优化的进行，图片慢慢地变得像数字$3$。在右图中，同样是将数字$3$作为正常样本训练的分类器，不过原始输入也是数字$3$，这时图像却没有怎么变化。</p><h1 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h1><ul><li>文中提到的在CIFAR100数据的实验上，由于类间差异比较大导致效果较差，那么很自然地，不同的变换样本对应的集簇实际上应当足够分开，集簇内的样本要足够进，这样对于分类器来说才能比较好的分类。不过采用的几何变换并没有针对这一点进行特别设计；</li><li>文中强调了所使用的变换为几何变换，其实除此之外，所使用的变换还都是可以用矩阵表示的可逆的变换。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Cross-dataset Time Series Anomaly Detection for Cloud Systems</title>
    <link href="http://qfxiao.me/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/"/>
    <id>http://qfxiao.me/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/</id>
    <published>2020-06-01T08:14:08.000Z</published>
    <updated>2020-06-25T05:28:22.135Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文介绍了一种用于云计算平台的时间序列异常检测框架。为了解决标签不足的问题，文中使用了迁移学习的方法，即在有标签的source domain上训练模型，在没有标签的target domain上检测。同时，文中还使用了主动学习的方法来挑选最有价值的无标签样本进行标记。</p><p><a href="https://www.usenix.org/system/files/atc19-zhang-xu.pdf">📰Get Paper</a></p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>针对云计算平台数据的异常检测通常是应用在云监控数据，如KPI、CPU使用率、系统负载等时序数据上。和传统的异常检测不一样的是，时序异常检测往往更难，文中总结了以下几个挑战：</p><ul><li>异常特征的差异性。在不同的云服务系统中，对异常的容忍度是不同的，所以对每个场景或系统组件设置准确的阈值来进行异常检测是十分困难的；</li><li>时间依赖性。该异常检测问题处理的是时间序列数据，而传统的异常检测并不会考虑时间依赖性；</li><li>无监督学习的性能问题。无监督的异常检测方法的性能有限，会带来大量的误报；</li><li>有监督学习需要大量标签。</li></ul><h1 id="Proposed-Approach"><a href="#Proposed-Approach" class="headerlink" title="Proposed Approach"></a>Proposed Approach</h1><p>为了解决上述挑战，文中提出了一个时间序列异常检测框架ATAD (Active Transfer Anomaly Detection)。该框架结合了迁移学习技术和主动学习技术，示意图如下：</p><img src="https://i.loli.net/2020/06/25/jOB4rC2gnH9VcQW.png" style="zoom:67%;" /><p>未标记数据$T_u$是我们要检测的目标数据 (target domain)，标记数据$T_l$是我们的源数据 (source domain)，可以是开源数据或者是其他系统的监控数据。</p><h2 id="Transfer-Learning-Component"><a href="#Transfer-Learning-Component" class="headerlink" title="Transfer Learning Component"></a>Transfer Learning Component</h2><p>在应用迁移学习时，我们需要考虑以下几个因素：</p><ul><li>我们处理的是时间序列数据，即在不同的时间点上样本之间不是相互独立的。为了解决这个问题，我们提取了不同的特征，每一个时间点被转换为了高维的特征向量，且每个时间点附近的背景信息被保存在了特征向量之中；</li><li>时间序列的粒度。粗粒度的迁移学习不利于发现异常，本文采用细粒度，即数据点级别的迁移学习；</li><li>迁移学习需要source domain和target domain具有潜在的相似性，所以我们需要对source domain中的样本进行过滤。</li></ul><img src="https://i.loli.net/2020/06/25/aM7Qvt6DwGXnThm.png" style="zoom:67%;" /><h3 id="Feature-Identification"><a href="#Feature-Identification" class="headerlink" title="Feature Identification"></a>Feature Identification</h3><p>这一节描述特征工程中用到的特征。在提取特征之前，文中使用了离散傅里叶变换来识别时间序列的周期$p$，并为后面滑动窗口的大小原则作参考。</p><h4 id="Statistical-Features"><a href="#Statistical-Features" class="headerlink" title="Statistical Features"></a>Statistical Features</h4><p>统计特征包含了一些基本的统计信息，如均值、方差等，用到的特征如下表所示：</p><img src="https://i.loli.net/2020/06/25/jI9EbCy1XueDViw.png" style="zoom:67%;" /><p>表中的统计特征都是基于大小等于周期$p$的滑动窗口的。</p><h4 id="Forecasting-Error-Features"><a href="#Forecasting-Error-Features" class="headerlink" title="Forecasting Error Features"></a>Forecasting Error Features</h4><p>使用预测特征的理由是如果一个数据点偏离预测值很远，那么它很有可能是异常。文中使用了多种时间序列预测模型，如SARIMA、Holt、Holt-Winters、STL等。最终的预测结果使用下式来加权集成：<br>$$<br>\hat{Y}<em>t=\sum\limits</em>{m=1}^{M}\frac{\hat{Y}<em>{m,t}}{M-1}\left(1-\frac{RMSE</em>{m,t}}{\sum\limits_{n=1}^M RMSE_{n,t}}\right)<br>$$<br>$M$代表$M$个不同模型，$RMSE_{m,t}$代表模型$m$在时间$t$的$RMSE$，$\hat{Y}_t$是在时间$t$的最终预测结果。之后，使用下表中的Metrics来计算不同预测特征：</p><img src="https://i.loli.net/2020/06/25/wRmfHj5xFcsLIXp.png" style="zoom:67%;" /><p>同样的，上述特征都是基于窗口的。</p><h4 id="Temporal-Features"><a href="#Temporal-Features" class="headerlink" title="Temporal Features"></a>Temporal Features</h4><p>这一部分是一些时间序列相关特征：</p><img src="https://i.loli.net/2020/06/25/mnBrzjfgV716yiR.png" style="zoom:67%;" /><p>最后，总共提取了37个特征，并且每个特征都进行了正则化。</p><h3 id="The-Transfer-between-Source-Domain-and-Target-Domain"><a href="#The-Transfer-between-Source-Domain-and-Target-Domain" class="headerlink" title="The Transfer between Source Domain and Target Domain"></a>The Transfer between Source Domain and Target Domain</h3><p>本文结合了基于实例的迁移学习(<strong>Instance-based Transfer Learning</strong>)和基于特征的迁移学习(<strong>Feature-based Transfer Learning</strong>)。</p><p>首先，source domain中的数据差异性是比较大的，所以我们需要选择与target domain相似的样本。</p><p>基于实例的迁移学习(<strong>Instance-based Transfer Learning</strong>)的思想是选择source domain中与target domain相似的样本。对于source domain，在将时间序列$T_l$转换为特征$F_l$之后，本文使用$K-means$算法将$F_l$分成若干个簇。每个簇$F_l^i, i\in[1,K]$是$F_l$的不重叠子集。为了选择合适的样本，我们计算了target domain中的样本和每个簇中心点的欧几里得距离，然后样本会和距离最近的簇$F_l^i$联系起来。</p><p>之后，为了使source domain和target domain在特征空间的差别更小，作者在每个簇上使用了<strong>CORrelation ALignment</strong> (CORAL) 算法。CORAL是一种领域适应算法 (<strong>Domain Adaption</strong>)，其基本思想是对source domain和target domain进行线性变换使其二阶统计信息（即协方差矩阵）的差别最小化：<br>$$<br>\min_A\parallel A^\top C^i_lA-C^i_u\parallel_F^2<br>$$</p><p>在最后一步，作者在每一个sub source domain $\hat{F}_l^i$训练了有监督模型（随机森林或SVM），所以最后我们得到了$K$个基模型。</p><h2 id="Active-Learning-Component"><a href="#Active-Learning-Component" class="headerlink" title="Active Learning Component"></a>Active Learning Component</h2><p>由于数据的差异性和复杂性太大，仅仅使用迁移学习的技术不足以达到很好的效果。在ATAD中，作者使用了主动学习技术来用较少的成本标注最有价值的样本来提升性能。本文中使用基于<strong>Uncertainty</strong>和<strong>Context Diversity</strong>的主动学习。</p><h3 id="Uncertainty"><a href="#Uncertainty" class="headerlink" title="Uncertainty"></a>Uncertainty</h3><p>大多数主动学习算法使用不确定性 (Uncertainty) 来作为选择要标记的样本的准则。<br>$$<br>Uncertainty=-|Prob(Normal)-Prob(Anomaly)|<br>$$<br>其中的$Prob$由基模型给出。</p><h3 id="Context-Diversity"><a href="#Context-Diversity" class="headerlink" title="Context Diversity"></a>Context Diversity</h3><p>多样性 (Diversity) 也是一个选择要标记样本的重要参考。如果有两个相似的样本，那么就没有必要将他们都标记。</p><p>时间上相邻的样本往往也是相似的。</p><p>具体的来说，我们对所有样本按照<strong>Uncertainty</strong>排序，然后进行一次扫描，如果当前样本在候选集中某个样本的<strong>Context</strong>之中，我们则忽略当前样本，因为这代表当前样本和候选集中的那个样本是相似的。如果不在<strong>Context</strong>之中，我们则将该样本加入候选集中。</p><p>判断是否在某个样本的<strong>Context</strong>中，如下图所示，直接判断是否落在区间$[t-\alpha,t+\alpha]$中就是了。</p><img src="https://i.loli.net/2020/06/25/nci9PvGDEdjky5R.png" style="zoom:67%;" /><p>主动学习模块的算法流程图如下图所示：</p><img src="https://i.loli.net/2020/06/25/RqonKfQS3IWw6Gb.png" style="zoom: 80%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>在实验部分，作者试图回答以下问题：</p><ol><li>ATAD的效果如何？</li><li>迁移学习模块的有效性如何？</li><li>主动学习模块的有效性如何？</li><li>ATAD在基于公开数据时对公司内部数据检测效果如何？</li></ol><h2 id="Dataset-and-Setup"><a href="#Dataset-and-Setup" class="headerlink" title="Dataset and Setup"></a>Dataset and Setup</h2><p>下表是用到的数据集的一些基本信息：</p><img src="https://i.loli.net/2020/06/25/HDNGCrYOxezLwaB.png" style="zoom:67%;" /><h2 id="Evaluation-Metric"><a href="#Evaluation-Metric" class="headerlink" title="Evaluation Metric"></a>Evaluation Metric</h2><p>评测标准使用的是F1-score：<br>$$<br>F1=\frac{2\cdot P\cdot R}{P+R}, \space P=\frac{TP}{TP+FP}, \space R=\frac{TP}{TP+FN}<br>$$</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="RQ1-How-effective-is-ATAD"><a href="#RQ1-How-effective-is-ATAD" class="headerlink" title="RQ1: How effective is ATAD?"></a>RQ1: How effective is ATAD?</h3><p>Baseline包括孤立森林、K-Sigma、S-H-ESD和随机森林。</p><p>最终结果如下表所示：</p><img src="https://i.loli.net/2020/06/25/HMneBzlkR7Qg4TN.png" style="zoom:67%;" /><p>为了评测ATAD利用标签的能力，我们比较了RF在达到和ATAD相似F1 score情况下所需标签的数量，如下表所示：</p><img src="https://i.loli.net/2020/06/25/fcoXhCL43yVwYes.png" style="zoom:67%;" /><h3 id="RQ2-How-effective-is-the-Transfer-Learning-Component"><a href="#RQ2-How-effective-is-the-Transfer-Learning-Component" class="headerlink" title="RQ2:    How  effective  is  the  Transfer  Learning Component?"></a>RQ2:    How  effective  is  the  Transfer  Learning Component?</h3><p>我们从以下两个方面来探究模型迁移知识的能力：</p><ul><li>使用文中所用到的特征的重要性</li><li>本模型迁移知识的能力</li></ul><p>对于第一点，作者提出传统的方法一般只提取了统计特征，而本文还提取了多种其他特征。作者对提取不同特征进行了比较试验，结果如下表所示：</p><img src="https://i.loli.net/2020/06/25/QV2eWzoOxGS6qJd.png" style="zoom:67%;" /><p>除此之外，作者还展示了不同数据集下前10有效的特征：</p><img src="https://i.loli.net/2020/06/25/QXYcP9V3xmJeIq5.png" style="zoom:67%;" /><p>对于第二点，作者比较了是否使用文中的领域适应算法CORAL，在达到相似F1 score下所需的标签数，如下表所示：</p><img src="https://i.loli.net/2020/06/25/JKFf4XngPBdGm3V.png" style="zoom:67%;" /><h3 id="RQ3-How-effective-is-the-Active-Learning-component"><a href="#RQ3-How-effective-is-the-Active-Learning-component" class="headerlink" title="RQ3:  How effective is the Active Learning component?"></a>RQ3:  How effective is the Active Learning component?</h3><p>为了验证本文所用的主动学习的有效性，作者进行了对比试验。第一个模型 (Supervised model) 使用全部标签但不使用迁移学习训练，第二个 (Naïve) 为只使用主动学习而不使用迁移学习，第三个为本文提出的模型。结果如下图所示，为了达到相似的性能，不同模型需要的标签数。</p><img src="https://i.loli.net/2020/06/25/jcXphwBmR8J6SeU.png" style="zoom:67%;" /><p>下表展示了使用不同主动学习策略 (U - conventional uncertainty method, UCD - 本文使用的方法, random - 随机选择) 进行标记得到的结果：</p><img src="https://i.loli.net/2020/06/25/pe24P9gFJfQVrKM.png" style="zoom:67%;" /><p>同时作者还对不同$\alpha$的选择进行了实验：</p><img src="https://i.loli.net/2020/06/25/ifRhv85IqaVw7gx.png" style="zoom:67%;" /><h3 id="RQ4-How-effective-is-ATAD-in-detecting-anomalies-in-a-company’s-local-dataset-based-on-public-datasets"><a href="#RQ4-How-effective-is-ATAD-in-detecting-anomalies-in-a-company’s-local-dataset-based-on-public-datasets" class="headerlink" title="RQ4: How effective is ATAD in detecting anomalies in a company’s local dataset based on public datasets?"></a>RQ4: How effective is ATAD in detecting anomalies in a company’s local dataset based on public datasets?</h3><p>这里作者对比了不同方法在微软内部数据集上的结果：</p><img src="https://i.loli.net/2020/06/25/5oi3rcGugKXmTha.png" style="zoom:67%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文介绍了一种用于云计算平台的时间序列异常检测框架。为了解决</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
    <category term="Transfer Learning" scheme="http://qfxiao.me/tags/Transfer-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection</title>
    <link href="http://qfxiao.me/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/"/>
    <id>http://qfxiao.me/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/</id>
    <published>2020-05-06T03:05:37.000Z</published>
    <updated>2020-06-25T08:15:23.573Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文提出了一种针对高维数据异常检测的表示学习方法。文中提出了<strong>RAMODO</strong>框架，一种基于排序的结合表示学习和异常检测的无监督框架。除此之外，基于<strong>RAMODO</strong>，文中还提出了基于此框架的模型<strong>REPEN</strong>。</p><p><a href="https://arxiv.org/pdf/1806.04808">Paper📰</a></p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="The-Proposed-Framework-RAMODO"><a href="#The-Proposed-Framework-RAMODO" class="headerlink" title="The Proposed Framework: RAMODO"></a>The Proposed Framework: <strong>RAMODO</strong></h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>我们的目的是为高维数据学习低维表示，同时在学到的低维表示中能够更好地进行异常检测。设有数据集$\mathcal{X}={\mathbf x_1,\mathbf x_2,\cdots, \mathbf x_N}$ ($\mathbf x_i\in \mathbb{R}^D$) 和一个基于随机距离的异常检测器$\phi:\mathcal{X}\mapsto \mathbb{R}$，我们的目标是学习一个表示函数$f:\mathcal{X}\mapsto\mathbb{R}^M (M\ll D)$使得对于所有异常样本$\mathbf x_i$和正常样本$\mathbf x_j$都有$\phi(f(\mathbf x_i))&gt;\phi(f(\mathbf x_j))$。</p><h3 id="Ranking-Model-based-Representation-Learning-Framework"><a href="#Ranking-Model-based-Representation-Learning-Framework" class="headerlink" title="Ranking Model-based Representation Learning Framework"></a>Ranking Model-based Representation Learning Framework</h3><p><strong>RAMODO</strong>基于<em>pairwise ranking model</em>。第一步是通过一定的预处理算法（原文中称为<em>outlier thresholding</em>）将数据划分为inlier候选集和outlier候选集；第二步通过随机从inlier候选集采样$n$个样本生成query set $(\mathbf x_i,\cdots,\mathbf x_{i+n-1})$，从inlier候选集采样一个样本生成<em>positive example</em> $(\mathbf x^+)$，从outlier候选集采样一个样本生成<em>negative example</em> $(\mathbf x^-)$，将三者组合生成 <em>metatriplet</em> $T=(&lt;\mathbf x_i,\cdots,\mathbf x_{i+n-1}&gt;,\mathbf x^+,\mathbf x^-)$；第三步通过神经网络$f$学习表示；第四步通过<em>outlier score-based ranking loss</em> $L(\phi(f(\mathbf x^+)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;),\phi(f(\mathbf x^-)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;))$来进行优化，其中$\phi(\cdot|\cdot)$为基于距离的异常检测器。</p><p><img src="https://i.loli.net/2020/06/25/4I7fx5ZjBhueUDz.png"></p><h2 id="A-RAMODO-Instance-REPEN"><a href="#A-RAMODO-Instance-REPEN" class="headerlink" title="A RAMODO Instance: REPEN"></a>A <strong>RAMODO</strong> Instance: <strong>REPEN</strong></h2><p><strong>REPEN</strong>为<strong>RAMODO</strong>的实例模型，使用Sp作为异常检测器。</p><h3 id="Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality"><a href="#Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality" class="headerlink" title="Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality"></a>Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality</h3><p>第一步使用Sp作为基础获得初始anomaly score：</p><blockquote><p><strong>Definition 1</strong> (<em>Sp-based Outlier Scoring</em>). 给定样本$x_i$，Sp 以以下方式定义该样本的异常程度：<br>$$<br>r_i=\frac{1}{m}\sum\limits_{j=1}^m nn_dist(\mathbf x_i|\mathcal{S}_j)<br>$$<br>其中$\mathcal S_j\subset \mathcal X$为数据集随机采样的子集，$m$为集成大小，$nn_dist(\cdot|\cdot)$为$\mathcal S_j$中最近邻居的距离。</p></blockquote><p>接着通过<em>Cantelli’s Inequality</em>来定义<em>Pseudo Outlier</em>：</p><blockquote><p>*<em>Definition 2 **(<em>Cantelli’s Inequality-based Outlier Thresholding</em>). 给定异常分数向量$\mathbf r\in\mathbb R^N$，更高异常分数代表更高的可能性为异常，设$\mu$和$\delta^2$分别为均值和方差，</em>Outlier*候选集由以下方式确定：<br>$$<br>\mathcal{O}={\mathbf x_i|r_i \geq \mu + \alpha\delta}, \space\forall \mathbf x_i\in\mathcal X, \space r_i\in\mathbf r<br>$$<br>其中$\alpha\geq 0$为自定义的阈值。</p></blockquote><p><em>Inlier</em>候选集$\mathcal I=\mathcal X\backslash \mathcal O$。</p><h3 id="Triplet-Sampling-Based-on-Outlier-Scores"><a href="#Triplet-Sampling-Based-on-Outlier-Scores" class="headerlink" title="Triplet Sampling Based on Outlier Scores"></a>Triplet Sampling Based on Outlier Scores</h3><p>首先，从$\mathcal I$采样一定数量的样本组成<em>query set</em>，每个样本被采样的概率与其对应的异常分数有关：</p><p>$$<br>p(\mathbf x_i)=\frac{\mathbb Z-r_i}{\sum_{t=1}^{|\mathcal I|}[\mathbb Z-r_t]}<br>$$</p><p>其中$\mathbb Z=\sum_{t=1}^{|\mathcal I|}r_t$。</p><p>之后从<em>inlier set</em>中均匀随机采样一个<em>positive sample</em> $\mathbf x^+$。最后从<em>outlier set</em>中根据以下概率采样一个<em>negative sample</em> $\mathbf x^-$：<br>$$<br>p(\mathbf x_j)=\frac{r_j}{\sum_{t=1}^{|\mathcal O|}r_t}<br>$$</p><h3 id="A-Shallow-Data-Representation"><a href="#A-Shallow-Data-Representation" class="headerlink" title="A Shallow Data Representation"></a>A Shallow Data Representation</h3><p>单层神经网络用来获得浅层的表示：</p><blockquote><p>**Definition 3 **(<em>Single-layer Fully-connected Representations</em>) 给定输入$x$，<br>$$<br>f_\Theta(\mathbf x)={\psi(\mathbf w_1^\top\mathbf x),\psi(\mathbf w_2^\top\mathbf x),\cdots,\psi(\mathbf w_M^\top\mathbf x)}<br>$$<br>其中$\psi(\cdot)$为激活函数，$\mathbf w$为权重矩阵。</p></blockquote><h3 id="Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores"><a href="#Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores" class="headerlink" title="Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores"></a>Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores</h3><p>设$\mathcal{Q}=&lt;f_\Theta(\mathbf x_i),\cdots,f_\Theta(\mathbf x_{i+n-1})&gt;$为<em>query set</em>，给定样本$\mathbf x$，<strong>REPEN</strong>根据最近邻距离定义了$f_\Theta(\mathbf x)$的异常程度：<br>$$<br>\phi(f_\Theta(\mathbf x)|\mathcal{Q})=nn_dist(f_\Theta(\mathbf x)|\mathcal Q)<br>$$<br>因此，给定三元组$T=(\mathcal Q,f_\Theta(\mathbf x^+),f_\Theta(\mathbf x^-))$，我们的目标是学得表示$f(\cdot)$使得：<br>$$<br>nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)&lt;nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)<br>$$<br>损失函数：<br>$$<br>J(\Theta;T)=L(\phi(f_\Theta(\mathbf x^+)|\mathcal Q),\phi(f_\Theta(\mathbf x^-)|\mathcal Q))=\\max{0, c+nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)-nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)}<br>$$<br>其中$c$为边界参数。给定一系列三元组，最终优化目标如下：<br>$$<br>\mathop{\text{arg min}}\limits_{\Theta}\frac{1}{|\mathcal{T}|}\sum\limits_{i=1}^{|\mathcal T|}J(\Theta;T_i)<br>$$</p><h3 id="The-Algorithm-and-Its-Time-Complexity"><a href="#The-Algorithm-and-Its-Time-Complexity" class="headerlink" title="The Algorithm and Its Time Complexity"></a>The Algorithm and Its Time Complexity</h3><p><img src="https://i.loli.net/2020/06/25/eYtKHBJ7szCgjNa.png"></p><h3 id="Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling"><a href="#Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling" class="headerlink" title="Leveraging A Few Labeled Outliers to Improve Triplet Sampling"></a>Leveraging A Few Labeled Outliers to Improve Triplet Sampling</h3><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul><li>AD：网络广告检测</li><li>LC：肺癌疾病监测</li><li>p53：异常蛋白质活动检测</li><li>R8：文本分类</li><li>News20：文本分类</li><li>URL：异常网址检测</li><li>Webspam：Pascal Large Scale LearningChallenge</li></ul><h2 id="Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features"><a href="#Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features" class="headerlink" title="Effectiveness in Real-world Data with Thousands to Millions of Features"></a>Effectiveness in Real-world Data with Thousands to Millions of Features</h2><p>作者分别使用原始特征和<em>REPEN</em>学到的特征进行异常检测，IMP代表性能提升比例，SU代表加速比例。</p><p><img src="https://i.loli.net/2020/06/25/mvUiE1NzyTwOgV8.png"></p><h2 id="Comparing-to-State-of-the-art-Representation-Learning-Competitors"><a href="#Comparing-to-State-of-the-art-Representation-Learning-Competitors" class="headerlink" title="Comparing to State-of-the-art Representation Learning Competitors"></a>Comparing to State-of-the-art Representation Learning Competitors</h2><ul><li>**AE: **自编码器</li><li>**HLLE: ** <em>Hessian Locally Linear Embedding</em></li><li>**SRP: ** <em>Sparse Random Projection</em></li><li>**CoP: ** <em>Coherent Pursuit</em></li></ul><p><img src="https://i.loli.net/2020/06/25/yQumCRNrHAheJ34.png"></p><h2 id="The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge"><a href="#The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge" class="headerlink" title="The Capability of Leveraging Labeled Outliers as Prior Knowledge"></a>The Capability of Leveraging Labeled Outliers as Prior Knowledge</h2><p><img src="https://i.loli.net/2020/06/25/NOLfKQd2u1JMPtp.png"></p><h2 id="Sensitivity-Test-w-r-t-the-Representation-Dimension"><a href="#Sensitivity-Test-w-r-t-the-Representation-Dimension" class="headerlink" title="Sensitivity Test w.r.t. the Representation Dimension"></a>Sensitivity Test w.r.t. the Representation Dimension</h2><p><img src="https://i.loli.net/2020/06/25/BoGjY5SEu6vrK3X.png"></p><p><img src="https://i.loli.net/2020/06/25/Rlx7Df9Hvsjp2Eg.png"></p><p>文中提到了对于R8、URL、News20这三个数据集在维度$M=1$的时候表现和其他维度一样好，作者给出的解释是在这几个数据集中异常部分是线性可分的，所以1维就足够了，另一个解释是优化问题。</p><h2 id="Scalability-Test"><a href="#Scalability-Test" class="headerlink" title="Scalability Test"></a>Scalability Test</h2><p><img src="https://i.loli.net/2020/06/25/1JfUclWyFYgLdNp.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;本文提出了一种针对高维数据异常检测的表示学习方法。文中提出了</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
    <category term="Representation Learning" scheme="http://qfxiao.me/tags/Representation-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Deep Weakly-supervised Anomaly Detection</title>
    <link href="http://qfxiao.me/2020/03/30/Deep-Weakly-supervised-Anomaly-Detection/"/>
    <id>http://qfxiao.me/2020/03/30/Deep-Weakly-supervised-Anomaly-Detection/</id>
    <published>2020-03-29T16:17:24.000Z</published>
    <updated>2020-06-25T05:33:35.419Z</updated>
    
    <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1><p>在文献中，因为标注成本的昂贵，无监督方法占据了异常检测的主要位置。然而，在现实生活中，我们可能会有少量标签，如何利用这部分标签信息就成为了一个问题，作者将其称之为<em>anomaly-informed modeling</em>。作者提出了两点挑战：</p><ol type="1"><li>少量标签可能无法提供所有类型异常的信息；</li><li>大部分无标签数据为正常样本，但其中包含少部分异常（污染）。</li></ol><p>作者提出了基于pairwise relation learning的方法来解决这些问题。文章的主要贡献如下：</p><ol type="1"><li>提出了一种基于pairing-based data augmentation和ordinal regression来进行弱监督异常检测的框架</li><li>基于该框架提出了PReNet，一种基于双流ordinal regression的网络</li><li>从理论和实践角度分析了方法的有效性</li><li>在40个真实数据集上进行了完善的实验</li></ol><h1 id="proposed-method">Proposed Method</h1><h2 id="learning-anomaly-scores-by-predicting-pairwise-relation">Learning Anomaly Scores by Predicting Pairwise Relation</h2><h3 id="problem-formulation">Problem Formulation</h3><p>给定数据集<span class="math inline">\(\mathcal{X}=\{\mathbf{x}_1,\mathbf {x}_2,\cdots,\mathbf{x}_N,\mathbf{x}_{N+1},\cdots,\mathbf{x}_{N+K}\}\)</span>，包含两部分，一部分是五标签数据<span class="math inline">\(\mathcal{U}=\{\mathbf{x}_1,\mathbf {x}_2,\cdots,\mathbf{x}_N\}\)</span>，另一部分是有标签异常数据<span class="math inline">\(\mathcal{A}=\{\mathbf{x}_{N+1},\cdots,\mathbf{x}_{N+K}\}\)</span>，其中<span class="math inline">\(K\ll N\)</span>。我们的任务目标是学习一个打分函数<span class="math inline">\(\phi:\mathcal{X}\mapsto \mathbb{R}\)</span>，使得对任任意异常样本的打分高于任意正常样本。</p><p>在这个Formulation里，作者将关系学习和异常打分统一了起来。首先，输入的数据集不再是原始样本，而是样本对。样本对包含三种：<em>anomaly-anomaly</em>，<em>anomaly-unlabeled</em>，<em>unlabeled-unlabeled</em>，记为<span class="math inline">\(C_{\{\mathbf{a},\mathbf{a}\}}\)</span>，<span class="math inline">\(C_{\{\mathbf{a},\mathbf{u}\}}\)</span>，<span class="math inline">\(C_{\{\mathbf{u},\mathbf{u}\}}\)</span>。每一个样本对包含一个标签<span class="math inline">\(y\)</span>，表示该pair对应的异常分数，整个输入数据集<span class="math inline">\(\mathcal{P}=\{\{\mathbf{x}_i,\mathbf{x}_j,y_{ij}\}|\mathbf{x}_i,\mathbf{x}_j\in\mathcal{X} \space\text{and}\space y_{ij}\in\mathbb{N}\}\)</span>。因为有<span class="math inline">\(y_{\{\mathbf a,\mathbf a\}}&gt;y_{\{\mathbf a,\mathbf u\}}&gt;y_{\{\mathbf u,\mathbf u\}}\)</span>，所以对关系的学习也是对异常打分的学习。</p><h3 id="the-instantiated-model-prenet">The Instantiated Model: PReNET</h3><p>下图为模型示意图，<strong>Data Augmentation</strong>模块负责产生pair数据，<strong>End-to-End Anomaly Score Learner <span class="math inline">\(\phi\)</span></strong> 模块负责关系学习（异常打分）。</p><p><img src="https://i.loli.net/2020/06/25/6ZF3w9v1Lux5t4Q.png" style="zoom:67%;" /></p><h4 id="data-argumentation-by-pairing">Data Argumentation by Pairing</h4><p>数据的产生分为两步：</p><ol type="1"><li>从<span class="math inline">\(\mathcal{A}\)</span>和<span class="math inline">\(\mathcal{U}\)</span>上随机采样，组成pair；</li><li>对每个pair打上次序(ordinal class feature) 标签<span class="math inline">\(\mathbf{y}\)</span>。</li></ol><p>部分<span class="math inline">\(C_{\{\mathbf{a},\mathbf{u}\}}\)</span>和<span class="math inline">\(C_{\{\mathbf{u},\mathbf{u}\}}\)</span>可能包含异常污染，因为在<span class="math inline">\(\mathcal{U}\)</span>中可能会有未标记的异常样本。</p><h4 id="end-to-end-anomaly-score-learner">End-to-End Anomaly Score Learner</h4><p>令<span class="math inline">\(\mathcal{Z}\in\mathbb{R}^M\)</span>为中间表示空间，那么<strong>Score Learner</strong>可以拆解为特征学习<span class="math inline">\(\psi(\cdot;\Theta_r):\mathcal{X}\mapsto \mathcal{Z}\)</span>和打分函数<span class="math inline">\(\eta((\cdot,\cdot);\Theta_s):(\mathcal{Z},\mathcal{Z})\mapsto\mathbb{R}\)</span>两部分，两部分都由神经网络组成。</p><h4 id="ordinal-regression">Ordinal Regression</h4><p>损失函数定义为： <span class="math display">\[L\left(\phi((\mathbf x_i,\mathbf x_j);\Theta),y_{ij}\right)=|y_{ij}-\phi((\mathbf x_i,\mathbf x_j);\Theta)|\]</span> 采用绝对值而不是均方误差的原因是为了减少异常污染的影响。默认<span class="math inline">\(y_{\{\mathbf a,\mathbf a\}}=8\)</span>，<span class="math inline">\(y_{\{\mathbf a,\mathbf u\}}=4\)</span>，<span class="math inline">\(y_{\{\mathbf u,\mathbf u\}}=0\)</span>。最后的优化函数可以写为： <span class="math display">\[\mathop{\text{argmin}}\limits_{\Theta}\frac{1}{|\mathcal{B}|}\sum\limits_{\{\mathbf x_i,\mathbf x_j, y_{ij}\}\in\mathcal{B}}|y_{ij}-\phi((\mathbf x_i,\mathbf x_j);\Theta)|+\lambda R(\Theta)\]</span> <span class="math inline">\(\mathcal{B}\)</span>为一个batch，<span class="math inline">\(R(\Theta)\)</span>为正则项。</p><h3 id="anomaly-detection-using-prenet">Anomaly Detection Using PReNet</h3><h4 id="training-stage">Training Stage</h4><p>训练流程如下图所示：</p><p><img src="https://i.loli.net/2020/06/25/oR6uTL3c7HMpwD4.png" style="zoom: 80%;" /></p><p>为了保证训练样本类别的平衡，<span class="math inline">\(\frac{|\mathcal{B}|}{2}\)</span>的样本采样自<span class="math inline">\(C_{\{\mathbf u,\mathbf u\}}\)</span>，采样自<span class="math inline">\(C_{\{\mathbf a,\mathbf u\}}\)</span>和<span class="math display">\[C_{\{\mathbf a,\mathbf a\}}\]</span>的样本都占<span class="math inline">\(\frac{|\mathcal{B}|}{4}\)</span>。</p><h4 id="anomaly-scoring-stage">Anomaly Scoring Stage</h4><p>在测试阶段，给定测试样本<span class="math inline">\(\mathbf{x}_k\)</span>，先分别从<span class="math inline">\(\mathcal{A}\)</span>和<span class="math inline">\(\mathcal{U}\)</span>采样，然后定义以下<em>anomaly score</em>： <span class="math display">\[s_{\mathbf{x}_k}=\frac{1}{2E}\left[\sum\limits_{i=1}^E\phi((\mathbf a_i,\mathbf x_k);\Theta^*)+\sum\limits_{j=1}^E\phi((\mathbf x_k,\mathbf u_j);\Theta^*)\right]\]</span> <span class="math inline">\(\mathbf a_i\)</span>和<span class="math inline">\(\mathbf u_j\)</span>为随机采样得到的异常样本和正常样本，采样大小<span class="math inline">\(E\)</span>默认为30。</p><h1 id="experiments">Experiments</h1><p>实验部分主要是回答以下四个问题：</p><ol type="1"><li>在有限的标签异常情况下，PReNet能否有效地检测已知和未知的异常；</li><li>在不同数量标签异常的情况下，PReNet的表现如何；</li><li>PReNet对异常污染的鲁棒性如何；</li><li>PReNet不同组件的重要性如何。</li></ol><h2 id="datasets">Datasets</h2><p>实验一共用到了40个数据集，其中12个用来评测算法检测已知的异常的能力（如Table 2所示），28个用来评测算法检测未知的异常的能力（如Table 3所示）。</p><h2 id="competing-methods-and-parameter-settings">Competing Methods and Parameter Settings</h2><p>用到的baseline有以下几个：</p><ul><li>DevNet：同一作者在KDD2019提出的异常检测框架</li><li>Deep support vector data description (DSVDD)：深度支持向量数据描述</li><li>Prototypical network： few-shot classification中的一种模型</li><li>iForest：孤立森林</li></ul><h2 id="performance-evaluation-metrics">Performance Evaluation Metrics</h2><p>用到的Metrics为AUC-ROC和AUC-PR。</p><h2 id="detection-of-known-anomalies">Detection of Known Anomalies</h2><p>在本实验中，异常污染的比例（2%）和有标记异常样本的数量（60）是固定的，下表为实验结果：</p><p><img src="https://i.loli.net/2020/06/25/BfhVE9z8DWipAM6.png" style="zoom: 80%;" /></p><h2 id="detection-of-unknown-anomalies">Detection of Unknown Anomalies</h2><p>在本实验中，异常污染的比例（2%）和有标记异常样本的数量（60）同样是固定的，下表为实验结果：</p><p><img src="https://i.loli.net/2020/06/25/9GM8XTYiSLUn2Ar.png" style="zoom:80%;" /></p><p><img src="https://i.loli.net/2020/06/25/4RxrGZWLqHNnXco.png" style="zoom:80%;" /></p><h2 id="availability-of-known-anomalies">Availability of Known Anomalies</h2><p>本实验主要是研究不同数量标注异常样本的条件下，算法的性能如何。异常污染的比例固定（2%），标注异常的数量从15到120变化。实验结果如下：</p><p><img src="https://i.loli.net/2020/06/25/x4Hf3lU5JO71bvo.png" style="zoom:80%;" /></p><h2 id="further-analysis-of-prenet">Further Analysis of PReNet</h2><h3 id="tolerance-to-anomaly-contamination-in-unlabeled-data">Tolerance to Anomaly Contamination in Unlabeled Data</h3><p>本实验主要研究不同异常污染比例下，算法的性能，即探究算法对异常污染的鲁棒性。标注异常样本的数量恒定（60），异常污染比例在<span class="math inline">\(\{0\%,2\%,5\%,10\%\}\)</span>中变化。实验结果如下所示：</p><p><img src="https://i.loli.net/2020/06/25/TGYCJUs8LlmreNV.png" style="zoom:80%;" /></p><h3 id="ablation-study">Ablation Study</h3><p>这一节是消融实验，分别设置了四个变体：</p><ul><li><strong>BOR: </strong>损失函数替换成了二值回归<em>Binary Ordinal Regression</em>；</li><li><strong>OSNet: </strong>将双流结构简化为单流；</li><li><strong>LDM: </strong>将网络中的隐藏层去除；</li><li><strong>A2H: </strong>加入了额外的隐藏层，并且加入了<span class="math inline">\(\ell_2\)</span>-norm防止过拟合。</li></ul><p><img src="https://i.loli.net/2020/06/25/oR7qlZWfepFT8jK.png" style="zoom:80%;" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;在文献中，因为标注成本的昂贵，无监督方法占据了异常检测的主要位置。然而，在现实生活中，我们可能会有少量标签，如何利用这部分标签信息就成为了一个问题，作者将其称之为&lt;em&gt;anomaly-inf</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
  </entry>
  
  <entry>
    <title>Discovering Physical Concepts with Neural Networks</title>
    <link href="http://qfxiao.me/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/"/>
    <id>http://qfxiao.me/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/</id>
    <published>2020-03-01T14:55:02.000Z</published>
    <updated>2020-06-25T05:35:20.215Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>如题目所示，本文的目的是利用神经网络来发掘物理概念。其思路是从实验数据学到表示，然后用学到的表示来回答物理问题，由此物理概念可以从学到的表示来提取出。作者进行了4个实验：</p><ol><li>在阻尼振动实验中，模型学到了相关的物理参数；</li><li>在角动量守恒实验中，模型预测了质点的运动；</li><li>给定量子系统的观测数据，模型正确的识别出了量子状态的自由度；</li><li>给定从地球观测的太阳和火星的位置时间序列数据，模型发现了日心说模型。</li></ol><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>作者在附录中对神经网络的基础知识进行了介绍，这里不再赘述，只截取了一些相对前沿的内容。</p><img src="https://i.loli.net/2020/06/25/yh5Wj9AQmd6nsFC.png" style="zoom:67%;" /><h2 id="Variational-Autoencoders"><a href="#Variational-Autoencoders" class="headerlink" title="Variational Autoencoders"></a>Variational Autoencoders</h2><p>本文用到的模型基础是VAE：</p><img src="https://i.loli.net/2020/06/25/zCnYjVEZHdbqAD3.png" style="zoom:67%;" /><h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p><em>Representation learning</em>的主要目标是将数据映射到一个隐向量 (encoder)，为了保证隐向量包含了所有相关信息， 那么应该能够从隐向量还原原数据 (decoder)。传统的Autoencoder是这个思想的最简单实现，而VAE则将AE和<em>Variational Inference</em>结合了起来，是一种经典的生成式模型。现在很多研究关注<em>Disentangled Representation Learning</em>，也就是说我们希望模型能够无监督地学习数据，从中学到有意义的表示。</p><h3 id="boldsymbol-beta-VAE"><a href="#boldsymbol-beta-VAE" class="headerlink" title="$\boldsymbol \beta$-VAE"></a>$\boldsymbol \beta$-VAE</h3><p>$\beta$-VAE是一种特殊的VAE，也是一个经典的<em>Disentangled Representation Learning</em>模型，它和VAE主要的区别是对KL散度一项加上了权重$\beta$进行调节：<br>$$<br>C_\beta(x)=-\left[\mathbb{E}_{z\sim p_\phi(z|x)}\log p_\theta(x|z)\right] + \beta D_\text{KL}\left[p_\phi(z|x)\parallel h(z)\right]<br>$$<br>如果假设$p_\phi(z|x)=\mathcal{N}(\mu,\sigma)$，那么损失函数可以进行简化：<br>$$<br>C_\beta(x)=\parallel \hat{x} - x \parallel^2_2-\frac{\beta}{2}\left(\sum\limits_i\log(\sigma_i^2)-\mu_i^2-\sigma_i^2\right)+C<br>$$</p><h1 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h1><h2 id="Network-Structure-SciNet"><a href="#Network-Structure-SciNet" class="headerlink" title="Network Structure: SciNet"></a>Network Structure: <em>SciNet</em></h2><p>模仿物理学家建模物理问题的过程，作者提出了<em>SciNet</em>，如下图所示：</p><img src="https://i.loli.net/2020/06/25/uWd1lOUFxXgQJ7f.png" style="zoom:67%;" /><p>物理学家在建模物理问题的时候，往往是从一些实验数据出发，根据物理常识提取更加精练的表示，然后用学到的表示来回答物理问题。</p><p>对于单纯的输入输出问题，<em>SciNet</em>可以看作是一个映射，$F:\mathcal{O}\times\mathcal{Q}\rightarrow\mathcal{A}$。$\mathcal{O}$是可能的实验数据集合，$\mathcal{Q}$是可能的问题集合，$\mathcal{A}$是可能的答案集合。可以将其分为两个步骤：编码过程$E:\mathcal{O}\rightarrow\mathcal{R}$从实验数据学到表示，解码过程$D:\mathcal{R}\times \mathcal{Q}\rightarrow \mathcal{A}$根据给定的问题从表示来回答问题。由此，$F(o,q)=D(E(o),q)$。在实现方面，<em>SciNet</em>采用的是全连接网络。</p><h2 id="Training-and-Testing-SciNet"><a href="#Training-and-Testing-SciNet" class="headerlink" title="Training and Testing SciNet"></a>Training and Testing <em>SciNet</em></h2><p>用来训练的数据形式为$(o,q,a_{cor}(o,q))$，观测$o$和问题$q$分别从观测集$\mathcal{O}$和问题集$\mathcal{Q}$选出，$a_{cor}(o,q)$为对应的正确答案。在训练过程中，我们希望准确度尽量高，并且学到<em>minimal uncorrelated representations</em>。为此，作者采用<em>disentangling variational autoencoder</em>作为模型。</p><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>在文中，作者进行了4个实验来验证模型的有效性。</p><h2 id="Damped-Pendulum"><a href="#Damped-Pendulum" class="headerlink" title="Damped Pendulum"></a>Damped Pendulum</h2><p>阻尼振动实验：</p><ul><li><p>任务：预测一维阻尼振动在不同时间的位置。</p></li><li><p>物理模型：$-kx-b\dot{x}=m\ddot{x}$，$k$为弹性模量，$b$为阻尼系数，通解为$x(t)=A_0e^{-\frac{b}{2m}t}\cos(\omega t+\delta_0), \space \omega=\sqrt{\frac{k}{m}}\sqrt{1-\frac{b^2}{4mk}}$</p></li><li><p>观测数据：位置时间序列数据$o=[x(t_i)]_{i\in{1,\cdots,50}}\in\mathbb{R}^{50}$，时间间隔相等，质量$m=1\text{kg}$，振幅$A_0=1\text{m}$，相位$\delta_0=0$，弹性模量$k\in[5,10]\text{kg}/\text{s}^2$，阻尼系数$b\in[0.5,1]\text{kg}/\text{s}$。</p></li><li><p>问题：预测$q=t_\text{pred}\in\mathbb{R}$</p></li></ul><p><img src="https://i.loli.net/2020/06/25/yWGzxo4eFKmABul.png"></p><p>隐变量大小设置为3，结果如下图所示：</p><img src="https://i.loli.net/2020/06/25/Q4PKa3pm2htekqd.png" style="zoom:67%;" /><p>(b)中的三幅图分别是学到的三个隐变量和我们感兴趣的参数$k$和$b$的关系图。第一幅图中变量$1$与$b$几乎完全线性相关，与$k$基于线性无关，变量$2$只和$k$相关。变量$3$几乎为一个常数，故不提供额外的信息。由此作者认为<em>SciNet</em>学到了我们关心的两个参数的知识。</p><h2 id="Conservation-of-Angular-Momentum"><a href="#Conservation-of-Angular-Momentum" class="headerlink" title="Conservation of Angular Momentum"></a>Conservation of Angular Momentum</h2><p>角动量守恒实验：</p><ul><li>任务：预测一个由长度为$r$的绳子捆绑着的旋转质点在位置$(0,r)$经一个自由质点撞击后的位置</li><li>物理模型：给定撞击之前的角动量，自由质点撞击之后的速度，旋转质点在撞击之后在时间$t_\text{pred}^\prime$的位置可以由角动量守恒定律给出：</li></ul><p>$$<br>J=m_\text{rot}r^2\omega-rm_\text{free}(\mathbf{v}_\text{free})_x=m_\text{rot}r^2\omega^\prime-rm_\text{free}(\mathbf{v}^\prime_\text{free})_x=J^\prime<br>$$</p><ul><li>观测数据：在撞击之前两个质点的位置数据$o=[(t_i^\text{rot},q_\text{rot}(t_i^\text{rot})),(t_i^\text{free},q_\text{free}(t_i^\text{free}))]_{i\in{1,\cdots,5}}$，质量为固定值，半径$r$也为固定值。数据添加高斯噪声。</li><li>问题：预测撞击之后自由质点在时间$t_\text{pred}^\prime$的位置</li></ul><p><img src="https://i.loli.net/2020/06/25/SKfJLxl1QmuzFt9.png"></p><p>实验室意图如下：</p><img src="https://i.loli.net/2020/06/25/qimk9ZYBe7UPs3z.png" style="zoom:67%;" /><p>实验结果表明<em>SciNet</em>能够正确预测质点撞击之后的位置，同时对噪音鲁棒。根据(b)，隐变量和角动量存在线性相关关系，作者认为<em>SciNet</em>学到了守恒的动量这一概念。</p><h2 id="Representation-of-Qubits"><a href="#Representation-of-Qubits" class="headerlink" title="Representation of Qubits"></a>Representation of Qubits</h2><p>量子比特实验：</p><ul><li>任务：预测在$n=1,2$的纯$n$量子位状态$\psi\in\mathbb{C}^{2^n}$下任何二进制投影测量$\omega\in\mathbb{C}^{2^n}$的测量概率。</li><li>物理模型：在执行测量$\omega\in\mathbb{C}^{2^n}$的状态$\psi\in\mathbb{C}^{2^n}$下测量0的概率$p(\omega,\psi)$由$p(\omega,\psi)=|\left&lt;\omega,\psi\right&gt;|^2$给定</li><li>观测数据：状态$\psi: o=[p(\alpha_i,\psi)]_{i\in{i,\cdots,n_1}}$的操作参数化：表示一组固定的随机二元射影测量值$\mathcal{M}_1={\alpha_1,\cdots,\alpha_{n_1}}$（一个量子位$n_1 = 10$，两个量子位$n_1 = 30$）</li><li>问题：对于固定的一组随机二元射影测量$\mathcal{M}<em>2={\beta_1,\cdots,\beta_{n_2}}$，测量$\omega:q=[p(\beta_i,\omega)]</em>{i\in{1,\cdots,n_2}}$的Operational参数化（一个量子位$n_2 = 10$，两个量子位$n_2 = 30$）</li></ul><p><img src="https://i.loli.net/2020/06/25/8lY1LBsQCZUwX2I.png"></p><p>实验结果如下：</p><img src="https://i.loli.net/2020/06/25/ZTRKfzb63Jrvk5C.png" style="zoom:67%;" /><p>通过实验发现，<em>SciNet</em>可以在不提供先验物理知识的条件下确定表述状态$\psi$最小的参数数量。同时，<em>SciNet</em>还能分辨<em>tomographically complete</em>和<em>tomographically incomplete</em>。</p><h2 id="Heliocentric-Model-of-the-Solar-System"><a href="#Heliocentric-Model-of-the-Solar-System" class="headerlink" title="Heliocentric Model of the Solar System"></a>Heliocentric Model of the Solar System</h2><p>日心说模型：</p><ul><li>问题：在给定初始条件下预测相对与地球的太阳和火星的角度$\theta_M(t)$和$\theta_S(t)$</li><li>物理模型：地球和火星围绕太阳以一定角速度做近似圆周运动</li><li>观测数据：给定初始角度，随机选择周周期的哥白尼的观测数据</li></ul><p><img src="https://i.loli.net/2020/06/25/vXl3Ae4RpzibrmY.png"></p><p>模型的实现稍有变化，如下图所示：</p><img src="https://i.loli.net/2020/06/25/XnsYqcRS6izZGEm.png" style="zoom:67%;" /><p>这样，对于不同时间都对应一个隐变量$r(t_i)$，而且隐变量是时间依赖的，对于一个隐变量$r(t_i)$有一个解码器来输出答案。</p><img src="https://i.loli.net/2020/06/25/az3UmkchyFWevP7.png" style="zoom:67%;" /><p>实验结果表示，<em>SciNet</em>不仅正确预测了太阳和火星相对地球的角度，同时隐变量揭示了火星和地球相对太阳的角度。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;如题目所示，本文的目的是利用神经网络来发掘物理概念。其思路是</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Misc" scheme="http://qfxiao.me/categories/Research/Misc/"/>
    
    
    <category term="Deep Learning" scheme="http://qfxiao.me/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Transfer Anomaly Detection by Inferring Latent Domain Representations</title>
    <link href="http://qfxiao.me/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/"/>
    <id>http://qfxiao.me/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/</id>
    <published>2020-02-27T12:02:18.000Z</published>
    <updated>2020-06-25T09:01:35.786Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>作者提出了一种利用迁移学习提升target domain异常检测性能的算法。文中指出现有的基于迁移学习的异常检测算法需要对每个 target domain 进行单独训练，这样做会带来很大的计算开销。本文通过<em>latent domain vectors</em>来实现无需重新训练的异常检测。<em>latent domain vectors</em>是domain的一种隐含表示，通过该domain中的正常样本得到。在本文中，<em>anomaly score function</em>通过Auto-encoder得到。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h2><p>令$\mathbf{X}<em>d^+:={\mathbf{x}^+</em>{dn}}^{N^+<em>d}</em>{n=1}$为第$d$个domain的异常样本集，$\mathbf{x}_{dn}^+\in\mathbb{R}^M$为其中第$n$个样本的$M$维特征向量，$N^+_d$为第$d$个domain异常样本的数量。</p><p>类似的，令$\mathbf{X}<em>d^-:={\mathbf{x}^-</em>{dn}}^{N^-<em>d}</em>{n=1}$为第$d$个domain的正常样本集。我们假设对于每个domain都有$N^+_d\ll N^-_d$，且特征向量维度都为$M$。</p><p>假设在 source domain $D_S$都有正常样本和异常样本，记为${\mathbf{X}^+<em>d\cup\mathbf{X}_d^-}^{D_S}</em>{d=1}$，在 target domain $D_T$只有正常样本${\mathbf{X}<em>d^-}^{D_S+D_T}</em>{d=D_S+1}$。我们的目标是得到一个对于 target domain 合适的 domain-specific 的异常打分函数。</p><img src="https://i.loli.net/2020/06/25/KW2YgScfVZN7Fjz.png" style="zoom:67%;" /><h2 id="Domain-specific-Anomaly-Score-Function"><a href="#Domain-specific-Anomaly-Score-Function" class="headerlink" title="Domain-specific Anomaly Score Function"></a>Domain-specific Anomaly Score Function</h2><p>我们基于Auto-encoder定义异常打分函数。对于每个domain，我们假设存在一个$K$维的隐变量$\mathbf{z}<em>d\in\mathbb{R}^K$。对于第$d$个 domain，异常打分函数定义如下：<br>$$<br>s_\theta(\mathbf{x}_{dn}|\mathbf{z}<em>d):=\parallel\mathbf{x}</em>{dn}-G</em>{\theta_G}(F_{\theta_F}(\mathbf{x}_{dn},\mathbf{z}_d))\parallel^2<br>$$<br>其中参数$\theta:=(\theta_G,\theta_F)$在所有 domain 之间共享。</p><h2 id="Models-for-Latent-Domain-Vectors"><a href="#Models-for-Latent-Domain-Vectors" class="headerlink" title="Models for Latent Domain Vectors"></a>Models for Latent Domain Vectors</h2><p>隐变量$\mathbf{z}_d$是无法观测到的，只能通过数据来估计。首先$\mathbf{z}_d$在$\mathbf{X}_d^-$条件下的条件分布假设为高斯分布：</p><p>$$<br>q_\theta(\mathbf{z}<em>d|\mathbf{X}_d^-):=\mathcal{N}(\mathbf{z}_d|\mu_\phi(\mathbf{X}_d^-),\text{diag}(\sigma_\phi^2(\mathbf{X}_d^-)))<br>$$<br>其中均值$\mu_\phi(\mathbf{X}_d^-)\in\mathbb{R}^K$和方差$\sigma^2_\phi(\mathbf{X}_d^-)\in\mathbb{R}^K</em>+$由神经网络建模，且在所有 domain 之间共享。在$\mathbf{X}_d^-$给定的时候，我们便能够推断出该 domain 对应的隐变量，</p><p>$q_\phi$的输入为正常样本的集合，故神经网络需要满足<em>permutation invariant</em>。$\tau(\mathbf{X}<em>d^-)=\rho(\sum</em>{n=1}^{N_d^-}\eta(\mathbf{x}_{dn}^-))$，其中$\tau(\mathbf{X}_d^-)$表示$\mu_\phi(\mathbf{X_d^-})$或$\ln\sigma_\phi^2(\mathbf{X}_d^-)$，$\rho$和$\eta$为神经网络，</p><h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>目标函数由anomaly score函数和隐变量组成。第$d$个domain在对应的隐变量$\mathbf{z}_d$条件下的目标函数为：</p><p>$$<br>L_d(\theta|\mathbf{z}<em>d):=\frac{1}{N_d^-}\sum\limits_{n=1}^{N_d^-}s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}<em>d)-\frac{\lambda}{N_d^-N_d^+}\sum\limits</em>{n,m=1}^{N_d^-,N_d^+}f(s_\theta(\mathbf{x}<em>{dm}^+|\mathbf{z}_d)-s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}_d))<br>$$</p><p>其中$\lambda\geq 0$为超参数，$f$为sigmoid函数。公式的第一项表示第$d$个domain正常样本对应的<em>anomaly score</em>。第二项为可微分的AUC。异常样本的<em>anomaly score</em>应当大于正常样本，所以对任何$\mathbf x_{dm}^+\in\mathbf X_d^+, \mathbf x_{dn}^-\in\mathbf X_d^-$有$s_\theta(\mathbf x_{dm}^+|\mathbf z_d)&gt;s_\theta(\mathbf x_{dn}^-|\mathbf z_d)$。第二项$\frac{\lambda}{N_d^-N_d^+}\sum\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\theta(\mathbf{x}<em>{dm}^+|\mathbf{z}_d)-s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}<em>d))$的取值范围是$[0,1]$，当所有的$s_\theta(\mathbf{x}_{dm}^+|\mathbf{z}_d)\gg s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}<em>d)$时该项为1，当所有的$s_\theta(\mathbf{x}_{dm}^+|\mathbf{z}_d)\ll s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}<em>d)$时该项为0，所以最小化该项的相反数相当于鼓励$s_\theta(\mathbf{x}_{dm}^+|\mathbf{z}_d)\gg s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}_d)$。</p><p>因为隐变量$\mathbf z_d$包含不确定性，我们应该在目标函数里考虑这一点：<br>$$<br>\mathcal{L}<em>d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z_d}))<br>$$</p><p>第一项是$L_d(\theta|\mathbf z_d)$关于$q_\phi(\mathbf z_d|\mathbf X_d^-)$的期望，第二项是$q_\phi(\mathbf z_d|\mathbf X_d^-)$和$p(\mathbf z_d):=\mathcal{N}(\boldsymbol 0,\boldsymbol I)$的KL散度。第一项可以用<em>monte carlo</em>估计$\mathbb{E}_{q_\phi(\mathbf{z}_d|\mathbf{X}<em>d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]\approx\frac{1}{L}\sum</em>{\ell=1}^L L_d(\theta|\mathbf z_d^{(\ell)})$，除此之外还需要用到<em>reparametrization trick</em>。</p><p>对于第$d$个target domain，因为没有异常样本（假设），所以$L_d(\theta|\mathbf{z}<em>d):=\frac{1}{N_d^-}\sum\limits_{n=1}^{N_d^-}s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}<em>d)$，有：<br>$$<br>\mathcal{L}<em>d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[\frac{1}{N_d^-}\sum\limits</em>{n=1}^{N_d^-}s_\theta(\mathbf{x}_{dn}^-|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z}_d))<br>$$</p><p>所以总的损失函数为各domain对应的损失函数之和$\mathcal{L}(\theta,\phi):=\sum_{d=1}^{D_S+D_T}\alpha_d\mathcal{L}_d(\theta,\phi)$。</p><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>训练好之后，domain-specific的<em>anomaly score</em>可以由下式计算出：</p><p>$$<br>s(\mathbf{x}<em>{d^\prime}):=\int s</em>{\theta_*}(\mathbf{x_{d^\prime}}|\mathbf{z}<em>{d^\prime})q</em>{\phi_*}(\mathbf{z}<em>{d^\prime}|\mathbf{X}</em>{d^\prime}^-)\mathrm{d}\mathbf{z}<em>{d^\prime}\approx\frac{1}{L}\sum\limits</em>{\ell=1}^L s_{\theta_*}(\mathbf{x}<em>{d^\prime}|\mathbf{z}</em>{d^\prime}^{(\ell)})<br>$$</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>实验包含五个数据集，第一个是合成数据集。如下图(a)所示，围绕$(0,0)$有$8$个圈，每个圈包含了一个内圈作为异常样本，第$7$个圈被选为target domain，其余的为source domain。第二个是MNIST-r，是加入旋转的MNIST，包含6个domain，其中数字“4”被选为异常样本，其余为正常。第三个为Anuran Calls，包含5个domain。第四个是Landmine，主要用在多任务学习中。第五个是IoT，网络流量数据，包含8个domain。</p><img src="https://i.loli.net/2020/06/25/6WLAfMwJPuN5Ov9.png" style="zoom:50%;" /><h2 id="Comparison-Methods"><a href="#Comparison-Methods" class="headerlink" title="Comparison Methods"></a>Comparison Methods</h2><p>对比的baseline包括NN（普通多层神经网络），NNAUC（加入可微分AUC作为损失函数），AE（普通Autoencoer），AEAUC（加入可微分AUC的AE），OSVM（单类支持向量机），CCSA，TOSVM和OTL。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>4个真实数据集的结果如下：</p><img src="https://i.loli.net/2020/06/25/nfkwTVexRNqyFMY.png" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/QaMskTZALyeiFI1.png" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/F7VTyeHMz8mK2uJ.png" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/B32UmgXcwGhZYk1.png" style="zoom:50%;" /><p>表5为考虑隐变量不确定性的ablation study。将原来的公式$\mathcal{L}<em>d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z_d}))$中$q_\phi(\mathbf z_d|\mathbf X_d^-)$用迪利克雷分布$q_\phi(\mathbf z_d|\mathbf X_d^-)=\delta(\mathbf z_d-\mu_\phi(\mathbf X_d^-))$代替并且去掉KL散度。</p><img src="https://i.loli.net/2020/06/25/yUHcTBzixsMlY7f.png" style="zoom: 50%;" /><p>表6展示了不同异常比例对效果的影响。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;作者提出了一种利用迁移学习提升target domain异常</summary>
      
    
    
    
    <category term="Research" scheme="http://qfxiao.me/categories/Research/"/>
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/categories/Research/Anomaly-Detection/"/>
    
    
    <category term="Anomaly Detection" scheme="http://qfxiao.me/tags/Anomaly-Detection/"/>
    
    <category term="Transfer Learning" scheme="http://qfxiao.me/tags/Transfer-Learning/"/>
    
  </entry>
  
</feed>
