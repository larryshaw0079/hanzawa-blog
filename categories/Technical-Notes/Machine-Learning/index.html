<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>分类: Machine Learning - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="website"><meta property="og:title" content="Hanzawa の 部屋"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://larryshaw0079.github.io/img/og_image.png"><meta property="article:author" content="Hanzawa"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog"},"headline":"Hanzawa の 部屋","image":["https://larryshaw0079.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":null}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li><a href="/categories/Technical-Notes/">Technical Notes</a></li><li class="is-active"><a href="#" aria-current="page">Machine Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-09-09T03:33:25.000Z" title="2020-9-9 11:33:25 ├F10: AM┤">2020-09-09</time>发表</span><span class="level-item"><time dateTime="2021-02-19T10:21:57.175Z" title="2021-2-19 6:21:57 ├F10: PM┤">2021-02-19</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Technical-Notes/">Technical Notes</a><span> / </span><a class="link-muted" href="/categories/Technical-Notes/Machine-Learning/">Machine Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/">Model Selection and Evaluation: Machine Learning Basics</a></h1><div class="content"><h1 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h1><p>我们将模型输出与真实值之间的差异称为误差，如对于分类问题，我们可以使用模型分类错误的样本数量占总样本数的比例。模型在训练集（我们收集到的数据）上的误差称作是<strong>训练误差 (training error)**，而在新样本（这里指的是新的样本而不是测试集，训练集测试集是从我们收集到的数据上人为划分出来的）上的误差称作是</strong>泛化误差 (generalization error)**。对于机器学习算法，我们希望算法能学到数据背后的普遍规律，所以我们总是希望模型的泛化误差越小越好。</p>
<p>不过测试集对训练过程来说是未知的，所以模型只能尽量从训练集中发掘数据的普遍规律，要是模型把训练集学得”太好“了，很可能把训练集中不属于普遍规律的部分特点作为了一般性质，这就会导致泛化性能下降，我们称这种情况为<strong>过拟合 (overfitting)**。反之，模型对训练集的特性学得不够，就会出现</strong>欠拟合 (underfitting)**。关于过拟合和欠拟合，周志华老师的《机器学习》中有一张很好的图：</p>
<img src="https://i.loli.net/2020/09/09/tVPeQfu9CWLaSi6.png" style="zoom:67%;" />

<p>一般来说，欠拟合比较容易克服，可以通过增加模型的复杂度来实现。而过拟合则比较难解决，一般而言可以通过增加数据量、加正则化约束来改善。</p>
<h1 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h1><p>对于一个机器学习任务，一般我们有多种模型供我们选择，并且模型也有不同的超参数，我们希望得到泛化性能尽可能高的模型。不过根据前面的讨论，新样本是未知的，所以没法直接得到泛化误差，而过拟合的存在使得我们不能贸然的根据模型在我们收集到的数据上的表现来选择模型（训练误差低不代表泛化误差低）。</p>
<p>我们假设无论是我们收集到的数据还是新样本都是从数据的真实分布中独立同分布采样得来，为此我们可以从数据中划分出一部分”测试集“，然后将模型在测试集上的表现作为泛化误差的近似，而剩下的部分用来模型训练。</p>
<p>那么如何划分训练集和测试集呢？比较常见的方法是”$k$折交叉验证法“ ($k$-fold cross validation)，一般$k$常取$10$，其基本思想如下图所示：</p>
<img src="https://i.loli.net/2020/09/09/8KEWDe3qMTsQoUx.png" style="zoom: 50%;" />

<p>$k$折交叉验证法首先将数据集均匀地划分为$k$个部分，然后进行$k$个循环，在每个循环中将第$k$份作为测试集，其余的作为训练集，最后得到的结果进行平均。</p>
<h1 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h1><p>前面我们讨论了评测的框架，但是没有说具体的评测指标。实际上评测指标要根据任务来确定，并且不同的评测指标也有自己的特点。</p>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>回归任务比较常用的评测标准是<strong>均方误差 (Mean Squared Error)**：<br>$$<br>\text{MSE}(f;D)=\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2<br>$$<br>和</strong>平均绝对误差 (Mean Absolute Error)**：<br>$$<br>\text{MAE}(f;D)=\frac{1}{m}\sum_{i=1}^m |f(x_i)-y_i|<br>$$</p>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><p>对于分类任务，最简单的想法是使用模型分类正确的比例来作为评测标准，我们称之为<strong>准确率 (Accuracy)**：<br>$$<br>\text{ACC}(f;D)=\frac{1}{m}\sum_{i=1}^m \mathbb{I}(f(x_i)=y_i)<br>$$<br>但准确率并不能满足我们的所有要求，比如说对于新冠病毒的分类任务，我们可能会更关注于对于所有患有新冠的病人，模型到底查出来了多少，而对于模型误把正常病人当作是患病的情况没有那么关注。对于二分类问题，我们可以将样例根据其真实类别与模型预测的类别划分为真正例 (true positive, TP)、假正例 (false positive, FP)、真反例 (true negative, TN) 和假反例 (false negative, FN) 四种，形成</strong>混淆矩阵 (Confusion Matrix)**：</p>
<p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg"></p>
<p>下面给一个具体的例子：</p>
<p><img src="https://i.loli.net/2020/09/09/tCLxvZfNoEgqWID.png"></p>
<p>比如我们的任务是预测一张手写数字图片是不是$5$，根据上图，右下角就是我们正确预测的是$5$的图片，左下角就是本来是$5$，但被预测成不是$5$的图片；左上角是本来不是$5$，我们也正确地预测出其不是$5$的，右上角是本来不是$5$却被预测成是$5$的。是不是有点被绕晕了😀，只要记住T和F代表的是预测结果对还是不对，P和N代表的是模型预测当前样本是正例还是负例。</p>
<p>基于混淆矩阵，我们可以定义<strong>查准率 (Precision)</strong> 和<strong>查全率 (Recall)</strong> 这两个评测标准。</p>
<p>查准率，顾名思义，对于检测出来的正例，有多少是真正的正例，即查的准不准，公式为：<br>$$<br>\text{Precision}=\frac{TP}{TP+FP}<br>$$<br>分母就是模型预测为正例的样本总数。</p>
<p>查全率，就对应刚才举的新冠的例子，我们比较在乎对于数据集中的正例，有多少被查出来了，公式为：<br>$$<br>\text{Recall} = \frac{TP}{TP+FN}<br>$$<br>分母就是真实类别为正例的样本总数。一般来说，查准率和查全率是相互矛盾的，除非是特别简单的任务，很难兼顾查准率和查全率。</p>
<p><strong>F1分数 (F1 Score)</strong> 综合了查准率和查全率：<br>$$<br>\text{F}1=\frac{2\cdot\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}<br>$$<br>查准率和查全率中任意一项较低都会导致F1分数较低。有时候我们对待查准率和查全率的权重不同，这时候可以使用F$_\beta$分数：<br>$$<br>\text{F}_\beta=\frac{(1+\beta^2)\cdot \text{Precision}\cdot\text{Recall}}{(\beta^2\cdot\text{Precision})+\text{Recall}}<br>$$<br>$\beta=1$时等价于F1分数，$\beta&gt;1$代表偏重查全率，$\beta&lt;1$代表偏重查准率。</p>
<h3 id="Multi-classification"><a href="#Multi-classification" class="headerlink" title="Multi-classification"></a>Multi-classification</h3><p>前面的讨论都是基于二分类任务，如果是多分类任务的话， 对于每一类，我们将该类作为正例，其他类别作为负例，都能得到一个混淆矩阵。如果我们在每个混淆矩阵上计算评测指标，然后进行平均，这样就得到宏查准率 (macro-Precision)、宏查全率 (macro-Recall) 和宏F1分数 (macro-F1)。如果我们事先将混淆矩阵的TP、FP、TN、FN先进行平均，再计算评测指标，就得到了微查准率 (micro-Precision)、微查全率 (micro-Recall) 和微F1分数 (micro-F1)。</p>
<h3 id="PR-Curve"><a href="#PR-Curve" class="headerlink" title="PR-Curve"></a>PR-Curve</h3><p>很多情况下模型的输出是样本为正例的“概率值”或者是分数，分数越高的样本代表越可能是正例。这种时候需要人为划定阈值，规定高于阈值的样本是正例。不过阈值的划分相当于超参数的选取，同时我们会认为一个鲁棒的模型的性能应该不受阈值选取的左右。这个时候我们可以使用**PR曲线 (Precision-Recall Curve)**，即遍历所有可能的阈值，对于每个阈值，计算其对应的Precision和Recall，然后画在图上，最后会得到一系列离散的点（理论上应该是连续曲线，不过阈值是连续值，我们只能取离散值），形成PR-曲线。</p>
<img src="https://i.loli.net/2020/09/09/ecP8flTYZIDUBrV.png" alt="2-class Precision-Recall curve: AP=0.88" style="zoom:67%;" />

<p>模型性能越好，曲线就会越接近右上角的点，我们可以把PR曲线的曲线下面积 (PR-AUC) 作为评测标准。</p>
<h3 id="ROC-Curve"><a href="#ROC-Curve" class="headerlink" title="ROC-Curve"></a>ROC-Curve</h3><p>ROC全称是<strong>受试者工作特征 (Receiver Operating Characteristic) 曲线</strong>, 和PR曲线类似，ROC曲线也是遍历不同的阈值计算点，不过ROC曲线计算的是真正例率 (True Positive Rate, TPR) 和假正例率 (False Positive Rate, FPR)，两者定义分别是：<br>$$<br>\begin{align}<br>\text{TPR}=\frac{TP}{TP+FN}\<br>\text{FPR}=\frac{FP}{TN+FP}<br>\end{align}<br>$$<br>其中TPR就是查全率，而FPR是所有负例中没有检测出来的比例，这一项是越低越好。</p>
<img src="https://i.loli.net/2020/09/09/CdHrDaKAns4EN93.png" style="zoom:67%;" />

<p>模型性能越好，曲线就会越接近左上角的点，我们可以把ROC曲线的曲线下面积 (ROC-AUC) 作为评测标准。</p>
<p>下面来总结一下PR曲线和ROC曲线之间的优缺点。</p>
<table>
<thead>
<tr>
<th></th>
<th>纵轴</th>
<th>横轴</th>
</tr>
</thead>
<tbody><tr>
<td><strong>PR</strong></td>
<td>$\text{Precision}=\frac{TP}{TP+FP}$</td>
<td>$\text{Recall} = \frac{TP}{TP+FN}$</td>
</tr>
<tr>
<td><strong>ROC</strong></td>
<td>$\text{TPR}=\frac{TP}{TP+FN}$</td>
<td>$\text{FPR}=\frac{FP}{TN+FP}$</td>
</tr>
</tbody></table>
<p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg"></p>
<p>ROC的优点：</p>
<ul>
<li>相比PR仅关注正例，ROC同时关注正例和负例</li>
<li>相比PR不易受到正负例相对数量的影响，ROC的两个指标的计算都只涉及到P、N中的一列，正例或负例增加对总体影响不大。而PR曲线就不一样，两个指标的计算都涉及到了P、N两列，那么正例或负例样本数量的变化会造成较大影响。如负例突然增大，那么FP也会增大，这样Precision会降低，而Recall却不变。</li>
</ul>
<p>ROC的缺点：</p>
<ul>
<li>对于类别不平衡问题，存在大量负例，这样会带来大量的FP，而ROC的FPR却不会因为FP的大幅增长而剧烈改变，结果是这一类错误很难在ROC曲线中体现出来。所以ROC会呈现出一个过于乐观的评价。</li>
</ul>
<p>我们来尝试下是否如此，下面是用随机森林分类器，测试样本正负例数量比为1:1的情况下的ROC曲线和PR曲线：</p>
<img src="https://i.loli.net/2020/09/10/yqMDQh5oTs96SJm.png" style="zoom:50%;" />

<img src="https://i.loli.net/2020/09/10/zFW941YTMl8yxiP.png" style="zoom:50%;" />

<p>在我们将正负例数量比调整为1:9之后（总数量相同），可以看到ROC曲线比较稳定，没出现较大变化，而PR曲线则出现了剧烈变化：</p>
<img src="https://i.loli.net/2020/09/10/HbnLtfGsiVc17q5.png" style="zoom:50%;" />

<img src="https://i.loli.net/2020/09/10/FfYrb3SnkeZ9JTv.png" alt="4" style="zoom:50%;" />

<h1 id="Bias-and-Variance"><a href="#Bias-and-Variance" class="headerlink" title="Bias and Variance"></a>Bias and Variance</h1><p>在机器学习中，偏差-方差分解是解释学习算法泛化性能的重要工具。假设我们要预测某一个地区的房子的房价，每一套房子都是一个样本，我们认为每个样本都是从总体分布$P(X)$独立同分布采样得来的。不过我们不可能得到所有的样本，我们采样得到的训练集只是其中一个子集。那么，即使对于同样的测试样本，使用不同的训练集（训练集大小相同）训练出来的模型对测试样本的预测也是不一样的，我们将这一部分模型自身的不稳定性用<strong>方差 (Variance) **来描述：$\text{Var}(X)=E_D\left[(\hat f(X)-E[\hat f(X)])^2\right]$，方差越小代表模型稳定性越强。模型输出的期望与真实值之间的差距我们用</strong>偏差 (Bias) **来描述：$\text{Bias}(X)=E[\hat f(X)]-f(X)$。</p>
<p>泛化误差与方差、偏差有下列关系：<br>$$<br>\begin{align}<br>\text{Err}(X)&amp;=E\left[(y-\hat f(X))^2\right]\<br>&amp;=E\left[(f(X)+\varepsilon-\hat f(X))^2\right]\<br>&amp;= (E[\hat f(X)]-f(X))^2 + E\left[(\hat f(X)-E[\hat f(X)])^2\right]+\sigma_{\varepsilon}^2\<br>&amp;=\text{Bias}^2 + \text{Variance} + \text{Random Error}<br>\end{align}<br>$$<br>也就是说泛化误差可以分解为方差、偏差和随机噪声之和。偏差刻画了模型的期望预测与真实值之间的偏离程度，方差刻画了不同训练集对模型性能的影响，他们之间的关系如下图所示：</p>
<img src="https://i.loli.net/2020/09/09/2IpmrwJGfqORU3z.png" style="zoom: 33%;" />

<p>图中左上角的部分是比较理想的情况，即方差和偏差都较小。但实际上方差和偏差往往是相互冲突的，如下图所示：</p>
<img src="https://i.loli.net/2020/09/09/GsREiklKYfuX3Ub.png" style="zoom:67%;" />

<p>模型复杂度不足的时候，模型的拟合能力不够强，偏差主导了泛化误差，而随着模型复杂度的提高，模型的拟合能力逐渐提高，训练数据的扰动会造成模型发生显著变化，这时方差逐渐主导了泛化误差。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-09-02T10:47:55.000Z" title="2020-9-2 6:47:55 ├F10: PM┤">2020-09-02</time>发表</span><span class="level-item"><time dateTime="2021-02-19T10:22:31.857Z" title="2021-2-19 6:22:31 ├F10: PM┤">2021-02-19</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Technical-Notes/">Technical Notes</a><span> / </span><a class="link-muted" href="/categories/Technical-Notes/Machine-Learning/">Machine Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/">Machine Learning Classification Algorithms: Decision Trees</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>（PS：本文内容是学习高级树模型（GBDT，XGBoost）的基础，强烈建议在看那些内容之前先了解本文的内容！）</p>
<p>本文主要是介绍常用的三种决策树模型：ID3、C4.5和CART。决策树（Decision Tree）是一种<strong>有监督分类模型</strong>（稍加改造可进行回归任务）。</p>
<p>比如我们要判断一个瓜是不是好瓜，对于人来说，要判断一个瓜是不是好瓜，可能会先去看看色泽，然后看看根蒂，然后再敲一敲听听声音，这样经过一系列的决策过程。</p>
<img src="https://i.loli.net/2020/09/02/WuGQ79g4NcHqJDh.png" style="zoom:50%;" />

<p>决策树正是模拟了这样的过程。给定数据集，决策树会不断地选择最佳的特征将数据集进行切分（如选择色泽，然后将数据分为青绿、乌黑、浅白这几个子集），然后递归地进行下去，直到达到停止条件：</p>
<ol>
<li>每个叶子节点的样本都属于同一个类别</li>
<li>没有可供划分的特征，或者集合中每个样本所有特征取值都相同</li>
<li>决策树达到预先指定的最大深度</li>
</ol>
<p>所以决策树算法要解决的关键问题就是如何去选择当前最好的划分特征。</p>
<h1 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h1><p>ID3算法根据信息熵来进行特征的划分。信息熵是衡量一个随机变量信息量的度量，如果把数据集的标签$y$看作是随机变量，那么$y$的熵越小代表不确定性越小（集合里几乎都是一种类别的样本），熵越大代表不确定性越大（集合包含不同类别的样本），其公式为：<br>$$<br>Ent(D)=-\sum_{k=1}^{|\mathcal Y|}p_k\log p_k<br>$$<br>$Ent(D)$代表集合$D$对应的熵，$|\mathcal Y|$是类别数量，二分类就是$|\mathcal Y|=2$，$p_k$为第$k$个类别对应的概率（频率）。很自然的，我们可以根据划分前后熵的变化来确定划分特征的选择，如果划分之后熵减小的最多，那么这个特征也是最好的。假设我们选定特征$a$来对集合进行划分，特征$a$共有$V$个离散取值，那么划分之后将会产生$V$个子集，我们记每个子集为$D^v, v=1,\cdots, V$。那么，信息增益可以写为：<br>$$<br>Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)<br>$$<br>不过，ID3存在两个致命的缺点：</p>
<ol>
<li>无法对连续取值的特征进行计算</li>
<li>对取值较多的特征具有很大的偏向性（极端的情况，把样本编号作为特征，由于每个样本的编号都不同，分裂之后每个自己只有一个样本/类别，熵是最小的）</li>
</ol>
<h1 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h1><p>C4.5算法在ID3的基础上做了诸多改进。C4.5解决了ID3对于取值数目较多的特征的偏向性问题，其采用的方案很直观，即对信息增益除以一个系数，特征取值数目越多的特征系数越大，该划分标准被称作是信息增益率：<br>$$<br>Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}<br>$$<br>其中$IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}\log \frac{|D^v|}{|D|}$。其实$IV(a)$可以看作是“划分之后每个样本属于集合$v$的概率”这个随机变量的熵，划分的子集越多，划分之后属于哪个集合就越不确定，所以熵就越大。</p>
<p>不过信息增益率反而会对特征取值数目少的特征有所偏好，所以C4.5算法是先计算信息增益，确定信息增益高于平均值的候选集，再从中选择信息增益率最高的特征。</p>
<p>除此之外，C4.5还能处理连续取值的特征，其做法是“离散化”，即将连续取值划分为若干个离散的区间，一般二分比较常用。设连续特征$a$，假设其出现了$n$个取值，将其排序得到${a^1,a^2,\cdots,a^n}$，我们考虑每两个相邻节点的中点集合$T_a={\frac{a^i+a^{i+1}}{2}|1\leq i \leq n-1}$，之后我们就可以像考察离散属性值一样选择最优划分。</p>
<p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p>
<p><img src="https://i.loli.net/2020/09/10/RNyxp8EM6BCsOHK.png"></p>
<h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p>CART (Classification and Regression Trees) 是一种应用广泛的决策树模型，既可应用于分类任务也可应用于回归任务。</p>
<h2 id="CART-Regression"><a href="#CART-Regression" class="headerlink" title="CART Regression"></a>CART Regression</h2><p>我们先来说说CART怎么进行回归。在回归问题中，CART使用了MSE作为划分准则：<br>$$<br>\frac{1}{N}\sum_{i=1}^N (f(x_i)-y_i)^2<br>$$<br>如果CART有$M$片叶子，那么相当于CART将输入划分成了$M$个单元$R_m, m=1,\cdots,M$，也即有$M$个输出，那么该CART在数据集上的MSE为：<br>$$<br>\frac{1}{N}\sum_{m=1}^M\sum_{x_i\in R_m} (c_m-y_i)^2<br>$$<br>这里$c_j$为叶子节点$j$的输出，一般选为对应样本的均值$c_m=\text{avg}(y_i|x_i\in R_m)$。这样，剩下的问题就是如何确定每次的切分特征和切分点了。假设选择的特征是$j$，切分点$s$，那么该划分方案对应的损失为：<br>$$<br>\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2<br>$$<br>遍历所有的$j$和$s$，我们就能找到最佳的特征和切分点：<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2\right]<br>$$</p>
<p>算法流程大致如下：</p>
<blockquote>
<p><strong>CART Decision Tree Algorithm</strong></p>
<p>INPUT: 数据集 $D={(x_1,y_1),\cdots,(x_N,y_N)}$</p>
<p>OUTPUT: 预测值${\hat y_1,\cdots,\hat y_N}$</p>
<p>PROCEDURE:</p>
<p><strong>1. 选取当前最优切分特征变量$j^*$与最优切分点$s^*$</strong></p>
<p>设当前选择的切分变量为$j$，切分点为$s$那么可以根据切分点将数据集分为两个子集，一个是$R_1(j,s)=\left{x|x^{(j)}\leq s\right}$，另一个是$R_2(j,s)=\left{x|x^{(j)}&gt; s\right}$。<br>遍历所有的$j$，求解<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum\limits_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min\limits_{c_2}\sum\limits_{x_i\in R_2(j,s)}(y_i-c_2)^2\right]<br>$$<br>注意$\hat c_1=\frac{1}{N_1}\sum\limits_{x_i\in R_1(j,s)}y_i$<br><strong>2. 用选定的$(j^*,s^*)$来划分区域并计算输出值</strong></p>
<p>此时，我们还需要确定这两个区域（划分到同一个区域的样本对应的输出是相同的）的输出值$c_1$和$c_2$，其确定方式是使得对应区域上的均方误差最小。这样我们相当于得到了给定$j,s$下的损失，所以只要找出使得损失最小的$j^*,s^*$即可：</p>
<p><strong>3. 递归地对划分出来的两个区域重复步骤1和步骤2，直到满足停止条件</strong></p>
<p><strong>4. 最后将输入空间划分为$M$，输出$f(x)=\sum_{m=1}^M \hat c_m I(x\in R_m)$</strong></p>
</blockquote>
<p>下图是在波士顿房价数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p>
<p><img src="https://i.loli.net/2020/09/09/knOHuvsfyorTpxt.png"></p>
<h2 id="CART-Classification"><a href="#CART-Classification" class="headerlink" title="CART Classification"></a>CART Classification</h2><p>从前面的讨论可以看到，CART回归树是一棵二叉树，对于分类任务，CART也是一棵二叉树。我们先来介绍CART的划分准则，再来介绍它是怎么进行划分的。</p>
<p>采用基尼系数作为准则，基尼系数的计算依赖于基尼值：<br>$$<br>\begin{align}<br>Gini(D)&amp;=1-\sum_{k=1}^{|\mathcal Y|}p_k^2<br>\end{align}<br>$$<br>直观上来说，基尼值表示随机抽取两个样本，其类别不一致的概率</p>
<p>如果说一个特征越好，那么划分之后其每个子集对应的基尼值应该越小越好。基尼系数的定义为：<br>$$<br>Gini_index(D,a)=\sum_{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)<br>$$</p>
<p>对于离散取值特征，CART不会根据不同取值个数进行划分，而是和连续值类似，会确定一个“划分点”，将样本进行二分。比如对于特征$a$，其对应取值为${a^1,a^2,\cdots,a^n}$，CART会考察每个取值，将样本集划分为特征$a$是不是等于$a^i$两部分，然后计算基尼系数，最终会采用基尼系数最小的取值作为划分点。</p>
<p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p>
<p><img src="https://i.loli.net/2020/09/10/mMf2EVkI1NaQLdS.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-08-25T18:09:24.000Z" title="2020-8-26 2:09:24 ├F10: AM┤">2020-08-26</time>发表</span><span class="level-item"><time dateTime="2021-02-19T10:23:31.925Z" title="2021-2-19 6:23:31 ├F10: PM┤">2021-02-19</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Technical-Notes/">Technical Notes</a><span> / </span><a class="link-muted" href="/categories/Technical-Notes/Machine-Learning/">Machine Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/">Machine Learning Classification Algorithms: Support Vector Machine</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Still working on it😅…</p>
<p><a target="_blank" rel="noopener" href="http://blog.pluskid.org/?page_id=683">blog</a></p>
<h1 id="Hyperplane"><a href="#Hyperplane" class="headerlink" title="Hyperplane"></a>Hyperplane</h1><p>超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程：<br>$$<br>a_1x_1+\cdots+a_nx_n=d<br>$$<br>的所有解形成的集合，其中$a_1,\cdots,a_n$为不全为$0$的实数，$d$也是实数。</p>
<p>从几何上来说，超平面可以看作是除空间$R^n$自身外维度最大的仿射空间。</p>
<p><img src="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg"></p>
<h1 id="Maximum-Margin-Classifier"><a href="#Maximum-Margin-Classifier" class="headerlink" title="Maximum Margin Classifier"></a>Maximum Margin Classifier</h1><img src="https://i.loli.net/2020/08/26/vjuyCGXMr4msaUK.png" style="zoom:67%;" />

<p>要谈SVM就得先谈线性分类器，其设置是这样的。对于$D$维空间，我们有一堆数据$X$，进行二分类任务，标签记为$y$，其中$y=-1$和$y=1$分别代表不同的类别。我们的任务就是找到一个超平面，将正负例切分开来（先假设数据是线性可分的），这个超平面的方程可以表示为：<br>$$<br>w^\top x+b=0<br>$$<br>我们令$f(x)=w^\top x+b$，对于$f(x)&lt;0$的样本，我们赋予其类别$-1$，对于$f(x)&gt;0$的样本，我们可以赋予其类别$1$。对于相同的分类结果，我们可以找出无限种超平面。不过，对于那些样本特别靠近超平面的情况，鲁棒性并不好。为什么呢？因为这时只要超平面有轻微的变化，样本的分类结果就会发生变化。直观上来说，我们希望样本到超平面的距离越大越好。</p>
<p>我们先定义函数间隔的概念，函数间隔$\hat \gamma=y(w^\top x+b)$，乘以$y$的目的主要是保持非负性，表示起来方便。可见函数间隔的大小并不能表示样本距离，因为同一个超平面，法向量$w$可以任意增大，函数间隔也会相应增大。</p>
<p>下面来推导点$x$到超平面的距离。设$x$在超平面上的投影为$x_0$，到超平面的距离为$\gamma$，$w$为法向量，那么有：<br>$$<br>x=x_0+\gamma\frac{w}{\parallel w\parallel}<br>$$<br>将上式带入到超平面方程可以得到<br>$$<br>\gamma=\frac{w^\top}{\parallel w\parallel}x+\frac{b}{\parallel w\parallel}<br>$$<br>我们称$\gamma$为几何间隔。</p>
<p><img src="https://i.loli.net/2020/08/26/b6qLJWzHwFAPDne.png"></p>
<p>可以很容易看出函数间隔和几何间隔的关系：<br>$$<br>\gamma = \frac{\hat \gamma}{\parallel w\parallel}<br>$$<br>前面提到我们希望几何间隔越大越好，于是可以直接最大化$\gamma$，得到：<br>$$<br>\begin{align}<br>\max \space &amp;\gamma\<br>s.t. \space &amp; y_i(w^\top x_i+b)=\hat\gamma_i\geq\hat\gamma, \space i=1,\cdots,n<br>\end{align}<br>$$<br>这里$\hat \gamma=\gamma \parallel w\parallel$，根据前面的分析我们知道，对于同一个超平面，函数间隔$\hat\gamma$可以随着$\parallel w\parallel$的变化而变化，所以为了找到最优的$\gamma$，我们可以考虑固定$\parallel w\parallel$或者$\hat\gamma$，这里我们固定$\hat \gamma=1$，所以有：<br>$$<br>\begin{align}<br>\max &amp; \space \frac{1}{\parallel w\parallel},\ s.t. \space&amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$</p>
<p>下面的约束条件代表前提是所有样本分类正确，而$\max\frac{1}{\parallel w\parallel}$代表最大化间隔。为了方便，我们将其化为等价的最小化形式：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中那些$y_i(w^\top x_i+b)=1$的样本就是“支持向量”。这个优化问题是典型的二次凸优化问题，可以调用现成的算法去解决。不过我们可以使用拉格朗日乘子法来更高效的解决。</p>
<h1 id="Dual-Problem"><a href="#Dual-Problem" class="headerlink" title="Dual Problem"></a>Dual Problem</h1><p>拉格朗日乘子法可以将有$d$个变量和$k$个约束条件的最优化问题转化成有$d+k$个变量的无约束最优化问题求解。</p>
<h2 id="Lagrange-Multiplier"><a href="#Lagrange-Multiplier" class="headerlink" title="Lagrange Multiplier"></a>Lagrange Multiplier</h2><p>对于以下有约束优化问题：<br>$$<br>\begin{align}<br>\min_x \space &amp; f(x)\<br>\text{s.t.} \space &amp; h_i(x)=0 \space (i=1,\cdots,m),\<br>&amp;g_j(x) \leq 0 \space (j=1,\cdots,n)<br>\end{align}<br>$$</p>
<p>引入拉格朗日乘子$\boldsymbol\lambda = (\lambda_1,\lambda_2,\cdots,\lambda_n)^\top$和$\boldsymbol\mu=(\mu_1,\mu_2,\cdots,\mu_m)^\top$，相应的广义拉格朗日函数 (generalized Lagrange function) 为：<br>$$<br>L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=f(\boldsymbol x)+\sum_{j=1}^n \lambda_j g_j(\boldsymbol x)+\sum_{i=1}^m \mu_i h_i(\boldsymbol x)<br>$$</p>
<p>其中$\lambda_j$，$\mu_i$被称作是拉格朗日乘子，$\lambda_j \geq 0$。</p>
<h3 id="Primal-Problem"><a href="#Primal-Problem" class="headerlink" title="Primal Problem"></a>Primal Problem</h3><p>现在我们来讨论原问题的等价性。假设给定某个$x$，如果$x$违反约束条件，即存在某个$x$使得$h_i(x)\neq 0$或者$g_j(x)&gt;0$，那么就有：<br>$$<br>\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=+\infty<br>$$<br>如果存在某个$x$使得$h_i(x)\neq 0$，那么可以令$\lambda_j \rightarrow +\infty$，如果存在$g_j(x)&gt;0$，那么可令$\mu_ih_i(x)\rightarrow +\infty$。</p>
<p>如果考虑以下极小化问题：<br>$$<br>p^*=\min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>他与原始带约束最优化问题是等价的（因为不符合约束时会有$+\infty$，而我们考虑的是极小化问题），我们将其记为原问题 (Primal problem)。</p>
<h3 id="Dual-Problem-1"><a href="#Dual-Problem-1" class="headerlink" title="Dual Problem"></a>Dual Problem</h3><p>如果先考虑最小化$x$，再考虑最大化$\boldsymbol\lambda$和$\boldsymbol\mu$，这时有：<br>$$<br>\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>对偶问题 (Dual problem)<br>$$<br>d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)<br>$$<br>原问题和对偶问题的关系<br>$$<br>d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) \leq \min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) = p^*<br>$$</p>
<h3 id="KKT-Condition"><a href="#KKT-Condition" class="headerlink" title="KKT Condition"></a>KKT Condition</h3><blockquote>
<p>对于原问题和对偶问题，设$f(x)$和$g_i(x)$为凸函数，$h_i(x)$为仿射函数，并且不等式约束$c_i(x)$是严格可行的，则$x^*$，$\lambda^*$，$\mu^*$分别是原问题和对偶问题的解的充分必要条件是满足下面的Karush-Kuhn-Tucker (KKT) 条件：<br>$$<br>\begin{cases}<br>\nabla_x L(x^*,\lambda^*,\mu^*)=0 &amp;\<br>\lambda^<em>_j g_j(x^</em>)=0 &amp; j=1,\cdots n\<br>g_j(x^*)\leq 0 &amp; j=1,\cdots n\<br>\lambda_j^<em>\geq 0 &amp; j=1,\cdots n\<br>h_i(x^</em>) = 0 &amp; i = 1, \cdots m<br>\end{cases}<br>$$</p>
</blockquote>
<p>这告诉我们</p>
<h2 id="Dual-Form-of-SVM-Optimization"><a href="#Dual-Form-of-SVM-Optimization" class="headerlink" title="Dual Form of SVM Optimization"></a>Dual Form of SVM Optimization</h2><p>支持向量机优化的对偶问题可以写为：<br>$$<br>L(w,b,\alpha)=\frac{1}{2}\parallel w\parallel^2-\sum_{i=1}^n \alpha_i(y_i(w^\top x_i+b)-1)<br>$$<br>我们先令：<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial w}=0&amp;\Rightarrow w=\sum_{i=1}^n\alpha_i y_i x_i\<br>\frac{\partial L}{\partial b}=0&amp;\Rightarrow \sum_{i=1}^n\alpha_i y_i =0<br>\end{align}<br>$$<br>带回到$L$得到：<br>$$<br>\begin{align}<br>L(w,b,\alpha)&amp;=\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_j y_i y_j x^\top_i x_j-\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_jx^\top_ix_j-b\sum_{i=1}^n\alpha_iy_i+\sum_{i=1}^n\alpha_i\<br>&amp;=\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j<br>\end{align}<br>$$<br>于是得到关于$\alpha$的对偶优化问题：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$</p>
<p>前面有提到我们根据$f(x)=w^\top x + b$的输出来判定样本类别，而刚才得到$w=\sum_{i=1}^n\alpha_i y_i x_i$，于是：<br>$$<br>\begin{align}<br>f(x) &amp;= (\sum_{i=1}^n \alpha_iy_ix_i)^\top x+b\<br>&amp;= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>\end{align}<br>$$<br>最后的$\sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b$值得特别注意，这意味着我们对于测试样本$x$的预测，只需要计算它与训练集的内积即可，同时由于所有非支持向量对应的$\alpha$都是$0$，我们只需要求一小部分内积。同时这个内积计算也是后面核方法应用的前提。</p>
<h1 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h1><p>到目前为止，我们的讨论都是在数据是线性可分的前提下进行讨论的，那么对于线性不可分的情况呢？答案是使用核方法。</p>
<p><img src="https://i.loli.net/2020/09/08/kSTVgelDjWqtu8v.png"></p>
<p>核方法的思想是，对于原始不可分的数据，我们假设原始数据通过一个映射$\phi(\cdot)$就变得线性可分了。核方法相当于对数据找到了一种新的表示，如上图没法用一个超平面直接分割，但通过$\phi(\cdot)$映射之后就变得可分了。原始的分类函数为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>$$<br>加上映射之后变为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle \phi(x_i), \phi(x)\rangle + b<br>$$<br>优化问题也变为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j \langle\phi(x_i), \phi(x_j)\rangle\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>我们把计算两个向量在映射后的空间中的内积的函数叫做核函数<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i k(x_i, x) + b<br>$$<br>优化问题改为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j k(\phi(x_i), \phi(x_j))\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>实际上，通过核函数，我们隐式地定义了一个映射$\phi(\cdot)$</p>
<p>常用核函数</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>表达式</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td>线性核</td>
<td></td>
<td></td>
</tr>
<tr>
<td>多项式核</td>
<td></td>
<td></td>
</tr>
<tr>
<td>RBF核</td>
<td></td>
<td></td>
</tr>
<tr>
<td>拉普拉斯核</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sigmoid核</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h1 id="Soft-Margin"><a href="#Soft-Margin" class="headerlink" title="Soft Margin"></a>Soft Margin</h1><p>数据线性不可分的情况，除了数据本身结构非线性的原因之外（核方法），还有可能是因为噪声或者离群点。为了处理这种情况，我们可以允许一部分点在一定程度上偏离超平面，具体来说就是原来的约束条件$y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n$变成了：<br>$$<br>y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>$$<br>其中$\xi_i\geq 0$称作是松弛变量，代表样本$i$允许的偏离程度。当然松弛变量不可能无限大，所以我们需要将$\xi_i$加入到优化目标函数中使其尽量小，于是有：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2+C\sum_{i=1}^n \xi_i,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中$C$为控制最优化$\parallel w\parallel$和松弛变量这两项的权重。这里的优化函数还是对偶问题之前的形式，我们马上会讨论对偶问题。</p>
<h1 id="Numerical-Optimization"><a href="#Numerical-Optimization" class="headerlink" title="Numerical Optimization"></a>Numerical Optimization</h1><p>这里讨论SVM高效求解的Sequential Minimal Optimization (SMO)算法。</p>
<p>坐标下降法是一种非梯度优化算法，</p>
<p><img src="https://i.loli.net/2020/09/08/I6AonzFRHGVBU3t.png"></p>
<p><img src="https://i.loli.net/2020/09/08/Hmr79nMlK4C8GeJ.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-08-25T16:28:26.000Z" title="2020-8-26 12:28:26 ├F10: AM┤">2020-08-26</time>发表</span><span class="level-item"><time dateTime="2021-02-28T05:38:18.079Z" title="2021-2-28 1:38:18 ├F10: PM┤">2021-02-28</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Technical-Notes/">Technical Notes</a><span> / </span><a class="link-muted" href="/categories/Technical-Notes/Machine-Learning/">Machine Learning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/26/Machine-Learning-Ensemble-Algorithms-GBDT-and-XGBoost/">Machine Learning Ensemble Algorithms: GBDT and XGBoost</a></h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文主要介绍GBDT和XGBoost，在学习本文内容之前建议先学习<a target="_blank" rel="noopener" href="http://hanzawa.me/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/">决策树相关内容</a>。</p>
<p>下面是一些有用的参考链接：</p>
<p><a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">XGBoost Documentation</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6133937.html">AdaBoost blog</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinard/p/6140514.html">GBDT blog</a></p>
<p><a target="_blank" rel="noopener" href="http://wepon.me/files/gbdt.pdf">slide</a></p>
<p><a target="_blank" rel="noopener" href="https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf">陈天奇slide</a></p>
<p><a target="_blank" rel="noopener" href="https://snaildove.github.io/2018/10/01/8.Booting-Methods_LiHang-Statistical-Learning-Methods/">blog</a></p>
<p><a target="_blank" rel="noopener" href="https://snaildove.github.io/2018/10/02/get-started-XGBoost/">blog</a></p>
<h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>实际上，GBDT和梯度下降、XGBoost和牛顿法之间是存在密切关系的，这里我们先回顾一下梯度下降算法和牛顿法的基础知识。</p>
<h2 id="Taylor-Formulation"><a href="#Taylor-Formulation" class="headerlink" title="Taylor Formulation"></a>Taylor Formulation</h2><p>函数$f(x)$在点$x_0$处的泰勒展开为：<br>$$<br>f(x)=\sum_{n=0}^\infty\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n<br>$$<br>特别的，一阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0)<br>$$<br>二阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0) + f^{\prime\prime}(x_0)\frac{(x-x_0)^2}{2}<br>$$<br>迭代形式：假设$x^t=x^{t-1}+\Delta x$，将$f(x)$在$x^{t-1}$处进行泰勒展开<br>$$<br>\begin{align}<br>f(x^t) &amp;= f(x^{t-1}+\Delta x)\<br>&amp;\approx f(x^{t-1})+f^\prime(x^{t-1})\Delta x + f^{\prime\prime}(x^{t-1})\frac{\Delta x^2}{2}<br>\end{align}<br>$$</p>
<h2 id="Gradient-Descend-Method"><a href="#Gradient-Descend-Method" class="headerlink" title="Gradient Descend Method"></a>Gradient Descend Method</h2><p>设参数$\theta$，那么参数对应的损失函数为$L(\theta)$，</p>
<p>设当前步数为$t$，那么$t-1$步时的参数为$\theta^{t-1}$，将$L(\theta^t)$在$\theta^{t-1}$处展开得到：</p>
<p>$$<br>L(\theta^t) \approx L(\theta^{t-1})+ L^\prime(\theta^{t-1})\Delta\theta<br>$$<br>我们想求的$\theta^t=\theta^{t-1}+\Delta \theta$</p>
<h2 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h2><p>将$L(\theta^t)$在$\theta^{t-1}$处进行二阶泰勒展开<br>$$<br>\begin{align}<br>L(\theta^t) &amp;= L(\theta^{t-1}+\Delta \theta)\<br>&amp;\approx L(\theta^{t-1})+L^\prime(\theta^{t-1})\Delta \theta + L^{\prime\prime}(\theta^{t-1})\frac{\Delta \theta^2}{2}<br>\end{align}<br>$$<br>记一阶导数和二阶导数分别为$g$和$H$，那么<br>$$<br>L(\theta^t)=L(\theta^{t-1})+g\Delta \theta + H\frac{\Delta \theta^2}{2}<br>$$<br>要使得迭代后的结果尽量小，即$g\Delta \theta + H\frac{\Delta \theta^2}{2}$尽量小，那么有$\frac{\left(g\Delta \theta + H\frac{\Delta \theta^2}{2}\right)}{\partial\Delta\theta}=0$</p>
<p>求得$\Delta \theta=H^{-1}g$，故$\theta^{t}=\theta^{t-1}+\Delta \theta=\theta^{t-1}-\frac{g}{h}$。如果$\theta$是一个向量，那么$\theta^{t}=\theta^{t-1}-H^{-1}g$，这里$H$为海森矩阵。</p>
<h1 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h1><p>我们首先来看基于树的Boosting模型中，非常经典的梯度提升树 (Gradient Boosting Decision Tree)。</p>
<h2 id="The-Additive-Model"><a href="#The-Additive-Model" class="headerlink" title="The Additive Model"></a>The Additive Model</h2><p>首先GBDT是一个加法模型，即最终模型由一系列树模型乘以对应权重相加得来：<br>$$<br>F_T(x;w)=\sum_{t=0}^T\alpha_t h_t(x;w_t)=\sum_{t=0}^T f_t(x;w_t)<br>$$<br>我们的目标是使得$F$的损失函数最小化：<br>$$<br>F_T^*=\mathop{\arg\min}\limits_{F}\sum_{i=1}^N L(y_i, F_T(x_i;w))<br>$$</p>
<p>直接优化这个损失函数复杂度是很高的，GBDT实际上运用了一种类似贪心的策略来优化这个函数，将优化过程分解成了迭代的步骤。</p>
<p>回想梯度下降算法进行优化的步骤，我们有参数$\theta$，损失函数$L(\theta)$是$\theta$的函数，我们希望找到最优的$\theta^*$使得$L(\theta^*)$最小，于是我们使用了迭代优化的步骤。假设迭代执行到第$t$步，也就是说我们现在的参数$\theta^{t-1}$为前面$t-1$步增量之和：$\theta^{t-1}=\sum_{j=1}^{t-1}\Delta \theta_j$，每一步的增量记为$\Delta \theta_t$。当前的增量$\Delta \theta_{t}$是怎么计算得到的呢？大家都知道是采用的损失函数在$\theta^{t-1}$的负梯度乘以一个步长，即$\Delta \theta_t=-\alpha_t \frac{\partial L(\theta)}{\partial \theta^{t-1}}$。</p>
<p>梯度下降相当于是在参数空间$\theta$找到最合适的参数$\theta^*$使得损失函数$L(\theta)$最小化，如果我们把模型$F_T$看作是函数空间，我们的目的是在函数空间中找到最优的$F_T^*$使得损失函数最小化，在这一个角度上GBDT和梯度下降就统一起来了。每一步的基模型$f_t$就相当于梯度下降中的增量$\Delta \theta$，所以我们就得到了GBDT每一的优化目标，即损失函数$L$对于$F_{t-1}$的负梯度。</p>
<table>
<thead>
<tr>
<th></th>
<th>梯度下降</th>
<th>GBDT</th>
</tr>
</thead>
<tbody><tr>
<td>损失函数</td>
<td>$L(\theta)$</td>
<td>$L(F_t)$</td>
</tr>
<tr>
<td>参数</td>
<td>$\theta^t$</td>
<td>$F_t$</td>
</tr>
<tr>
<td>增量</td>
<td>$\Delta \theta_t=-\alpha_t g_t$</td>
<td>$f_t=-\alpha_t g_t$</td>
</tr>
<tr>
<td>步长</td>
<td>$\alpha_t$</td>
<td>$\alpha_t$</td>
</tr>
<tr>
<td>初始值</td>
<td>$\theta_0$</td>
<td>$f_0$</td>
</tr>
</tbody></table>
<h2 id="Gradient-Boosting-Tree-for-Regression"><a href="#Gradient-Boosting-Tree-for-Regression" class="headerlink" title="Gradient Boosting Tree for Regression"></a>Gradient Boosting Tree for Regression</h2><p>我们先来讨论GBDT解决回归问题的算法。前面我们已经讨论过，在每一步GBDT的优化目标是损失函数的负梯度，那么现在的问题就是如何求得每一步最优的基模型（GBDT的基模型选用的是CART）。GBDT的算法步骤如下：</p>
<blockquote>
<p><strong>Gradient Boosting Tree Algorithm</strong></p>
<p>INPUT: 训练样本${(x_1,y_1),\cdots,(x_m,y_m)}$，迭代轮数$T$，损失函数$L$</p>
<p>OUTPUT: 强模型$F_T$</p>
<ol>
<li>初始化弱学习器$f_0$，直接使用一个基模型在训练集上进行训练</li>
<li>在步骤$t=1…T$，对于每个样本计算负梯度$r_{ti}=\left[\frac{\partial L(y_i,F_{t-1}(x_i))}{\partial F_{t-1}}\right]$</li>
<li>在$(x_i,r_{ti})$上训练得到一个CART回归树，确定树的结构</li>
<li>假设一共有$J$个叶子节点，那么对每个叶子节点计算最佳输出值$c_{tj}=\mathop{\arg\min}\limits_{c_{tj}}\sum_{x_i\in R_{tj}} L(y_i,F_{t-1}(x_i)+c_{tj})$（其中$c_{tj}$代表第$j$个叶子的输出，$R_{tj}$代表第$j$个叶子对应的样本集合），确定每个叶子节点的输出</li>
<li>更新强学习器$F_t=F_{t-1}+f_t$，回到步骤2直到达到迭代轮数</li>
<li>最终得到强学习器的表达式：$f(x)=f_0(x)+\sum\limits_{t=1}^T\sum\limits_{j=1}^J c_{tj}\mathrm I(x\in R_{tj})$</li>
</ol>
</blockquote>
<p>于是我们就得到了最终模型$F_T$。</p>
<h2 id="Gradient-Boosting-Tree-for-Classification"><a href="#Gradient-Boosting-Tree-for-Classification" class="headerlink" title="Gradient Boosting Tree for Classification"></a>Gradient Boosting Tree for Classification</h2><p>在处理分类任务时，由于输出是离散的值</p>
<p>一种方法是使用指数损失函数，此时GBDT退化为AdaBoost；另一种方法是借鉴逻辑回归的方法，去建模真实值的概率</p>
<h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><h2 id="GBDT-Sumarry"><a href="#GBDT-Sumarry" class="headerlink" title="GBDT Sumarry"></a>GBDT Sumarry</h2><p>优点：</p>
<ol>
<li>可以灵活处理</li>
<li>相对SVM，调参较少</li>
<li>使用某些损失函数对异常值的鲁棒性高</li>
</ol>
<p>缺点：</p>
<ol>
<li>难以并行训练</li>
</ol>
<h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p>前面我们讲了梯度下降和牛顿法，刚才又讨论了GBDT和梯度下降的关系，那么XGBoost是否和牛顿法有什么关系呢？答案是肯定的。GBDT利用了损失函数在$F_{t-1}$的一阶展开（即一阶导数信息），而XGBoost则利用了损失函数在$F_{t-1}$的二阶展开，这也是XGBoost和GBDT最根本的区别。下面我们将详细讲解XGBoost算法。</p>
<table>
<thead>
<tr>
<th></th>
<th>牛顿法</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody><tr>
<td>损失函数</td>
<td>$L(\theta)$</td>
<td>$L(F_t)$</td>
</tr>
<tr>
<td>参数</td>
<td>$\theta^t$</td>
<td>$F_t$</td>
</tr>
<tr>
<td>增量</td>
<td>$\Delta \theta_t=-\alpha_t H^{-1}_tg_t$</td>
<td>$f_t=-\alpha_t H^{-1}_tg_t$</td>
</tr>
<tr>
<td>步长</td>
<td>$\alpha_t$</td>
<td>$\alpha_t$</td>
</tr>
<tr>
<td>初始值</td>
<td>$\theta_0$</td>
<td>$f_0$</td>
</tr>
</tbody></table>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>XGBoost相比GBDT的另一大改进是加入了正则化项，即控制每个树的复杂度。衡量树的复杂度的度量有很多，XGBoost采用的是每棵树叶子节点的个数$T$和每个叶子节点输出$w$的平方和：<br>$$<br>\Omega(f)=\gamma T+\frac{1}{2}\lambda\parallel w\parallel^2<br>$$</p>
<p>这一步主要是为了进一步降低每个弱学习器的方差。</p>
<h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>加上正则项之后总的损失函数变为：<br>$$<br>L=\sum_{i=1}^N \ell(y_i, F_T(x_i))+\Omega(F_T)<br>$$<br>和GBDT类似，我们来推导第$t$步的优化公式，对于第$t$步，我们的损失函数为：<br>$$<br>\begin{align}<br>L_t&amp;=\sum_{i=1}^N \ell(y_i,F_t(x_i))+\Omega(F_t)\<br>&amp;=\sum_{i=1}^N \ell(y_i, F_{t-1}(x_i) + f_t(x_i))+\Omega(F_t)<br>\end{align}<br>$$<br>将损失函数在$F_{t-1}$处进行二阶泰勒展开，得到<br>$$<br>L_t \approx \left[\sum_{i=1}^N \ell(y_i, F_{t-1}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(F_t)<br>$$<br>其中$g_i=\frac{\partial \ell(y_i, F_{t-1})}{\partial F_{t-1}}$，$h_i=\frac{\partial \ell(y_i, F_{t-1}) ^2}{\partial^2 F_{t-1}}$，分别代表损失函数对$F_{t-1}$的一阶导和二阶导。</p>
<p>由于我们要优化的是本轮的基模型$f_t$，$\ell(y_i, F_{t-1})$已经是固定的了，相当于常数，把常数项去掉，得到：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(f_t)\<br>&amp;=\left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \gamma T + \frac{1}{2}\lambda \parallel w \parallel^2<br>\end{align}<br>$$<br>我们都知道样本$x_i$在树$f_t$上的输出取决于$x_i$在哪个叶子节点。假设树$f_t$一共有$J$个叶节点，记$q(x_i)=j$代表样本$x_i$经过决策树对应的叶节点是$j$，$I_j$代表叶子节点$j$的所有样本下标集合，$w_j$代表叶子节点$j$的输出，我们可以将损失函数改写为：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \sum_{j=1}^J\left[\sum_{i\in I_j}g_i w_j+\frac{1}{2}(\sum_{i\in I_j}h_i +\lambda)w_j^2\right]+\gamma T\<br>&amp;= \sum_{j=1}^J\left[G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2 \right] + \gamma T<br>\end{align}<br>$$<br>其中$G_j=\sum_{i\in I_j}g_i$和$H_j=\sum_{i\in I_j}h_i$为简记，分别代表损失函数在叶子节点$j$对应的所有样本上的一阶导之和与二阶导之和。</p>
<p>到现在，我们还剩两个问题需要解决，一个是确定树$f_t$的最优结构，也就是怎么去分裂节点，另一个是确定每个叶子节点的最优输出。我们可以先确定下一个问题，找到另一个问题的最优答案，再来确定剩下的问题。</p>
<p>这里先去寻找树$f_t$每一个叶子节点对应的最优输出。和牛顿法的推导类似，为了使损失函数下降的最快，我们令$G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2$的导数为$0$，得到：<br>$$<br>w_j^*=-\frac{G_j}{H_j + \lambda}<br>$$<br>加上正则项有：<br>$$<br>\tilde L_t^*=-\frac{1}{2}\sum_{j=1}^J\frac{G_j^2}{H_j+\lambda}+\gamma T<br>$$</p>
<h2 id="Splitting-Strategy"><a href="#Splitting-Strategy" class="headerlink" title="Splitting Strategy"></a>Splitting Strategy</h2><p>现在来确定树$f_t$的最优结构。最优结构的确定实际上使用了一种类似贪心的策略，和决策树类似，我们从一个只有根节点的树出发（所有样本都在根节点这一叶子节点上），不断分裂节点来降低$\tilde L_t^*$。在每一步的分裂中，我们会希望$\frac{G_j^2}{H_j+\lambda}$越大越好，于是：<br>$$<br>Gain = \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda} - \frac{(G_L+G_R)^2}{H_L+H_R+\lambda} - \gamma<br>$$</p>
<p>我们希望挑选能使得$Gain$最大的特征和特征分裂点，而选择的策略又有很多种，下面介绍三种。</p>
<h3 id="Exact-Greedy-Algorithm-for-Split-Finding"><a href="#Exact-Greedy-Algorithm-for-Split-Finding" class="headerlink" title="Exact Greedy Algorithm for Split Finding"></a>Exact Greedy Algorithm for Split Finding</h3><p>最简单的方法是枚举所有特征，然后对于这个特征下的所有可能取值进行排序，然后遍历分裂点，找到使得$gain$最高的那个。这样做的好处是找到的分裂点确定是最好的，不过坏处是时间复杂度过高。</p>
<h3 id="Approximate-Algorithm-for-Split-Finding"><a href="#Approximate-Algorithm-for-Split-Finding" class="headerlink" title="Approximate Algorithm for Split Finding"></a>Approximate Algorithm for Split Finding</h3><p>一个比较容易想到的优化方案是不去遍历所有可能的分裂点，而是只考察其中的分位数，如下图展示了三分位数方法：</p>
<p><img src="https://i.loli.net/2020/09/10/HoPR9XlpZSm1Gju.png"></p>
<p>这样需要考察的点就大大减少。</p>
<p>同时分位数的选择由有global和local之分，global是指在训练之前我们就可以提前对每个特征的分位数进行预处理，local是指每次分裂前计算分位数点。直观上来说global需要更多的分位点数，而local则需要更多的计算量。</p>
<p>实际上，XGBoost还会使用二阶导信息$h_i$对样本进行夹权，如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/15/nxloKNmTHwJRqI9.png"></p>
<h3 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h3><p>稀疏感知分裂算法 (Sparsity-aware Split Finding) </p>
<h2 id="Other-Features"><a href="#Other-Features" class="headerlink" title="Other Features"></a>Other Features</h2><p>除了上面提到的之外，XGBoost还有很多工程优化。</p>
<h3 id="Block-Structure-and-Parallelism"><a href="#Block-Structure-and-Parallelism" class="headerlink" title="Block Structure and Parallelism"></a>Block Structure and Parallelism</h3><p>XGBoost预先对特征进行了排序，</p>
<p>每个特征的增益的计算可以并行进行</p>
<h3 id="Column-Sample"><a href="#Column-Sample" class="headerlink" title="Column Sample"></a>Column Sample</h3><p>借鉴随机森林，即每次只用一部分特征进行特征选择，进一步降低过拟合</p>
<h3 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h3><p>在每次迭代会对叶子节点的权总乘以一个系数，让后面的树有更大的学习空间。</p>
<h3 id="Custom-Loss-Function"><a href="#Custom-Loss-Function" class="headerlink" title="Custom Loss Function"></a>Custom Loss Function</h3><h3 id="Missing-Values"><a href="#Missing-Values" class="headerlink" title="Missing Values"></a>Missing Values</h3><h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/227782064">parameter tuning</a></p>
</div></article></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>