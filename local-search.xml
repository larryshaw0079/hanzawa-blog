<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Graph Embedding and Graph Neural Networks</title>
    <link href="/2020/09/16/Graph-Embedding-and-Graph-Neural-Networks/"/>
    <url>/2020/09/16/Graph-Embedding-and-Graph-Neural-Networks/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="Graph-Embedding"><a href="#Graph-Embedding" class="headerlink" title="Graph Embedding"></a>Graph Embedding</h1><h1 id="Graph-Convolutional-Network"><a href="#Graph-Convolutional-Network" class="headerlink" title="Graph Convolutional Network"></a>Graph Convolutional Network</h1>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GCN</tag>
      
      <tag>GNN</tag>
      
      <tag>RandomWalk</tag>
      
      <tag>Node2Vec</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Factorization Machines: Machine Learning Algorithms Extra 1</title>
    <link href="/2020/09/15/Factorization-Machines-Machine-Learning-Algorithms-Extra-1/"/>
    <url>/2020/09/15/Factorization-Machines-Machine-Learning-Algorithms-Extra-1/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对于一般的线性模型或者广义线性模型，我们的模型是$\hat y = w_0 + \sum_{i=1}^n w_i x_i$或者$g^{-1}(\hat y)=w_0+\sum_{i=1}^n w_i x_i$的形式。在推荐的场景下，我们希望考虑特征之间的关系，比如特征“男性”往往和“运动”之类的特征有关系，实践中这种特征组合往往能带来很好的模型效果提升。由于推荐场景下特征往往是Categorical的，在One-hot编码之后有很高的稀疏性，这会为我们训练考虑特征组合的模型带来很大的问题（后面会说明）。</p><h1 id="Factorization-Machine"><a href="#Factorization-Machine" class="headerlink" title="Factorization Machine"></a>Factorization Machine</h1><p>Factorization Machine （简称FM），是一种</p><p><a href="https://zhuanlan.zhihu.com/p/89639306" target="_blank" rel="noopener">blog</a></p><img src="https://i.loli.net/2020/09/15/sADWeTi62dhqu5f.jpg" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Feature-Crossing"><a href="#Feature-Crossing" class="headerlink" title="Feature Crossing"></a>Feature Crossing</h2><p>考虑特征组合的初始模型<br>$$<br>\hat y(x) = w_0 + \color{blue}{\boxed{\sum_{i=1}^n w_i x_i}} + \sum_{i=1}^{n-1} \sum_{j=i+1}^n w_{ij} x_i x_j<br>$$<br>不过这会有一些问题，比如$x_i$是用户B，$x_j$是电影TI，而我们想知道用户B和电影TI之间的关系，而训练集中不存在$x_i=1$且$x_j=1$的样本让我们学习，这样会导致$w_{ij}$永远等于$0$，但实际上用户B和电影TI之间的关系可能是存在的，我们只是没有训练样本来推断它而已。</p><p>FM的做法是对于这种$w_{ij}$，我们想办法去估计它。首先对于每个特征$x_i$，FM假设其存在一个$k$维的隐向量$\mathbf v_i$与之对应（也可以理解为特征的一个embedding）。如下图展示了用户特征与电影特征之间的特征组合（$k=2$）：</p><img src="https://i.loli.net/2020/09/16/8Ihz6OBKkZDpVsw.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>任意两个特征之间的关系可以通过隐向量之间的内积来体现，如果两个特征之间相关度越高，那么他们之间的内积也会越大。不过FM是如何解决刚才所说的，用户B和电影TI之间的关系没有样本来体现，我们要如何学习用户B和电影TI这两个特征之间的关系的问题呢？大家可以想想，虽然没有用户B和电影TI都为$1$的样本，但这两个特征对应的隐向量是不为$0$的，我们依然可以通过两个向量的内积来反应用户B和电影TI的相关性（这里其实和自监督对比学习很相似😄）。</p><p>于是我们的模型变为：<br>$$<br>\hat y(x) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n-1} \sum_{j=i+1}^n \langle \mathbf v_i, \mathbf v_j\rangle x_i x_j<br>$$<br>其中$\langle\cdot,\cdot\rangle$代表两个向量的内积。每个参数$w_{ij}=\langle \mathbf v_i,\mathbf v_j\rangle$，$\mathbf v_i$代表第$i$特征的隐向量，隐向量长度$k\ll n$。</p><p>以前$w_{ij}$和$w_{ik}$之间无关，但现在$w_{ij}=\langle \mathbf v_i,\mathbf v_j\rangle$，$w_{ik}=\langle \mathbf v_i, \mathbf v_k\rangle$，两者之间有共同的$\mathbf v_i$，也就是说所有包含特征$x_i$和$x_j$的非零特征组合都可用来学习隐向量$\mathbf v_i$</p><h2 id="An-Efficient-Optimization-Criterion"><a href="#An-Efficient-Optimization-Criterion" class="headerlink" title="An Efficient Optimization Criterion"></a>An Efficient Optimization Criterion</h2><p>其实公式的第二项$\sum_{i=1}^n\sum_{i=1}^n \langle \mathbf v_i, \mathbf v_j\rangle x_i x_j$，我们可以进行一些等价变换使得其计算更加高效，毕竟上线的场景中模型推断的速度也是十分重要的。<br>$$<br>\begin{align}<br>\sum_{i=1}^{n-1} \sum_{j=i+1}^n \langle \mathbf v_i, \mathbf v_j\rangle x_i x_j<br>&amp;= \frac{1}{2}\cdot \left{\sum_{i=1}^n\sum_{j=1}^n\langle\mathbf v_i,\mathbf v_j\rangle x_i x_j-\sum_{i=1}^n\langle\mathbf v_i,\mathbf v_j\rangle x_i x_i\right} \<br>&amp;= \frac{1}{2}\cdot \left{\sum_{i=1}^n\sum_{j=1}^n\sum_{f=1}^k\mathbf v_{if}\mathbf v_{jf} x_i x_j-\sum_{i=1}^n\sum_{f=1}^k\mathbf v_{if}\mathbf v_{jf}x_i x_i\right}\<br>&amp;= \frac{1}{2}\cdot\sum_{f=1}^k\left{\sum_{i=1}^n\sum_{j=1}^n\mathbf v_{if}\mathbf v_{jf} x_i x_j-\sum_{i=1}^n\mathbf v_{if}\mathbf v_{jf}x_i x_i\right}\<br>&amp;= \frac{1}{2}\cdot\sum_{f=1}^k\left{\left(\sum_{i=1}^n \mathbf v_{if}x_i\right)\left(\sum_{j=1}^n\mathbf v_{jf}x_j\right)-\sum_{i=1}^n \mathbf v_{if}^2 x_i^2\right}\<br>&amp;= \frac{1}{2}\cdot \sum_{f=1}^k\left{\left(\sum_{i=1}^n v_{if} x_i\right)^2-\sum_{i=1}^n v_{if}^2 x_i^2\right}<br>\end{align}<br>$$<br>综合起来我们可以得到：<br>$$<br>\begin{align}<br>\hat y(x) &amp;= w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n-1} \sum_{j=i+1}^n \langle \mathbf v_i, \mathbf v_j\rangle x_i x_j\<br>&amp;= w_0 + \sum_{i=1}^n w_i x_i +\frac{1}{2}\cdot \sum_{f=1}^k\left{\left(\sum_{i=1}^n v_{if} x_i\right)^2-\sum_{i=1}^n v_{if}^2 x_i^2\right}<br>\end{align}<br>$$<br>之前，计算$\hat y$的复杂度是$O(kn^2)$，改写后复杂度降低为$O(kn)$。</p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><p>FM可以用梯度下降来解决</p><p>首先对$w_0$求导：<br>$$<br>\frac{\partial y}{\partial w_0} = 1<br>$$<br>对$w_i$求导也很简单：<br>$$<br>\frac{\partial y}{\partial w_i} = x_i<br>$$<br>接下来是对$\mathbf v_{if}$求导：<br>$$<br>\frac{\partial y}{\partial \mathbf v_{if}} = x_i \sum_{j=1}^n \mathbf v_{jf}x_j-x_i^2 \mathbf v_{if}<br>$$<br>训练复杂度，由于$\sum_{j=1}^n\mathbf v_{jf}x_j$与$i$无关，所以可以进行预处理算出来，复杂度为$O(kN)$。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>优点：</p><ul><li>考虑了二阶组合特征</li><li>效率高，推断时的时间复杂度为线性，$O(kN)$</li></ul><p>缺点：</p><ul><li>每个特征仅对应一个隐向量，不同类型的特征交叉没有区分性</li></ul><h1 id="Field-aware-Factorization-Machine"><a href="#Field-aware-Factorization-Machine" class="headerlink" title="Field-aware Factorization Machine"></a>Field-aware Factorization Machine</h1><p>Field-aware Factorization Machine（简称FFM）</p><h2 id="Field-aware-Feature-Crossing"><a href="#Field-aware-Feature-Crossing" class="headerlink" title="Field-aware Feature Crossing"></a>Field-aware Feature Crossing</h2><p>FFM<br>$$<br>\hat y(x) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n-1} \sum_{j=i+1}^n \langle \mathbf v_{i,f_j}, \mathbf v_{j, f_j}\rangle x_i x_j<br>$$<br>FFM模型公式和FM的不同之处仅在于二阶交叉时的隐向量。在FFM中，每个特征有$F$个隐向量，$F$为filed的数量，也可以理解为特征分组的数量。</p><h2 id="Optimization-1"><a href="#Optimization-1" class="headerlink" title="Optimization"></a>Optimization</h2><p>模型的表达式为：<br>$$<br>\hat y(x) = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n-1} \sum_{j=i+1}^n \sum_{q=1}^k \mathbf v_{i,f_j}^q \mathbf v_{j, f_j}^q x_i x_j<br>$$<br>首先对$w_0$求导：<br>$$<br>\frac{\partial y}{\partial w_0} = 1<br>$$<br>对$w_i$求导也很简单：<br>$$<br>\frac{\partial y}{\partial w_i} = x_i<br>$$<br>对$\mathbf v_{i,f_j}^q$求导<br>$$<br>\frac{\partial y}{\partial \mathbf v_{i,f_j}^q}=\mathbf v_{i,f_j}^q x_i x_j<br>$$<br>由于</p><h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><p>优点：</p><ul><li>相对于FM</li></ul><p>缺点：</p><ul><li>时间开销大</li></ul><h1 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h1><h2 id="FM-Component"><a href="#FM-Component" class="headerlink" title="FM Component"></a>FM Component</h2><p>FM部分主要是包含一阶组合特征和二阶组合特征</p><p><img src="https://i.loli.net/2020/09/16/TLC56XFD9hIgPGc.png" srcset="/img/loading.gif" alt=""></p><p>去掉了偏置项<br>$$<br>y_{FM}(x) = \sum_{i=1}^n w_i x_i + \sum_{i=1}^{n-1} \sum_{j=i+1}^n \langle \mathbf v_i, \mathbf v_j\rangle x_i x_j<br>$$<br>第一项代表了一阶组合特征（就是特征本身），第二项代表了二阶组合特征</p><h2 id="Deep-Component"><a href="#Deep-Component" class="headerlink" title="Deep Component"></a>Deep Component</h2><p>Deep部分主要是为了学习更高阶的组合特征。</p><p><img src="https://i.loli.net/2020/09/16/3JGQI5gYBadKktL.png" srcset="/img/loading.gif" alt=""></p><p>其中Dense Embeddings是FM部分和Deep部分所共享的。</p><p><img src="https://i.loli.net/2020/09/16/OrUJPWsiSyoYdlk.png" srcset="/img/loading.gif" alt=""></p><p>假设Dense Embeddings的输出为：<br>$$<br>a^{(0)} = [e_1,e_2,\cdots,e_m]<br>$$<br>其中$e_i$代表第$i$个field的嵌入，$m$为filed的数量。<br>$$<br>a^{(l+1)}=\sigma(W^{(l)}a^{(l)}+b^{(l)})<br>$$<br>Deep部分的输出为：<br>$$<br>y_{DNN}=\sigma(W^{(H+1)}a^{(H)}+b^{(H+1)})<br>$$<br>$H$为隐藏层数。</p><h2 id="Concatenation"><a href="#Concatenation" class="headerlink" title="Concatenation"></a>Concatenation</h2><p>最终的结果为<br>$$<br>\hat y=\text{Sigmoid}(y_{FM} + y_{DNN})<br>$$</p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>FM</tag>
      
      <tag>FFM</tag>
      
      <tag>DeepFM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Bagging and Random Forest: Machine Learning Ensemble Algorithms 3</title>
    <link href="/2020/09/15/Bagging-and-Random-Forest-Machine-Learning-Ensemble-Algorithms-3/"/>
    <url>/2020/09/15/Bagging-and-Random-Forest-Machine-Learning-Ensemble-Algorithms-3/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h1><p>Bagging的步骤如下图所示：</p><img src="https://i.loli.net/2020/09/15/x85li9MqPaeLShZ.jpg" srcset="/img/loading.gif" style="zoom:67%;" /><p>分为几个步骤</p><ol><li><strong>随机采样 (Bootstrap)</strong>，按照固定的数目对数据集做<strong>有放回</strong>采样，一般情况下采样集的数目和训练集一样，设为$N$，那么每个样本被采到的机率就是$\frac{1}{N}$，采样$N$次都没采到的机率是$(1-\frac{1}{N})^N$，当采样数目$N$比较大的时候，即$N\rightarrow \infty$有$(1-\frac{1}{N})^N\rightarrow \frac{1}{e}\approx 0.3679$。也就是说在每轮采样中，采样数目足够大的情况下，大概有$36.79%$的样本没有被采样中；</li><li>使用基模型在采样集上进行训练</li><li>进行模型组合的时候，对于分类问题，可以使用简单的投票法，对于回归问题，可以使用简单的平均法</li></ol><h1 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h1><p>随机森林 (Random Forest) 是Bagging模型的一种，</p><img src="https://i.loli.net/2020/09/15/jnJ8IKc52e1rtax.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>进行了诸多改进：</p><ol><li>使用CART决策树作为弱学习器，</li><li>使用列采样策略，对于划分特征的选择进行下采样，即有$M$个特征，只会随机选取这$M$个特征的一个子集进行特征选取，进一步减小方差</li></ol>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Random Forest</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unsupervised Anomaly Detection Algorithms Overview</title>
    <link href="/2020/09/10/Unsupervised-Anomaly-Detection-Algorithms-Overview/"/>
    <url>/2020/09/10/Unsupervised-Anomaly-Detection-Algorithms-Overview/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="LOF"><a href="#LOF" class="headerlink" title="LOF"></a>LOF</h1><h1 id="One-Class-SVM"><a href="#One-Class-SVM" class="headerlink" title="One-Class SVM"></a>One-Class SVM</h1><h1 id="Isolation-Forest"><a href="#Isolation-Forest" class="headerlink" title="Isolation Forest"></a>Isolation Forest</h1><p><img src="https://i.loli.net/2020/09/15/hSrG3W1JzbByEkH.png" srcset="/img/loading.gif" alt=""></p><p>孤立森林 (Isolation Forest) 的思路和随机森林有异曲同工之妙（随机森林可以参考我的<a href="http://qfxiao.me/2020/09/15/Bagging-and-Random-Forest-Machine-Learning-Ensemble-Algorithms-3/">另一篇博文</a>），孤立森林本身也是一种树模型。孤立森林要解决的是无监督异常检测问题，即给定无标签的训练集，把其中的异常值挑选出来。孤立森林的基本假设是我不断选择特征进行分裂，达到停止条件后，每个叶子节点就对应一个/多个样本，正常样本由于比较集中，往往处于比较深的叶子节点，而异常样本由于偏离正常范围，所以往往处于比较浅的叶子节点。在此基础之上，孤立森林和随机森林类似，采用了集成的方法，即采样多个采样集，分别在采样集上训练，最后集成结果。孤立森林的主要特征如下：</p><ol><li>首先，和随机森林一样，孤立森林也需要对数据集进行采样，不过采样集的数量往往比较小；</li><li>对于每一棵树的建立，孤立森林采用的是随机选择特征进行划分，划分点也是随机选取（所以孤立森林的每棵树都是二叉树），这样做的原因可能是我们的数据没有标签，孤立森林对数据分布没有做特定假设，所以采用随机的方式</li></ol><p>对于异常点的判断，孤立森林根据的是该样本在树上的深度。对于样本$x$在树$T$上的异常分数，使用下面的公式进行计算：<br>$$<br>h(x) = e + C(N_T)<br>$$<br>其中$e$为该样本在树上的深度，$C(N_T)$为用$N_T$个样本构建二叉树的一个平均深度的估计值，可以由下式计算：<br>$$<br>C(n)=2H(n-1)-\frac{2(n-1)}{n}<br>$$<br>其中$H(n-1)$可以由$\ln (n-1)+\gamma$估算，$\gamma$为欧拉常数。</p><p>最后的异常分数采用集成的方式：<br>$$<br>\mathcal S(x) = 2^{-\frac{E(h(x))}{C(\psi)}}<br>$$<br>$E(h(x))$代表样本$x$在不同树上分数的均值，$C(\psi)$代表主要用来做归一化，$\psi$代表用来建树的采样集的样本数。</p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LOF</tag>
      
      <tag>OCSVM</tag>
      
      <tag>iForest</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Model Selection and Evaluation: Machine Learning Basics</title>
    <link href="/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/"/>
    <url>/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h1><p>我们将模型输出与真实值之间的差异称为误差，如对于分类问题，我们可以使用模型分类错误的样本数量占总样本数的比例。模型在训练集（我们收集到的数据）上的误差称作是<strong>训练误差 (training error)</strong>，而在新样本（这里指的是新的样本而不是测试集，训练集测试集是从我们收集到的数据上人为划分出来的）上的误差称作是<strong>泛化误差 (generalization error)</strong>。对于机器学习算法，我们希望算法能学到数据背后的普遍规律，所以我们总是希望模型的泛化误差越小越好。</p><p>不过测试集对训练过程来说是未知的，所以模型只能尽量从训练集中发掘数据的普遍规律，要是模型把训练集学得”太好“了，很可能把训练集中不属于普遍规律的部分特点作为了一般性质，这就会导致泛化性能下降，我们称这种情况为<strong>过拟合 (overfitting)</strong>。反之，模型对训练集的特性学得不够，就会出现<strong>欠拟合 (underfitting)</strong>。关于过拟合和欠拟合，周志华老师的《机器学习》中有一张很好的图：</p><img src="https://i.loli.net/2020/09/09/tVPeQfu9CWLaSi6.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>一般来说，欠拟合比较容易克服，可以通过增加模型的复杂度来实现。而过拟合则比较难解决，一般而言可以通过增加数据量、加正则化约束来改善。</p><h1 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h1><p>对于一个机器学习任务，一般我们有多种模型供我们选择，并且模型也有不同的超参数，我们希望得到泛化性能尽可能高的模型。不过根据前面的讨论，新样本是未知的，所以没法直接得到泛化误差，而过拟合的存在使得我们不能贸然的根据模型在我们收集到的数据上的表现来选择模型（训练误差低不代表泛化误差低）。</p><p>我们假设无论是我们收集到的数据还是新样本都是从数据的真实分布中独立同分布采样得来，为此我们可以从数据中划分出一部分”测试集“，然后将模型在测试集上的表现作为泛化误差的近似，而剩下的部分用来模型训练。</p><p>那么如何划分训练集和测试集呢？比较常见的方法是”$k$折交叉验证法“ ($k$-fold cross validation)，一般$k$常取$10$，其基本思想如下图所示：</p><img src="https://i.loli.net/2020/09/09/8KEWDe3qMTsQoUx.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>$k$折交叉验证法首先将数据集均匀地划分为$k$个部分，然后进行$k$个循环，在每个循环中将第$k$份作为测试集，其余的作为训练集，最后得到的结果进行平均。</p><h1 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h1><p>前面我们讨论了评测的框架，但是没有说具体的评测指标。实际上评测指标要根据任务来确定，并且不同的评测指标也有自己的特点。</p><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>回归任务比较常用的评测标准是<strong>均方误差 (Mean Squared Error)</strong>：<br>$$<br>\text{MSE}(f;D)=\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2<br>$$<br>和<strong>平均绝对误差 (Mean Absolute Error)</strong>：<br>$$<br>\text{MAE}(f;D)=\frac{1}{m}\sum_{i=1}^m |f(x_i)-y_i|<br>$$</p><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><p>对于分类任务，最简单的想法是使用模型分类正确的比例来作为评测标准，我们称之为<strong>准确率 (Accuracy)</strong>：<br>$$<br>\text{ACC}(f;D)=\frac{1}{m}\sum_{i=1}^m \mathbb{I}(f(x_i)=y_i)<br>$$<br>但准确率并不能满足我们的所有要求，比如说对于新冠病毒的分类任务，我们可能会更关注于对于所有患有新冠的病人，模型到底查出来了多少，而对于模型误把正常病人当作是患病的情况没有那么关注。对于二分类问题，我们可以将样例根据其真实类别与模型预测的类别划分为真正例 (true positive, TP)、假正例 (false positive, FP)、真反例 (true negative, TN) 和假反例 (false negative, FN) 四种，形成<strong>混淆矩阵 (Confusion Matrix)</strong>：</p><p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg" srcset="/img/loading.gif" alt=""></p><p>下面给一个具体的例子：</p><p><img src="https://i.loli.net/2020/09/09/tCLxvZfNoEgqWID.png" srcset="/img/loading.gif" alt=""></p><p>比如我们的任务是预测一张手写数字图片是不是$5$，根据上图，右下角就是我们正确预测的是$5$的图片，左下角就是本来是$5$，但被预测成不是$5$的图片；左上角是本来不是$5$，我们也正确地预测出其不是$5$的，右上角是本来不是$5$却被预测成是$5$的。是不是有点被绕晕了😀，只要记住T和F代表的是预测结果对还是不对，P和N代表的是模型预测当前样本是正例还是负例。</p><p>基于混淆矩阵，我们可以定义<strong>查准率 (Precision)</strong> 和<strong>查全率 (Recall)</strong> 这两个评测标准。</p><p>查准率，顾名思义，对于检测出来的正例，有多少是真正的正例，即查的准不准，公式为：<br>$$<br>\text{Precision}=\frac{TP}{TP+FP}<br>$$<br>分母就是模型预测为正例的样本总数。</p><p>查全率，就对应刚才举的新冠的例子，我们比较在乎对于数据集中的正例，有多少被查出来了，公式为：<br>$$<br>\text{Recall} = \frac{TP}{TP+FN}<br>$$<br>分母就是真实类别为正例的样本总数。一般来说，查准率和查全率是相互矛盾的，除非是特别简单的任务，很难兼顾查准率和查全率。</p><p><strong>F1分数 (F1 Score)</strong> 综合了查准率和查全率：<br>$$<br>\text{F}1=\frac{2\cdot\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}<br>$$<br>查准率和查全率中任意一项较低都会导致F1分数较低。有时候我们对待查准率和查全率的权重不同，这时候可以使用F$_\beta$分数：<br>$$<br>\text{F}_\beta=\frac{(1+\beta^2)\cdot \text{Precision}\cdot\text{Recall}}{(\beta^2\cdot\text{Precision})+\text{Recall}}<br>$$<br>$\beta=1$时等价于F1分数，$\beta&gt;1$代表偏重查全率，$\beta&lt;1$代表偏重查准率。</p><h3 id="Multi-classification"><a href="#Multi-classification" class="headerlink" title="Multi-classification"></a>Multi-classification</h3><p>前面的讨论都是基于二分类任务，如果是多分类任务的话， 对于每一类，我们将该类作为正例，其他类别作为负例，都能得到一个混淆矩阵。如果我们在每个混淆矩阵上计算评测指标，然后进行平均，这样就得到宏查准率 (macro-Precision)、宏查全率 (macro-Recall) 和宏F1分数 (macro-F1)。如果我们事先将混淆矩阵的TP、FP、TN、FN先进行平均，再计算评测指标，就得到了微查准率 (micro-Precision)、微查全率 (micro-Recall) 和微F1分数 (micro-F1)。</p><h3 id="PR-Curve"><a href="#PR-Curve" class="headerlink" title="PR-Curve"></a>PR-Curve</h3><p>很多情况下模型的输出是样本为正例的“概率值”或者是分数，分数越高的样本代表越可能是正例。这种时候需要人为划定阈值，规定高于阈值的样本是正例。不过阈值的划分相当于超参数的选取，同时我们会认为一个鲁棒的模型的性能应该不受阈值选取的左右。这个时候我们可以使用<strong>PR曲线 (Precision-Recall Curve)</strong>，即遍历所有可能的阈值，对于每个阈值，计算其对应的Precision和Recall，然后画在图上，最后会得到一系列离散的点（理论上应该是连续曲线，不过阈值是连续值，我们只能取离散值），形成PR-曲线。</p><img src="https://i.loli.net/2020/09/09/ecP8flTYZIDUBrV.png" srcset="/img/loading.gif" alt="2-class Precision-Recall curve: AP=0.88" style="zoom:67%;" /><p>模型性能越好，曲线就会越接近右上角的点，我们可以把PR曲线的曲线下面积 (PR-AUC) 作为评测标准。</p><h3 id="ROC-Curve"><a href="#ROC-Curve" class="headerlink" title="ROC-Curve"></a>ROC-Curve</h3><p>ROC全称是<strong>受试者工作特征 (Receiver Operating Characteristic) 曲线</strong>, 和PR曲线类似，ROC曲线也是遍历不同的阈值计算点，不过ROC曲线计算的是真正例率 (True Positive Rate, TPR) 和假正例率 (False Positive Rate, FPR)，两者定义分别是：<br>$$<br>\begin{align}<br>\text{TPR}=\frac{TP}{TP+FN}\<br>\text{FPR}=\frac{FP}{TN+FP}<br>\end{align}<br>$$<br>其中TPR就是查全率，而FPR是所有负例中没有检测出来的比例，这一项是越低越好。</p><img src="https://i.loli.net/2020/09/09/CdHrDaKAns4EN93.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>模型性能越好，曲线就会越接近左上角的点，我们可以把ROC曲线的曲线下面积 (ROC-AUC) 作为评测标准。</p><p>下面来总结一下PR曲线和ROC曲线之间的优缺点。</p><table><thead><tr><th></th><th>纵轴</th><th>横轴</th></tr></thead><tbody><tr><td><strong>PR</strong></td><td>$\text{Precision}=\frac{TP}{TP+FP}$</td><td>$\text{Recall} = \frac{TP}{TP+FN}$</td></tr><tr><td><strong>ROC</strong></td><td>$\text{TPR}=\frac{TP}{TP+FN}$</td><td>$\text{FPR}=\frac{FP}{TN+FP}$</td></tr></tbody></table><p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg" srcset="/img/loading.gif" alt=""></p><p>ROC的优点：</p><ul><li>相比PR仅关注正例，ROC同时关注正例和负例</li><li>相比PR不易受到正负例相对数量的影响，ROC的两个指标的计算都只涉及到P、N中的一列，正例或负例增加对总体影响不大。而PR曲线就不一样，两个指标的计算都涉及到了P、N两列，那么正例或负例样本数量的变化会造成较大影响。如负例突然增大，那么FP也会增大，这样Precision会降低，而Recall却不变。</li></ul><p>ROC的缺点：</p><ul><li>对于类别不平衡问题，存在大量负例，这样会带来大量的FP，而ROC的FPR却不会因为FP的大幅增长而剧烈改变，结果是这一类错误很难在ROC曲线中体现出来。所以ROC会呈现出一个过于乐观的评价。</li></ul><p>我们来尝试下是否如此，下面是用随机森林分类器，测试样本正负例数量比为1:1的情况下的ROC曲线和PR曲线：</p><img src="https://i.loli.net/2020/09/10/yqMDQh5oTs96SJm.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/09/10/zFW941YTMl8yxiP.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>在我们将正负例数量比调整为1:9之后（总数量相同），可以看到ROC曲线比较稳定，没出现较大变化，而PR曲线则出现了剧烈变化：</p><img src="https://i.loli.net/2020/09/10/HbnLtfGsiVc17q5.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/09/10/FfYrb3SnkeZ9JTv.png" srcset="/img/loading.gif" alt="4" style="zoom:50%;" /><h1 id="Bias-and-Variance"><a href="#Bias-and-Variance" class="headerlink" title="Bias and Variance"></a>Bias and Variance</h1><p>在机器学习中，偏差-方差分解是解释学习算法泛化性能的重要工具。假设我们要预测某一个地区的房子的房价，每一套房子都是一个样本，我们认为每个样本都是从总体分布$P(X)$独立同分布采样得来的。不过我们不可能得到所有的样本，我们采样得到的训练集只是其中一个子集。那么，即使对于同样的测试样本，使用不同的训练集（训练集大小相同）训练出来的模型对测试样本的预测也是不一样的，我们将这一部分模型自身的不稳定性用<strong>方差 (Variance) **来描述：$\text{Var}(X)=E_D\left[(\hat f(X)-E[\hat f(X)])^2\right]$，方差越小代表模型稳定性越强。模型输出的期望与真实值之间的差距我们用</strong>偏差 (Bias) **来描述：$\text{Bias}(X)=E[\hat f(X)]-f(X)$。</p><p>泛化误差与方差、偏差有下列关系：<br>$$<br>\begin{align}<br>\text{Err}(X)&amp;=E\left[(y-\hat f(X))^2\right]\<br>&amp;=E\left[(f(X)+\varepsilon-\hat f(X))^2\right]\<br>&amp;= (E[\hat f(X)]-f(X))^2 + E\left[(\hat f(X)-E[\hat f(X)])^2\right]+\sigma_{\varepsilon}^2\<br>&amp;=\text{Bias}^2 + \text{Variance} + \text{Random Error}<br>\end{align}<br>$$<br>也就是说泛化误差可以分解为方差、偏差和随机噪声之和。偏差刻画了模型的期望预测与真实值之间的偏离程度，方差刻画了不同训练集对模型性能的影响，他们之间的关系如下图所示：</p><img src="https://i.loli.net/2020/09/09/2IpmrwJGfqORU3z.png" srcset="/img/loading.gif" style="zoom: 33%;" /><p>图中左上角的部分是比较理想的情况，即方差和偏差都较小。但实际上方差和偏差往往是相互冲突的，如下图所示：</p><img src="https://i.loli.net/2020/09/09/GsREiklKYfuX3Ub.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>模型复杂度不足的时候，模型的拟合能力不够强，偏差主导了泛化误差，而随着模型复杂度的提高，模型的拟合能力逐渐提高，训练数据的扰动会造成模型发生显著变化，这时方差逐渐主导了泛化误差。</p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Overfitting</tag>
      
      <tag>Bias</tag>
      
      <tag>Variance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Decision Tree: Machine Learning Classification Algorithms 3</title>
    <link href="/2020/09/02/Decision-Tree-Machine-Learning-Classification-Algorithms-3/"/>
    <url>/2020/09/02/Decision-Tree-Machine-Learning-Classification-Algorithms-3/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>（PS：本文内容是学习高级树模型（GBDT，XGBoost）的基础，强烈建议在看那些内容之前先了解本文的内容！）</p><p>本文主要是介绍常用的三种决策树模型：ID3、C4.5和CART。决策树（Decision Tree）是一种<strong>有监督分类模型</strong>（稍加改造可进行回归任务）。</p><p>比如我们要判断一个瓜是不是好瓜，对于人来说，要判断一个瓜是不是好瓜，可能会先去看看色泽，然后看看根蒂，然后再敲一敲听听声音，这样经过一系列的决策过程。</p><img src="https://i.loli.net/2020/09/02/WuGQ79g4NcHqJDh.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>决策树正是模拟了这样的过程。给定数据集，决策树会不断地选择最佳的特征将数据集进行切分（如选择色泽，然后将数据分为青绿、乌黑、浅白这几个子集），然后递归地进行下去，直到达到停止条件：</p><ol><li>每个叶子节点的样本都属于同一个类别</li><li>没有可供划分的特征，或者集合中每个样本所有特征取值都相同</li><li>决策树达到预先指定的最大深度</li></ol><p>所以决策树算法要解决的关键问题就是如何去选择当前最好的划分特征。</p><h1 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h1><p>ID3算法根据信息熵来进行特征的划分。信息熵是衡量一个随机变量信息量的度量，如果把数据集的标签$y$看作是随机变量，那么$y$的熵越小代表不确定性越小（集合里几乎都是一种类别的样本），熵越大代表不确定性越大（集合包含不同类别的样本），其公式为：<br>$$<br>Ent(D)=-\sum_{k=1}^{|\mathcal Y|}p_k\log p_k<br>$$<br>$Ent(D)$代表集合$D$对应的熵，$|\mathcal Y|$是类别数量，二分类就是$|\mathcal Y|=2$，$p_k$为第$k$个类别对应的概率（频率）。很自然的，我们可以根据划分前后熵的变化来确定划分特征的选择，如果划分之后熵减小的最多，那么这个特征也是最好的。假设我们选定特征$a$来对集合进行划分，特征$a$共有$V$个离散取值，那么划分之后将会产生$V$个子集，我们记每个子集为$D^v, v=1,\cdots, V$。那么，信息增益可以写为：<br>$$<br>Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)<br>$$<br>不过，ID3存在两个致命的缺点：</p><ol><li>无法对连续取值的特征进行计算</li><li>对取值较多的特征具有很大的偏向性（极端的情况，把样本编号作为特征，由于每个样本的编号都不同，分裂之后每个自己只有一个样本/类别，熵是最小的）</li></ol><h1 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h1><p>C4.5算法在ID3的基础上做了诸多改进。C4.5解决了ID3对于取值数目较多的特征的偏向性问题，其采用的方案很直观，即对信息增益除以一个系数，特征取值数目越多的特征系数越大，该划分标准被称作是信息增益率：<br>$$<br>Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}<br>$$<br>其中$IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}\log \frac{|D^v|}{|D|}$。其实$IV(a)$可以看作是“划分之后每个样本属于集合$v$的概率”这个随机变量的熵，划分的子集越多，划分之后属于哪个集合就越不确定，所以熵就越大。</p><p>不过信息增益率反而会对特征取值数目少的特征有所偏好，所以C4.5算法是先计算信息增益，确定信息增益高于平均值的候选集，再从中选择信息增益率最高的特征。</p><p>除此之外，C4.5还能处理连续取值的特征，其做法是“离散化”，即将连续取值划分为若干个离散的区间，一般二分比较常用。设连续特征$a$，假设其出现了$n$个取值，将其排序得到${a^1,a^2,\cdots,a^n}$，我们考虑每两个相邻节点的中点集合$T_a={\frac{a^i+a^{i+1}}{2}|1\leq i \leq n-1}$，之后我们就可以像考察离散属性值一样选择最优划分。</p><p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/10/RNyxp8EM6BCsOHK.png" srcset="/img/loading.gif" alt=""></p><h1 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h1><p>CART (Classification and Regression Trees) 是一种应用广泛的决策树模型，既可应用于分类任务也可应用于回归任务。</p><h2 id="CART-Regression"><a href="#CART-Regression" class="headerlink" title="CART Regression"></a>CART Regression</h2><p>我们先来说说CART怎么进行回归。在回归问题中，CART使用了MSE作为划分准则：<br>$$<br>\frac{1}{N}\sum_{i=1}^N (f(x_i)-y_i)^2<br>$$<br>如果CART有$M$片叶子，那么相当于CART将输入划分成了$M$个单元$R_m, m=1,\cdots,M$，也即有$M$个输出，那么该CART在数据集上的MSE为：<br>$$<br>\frac{1}{N}\sum_{m=1}^M\sum_{x_i\in R_m} (c_m-y_i)^2<br>$$<br>这里$c_j$为叶子节点$j$的输出，一般选为对应样本的均值$c_m=\text{avg}(y_i|x_i\in R_m)$。这样，剩下的问题就是如何确定每次的切分特征和切分点了。假设选择的特征是$j$，切分点$s$，那么该划分方案对应的损失为：<br>$$<br>\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2<br>$$<br>遍历所有的$j$和$s$，我们就能找到最佳的特征和切分点：<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum_{x_i\in R_1{j,s}}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_2{j,s}}(y_i-c_2)^2\right]<br>$$</p><p>算法流程大致如下：</p><blockquote><p><strong>CART Decision Tree Algorithm</strong></p><p>INPUT: 数据集 $D={(x_1,y_1),\cdots,(x_N,y_N)}$</p><p>OUTPUT: 预测值${\hat y_1,\cdots,\hat y_N}$</p><p>PROCEDURE:</p><p><strong>1. 选取当前最优切分特征变量$j^<em>$与最优切分点$s^</em>$</strong></p><p>设当前选择的切分变量为$j$，切分点为$s$那么可以根据切分点将数据集分为两个子集，一个是$R_1(j,s)=\left{x|x^{(j)}\leq s\right}$，另一个是$R_2(j,s)=\left{x|x^{(j)}&gt; s\right}$。<br>遍历所有的$j$，求解<br>$$<br>\min_{j,s}\left[\min_{c_1}\sum\limits_{x_i\in R_1(j,s)}(y_i-c_1)^2+\min\limits_{c_2}\sum\limits_{x_i\in R_2(j,s)}(y_i-c_2)^2\right]<br>$$<br>注意$\hat c_1=\frac{1}{N_1}\sum\limits_{x_i\in R_1(j,s)}y_i$<br><strong>2. 用选定的$(j^<em>,s^</em>)$来划分区域并计算输出值</strong></p><p>此时，我们还需要确定这两个区域（划分到同一个区域的样本对应的输出是相同的）的输出值$c_1$和$c_2$，其确定方式是使得对应区域上的均方误差最小。这样我们相当于得到了给定$j,s$下的损失，所以只要找出使得损失最小的$j^<em>,s^</em>$即可：</p><p><strong>3. 递归地对划分出来的两个区域重复步骤1和步骤2，直到满足停止条件</strong></p><p><strong>4. 最后将输入空间划分为$M$，输出$f(x)=\sum_{m=1}^M \hat c_m I(x\in R_m)$</strong></p></blockquote><p>下图是在波士顿房价数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/09/knOHuvsfyorTpxt.png" srcset="/img/loading.gif" alt=""></p><h2 id="CART-Classification"><a href="#CART-Classification" class="headerlink" title="CART Classification"></a>CART Classification</h2><p>从前面的讨论可以看到，CART回归树是一棵二叉树，对于分类任务，CART也是一棵二叉树。我们先来介绍CART的划分准则，再来介绍它是怎么进行划分的。</p><p>采用基尼系数作为准则，基尼系数的计算依赖于基尼值：<br>$$<br>\begin{align}<br>Gini(D)&amp;=1-\sum_{k=1}^{|\mathcal Y|}p_k^2<br>\end{align}<br>$$<br>直观上来说，基尼值表示随机抽取两个样本，其类别不一致的概率</p><p>如果说一个特征越好，那么划分之后其每个子集对应的基尼值应该越小越好。基尼系数的定义为：<br>$$<br>Gini_index(D,a)=\sum_{v=1}^V \frac{|D^v|}{|D|}Gini(D^v)<br>$$</p><p>对于离散取值特征，CART不会根据不同取值个数进行划分，而是和连续值类似，会确定一个“划分点”，将样本进行二分。比如对于特征$a$，其对应取值为${a^1,a^2,\cdots,a^n}$，CART会考察每个取值，将样本集划分为特征$a$是不是等于$a^i$两部分，然后计算基尼系数，最终会采用基尼系数最小的取值作为划分点。</p><p>下图是在breast cancer数据上决策树的可视化（图片太大了，可以点开放大🔍看）：</p><p><img src="https://i.loli.net/2020/09/10/mMf2EVkI1NaQLdS.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ID3</tag>
      
      <tag>C4.5</tag>
      
      <tag>CART</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch Practice Guide: Distributed Training, Automatic Mixed Precision and etc.</title>
    <link href="/2020/09/01/PyTorch-Practice-Guide-Distributed-Training-Automatic-Mixed-Precision-and-etc/"/>
    <url>/2020/09/01/PyTorch-Practice-Guide-Distributed-Training-Automatic-Mixed-Precision-and-etc/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>still working on it…</p><p>本文主要是对<code>PyTorch</code>实际应用中会用到的经验、技巧的总结。</p><h1 id="Adjust-Learning-Rate"><a href="#Adjust-Learning-Rate" class="headerlink" title="Adjust Learning Rate"></a>Adjust Learning Rate</h1><p>学习率调节是模型训练中的常用技巧，其主要思想是随着训练的进行，通过调节学习率来促使模型进行进一步的学习。<code>PyTorch</code>内置了很多调节学习率的方案，可以参考<a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" target="_blank" rel="noopener">官方教程</a>。学习率调节的伪代码大概如下：</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = ...<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):<span class="hljs-meta">&gt;&gt;&gt; </span>    train(...)<span class="hljs-meta">&gt;&gt;&gt; </span>    validate(...)<span class="hljs-meta">&gt;&gt;&gt; </span>    scheduler.step()</code></pre><p>下面介绍几种常见的学习率调节方案。</p><h2 id="StepLR"><a href="#StepLR" class="headerlink" title="StepLR"></a>StepLR</h2><p><code>StepLR</code>就是每经过一定的epoch（参数<code>step_size</code>），就将学习率乘以一个衰减系数（参数<code>gamma</code>），注意每一个epoch的结束都要调用<code>scheduler.step()</code>。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Assuming optimizer uses lr = 0.05 for all groups</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># lr = 0.05     if epoch &lt; 30</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># lr = 0.005    if 30 &lt;= epoch &lt; 60</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># lr = 0.0005   if 60 &lt;= epoch &lt; 90</span><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ...</span><span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = StepLR(optimizer, step_size=<span class="hljs-number">30</span>, gamma=<span class="hljs-number">0.1</span>)<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):<span class="hljs-meta">&gt;&gt;&gt; </span>    train(...)<span class="hljs-meta">&gt;&gt;&gt; </span>    validate(...)<span class="hljs-meta">&gt;&gt;&gt; </span>    scheduler.step()</code></pre><h2 id="CosineAnnealingLR"><a href="#CosineAnnealingLR" class="headerlink" title="CosineAnnealingLR"></a>CosineAnnealingLR</h2><p>大名鼎鼎的余弦退火。</p><img src="https://i.loli.net/2020/09/04/IjRElrHS1xLFcDM.png" srcset="/img/loading.gif" style="zoom: 33%;" /><h2 id="ReduceLROnPlateau"><a href="#ReduceLROnPlateau" class="headerlink" title="ReduceLROnPlateau"></a>ReduceLROnPlateau</h2><p><code>ReduceLROnPlateau</code>，顾名思义，就是在某一指标处于基本不变的时候调整学习率，这样做也很符合直觉。</p><h1 id="Distributed-Training"><a href="#Distributed-Training" class="headerlink" title="Distributed Training"></a>Distributed Training</h1><p><a href="https://zhuanlan.zhihu.com/p/86441879" target="_blank" rel="noopener">blog</a></p><p><a href="https://zhuanlan.zhihu.com/p/98535650" target="_blank" rel="noopener">blog</a></p><p><a href="https://zhuanlan.zhihu.com/p/145427849" target="_blank" rel="noopener">blog</a></p><p>可以参考<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html" target="_blank" rel="noopener">官方示例</a></p><h2 id="A-Naive-Way-nn-DataParallel"><a href="#A-Naive-Way-nn-DataParallel" class="headerlink" title="A Naïve Way: nn.DataParallel"></a>A Naïve Way: <code>nn.DataParallel</code></h2><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel" target="_blank" rel="noopener">doc</a></p><p><a href="https://zhuanlan.zhihu.com/p/69940683" target="_blank" rel="noopener">blog</a></p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>官方给出的Signature：</p><pre><code class="hljs python">torch.nn.DataParallel(module, device_ids=<span class="hljs-literal">None</span>, output_device=<span class="hljs-literal">None</span>, dim=<span class="hljs-number">0</span>)</code></pre><p>其中</p><ul><li><code>module</code></li><li><code>device_ids</code>：指定用到的GPU，默认会全部使用</li><li><code>output_device</code>：指定汇总梯度的GPU，默认为GPU 0</li></ul><h3 id="Shortage"><a href="#Shortage" class="headerlink" title="Shortage"></a>Shortage</h3><p>当然，这个做法最为简单，效率也是最低的，这个方法官方也不推荐使用了。</p><h2 id="A-Better-Way-nn-parallel-DistributedDataParallel"><a href="#A-Better-Way-nn-parallel-DistributedDataParallel" class="headerlink" title="A Better Way: nn.parallel.DistributedDataParallel"></a>A Better Way: <code>nn.parallel.DistributedDataParallel</code></h2><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel" target="_blank" rel="noopener">doc</a></p><p><a href="https://pytorch.org/docs/stable/notes/ddp.html" target="_blank" rel="noopener">note</a></p><p><a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html" target="_blank" rel="noopener">tutorial</a></p><h3 id="Usage-1"><a href="#Usage-1" class="headerlink" title="Usage"></a>Usage</h3><pre><code class="hljs python">torch.nn.parallel.DistributedDataParallel(module, device_ids=<span class="hljs-literal">None</span>, output_device=<span class="hljs-literal">None</span>, dim=<span class="hljs-number">0</span>, broadcast_buffers=<span class="hljs-literal">True</span>, process_group=<span class="hljs-literal">None</span>, bucket_cap_mb=<span class="hljs-number">25</span>, find_unused_parameters=<span class="hljs-literal">False</span>, check_reduction=<span class="hljs-literal">False</span>)</code></pre><p>需要注意的几点：</p><ul><li>无法使用shuffle</li></ul><h2 id="Sync-Batch-Normalization"><a href="#Sync-Batch-Normalization" class="headerlink" title="Sync Batch Normalization"></a>Sync Batch Normalization</h2><p><a href="https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html" target="_blank" rel="noopener">doc</a></p><pre><code class="hljs python">torch.nn.SyncBatchNorm(num_features: int, eps: float = <span class="hljs-number">1e-05</span>, momentum: float = <span class="hljs-number">0.1</span>, affine: bool = <span class="hljs-literal">True</span>, track_running_stats: bool = <span class="hljs-literal">True</span>, process_group: Optional[Any] = <span class="hljs-literal">None</span>)</code></pre><h1 id="Automatic-Mixed-Precision"><a href="#Automatic-Mixed-Precision" class="headerlink" title="Automatic Mixed Precision"></a>Automatic Mixed Precision</h1><p>可以参考<a href="https://pytorch.org/docs/stable/notes/amp_examples.html" target="_blank" rel="noopener">官方示例</a></p><h1 id="libtorch-C-API"><a href="#libtorch-C-API" class="headerlink" title="libtorch: C++ API"></a>libtorch: C++ API</h1><h1 id="ONNX"><a href="#ONNX" class="headerlink" title="ONNX"></a>ONNX</h1><h1 id="TensorRT"><a href="#TensorRT" class="headerlink" title="TensorRT"></a>TensorRT</h1>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
      <tag>Distributed Training</tag>
      
      <tag>AMP</tag>
      
      <tag>ONNX</tag>
      
      <tag>TensorRT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Grokking the Interview Coding Questions: High Frequency Problems</title>
    <link href="/2020/08/29/Grokking-the-Interview-Coding-Questions/"/>
    <url>/2020/08/29/Grokking-the-Interview-Coding-Questions/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>[TOC]</p><p>本文不会对算法的原理做过多的讲解，主要是记录常见问题的思路。。。</p><p>PS：本文代码皆通过LeetCode提交通过。。。</p><p>推荐两个网站：</p><ul><li><p><a href="https://oi-wiki.org/" target="_blank" rel="noopener">🐱‍🏍OI WIKI</a></p></li><li><p><a href="https://en.cppreference.com/w/" target="_blank" rel="noopener">📓C++文档</a>   也有中文版</p></li></ul><p>会不断更新😀…</p><h1 id="Sorting-amp-Arrays"><a href="#Sorting-amp-Arrays" class="headerlink" title="Sorting &amp; Arrays"></a>Sorting &amp; Arrays</h1><h2 id="Sorting-Basics"><a href="#Sorting-Basics" class="headerlink" title="Sorting Basics"></a>Sorting Basics</h2><p>LeetCode上有一道题可供练习：</p><p><a href="https://leetcode-cn.com/problems/sort-an-array/" target="_blank" rel="noopener">🐱‍💻Leetcode 912 Medium</a>   </p><p>不多说了，都是基础，几个$O(N^2)$的算法实现起来没什么问题，主要是下面两个注意不要写错：</p><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><p><code>std::sort</code>内部就是快速排序（准确的来说是内省排序，标准规定最坏时间复杂度$O(N\log N)$，在递归深的情况下会转为堆排序）。</p><pre><code class="hljs cpp"><span class="hljs-comment">// 要修改原数组的内容，引用&amp;是必须的</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">QuickSort</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &amp;arr)</span> </span>&#123;    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt; ranges; <span class="hljs-comment">// 用来保存需要迭代的范围</span>    ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(<span class="hljs-number">0</span>, arr.size()<span class="hljs-number">-1</span>)); <span class="hljs-comment">// 初始化，闭区间</span>        <span class="hljs-keyword">while</span> (!ranges.empty()) &#123;        <span class="hljs-keyword">auto</span> range = ranges.back(); <span class="hljs-comment">// 取出栈顶</span>        ranges.pop_back();                <span class="hljs-keyword">if</span> (range.first &gt;= range.second) <span class="hljs-keyword">continue</span>; <span class="hljs-comment">// 只有一个数的情况直接跳过</span>                <span class="hljs-keyword">int</span> mid_val = arr[range.second]; <span class="hljs-comment">// 最后一个数作为anchor</span>        <span class="hljs-keyword">int</span> left = range.first, right = range.second<span class="hljs-number">-1</span>;                <span class="hljs-keyword">while</span> (left &lt; right) &#123;            <span class="hljs-keyword">while</span> (left &lt; right &amp;&amp; arr[left] &lt; mid_val) left++;            <span class="hljs-keyword">while</span> (left &lt; right &amp;&amp; arr[right] &gt;= mid_val) right--;            <span class="hljs-built_in">std</span>::swap(arr[left], arr[right]);        &#125;                <span class="hljs-comment">// 处理特殊情况</span>        <span class="hljs-keyword">if</span> (arr[left] &gt;= arr[range.second]) <span class="hljs-built_in">std</span>::swap(arr[left], arr[range.second]);        <span class="hljs-keyword">else</span> left++;                ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(range.first, left<span class="hljs-number">-1</span>));        ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(left+<span class="hljs-number">1</span>, range.second));    &#125;&#125;</code></pre><p><strong>应用：找K大数</strong></p><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">HeadAdjust</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; arr, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> end)</span> </span>&#123;    <span class="hljs-keyword">int</span> dad = start;    <span class="hljs-keyword">int</span> son = dad*<span class="hljs-number">2</span>+<span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span> (son &lt;= end) &#123;            &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">HeapSort</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; arr)</span> </span>&#123;    &#125;</code></pre><p><code>STL</code>也内置了堆相关的算法，在包含头文件<code>#include &lt;algorithm&gt;</code>之后，</p><ul><li><code>std::make_heap</code>：指定头尾迭代器，可选Compare函数，构造堆；</li><li><code>std::push_heap</code>：指定头尾迭代器，可选Compare函数，将最后一个元素插入到已构造好的堆中（如给定的迭代器范围为<code>[first, last)</code>，需要保证<code>[first,last-1)</code>已经形成一个堆，该函数做的就是将<code>last-1</code>这个元素插入到堆中）；</li><li><code>std::pop_heap</code>：指定头尾迭代器，可选Compare函数，将<code>first</code>和<code>(last-1)</code>的元素交换，并将<code>[first, last-1)</code>调整成堆；</li><li><code>std::sort_heap</code>：指定头尾迭代器，可选Compare函数，将范围<code>[first, last)</code>的元素进行排序（排序之后就不构成堆了）；</li><li><code>std::is_heap</code>：判断是否为堆。</li></ul><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><pre><code class="hljs cpp"></code></pre><p><strong>应用：逆序对</strong></p><h3 id="STL-相关"><a href="#STL-相关" class="headerlink" title="STL 相关"></a>STL 相关</h3><ul><li><code>std::sort</code>：最常用的排序接口，标准规定该算法的最坏时间复杂度$O(N\log N)$；</li><li><code>std::nth_element</code>：返回第$K$大的数，并且所有比它小的数在左边，所有比它大的数在右边，采用的是快速排序的思想，时间复杂度$O(N)$；</li><li><code>std::stable_sort</code>：稳定$O(N\log N)$排序，内部实现似乎是归并排序？</li></ul><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>主要排序算法的特点：</p><table><thead><tr><th></th><th>主要思想</th><th>期望时间复杂度</th><th>最坏时间复杂度</th><th>稳定排序</th></tr></thead><tbody><tr><td>冒泡排序</td><td></td><td></td><td></td><td></td></tr><tr><td>插入排序</td><td></td><td></td><td></td><td></td></tr><tr><td>选择排序</td><td></td><td></td><td></td><td></td></tr><tr><td>基数排序</td><td></td><td></td><td></td><td></td></tr><tr><td>快速排序</td><td></td><td></td><td></td><td></td></tr><tr><td>堆排序</td><td></td><td></td><td></td><td></td></tr><tr><td>归并排序</td><td></td><td></td><td></td><td></td></tr><tr><td>希尔排序</td><td></td><td></td><td></td><td></td></tr></tbody></table><h2 id="Merge-Intervals-合并区间"><a href="#Merge-Intervals-合并区间" class="headerlink" title="Merge Intervals 合并区间"></a>Merge Intervals 合并区间</h2><p><a href="https://leetcode-cn.com/problems/merge-intervals/" target="_blank" rel="noopener">🐱‍💻Leetcode 56 Medium</a></p><h2 id="Stock-Series-股票系列问题"><a href="#Stock-Series-股票系列问题" class="headerlink" title="Stock Series 股票系列问题"></a>Stock Series 股票系列问题</h2><h3 id="买卖股票的最佳时机"><a href="#买卖股票的最佳时机" class="headerlink" title="买卖股票的最佳时机"></a>买卖股票的最佳时机</h3><p><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/" target="_blank" rel="noopener">🐱‍💻Leetcode 121 Easy</a></p><p>暴力的解法就不说了，这里给的是一次遍历的做法，假设当前是第$K$天，如果要在当天卖出，那么最后价格肯定是第$K$天的价格减去前$K-1$天的最低价，同时前$K-1$天的最低价是可以边遍历边更新的，所以最终只需要一次遍历即可：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span> <span class="hljs-keyword">public</span>:  <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; prices)</span> </span>&#123;    <span class="hljs-keyword">int</span> min_price = INT_MAX, max_profit = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> price : prices) &#123;      max_profit = max_profit &gt; price - min_price ? max_profit : price - min_price;      <span class="hljs-comment">// min_price一定要后更新，因为min_price代表的是当前天以前的最低价格</span>      min_price = price &lt; min_price ? price : min_price;    &#125;    <span class="hljs-keyword">return</span> max_profit;  &#125;&#125;;</code></pre><h2 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h2><h3 id="缺失数字"><a href="#缺失数字" class="headerlink" title="缺失数字"></a>缺失数字</h3><p><a href="https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/" target="_blank" rel="noopener">🐱‍💻剑指Offer 53 Easy</a></p><h2 id="Top-K-Element-第K大-小元素"><a href="#Top-K-Element-第K大-小元素" class="headerlink" title="Top K Element 第K大/小元素"></a>Top K Element 第K大/小元素</h2><p><a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/" target="_blank" rel="noopener">🐱‍💻Leetcode 215 Medium</a>     （同类题：<a href="https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/" target="_blank" rel="noopener">🐱‍💻剑指Offer 40 Easy</a>）</p><p><strong>题目中说了给定的$K$是合法的，所以下面的代码没有检查$K$的合法性</strong></p><ul><li>先排序再求解 $O(N\log N)$ （⭐）</li></ul><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findKthLargest</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;        <span class="hljs-built_in">std</span>::sort(nums.begin(), nums.end());        <span class="hljs-keyword">return</span> nums[nums.size()-k];    &#125;&#125;;</code></pre><ul><li>堆 $O(N\log K)$ （⭐⭐）</li></ul><p>注意求最小的$K$个数的话用大顶堆，不然把全部数push到堆中然后一个一个弹出的话复杂度是$O(N\log N)$，和排序没什么区别了。</p><p>使用<code>C++</code>自带<code>priority_queue</code>的版本：</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">TopK</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; arr, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">std</span>::priority_queue&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, <span class="hljs-built_in">std</span>::greater&lt;<span class="hljs-keyword">int</span>&gt;&gt; pq; <span class="hljs-comment">// greater是小顶堆，less是大顶堆</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> num : arr) &#123;        <span class="hljs-keyword">if</span> (pq.size() &lt; k) &#123;            pq.push(num);        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (num &gt; pq.top()) &#123;            <span class="hljs-comment">// 如果栈顶元素大于当前元素</span>            pq.pop();            pq.push(num);        &#125;    &#125;        <span class="hljs-keyword">return</span> pq.top();&#125;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findKthLargest</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;        <span class="hljs-keyword">return</span> TopK(nums, k);    &#125;&#125;;</code></pre><ul><li>快排变体 $O(N)$ （⭐⭐⭐）</li></ul><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">TopK</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; arr, <span class="hljs-keyword">int</span> k)</span> </span>&#123;  <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt; ranges;  ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(<span class="hljs-number">0</span>, arr.size()<span class="hljs-number">-1</span>));  <span class="hljs-keyword">while</span> (!ranges.empty()) &#123;    <span class="hljs-keyword">auto</span> range = ranges.back();    ranges.pop_back();    <span class="hljs-keyword">if</span> (range.first &gt;= range.second) &#123;      <span class="hljs-keyword">if</span> (range.first == k || range.second == k) &#123;        <span class="hljs-keyword">return</span> arr[k];      &#125;      <span class="hljs-keyword">continue</span>;    &#125;    <span class="hljs-keyword">int</span> mid_val = arr[range.second];    <span class="hljs-keyword">int</span> left = range.first, right = range.second<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span> (left &lt; right) &#123;      <span class="hljs-keyword">while</span> (left &lt; right &amp;&amp; arr[left] &lt; mid_val) left++;      <span class="hljs-keyword">while</span> (left &lt; right &amp;&amp; arr[right] &gt;= mid_val) right--;      <span class="hljs-built_in">std</span>::swap(arr[left], arr[right]);    &#125;    <span class="hljs-keyword">if</span> (arr[left] &gt;= arr[range.second]) <span class="hljs-built_in">std</span>::swap(arr[left], arr[range.second]);    <span class="hljs-keyword">else</span> left++;    <span class="hljs-keyword">if</span> (left == k) <span class="hljs-keyword">return</span> arr[left];    ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(range.first, left<span class="hljs-number">-1</span>));    ranges.push_back(<span class="hljs-built_in">std</span>::make_pair(left+<span class="hljs-number">1</span>, range.second));  &#125;  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findKthLargest</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;        <span class="hljs-keyword">return</span> TopK(nums, nums.size()-k);    &#125;&#125;;</code></pre><h2 id="Inversions-数组中的逆序对"><a href="#Inversions-数组中的逆序对" class="headerlink" title="Inversions 数组中的逆序对"></a>Inversions 数组中的逆序对</h2><p><a href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/" target="_blank" rel="noopener">🐱‍💻剑指Offer 51 Hard</a></p><ul><li>归并排序 $O(n\log n)$ （⭐⭐）</li></ul><pre><code class="hljs cpp"></code></pre><ul><li>树状数组 $O(n\log n)$ （⭐⭐⭐）</li></ul><p><img src="https://i.loli.net/2020/08/29/9M3wtaYEJvDWdn4.png" srcset="/img/loading.gif" alt=""></p><pre><code class="hljs cpp"></code></pre><h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><h2 id="Add-Two-Numbers-链表相加"><a href="#Add-Two-Numbers-链表相加" class="headerlink" title="Add Two Numbers 链表相加"></a>Add Two Numbers 链表相加</h2><p><a href="https://leetcode-cn.com/problems/add-two-numbers/" target="_blank" rel="noopener">🐱‍💻Leetcode 2 Medium</a>  </p><h2 id="Intersection-of-Two-Lists-链表相交节点"><a href="#Intersection-of-Two-Lists-链表相交节点" class="headerlink" title="Intersection of Two Lists 链表相交节点"></a>Intersection of Two Lists 链表相交节点</h2><p><a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/" target="_blank" rel="noopener">🐱‍💻Leetcode 160 Easy</a></p><ul><li>HashTable法 $O(M+N)$（⭐⭐）</li></ul><p>空间复杂度$O(M)$或$O(N)$，这里使用<code>unordered_set</code>实现：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode *<span class="hljs-title">getIntersectionNode</span><span class="hljs-params">(ListNode *headA, ListNode *headB)</span> </span>&#123;        <span class="hljs-keyword">if</span> (headA == <span class="hljs-literal">nullptr</span> || headB == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">unordered_set</span>&lt;ListNode*&gt; us;                ListNode* current = headA;        <span class="hljs-keyword">while</span> (current) &#123;            us.insert(current);            current = current-&gt;next;        &#125;        ListNode* res = <span class="hljs-literal">nullptr</span>;        current = headB;        <span class="hljs-keyword">while</span> (current) &#123;            <span class="hljs-keyword">if</span> (us.find(current) != us.end()) &#123;                res = current;                <span class="hljs-keyword">break</span>;            &#125;            current = current-&gt;next;        &#125;        <span class="hljs-keyword">return</span> res;    &#125;&#125;;</code></pre><ul><li>双指针法 $O(M+N)$（⭐⭐⭐）</li></ul><p>空间复杂度$O(1)$</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode *<span class="hljs-title">getIntersectionNode</span><span class="hljs-params">(ListNode *headA, ListNode *headB)</span> </span>&#123;        <span class="hljs-keyword">if</span> (headA == <span class="hljs-literal">nullptr</span> || headB == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;        ListNode* a = headA, *b = headB;        <span class="hljs-keyword">while</span> (a != b) &#123;            <span class="hljs-keyword">if</span> (a == <span class="hljs-literal">nullptr</span>) &#123;                a = headB;            &#125; <span class="hljs-keyword">else</span> &#123;                a = a-&gt;next;            &#125;            <span class="hljs-keyword">if</span> (b == <span class="hljs-literal">nullptr</span>) &#123;                b = headA;            &#125; <span class="hljs-keyword">else</span> &#123;                b = b-&gt;next;            &#125;        &#125;        <span class="hljs-keyword">return</span> a;    &#125;&#125;;</code></pre><h2 id="Reverse-the-List-翻转链表"><a href="#Reverse-the-List-翻转链表" class="headerlink" title="Reverse the List 翻转链表"></a>Reverse the List 翻转链表</h2><p><a href="https://leetcode-cn.com/problems/reverse-linked-list/" target="_blank" rel="noopener">🐱‍💻Leetcode 206 Easy</a></p><p>面试中出现频率还挺高的</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode* <span class="hljs-title">enumerate</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; buffer;        <span class="hljs-keyword">while</span> (head != <span class="hljs-literal">nullptr</span>) &#123;            buffer.push_back(head-&gt;val);            head = head-&gt;next;        &#125;        ListNode* res = <span class="hljs-keyword">new</span> ListNode(buffer.back());        ListNode* current = res;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = buffer.size()<span class="hljs-number">-2</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;            current-&gt;next = <span class="hljs-keyword">new</span> ListNode(buffer[i]);            current = current-&gt;next;        &#125;        <span class="hljs-keyword">return</span> res;    &#125;    <span class="hljs-function">ListNode* <span class="hljs-title">reverseList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;        <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> head;        <span class="hljs-keyword">return</span> enumerate(head);    &#125;&#125;;</code></pre><h2 id="Merge-Lists-合并（2或K个）链表"><a href="#Merge-Lists-合并（2或K个）链表" class="headerlink" title="Merge Lists 合并（2或K个）链表"></a>Merge Lists 合并（2或K个）链表</h2><p><a href="https://leetcode-cn.com/problems/merge-k-sorted-lists/" target="_blank" rel="noopener">🐱‍💻Leetcode 23 Hard</a></p><p>最简单的hard题🤣？？？优先队列法写起来是最舒服的，效率也是最高的，时间复杂度$O(nk\times\log nk)$</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span>    <span class="hljs-built_in">std</span>::priority_queue&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">int</span>, ListNode*&gt;, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">int</span>, ListNode*&gt;&gt;, <span class="hljs-built_in">std</span>::greater&lt;<span class="hljs-built_in">std</span>::pair&lt;<span class="hljs-keyword">int</span>, ListNode*&gt;&gt;&gt; q;<span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode* <span class="hljs-title">mergeKLists</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span>&#123;        <span class="hljs-keyword">if</span> (lists.empty()) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> <span class="hljs-built_in">list</span> : lists) &#123;            <span class="hljs-keyword">if</span> (<span class="hljs-built_in">list</span> != <span class="hljs-literal">nullptr</span>) &#123;                q.push(<span class="hljs-built_in">std</span>::make_pair(<span class="hljs-built_in">list</span>-&gt;val, <span class="hljs-built_in">list</span>));            &#125;        &#125;        <span class="hljs-keyword">auto</span>* dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">-1</span>);        <span class="hljs-keyword">auto</span>* current = dummy;        <span class="hljs-keyword">while</span> (q.size()) &#123;            <span class="hljs-keyword">auto</span> pair = q.top();            <span class="hljs-keyword">auto</span>* p = pair.second;            q.pop();            current-&gt;next = p;            <span class="hljs-keyword">if</span> (p-&gt;next) q.push(<span class="hljs-built_in">std</span>::make_pair(p-&gt;next-&gt;val, p-&gt;next));            current = current-&gt;next;        &#125;        <span class="hljs-keyword">return</span> dummy-&gt;next;    &#125;&#125;;</code></pre><h2 id="Sort-List-排序链表"><a href="#Sort-List-排序链表" class="headerlink" title="Sort List 排序链表"></a>Sort List 排序链表</h2><p><a href="https://leetcode-cn.com/problems/sort-list/" target="_blank" rel="noopener">🐱‍💻Leetcode 148 Medium</a></p><h1 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h1><h2 id="Binary-Tree-In-order-Traversal-二叉树中序遍历"><a href="#Binary-Tree-In-order-Traversal-二叉树中序遍历" class="headerlink" title="Binary Tree In-order Traversal 二叉树中序遍历"></a>Binary Tree In-order Traversal 二叉树中序遍历</h2><p><a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="noopener">🐱‍💻Leetcode 94 Medium</a></p><h2 id="Binary-Tree-Level-Order-Traversal-二叉树层序遍历"><a href="#Binary-Tree-Level-Order-Traversal-二叉树层序遍历" class="headerlink" title="Binary Tree Level Order Traversal 二叉树层序遍历"></a>Binary Tree Level Order Traversal 二叉树层序遍历</h2><p><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/" target="_blank" rel="noopener">🐱‍💻Leetcode 102 Medium</a></p><h1 id="String"><a href="#String" class="headerlink" title="String"></a>String</h1><h2 id="Palindrome-Number-回文数"><a href="#Palindrome-Number-回文数" class="headerlink" title="Palindrome Number 回文数"></a>Palindrome Number 回文数</h2><p><a href="https://leetcode-cn.com/problems/palindrome-number/" target="_blank" rel="noopener">🐱‍💻Leetcode 9 Easy</a></p><h1 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h1><h2 id="LRU-Cache-LRU缓存机制"><a href="#LRU-Cache-LRU缓存机制" class="headerlink" title="LRU Cache LRU缓存机制"></a>LRU Cache LRU缓存机制</h2><p><a href="https://leetcode-cn.com/problems/lru-cache/" target="_blank" rel="noopener">🐱‍💻Leetcode 146 Medium</a></p><h2 id="Find-Median-from-Data-Stream-找到数据流的中位数"><a href="#Find-Median-from-Data-Stream-找到数据流的中位数" class="headerlink" title="Find Median from Data Stream 找到数据流的中位数"></a>Find Median from Data Stream 找到数据流的中位数</h2><p><a href="https://leetcode-cn.com/problems/find-median-from-data-stream/" target="_blank" rel="noopener">🐱‍💻Leetcode 295 Hard</a></p><p>双堆做法：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MedianFinder</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-built_in">std</span>::priority_queue&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, <span class="hljs-built_in">std</span>::less&lt;<span class="hljs-keyword">int</span>&gt;&gt; big_root;    <span class="hljs-built_in">std</span>::priority_queue&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, <span class="hljs-built_in">std</span>::greater&lt;<span class="hljs-keyword">int</span>&gt;&gt; small_root;        <span class="hljs-comment">/** initialize your data structure here. */</span>    MedianFinder() &#123;            &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">addNum</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num)</span> </span>&#123;        big_root.push(num);        <span class="hljs-keyword">int</span> tmp = big_root.top();        big_root.pop();        small_root.push(tmp);        <span class="hljs-keyword">if</span> (small_root.size() &gt; big_root.size()) &#123;            tmp = small_root.top();            small_root.pop();            big_root.push(tmp);        &#125;    &#125;        <span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">findMedian</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">if</span> (big_root.size() == small_root.size()) &#123;            <span class="hljs-keyword">return</span> (<span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">double</span>&gt;(big_root.top()) + small_root.top())/<span class="hljs-number">2.0</span>;        &#125; <span class="hljs-keyword">else</span> &#123;            <span class="hljs-keyword">return</span> <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">double</span>&gt;(big_root.top());        &#125;    &#125;&#125;;</code></pre><h1 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h1><h2 id="打家劫舍系列"><a href="#打家劫舍系列" class="headerlink" title="打家劫舍系列"></a>打家劫舍系列</h2><h3 id="House-Robber-I-打家劫舍-I"><a href="#House-Robber-I-打家劫舍-I" class="headerlink" title="House Robber I 打家劫舍 I"></a>House Robber I 打家劫舍 I</h3><p><a href="https://leetcode-cn.com/problems/house-robber/" target="_blank" rel="noopener">🐱‍💻Leetcode 198 Easy</a></p><h3 id="House-Robber-II-打家劫舍-II"><a href="#House-Robber-II-打家劫舍-II" class="headerlink" title="House Robber II 打家劫舍 II"></a>House Robber II 打家劫舍 II</h3><p><a href="https://leetcode-cn.com/problems/house-robber-ii/" target="_blank" rel="noopener">🐱‍💻Leetcode 213 Medium</a></p><h3 id="House-Robber-III-打家劫舍-III"><a href="#House-Robber-III-打家劫舍-III" class="headerlink" title="House Robber III 打家劫舍 III"></a>House Robber III 打家劫舍 III</h3><p><a href="https://leetcode-cn.com/problems/house-robber-iii/" target="_blank" rel="noopener">🐱‍💻Leetcode 337 Medium</a></p><h2 id="Maximum-Subarray-最大子序列和"><a href="#Maximum-Subarray-最大子序列和" class="headerlink" title="Maximum Subarray 最大子序列和"></a>Maximum Subarray 最大子序列和</h2><p><a href="https://leetcode-cn.com/problems/maximum-subarray/" target="_blank" rel="noopener">🐱‍💻Leetcode 53 Easy</a></p><p>定义$dp(i)$为以第$i$元素结尾的最大子序列和，由于子序列是连续的，所以状态转移只有两种情况：选择第$i-1$个元素和不选第$i-1$个元素。如果选第$i-1$个元素，相当于把第$i$个元素接在$dp(i-1)$对应的最优子序列后面，如果不选第$i-1$个元素，那么意味着只有$i$一个元素，所以状态转移方程为：<br>$$<br>dp(i) = \max{dp(i-1)+a(i),a(i)}<br>$$<br>代码也比较简单：</p><pre><code class="hljs python">class Solution &#123;public:    int maxSubArray(vector&lt;int&gt;&amp; nums) &#123;        std::vector&lt;int&gt; dp(nums.size());        dp[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];        int res = dp[<span class="hljs-number">0</span>];        <span class="hljs-keyword">for</span> (int i = <span class="hljs-number">1</span>; i &lt; nums.size(); i++) &#123;            dp[i] = std::max(nums[i] + dp[i<span class="hljs-number">-1</span>], nums[i]);            res = dp[i] &gt; res ? dp[i] : res;        &#125;        <span class="hljs-keyword">return</span> res;    &#125;&#125;;</code></pre><h2 id="Longest-Increasing-Subsequence-最长上升子序列"><a href="#Longest-Increasing-Subsequence-最长上升子序列" class="headerlink" title="Longest Increasing Subsequence 最长上升子序列"></a>Longest Increasing Subsequence 最长上升子序列</h2><p><a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">🐱‍💻Leetcode 300 Medium</a></p><h2 id="Edit-Distance-编辑距离"><a href="#Edit-Distance-编辑距离" class="headerlink" title="Edit Distance 编辑距离"></a>Edit Distance 编辑距离</h2><p><a href="https://leetcode-cn.com/problems/edit-distance/" target="_blank" rel="noopener">🐱‍💻Leetcode 72 Hard</a></p><h1 id="Mathematics"><a href="#Mathematics" class="headerlink" title="Mathematics"></a>Mathematics</h1><h2 id="Power-of-Two-判断-2-的幂"><a href="#Power-of-Two-判断-2-的幂" class="headerlink" title="Power of Two 判断$2$的幂"></a>Power of Two 判断$2$的幂</h2><p><a href="https://leetcode-cn.com/problems/power-of-two/" target="_blank" rel="noopener">🐱‍💻Leetcode 231 Easy</a></p><p>$n$为$2$的幂只需检查$n$与$n-1$的与是否为$0$即可，如$8$的二进制表示（假设只有$8$位）为<code>[0001000]</code>，$7$的二进制为<code>[0000111]</code>。</p><p>一行解决。记得判断大于$0$。</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPowerOfTwo</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;        <span class="hljs-keyword">return</span> n &gt; <span class="hljs-number">0</span> &amp;&amp; (n&amp;(n<span class="hljs-number">-1</span>))==<span class="hljs-number">0</span>;    &#125;&#125;;</code></pre><h1 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h1><pre><code class="hljs cpp"><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> maxn = <span class="hljs-number">100</span> + <span class="hljs-number">5</span>;<span class="hljs-keyword">int</span> graph[maxn][maxn];<span class="hljs-keyword">int</span> min_dis[maxn][maxn];<span class="hljs-keyword">int</span> INF = <span class="hljs-number">100000</span>;</code></pre><ul><li>Floyd</li></ul><p>$$<br>f(0, x, y)=\begin{cases}<br>\text{edge}(x, y)\<br>0\<br>+\infty<br>\end{cases}<br>$$</p><p>状态<br>$$<br>f(k,x,y) = \min{f(k-1, x, y), f(k-1, x, k) + f(k-1, k, y)}<br>$$<br>时间复杂度$O(N^3)$，空间复杂度$O(N^2)$</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">Floyd</span><span class="hljs-params">(<span class="hljs-keyword">int</span> N)</span> </span>&#123;  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= N; i++) &#123;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= N; j++) &#123;      <span class="hljs-keyword">if</span> (i == j) &#123;        min_dis[i][j] = <span class="hljs-number">0</span>;      &#125; <span class="hljs-keyword">else</span> &#123;        <span class="hljs-keyword">if</span> (graph[i][j] == <span class="hljs-number">-1</span>) &#123;          min_dis[i][j] = INF;        &#125; <span class="hljs-keyword">else</span> &#123;          min_dis[i][j] = graph[i][j];        &#125;      &#125;    &#125;  &#125;  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = <span class="hljs-number">1</span>; k &lt;= N; k++) &#123;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= N; i++) &#123;      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= N; j++) &#123;        min_dis[i][j] = <span class="hljs-built_in">std</span>::min(min_dis[i][j], min_dis[i][k] + min_dis[k][j]);      &#125;    &#125;  &#125;&#125;</code></pre><ul><li>Bellman-Ford</li></ul><pre><code class="hljs cpp"></code></pre><ul><li>Dijkstra</li></ul><pre><code class="hljs cpp"></code></pre><table><thead><tr><th></th><th>Floyd</th><th>Bellman-Ford</th><th>Dijkstra</th></tr></thead><tbody><tr><td>适用场景</td><td>每对结点之间的最短路</td><td>单源最短路</td><td>单源最短路</td></tr><tr><td>适用数据</td><td>没有负环的图</td><td>任意图（可以判定负环是否存在）</td><td>非负权图</td></tr><tr><td>时间复杂度</td><td>$O(N^3)$</td><td>$O(NM)$</td><td>$O(M\log M)$</td></tr></tbody></table><h2 id="Network-Delay-Time-网络延迟时间"><a href="#Network-Delay-Time-网络延迟时间" class="headerlink" title="Network Delay Time 网络延迟时间"></a>Network Delay Time 网络延迟时间</h2><p><a href="https://leetcode-cn.com/problems/network-delay-time/" target="_blank" rel="noopener">🐱‍💻Leetcode 743 Medium</a></p><h1 id="Misc"><a href="#Misc" class="headerlink" title="Misc"></a>Misc</h1><h2 id="Single-Number-只出现过一次的数字"><a href="#Single-Number-只出现过一次的数字" class="headerlink" title="Single Number 只出现过一次的数字"></a>Single Number 只出现过一次的数字</h2><p><a href="https://leetcode-cn.com/problems/single-number/" target="_blank" rel="noopener">🐱‍💻Leetcode 136 Easy</a></p><p>运用位运算的性质</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">singleNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;        <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span> i : nums) res ^= i;        <span class="hljs-keyword">return</span> res;    &#125;&#125;;</code></pre>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Algorithm</tag>
      
      <tag>Data Structure</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Support Vector Machine: Machine Learning Classification Algorithms 2</title>
    <link href="/2020/08/26/Support-Vector-Machine-Machine-Learning-Classification-Algorithms-2/"/>
    <url>/2020/08/26/Support-Vector-Machine-Machine-Learning-Classification-Algorithms-2/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Still working on it😅…</p><p><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">blog</a></p><h1 id="Hyperplane"><a href="#Hyperplane" class="headerlink" title="Hyperplane"></a>Hyperplane</h1><p>超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程：<br>$$<br>a_1x_1+\cdots+a_nx_n=d<br>$$<br>的所有解形成的集合，其中$a_1,\cdots,a_n$为不全为$0$的实数，$d$也是实数。</p><p>从几何上来说，超平面可以看作是除空间$R^n$自身外维度最大的仿射空间。</p><p><img src="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg" srcset="/img/loading.gif" alt=""></p><h1 id="Maximum-Margin-Classifier"><a href="#Maximum-Margin-Classifier" class="headerlink" title="Maximum Margin Classifier"></a>Maximum Margin Classifier</h1><img src="https://i.loli.net/2020/08/26/vjuyCGXMr4msaUK.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>要谈SVM就得先谈线性分类器，其设置是这样的。对于$D$维空间，我们有一堆数据$X$，进行二分类任务，标签记为$y$，其中$y=-1$和$y=1$分别代表不同的类别。我们的任务就是找到一个超平面，将正负例切分开来（先假设数据是线性可分的），这个超平面的方程可以表示为：<br>$$<br>w^\top x+b=0<br>$$<br>我们令$f(x)=w^\top x+b$，对于$f(x)&lt;0$的样本，我们赋予其类别$-1$，对于$f(x)&gt;0$的样本，我们可以赋予其类别$1$。对于相同的分类结果，我们可以找出无限种超平面。不过，对于那些样本特别靠近超平面的情况，鲁棒性并不好。为什么呢？因为这时只要超平面有轻微的变化，样本的分类结果就会发生变化。直观上来说，我们希望样本到超平面的距离越大越好。</p><p>我们先定义函数间隔的概念，函数间隔$\hat \gamma=y(w^\top x+b)$，乘以$y$的目的主要是保持非负性，表示起来方便。可见函数间隔的大小并不能表示样本距离，因为同一个超平面，法向量$w$可以任意增大，函数间隔也会相应增大。</p><p>下面来推导点$x$到超平面的距离。设$x$在超平面上的投影为$x_0$，到超平面的距离为$\gamma$，$w$为法向量，那么有：<br>$$<br>x=x_0+\gamma\frac{w}{\parallel w\parallel}<br>$$<br>将上式带入到超平面方程可以得到<br>$$<br>\gamma=\frac{w^\top}{\parallel w\parallel}x+\frac{b}{\parallel w\parallel}<br>$$<br>我们称$\gamma$为几何间隔。</p><p><img src="https://i.loli.net/2020/08/26/b6qLJWzHwFAPDne.png" srcset="/img/loading.gif" alt=""></p><p>可以很容易看出函数间隔和几何间隔的关系：<br>$$<br>\gamma = \frac{\hat \gamma}{\parallel w\parallel}<br>$$<br>前面提到我们希望几何间隔越大越好，于是可以直接最大化$\gamma$，得到：<br>$$<br>\begin{align}<br>\max \space &amp;\gamma\<br>s.t. \space &amp; y_i(w^\top x_i+b)=\hat\gamma_i\geq\hat\gamma, \space i=1,\cdots,n<br>\end{align}<br>$$<br>这里$\hat \gamma=\gamma \parallel w\parallel$，根据前面的分析我们知道，对于同一个超平面，函数间隔$\hat\gamma$可以随着$\parallel w\parallel$的变化而变化，所以为了找到最优的$\gamma$，我们可以考虑固定$\parallel w\parallel$或者$\hat\gamma$，这里我们固定$\hat \gamma=1$，所以有：<br>$$<br>\begin{align}<br>\max &amp; \space \frac{1}{\parallel w\parallel},\ s.t. \space&amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$</p><p>下面的约束条件代表前提是所有样本分类正确，而$\max\frac{1}{\parallel w\parallel}$代表最大化间隔。为了方便，我们将其化为等价的最小化形式：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中那些$y_i(w^\top x_i+b)=1$的样本就是“支持向量”。这个优化问题是典型的二次凸优化问题，可以调用现成的算法去解决。不过我们可以使用拉格朗日乘子法来更高效的解决。</p><h1 id="Dual-Problem"><a href="#Dual-Problem" class="headerlink" title="Dual Problem"></a>Dual Problem</h1><p>拉格朗日乘子法可以将有$d$个变量和$k$个约束条件的最优化问题转化成有$d+k$个变量的无约束最优化问题求解。</p><h2 id="Lagrange-Multiplier"><a href="#Lagrange-Multiplier" class="headerlink" title="Lagrange Multiplier"></a>Lagrange Multiplier</h2><p>对于以下有约束优化问题：<br>$$<br>\begin{align}<br>\min_x \space &amp; f(x)\<br>\text{s.t.} \space &amp; h_i(x)=0 \space (i=1,\cdots,m),\<br>&amp;g_j(x) \leq 0 \space (j=1,\cdots,n)<br>\end{align}<br>$$</p><p>引入拉格朗日乘子$\boldsymbol\lambda = (\lambda_1,\lambda_2,\cdots,\lambda_m)^\top$和$\boldsymbol\mu=(\mu_1,\mu_2,\cdots,\mu_n)^\top$，相应的拉格朗日函数为：<br>$$<br>L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=f(\boldsymbol x)+\sum_{i=1}^m \lambda_i h_i(\boldsymbol x)+\sum_{j=1}^n \mu_jg_j(\boldsymbol x)<br>$$</p><h3 id="Primal-Problem"><a href="#Primal-Problem" class="headerlink" title="Primal Problem"></a>Primal Problem</h3><h3 id="Dual-Problem-1"><a href="#Dual-Problem-1" class="headerlink" title="Dual Problem"></a>Dual Problem</h3><h3 id="KKT-Condition"><a href="#KKT-Condition" class="headerlink" title="KKT Condition"></a>KKT Condition</h3><p>由不等式引入的KKT条件为：<br>$$<br>\begin{cases}<br>g_j(\boldsymbol x)\leq 0;\<br>\mu_j \geq 0;\<br>\mu_j g_j(\boldsymbol x)=0<br>\end{cases}<br>$$</p><h2 id="Dual-Form-of-SVM-Optimization"><a href="#Dual-Form-of-SVM-Optimization" class="headerlink" title="Dual Form of SVM Optimization"></a>Dual Form of SVM Optimization</h2><p>支持向量机优化的对偶问题可以写为：<br>$$<br>L(w,b,\alpha)=\frac{1}{2}\parallel w\parallel^2-\sum_{i=1}^n \alpha_i(y_i(w^\top x_i+b)-1)<br>$$<br>我们先令：<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial w}=0&amp;\Rightarrow w=\sum_{i=1}^n\alpha_i y_i x_i\<br>\frac{\partial L}{\partial b}=0&amp;\Rightarrow \sum_{i=1}^n\alpha_i y_i =0<br>\end{align}<br>$$<br>带回到$L$得到：<br>$$<br>\begin{align}<br>L(w,b,\alpha)&amp;=\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_j y_i y_j x^\top_i x_j-\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_jx^\top_ix_j-b\sum_{i=1}^n\alpha_iy_i+\sum_{i=1}^n\alpha_i\<br>&amp;=\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j<br>\end{align}<br>$$<br>于是得到关于$\alpha$的对偶优化问题：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$</p><p>前面有提到我们根据$f(x)=w^\top x + b$的输出来判定样本类别，而刚才得到$w=\sum_{i=1}^n\alpha_i y_i x_i$，于是：<br>$$<br>\begin{align}<br>f(x) &amp;= (\sum_{i=1}^n \alpha_iy_ix_i)^\top x+b\<br>&amp;= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>\end{align}<br>$$<br>最后的$\sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b$值得特别注意，这意味着我们对于测试样本$x$的预测，只需要计算它与训练集的内积即可，同时由于所有非支持向量对应的$\alpha$都是$0$，我们只需要求一小部分内积。同时这个内积计算也是后面核方法应用的前提。</p><h1 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h1><p>到目前为止，我们的讨论都是在数据是线性可分的前提下进行讨论的，那么对于线性不可分的情况呢？答案是使用核方法。</p><p><img src="https://i.loli.net/2020/09/08/kSTVgelDjWqtu8v.png" srcset="/img/loading.gif" alt=""></p><p>核方法的思想是，对于原始不可分的数据，我们假设原始数据通过一个映射$\phi(\cdot)$就变得线性可分了。核方法相当于对数据找到了一种新的表示，如上图没法用一个超平面直接分割，但通过$\phi(\cdot)$映射之后就变得可分了。原始的分类函数为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b<br>$$<br>加上映射之后变为：<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i \langle \phi(x_i), \phi(x)\rangle + b<br>$$<br>优化问题也变为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j \langle\phi(x_i), \phi(x_j)\rangle\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>我们把计算两个向量在映射后的空间中的内积的函数叫做核函数<br>$$<br>f(x)= \sum_{i=1}^n \alpha_i y_i k(x_i, x) + b<br>$$<br>优化问题改为：<br>$$<br>\begin{align}<br>\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j k(\phi(x_i), \phi(x_j))\<br>\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\<br>&amp; \sum_{i=1}^n \alpha_i y_i = 0<br>\end{align}<br>$$<br>实际上，通过核函数，我们隐式地定义了一个映射$\phi(\cdot)$</p><p>常用核函数</p><table><thead><tr><th>名称</th><th>表达式</th><th>参数</th></tr></thead><tbody><tr><td>线性核</td><td></td><td></td></tr><tr><td>多项式核</td><td></td><td></td></tr><tr><td>RBF核</td><td></td><td></td></tr><tr><td>拉普拉斯核</td><td></td><td></td></tr><tr><td>Sigmoid核</td><td></td><td></td></tr></tbody></table><h1 id="Soft-Margin"><a href="#Soft-Margin" class="headerlink" title="Soft Margin"></a>Soft Margin</h1><p>数据线性不可分的情况，除了数据本身结构非线性的原因之外（核方法），还有可能是因为噪声或者离群点。为了处理这种情况，我们可以允许一部分点在一定程度上偏离超平面，具体来说就是原来的约束条件$y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n$变成了：<br>$$<br>y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>$$<br>其中$\xi_i\geq 0$称作是松弛变量，代表样本$i$允许的偏离程度。当然松弛变量不可能无限大，所以我们需要将$\xi_i$加入到优化目标函数中使其尽量小，于是有：<br>$$<br>\begin{align}<br>\min &amp; \space \frac{1}{2}\parallel w\parallel^2+C\sum_{i=1}^n \xi_i,\ s.t. &amp; y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n<br>\end{align}<br>$$<br>其中$C$为控制最优化$\parallel w\parallel$和松弛变量这两项的权重。这里的优化函数还是对偶问题之前的形式，我们马上会讨论对偶问题。</p><h1 id="Numerical-Optimization"><a href="#Numerical-Optimization" class="headerlink" title="Numerical Optimization"></a>Numerical Optimization</h1><p>这里讨论SVM高效求解的Sequential Minimal Optimization (SMO)算法。</p><p>坐标下降法是一种非梯度优化算法，</p><p><img src="https://i.loli.net/2020/09/08/I6AonzFRHGVBU3t.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/09/08/Hmr79nMlK4C8GeJ.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linear Regression and Logistic Regression - Machine Learning Classification Algorithms 1</title>
    <link href="/2020/08/26/Linear-Regression-and-Logistic-Regression-Machine-Learning-Classification-Algorithms-1/"/>
    <url>/2020/08/26/Linear-Regression-and-Logistic-Regression-Machine-Learning-Classification-Algorithms-1/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Still working on it…</p><h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><h2 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h2><p><img src="https://i.loli.net/2020/09/04/Ji14CNOLADmysah.png" srcset="/img/loading.gif" alt=""></p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><p>设训练集包含$M$个样本，$N$个特征，为了方便后续推导，我们添加一列全是$1$的向量：<br>$$<br>\mathbf X=\left(<br>\begin{matrix}<br>x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1N} &amp; 1\<br>x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2N} &amp; 1\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\<br>x_{M1} &amp; x_{M2} &amp; \cdots &amp; x_{MN} &amp; 1<br>\end{matrix}<br>\right)<br>$$<br>我们的模型<br>$$<br>\boldsymbol{\hat y} = \mathbf X \hat{\boldsymbol w}<br>$$<br>最终得到</p><h2 id="Projection-Matrix"><a href="#Projection-Matrix" class="headerlink" title="Projection Matrix"></a>Projection Matrix</h2><h2 id="Probabilistic-Interpretation"><a href="#Probabilistic-Interpretation" class="headerlink" title="Probabilistic Interpretation"></a>Probabilistic Interpretation</h2><p>$$<br>\hat{\boldsymbol w}^* = (\mathbf X^\top \mathbf X)^{-1}\mathbf X^\top\boldsymbol y<br>$$</p><h1 id="Linear-Regression-with-Regularization"><a href="#Linear-Regression-with-Regularization" class="headerlink" title="Linear Regression with Regularization"></a>Linear Regression with Regularization</h1><h2 id="L1-Norm-and-L2-Norm"><a href="#L1-Norm-and-L2-Norm" class="headerlink" title="L1 Norm and L2 Norm"></a>L1 Norm and L2 Norm</h2><p>常见的正则项有$\ell_1$正则和$\ell_2$正则。假设原始优化函数为<br>$$<br>\mathop{\arg\min}\limits_{\theta} \mathcal L(\theta)<br>$$<br>加入$\ell_1$正则化之后<br>$$<br>\mathop{\arg\min}\limits_{\theta} \mathcal J_1(\theta)=\mathcal L(\theta)+\color{purple}{\lambda\parallel \theta\parallel_1}<br>$$<br>加入$\ell_2$正则化之后<br>$$<br>\mathop{\arg\min}\limits_{\theta} \mathcal J_2(\theta)=\mathcal L(\theta)+\color{purple}{\lambda\parallel \theta\parallel_2^2}<br>$$</p><h3 id="Probabilistic-Interpretation-1"><a href="#Probabilistic-Interpretation-1" class="headerlink" title="Probabilistic Interpretation"></a>Probabilistic Interpretation</h3><h3 id="Optimization-Interpretation"><a href="#Optimization-Interpretation" class="headerlink" title="Optimization Interpretation"></a>Optimization Interpretation</h3><img src="https://i.loli.net/2020/09/15/lSLrOGsTvqkxpV6.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/09/15/HqL8mtAujkGFozZ.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="LASSO-Regression"><a href="#LASSO-Regression" class="headerlink" title="LASSO Regression"></a>LASSO Regression</h2><p>LASSO (Least Absolute Shrinkage and Selection Operator)</p><h2 id="Ridge-Regression"><a href="#Ridge-Regression" class="headerlink" title="Ridge Regression"></a>Ridge Regression</h2><p>$$<br>\sum_{i=1}^N\parallel \hat{\boldsymbol w}^\top x_i-y_i\parallel^2+\lambda \hat{\boldsymbol w}^\top\hat{\boldsymbol w}<br>$$<br>最优解<br>$$<br>\hat{\boldsymbol w}^* = (\mathbf X^\top \mathbf X + \lambda \mathbf I)^{-1}\mathbf X^\top\boldsymbol y<br>$$</p><h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><p>假设我们线性回归的对象不是标签，而是关于标签的一个函数$g(y)$，<br>$$<br>g(y)=w^\top x+b<br>$$<br>取反函数得到<br>$$<br>y=g^{-1}(w^\top x+b)<br>$$<br>我们就得到了广义线性模型，可以将线性回归适用到更广的情形</p><h2 id="The-Model-1"><a href="#The-Model-1" class="headerlink" title="The Model"></a>The Model</h2><p>将线性回归的输出值与标签$y$联系起来，最直观的想法是使用一个单位阶跃函数：<br>$$<br>y=\begin{cases}0, &amp;z&lt;0\<br>0.5, &amp;z=0\<br>1, &amp;z&gt;0\end{cases}<br>$$<br>这样，对于线性回归输出大于$0$的认为是正样本，小于$0$的认为是负样本。不过这样的函数是不可导的，我们可以使用一个替代函数：<br>$$<br>\sigma(z)=\sigma(w^\top x+b)=\frac{1}{1+e^{-(w^\top x+b)}}<br>$$<br>其函数图像如下图所示：</p><img src="https://i.loli.net/2020/09/14/xa6QIhbGi4eCog1.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>该函数被称为是Sigmoid函数，其导数具有以下性质：<br>$$<br>\sigma^\prime(x)=\sigma(x)(1-\sigma(x))<br>$$<br>其输出在$0-1$之间，可以用作概率解释。</p><p>这样我们就有<br>$$<br>y=\frac{1}{1+e^{-(w^\top x+b)}}<br>$$<br>我们可以通过变换将其写成广义线性模型的形式，即：<br>$$<br>\log \frac{y}{1-y}=w^\top x+b<br>$$<br>从这一层面上可以认为逻辑回归是以“对数几率”为对象的线性回归</p><h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><p>前面我们说过Sigmoid函数的输出在$0-1$之间，可以从概率分布的角度来解释。我们设定Sigmoid为$x$为负例的概率：<br>$$<br>p_w(y=0|x) = \frac{1}{1+e^{-(w^\top x+b)}}<br>$$<br>那么<br>$$<br>p_w(y=1|x)=\frac{e^{-(w^\top x + b)}}{1+e^{-(w^\top x+b)}}<br>$$<br>这样我们实际上是认为$p(y|x)$服从伯努利分布。我们当然是希望参数$w$得到的模型与真实数据的拟合程度越高越好，可以使用极大似然估计来解决。</p><p>似然<br>$$<br>L(w,b) = \prod_{i=1}^N (p_w(y=1|x_i))^{y_i} (1-p_w(y=1|x_i))^{1-y_i}<br>$$<br>对数似然为<br>$$<br>\begin{align}<br>\log L(w,b) &amp;= \log \prod_{i=1}^N (p_w(y=1|x_i))^{y_i} (1-p_w(y=1|x_i))^{1-y_i}<br>\end{align}<br>$$<br>为了方便推导，我们将偏置项$b$与$w$合并起来：<br>$$<br>w^\top x+b\Rightarrow \beta x<br>$$<br>于是<br>$$<br>\begin{align}<br>\log L(\beta) &amp;=\sum_{i=1}^N y_i\log p_\beta(y=1|x_i)+(1-y_i)\log(1-p_\beta(y=1|x_i))\<br>&amp;=\sum_{i=1}^N y_i \log \frac{e^{-\beta x_i}}{1+e^{-\beta x_i}} +(1-y_i)\log \frac{1}{1+e^{-\beta x_i}}\<br>&amp;=\sum_{i=1}^N y_i\log (e^{-\beta x_i} \cdot \frac{1}{1+e^{-\beta x}})+(1-y_i)\log \frac{1}{1+e^{-\beta x}}\<br>&amp; = \sum_{i=1}^N -y_i\beta x_i+y_i \log \frac{1}{1+e^{-\beta x_i}}+\log \frac{1}{1+e^{-\beta x_i}}-y_i \log \frac{1}{1+e^{-\beta x_i}}\<br>&amp;=\sum_{i=1}^N -y_i\beta x_i + \log \frac{1}{1+ e^{-\beta x_i}}\<br>&amp;=\sum_{i=1}^N -y_i\beta x_i - \log(1+ e^{-\beta x_i})<br>\end{align}<br>$$<br>损失函数相当于最小化$\log L(\beta)$的负数：<br>$$<br>\ell (\beta) = \sum_{i=1}^N y_i\beta x_i + \log(1+ e^{-\beta x_i})<br>$$</p><p>损失函数的导数<br>$$<br>\frac{\partial \ell(\beta)}{\partial \beta}=\sum_{i=1}^N x_i(y_i-p_\beta(y=1|x_i))<br>$$<br>二阶导数为<br>$$<br>\frac{\partial^2\ell(\beta)}{\partial\beta\partial\beta^\top}=\sum_{i=1}^N x_ix_i^\top p_\beta(y=0|x)p_\beta(y=1|x)<br>$$</p><h2 id="Optimization-1"><a href="#Optimization-1" class="headerlink" title="Optimization"></a>Optimization</h2>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linear Regression</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Boosting and AdaBoost: Machine Learning Ensemble Algorithms 1</title>
    <link href="/2020/08/26/Boosting-and-AdaBoost-Machine-Learning-Ensemble-Algorithms-1/"/>
    <url>/2020/08/26/Boosting-and-AdaBoost-Machine-Learning-Ensemble-Algorithms-1/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h1><h1 id="AdaBoost-Algorithm"><a href="#AdaBoost-Algorithm" class="headerlink" title="AdaBoost Algorithm"></a>AdaBoost Algorithm</h1><p>给定数据集$X={(x_1,y_1),\cdots,(x_N,y_N)}$，AdaBoost的思想是通过训练一系列弱分类器，并通过线性相加将这些弱分类器组合成强分类器。</p><ol><li>初始化数据的权重分布$D_1$</li><li>在训练数据上使用权重分布$D_m$进行训练，得到基分类器$G_m(x)$</li><li>计算基分类器$G(x)$在训练数据上的误差$e_m$</li><li>计算基分类器$G(x)$的权重$\alpha_m$，可以看出这个权重是与误差$e_m$成反比的，即误差越大，权重越低</li><li>更新训练数据的权重分布$D_{m+1}$，可以看到这个权重是和误差成正比的，即误差大的样本会受到更高的关注</li><li>回到步骤2，直到得到$M$个分类器</li><li>将分类器进行线性组合得到最终分类器</li></ol>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Boosting</tag>
      
      <tag>Adaboost</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GBDT and XGBoost: Machine Learning Ensemble Algorithms 2</title>
    <link href="/2020/08/26/GBDT-and-XGBoost-Machine-Learning-Ensemble-Algorithms-2/"/>
    <url>/2020/08/26/GBDT-and-XGBoost-Machine-Learning-Ensemble-Algorithms-2/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>在学习本文内容之前建议先学习<a href="http://qfxiao.me/2020/09/02/Decision-Tree-Machine-Learning-Classification-Algorithms-3/">决策树相关内容</a>。</p><p>Still working on it😅…</p><p><a href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html" target="_blank" rel="noopener">XGBoost Documentation</a></p><p><a href="https://www.cnblogs.com/pinard/p/6133937.html" target="_blank" rel="noopener">AdaBoost blog</a></p><p><a href="https://www.cnblogs.com/pinard/p/6140514.html" target="_blank" rel="noopener">GBDT blog</a></p><p><a href="http://wepon.me/files/gbdt.pdf" target="_blank" rel="noopener">slide</a></p><p><a href="https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf" target="_blank" rel="noopener">陈天奇slide</a></p><p><a href="https://snaildove.github.io/2018/10/01/8.Booting-Methods_LiHang-Statistical-Learning-Methods/" target="_blank" rel="noopener">blog</a></p><p><a href="https://snaildove.github.io/2018/10/02/get-started-XGBoost/" target="_blank" rel="noopener">blog</a></p><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>实际上，GBDT和梯度下降、XGBoost和牛顿法之间是存在密切关系的，这里我们先回顾一下梯度下降算法和牛顿法的基础知识。</p><h2 id="Taylor-Formulation"><a href="#Taylor-Formulation" class="headerlink" title="Taylor Formulation"></a>Taylor Formulation</h2><p>函数$f(x)$在点$x_0$处的泰勒展开为：<br>$$<br>f(x)=\sum_{n=0}^\infty\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n<br>$$<br>特别的，一阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0)<br>$$<br>二阶展开为：<br>$$<br>f(x)\approx f(x_0)+f^\prime(x_0)(x-x_0) + f^{\prime\prime}(x_0)\frac{(x-x_0)^2}{2}<br>$$<br>迭代形式：假设$x^t=x^{t-1}+\Delta x$，将$f(x)$在$x^{t-1}$处进行泰勒展开<br>$$<br>\begin{align}<br>f(x^t) &amp;= f(x^{t-1}+\Delta x)\<br>&amp;\approx f(x^{t-1})+f^\prime(x^{t-1})\Delta x + f^{\prime\prime}(x^{t-1})\frac{\Delta x^2}{2}<br>\end{align}<br>$$</p><h2 id="Gradient-Descend-Method"><a href="#Gradient-Descend-Method" class="headerlink" title="Gradient Descend Method"></a>Gradient Descend Method</h2><p>设参数$\theta$，那么参数对应的损失函数为$L(\theta)$，</p><p>设当前步数为$t$，那么$t-1$步时的参数为$\theta^{t-1}$，将$L(\theta^t)$在$\theta^{t-1}$处展开得到：</p><p>$$<br>L(\theta^t) \approx L(\theta^{t-1})+ L^\prime(\theta^{t-1})\Delta\theta<br>$$<br>我们想求的$\theta^t=\theta^{t-1}+\Delta \theta$</p><h2 id="Newton’s-Method"><a href="#Newton’s-Method" class="headerlink" title="Newton’s Method"></a>Newton’s Method</h2><p>将$L(\theta^t)$在$\theta^{t-1}$处进行二阶泰勒展开<br>$$<br>\begin{align}<br>L(\theta^t) &amp;= L(\theta^{t-1}+\Delta \theta)\<br>&amp;\approx L(\theta^{t-1})+L^\prime(\theta^{t-1})\Delta \theta + L^{\prime\prime}(\theta^{t-1})\frac{\Delta \theta^2}{2}<br>\end{align}<br>$$<br>记一阶导数和二阶导数分别为$g$和$H$，那么<br>$$<br>L(\theta^t)=L(\theta^{t-1})+g\Delta \theta + H\frac{\Delta \theta^2}{2}<br>$$<br>要使得迭代后的结果尽量小，即$g\Delta \theta + H\frac{\Delta \theta^2}{2}$尽量小，那么有$\frac{\left(g\Delta \theta + H\frac{\Delta \theta^2}{2}\right)}{\partial\Delta\theta}=0$</p><p>求得$\Delta \theta=H^{-1}g$，故$\theta^{t}=\theta^{t-1}+\Delta \theta=\theta^{t-1}-\frac{g}{h}$。如果$\theta$是一个向量，那么$\theta^{t}=\theta^{t-1}-H^{-1}g$，这里$H$为海森矩阵。</p><h1 id="Gradient-Boosting-Decision-Tree-GBDT"><a href="#Gradient-Boosting-Decision-Tree-GBDT" class="headerlink" title="Gradient Boosting Decision Tree (GBDT)"></a>Gradient Boosting Decision Tree (GBDT)</h1><p>我们首先来看基于树的Boosting模型中，非常经典的梯度提升树 (Gradient Boosting Decision Tree)。</p><h2 id="The-Additive-Model"><a href="#The-Additive-Model" class="headerlink" title="The Additive Model"></a>The Additive Model</h2><p>首先GBDT是一个加法模型，即最终模型由一系列树模型乘以对应权重相加得来：<br>$$<br>F_T(x;w)=\sum_{t=0}^T\alpha_t h_t(x;w_t)=\sum_{t=0}^T f_t(x;w_t)<br>$$<br>我们的目标是使得$F$的损失函数最小化：<br>$$<br>F_T^*=\mathop{\arg\min}\limits_{F}\sum_{i=1}^N L(y_i, F_T(x_i;w))<br>$$</p><p>直接优化这个损失函数复杂度是很高的，GBDT实际上运用了一种类似贪心的策略来优化这个函数，将优化过程分解成了迭代的步骤。</p><p>回想梯度下降算法进行优化的步骤，我们有参数$\theta$，损失函数$L(\theta)$是$\theta$的函数，我们希望找到最优的$\theta^<em>$使得$L(\theta^</em>)$最小，于是我们使用了迭代优化的步骤。假设迭代执行到第$t$步，也就是说我们现在的参数$\theta^{t-1}$为前面$t-1$步增量之和：$\theta^{t-1}=\sum_{j=1}^{t-1}\Delta \theta_j$，每一步的增量记为$\Delta \theta_t$。当前的增量$\Delta \theta_{t}$是怎么计算得到的呢？大家都知道是采用的损失函数在$\theta^{t-1}$的负梯度乘以一个步长，即$\Delta \theta_t=-\alpha_t \frac{\partial L(\theta)}{\partial \theta^{t-1}}$。</p><p>梯度下降相当于是在参数空间$\theta$找到最合适的参数$\theta^<em>$使得损失函数$L(\theta)$最小化，如果我们把模型$F_T$看作是函数空间，我们的目的是在函数空间中找到最优的$F_T^</em>$使得损失函数最小化，在这一个角度上GBDT和梯度下降就统一起来了。每一步的基模型$f_t$就相当于梯度下降中的增量$\Delta \theta$，所以我们就得到了GBDT每一的优化目标，即损失函数$L$对于$F_{t-1}$的负梯度。</p><table><thead><tr><th></th><th>梯度下降</th><th>GBDT</th></tr></thead><tbody><tr><td>损失函数</td><td>$L(\theta)$</td><td>$L(F_t)$</td></tr><tr><td>参数</td><td>$\theta^t$</td><td>$F_t$</td></tr><tr><td>增量</td><td>$\Delta \theta_t=-\alpha_t g_t$</td><td>$f_t=-\alpha_t g_t$</td></tr><tr><td>步长</td><td>$\alpha_t$</td><td>$\alpha_t$</td></tr><tr><td>初始值</td><td>$\theta_0$</td><td>$f_0$</td></tr></tbody></table><h2 id="Gradient-Boosting-Tree-for-Regression"><a href="#Gradient-Boosting-Tree-for-Regression" class="headerlink" title="Gradient Boosting Tree for Regression"></a>Gradient Boosting Tree for Regression</h2><p>我们先来讨论GBDT解决回归问题的算法。前面我们已经讨论过，在每一步GBDT的优化目标是损失函数的负梯度，那么现在的问题就是如何求得每一步最优的基模型（GBDT的基模型选用的是CART）。GBDT的算法步骤如下：</p><blockquote><p><strong>Gradient Boosting Tree Algorithm</strong></p><p>INPUT: 训练样本${(x_1,y_1),\cdots,(x_m,y_m)}$，迭代轮数$T$，损失函数$L$</p><p>OUTPUT: 强模型$F_T$</p><ol><li>初始化弱学习器$f_0$，直接使用一个基模型在训练集上进行训练</li><li>在步骤$t=1…T$，对于每个样本计算负梯度$r_{ti}=\left[\frac{\partial L(y_i,F_{t-1}(x_i))}{\partial F_{t-1}}\right]$</li><li>在$(x_i,r_{ti})$上训练得到一个CART回归树，确定树的结构</li><li>假设一共有$J$个叶子节点，那么对每个叶子节点计算最佳输出值$c_{tj}=\mathop{\arg\min}\limits_{c_{tj}}\sum_{x_i\in R_{tj}} L(y_i,F_{t-1}(x_i)+c_{tj})$（其中$c_{tj}$代表第$j$个叶子的输出，$R_{tj}$代表第$j$个叶子对应的样本集合），确定每个叶子节点的输出</li><li>更新强学习器$F_t=F_{t-1}+f_t$，回到步骤2直到达到迭代轮数</li><li>最终得到强学习器的表达式：$f(x)=f_0(x)+\sum\limits_{t=1}^T\sum\limits_{j=1}^J c_{tj}\mathrm I(x\in R_{tj})$</li></ol></blockquote><p>于是我们就得到了最终模型$F_T$。</p><h2 id="Gradient-Boosting-Tree-for-Classification"><a href="#Gradient-Boosting-Tree-for-Classification" class="headerlink" title="Gradient Boosting Tree for Classification"></a>Gradient Boosting Tree for Classification</h2><p>在处理分类任务时，由于输出是离散的值</p><p>一种方法是使用指数损失函数，此时GBDT退化为AdaBoost；另一种方法是借鉴逻辑回归的方法，去建模真实值的概率</p><h3 id="Binary-Classification"><a href="#Binary-Classification" class="headerlink" title="Binary Classification"></a>Binary Classification</h3><h3 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h3><h2 id="GBDT-Sumarry"><a href="#GBDT-Sumarry" class="headerlink" title="GBDT Sumarry"></a>GBDT Sumarry</h2><p>优点：</p><ol><li>可以灵活处理</li><li>相对SVM，调参较少</li><li>使用某些损失函数对异常值的鲁棒性高</li></ol><p>缺点：</p><ol><li>难以并行训练</li></ol><h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p>前面我们讲了梯度下降和牛顿法，刚才又讨论了GBDT和梯度下降的关系，那么XGBoost是否和牛顿法有什么关系呢？答案是肯定的。GBDT利用了损失函数在$F_{t-1}$的一阶展开（即一阶导数信息），而XGBoost则利用了损失函数在$F_{t-1}$的二阶展开，这也是XGBoost和GBDT最根本的区别。下面我们将详细讲解XGBoost算法。</p><table><thead><tr><th></th><th>牛顿法</th><th>XGBoost</th></tr></thead><tbody><tr><td>损失函数</td><td>$L(\theta)$</td><td>$L(F_t)$</td></tr><tr><td>参数</td><td>$\theta^t$</td><td>$F_t$</td></tr><tr><td>增量</td><td>$\Delta \theta_t=-\alpha_t H^{-1}_tg_t$</td><td>$f_t=-\alpha_t H^{-1}_tg_t$</td></tr><tr><td>步长</td><td>$\alpha_t$</td><td>$\alpha_t$</td></tr><tr><td>初始值</td><td>$\theta_0$</td><td>$f_0$</td></tr></tbody></table><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>XGBoost相比GBDT的另一大改进是加入了正则化项，即控制每个树的复杂度。衡量树的复杂度的度量有很多，XGBoost采用的是每棵树叶子节点的个数$T$和每个叶子节点输出$w$的平方和：<br>$$<br>\Omega(f)=\gamma T+\frac{1}{2}\lambda\parallel w\parallel^2<br>$$</p><p>这一步主要是为了进一步降低每个弱学习器的方差。</p><h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>加上正则项之后总的损失函数变为：<br>$$<br>L=\sum_{i=1}^N \ell(y_i, F_T(x_i))+\Omega(F_T)<br>$$<br>和GBDT类似，我们来推导第$t$步的优化公式，对于第$t$步，我们的损失函数为：<br>$$<br>\begin{align}<br>L_t&amp;=\sum_{i=1}^N \ell(y_i,F_t(x_i))+\Omega(F_t)\<br>&amp;=\sum_{i=1}^N \ell(y_i, F_{t-1}(x_i) + f_t(x_i))+\Omega(F_t)<br>\end{align}<br>$$<br>将损失函数在$F_{t-1}$处进行二阶泰勒展开，得到<br>$$<br>L_t \approx \left[\sum_{i=1}^N \ell(y_i, F_{t-1}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(F_t)<br>$$<br>其中$g_i=\frac{\partial \ell(y_i, F_{t-1})}{\partial F_{t-1}}$，$h_i=\frac{\partial \ell(y_i, F_{t-1}) ^2}{\partial^2 F_{t-1}}$，分别代表损失函数对$F_{t-1}$的一阶导和二阶导。</p><p>由于我们要优化的是本轮的基模型$f_t$，$\ell(y_i, F_{t-1})$已经是固定的了，相当于常数，把常数项去掉，得到：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \Omega(f_t)\<br>&amp;=\left[\sum_{i=1}^N  g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i) \right] + \gamma T + \frac{1}{2}\lambda \parallel w \parallel^2<br>\end{align}<br>$$<br>我们都知道样本$x_i$在树$f_t$上的输出取决于$x_i$在哪个叶子节点。假设树$f_t$一共有$J$个叶节点，记$q(x_i)=j$代表样本$x_i$经过决策树对应的叶节点是$j$，$I_j$代表叶子节点$j$的所有样本下标集合，$w_j$代表叶子节点$j$的输出，我们可以将损失函数改写为：<br>$$<br>\begin{align}<br>\tilde L_t &amp;= \sum_{j=1}^J\left[\sum_{i\in I_j}g_i w_j+\frac{1}{2}(\sum_{i\in I_j}h_i +\lambda)w_j^2\right]+\gamma T\<br>&amp;= \sum_{j=1}^J\left[G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2 \right] + \gamma T<br>\end{align}<br>$$<br>其中$G_j=\sum_{i\in I_j}g_i$和$H_j=\sum_{i\in I_j}h_i$为简记，分别代表损失函数在叶子节点$j$对应的所有样本上的一阶导之和与二阶导之和。</p><p>到现在，我们还剩两个问题需要解决，一个是确定树$f_t$的最优结构，也就是怎么去分裂节点，另一个是确定每个叶子节点的最优输出。我们可以先确定下一个问题，找到另一个问题的最优答案，再来确定剩下的问题。</p><p>这里先去寻找树$f_t$每一个叶子节点对应的最优输出。和牛顿法的推导类似，为了使损失函数下降的最快，我们令$G_j w_j + \frac{1}{2}(H_j+\lambda)w_j^2$的导数为$0$，得到：<br>$$<br>w_j^<em>=-\frac{G_j}{H_j + \lambda}<br>$$<br>加上正则项有：<br>$$<br>\tilde L_t^</em>=-\frac{1}{2}\sum_{j=1}^J\frac{G_j^2}{H_j+\lambda}+\gamma T<br>$$</p><h2 id="Splitting-Strategy"><a href="#Splitting-Strategy" class="headerlink" title="Splitting Strategy"></a>Splitting Strategy</h2><p>现在来确定树$f_t$的最优结构。最优结构的确定实际上使用了一种类似贪心的策略，和决策树类似，我们从一个只有根节点的树出发（所有样本都在根节点这一叶子节点上），不断分裂节点来降低$\tilde L_t^*$。在每一步的分裂中，我们会希望$\frac{G_j^2}{H_j+\lambda}$越大越好，于是：<br>$$<br>Gain = \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda} - \frac{(G_L+G_R)^2}{H_L+H_R+\lambda} - \gamma<br>$$</p><p>我们希望挑选能使得$Gain$最大的特征和特征分裂点，而选择的策略又有很多种，下面介绍三种。</p><h3 id="Exact-Greedy-Algorithm-for-Split-Finding"><a href="#Exact-Greedy-Algorithm-for-Split-Finding" class="headerlink" title="Exact Greedy Algorithm for Split Finding"></a>Exact Greedy Algorithm for Split Finding</h3><p>最简单的方法是枚举所有特征，然后对于这个特征下的所有可能取值进行排序，然后遍历分裂点，找到使得$gain$最高的那个。这样做的好处是找到的分裂点确定是最好的，不过坏处是时间复杂度过高。</p><h3 id="Approximate-Algorithm-for-Split-Finding"><a href="#Approximate-Algorithm-for-Split-Finding" class="headerlink" title="Approximate Algorithm for Split Finding"></a>Approximate Algorithm for Split Finding</h3><p>一个比较容易想到的优化方案是不去遍历所有可能的分裂点，而是只考察其中的分位数，如下图展示了三分位数方法：</p><p><img src="https://i.loli.net/2020/09/10/HoPR9XlpZSm1Gju.png" srcset="/img/loading.gif" alt=""></p><p>这样需要考察的点就大大减少。</p><p>同时分位数的选择由有global和local之分，global是指在训练之前我们就可以提前对每个特征的分位数进行预处理，local是指每次分裂前计算分位数点。直观上来说global需要更多的分位点数，而local则需要更多的计算量。</p><p>实际上，XGBoost还会使用二阶导信息$h_i$对样本进行夹权，如下图所示：</p><p><img src="https://i.loli.net/2020/09/15/nxloKNmTHwJRqI9.png" srcset="/img/loading.gif" alt=""></p><h3 id="Sparsity-aware-Split-Finding"><a href="#Sparsity-aware-Split-Finding" class="headerlink" title="Sparsity-aware Split Finding"></a>Sparsity-aware Split Finding</h3><p>稀疏感知分裂算法 (Sparsity-aware Split Finding) </p><h2 id="Other-Features"><a href="#Other-Features" class="headerlink" title="Other Features"></a>Other Features</h2><p>除了上面提到的之外，XGBoost还有很多工程优化。</p><h3 id="Block-Structure-and-Parallelism"><a href="#Block-Structure-and-Parallelism" class="headerlink" title="Block Structure and Parallelism"></a>Block Structure and Parallelism</h3><p>XGBoost预先对特征进行了排序，</p><p>每个特征的增益的计算可以并行进行</p><h3 id="Column-Sample"><a href="#Column-Sample" class="headerlink" title="Column Sample"></a>Column Sample</h3><p>借鉴随机森林，即每次只用一部分特征进行特征选择，进一步降低过拟合</p><h3 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h3><p>在每次迭代会对叶子节点的权总乘以一个系数，让后面的树有更大的学习空间。</p><h3 id="Custom-Loss-Function"><a href="#Custom-Loss-Function" class="headerlink" title="Custom Loss Function"></a>Custom Loss Function</h3><h3 id="Missing-Values"><a href="#Missing-Values" class="headerlink" title="Missing Values"></a>Missing Values</h3><h1 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h1>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GBDT</tag>
      
      <tag>XGBoost</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unsupervised Representation Learning by Predicting Random Distances</title>
    <link href="/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/"/>
    <url>/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>针对高维表格数据的表示学习，作者提出了基于预测预计变换后的距离的无监督表示学习框架RDP，并进行了理论上的讨论。To be finished…</p><p><a href="https://arxiv.org/abs/1912.12186" target="_blank" rel="noopener">论文地址</a>         <a href="https://github.com/billhhh/RDP" target="_blank" rel="noopener">代码地址</a></p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Random-Distance-Prediction-Model"><a href="#Random-Distance-Prediction-Model" class="headerlink" title="Random Distance Prediction Model"></a>Random Distance Prediction Model</h2><p>对于很多下游任务来说，高维数据对模型效率和性能都很大，所以学习低维的有意义（能够最大限度保存原始空间的信息）的表示十分重要。本文的大致思想是给定一个确定的随机映射将样本映射到一个新的空间，然后构造数据集，输入时任意一对样本，标签是两个样本在新的空间的距离，之后训练一个模型来学习这个距离。作者认为通过该任务的训练，模型能够学到有意义的低维表示。模型的框架如下图：</p><img src="https://i.loli.net/2020/07/19/vRV32EgLiYkWaQN.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>其中$\phi(\mathbf x;\Theta):\mathbb R^D\mapsto\mathbb R^M$为孪生神经网络（Siamese Neural Network），将数据映射到$M$的新空间。损失函数为：</p><p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=l(\langle \phi(\mathbf x_i;\Theta),\phi(\mathbf x_j;\Theta)\rangle,\langle\eta(\mathbf x_i),\eta(\mathbf x_j)\rangle)<br>$$</p><p>其中$\eta(\cdot)$为已知的映射，$l(\cdot)$为衡量两个输入相似程度的度量。具体的来说，文中选取了简单的实现方案，即采用内积作为映射后的样本的距离度量：</p><p>$$<br>\mathcal L_{rdp}(\mathbf x_i,\mathbf x_j)=\left(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)\right)^2<br>$$</p><p>$\eta(\cdot)$为现成的映射。至于为什么要这么做，可以先接着看下面原文给出的理论分析，然后我再说说我自己的理解。</p><h2 id="Incorporating-Task-Dependent-Complementary-Auxiliary-Loss"><a href="#Incorporating-Task-Dependent-Complementary-Auxiliary-Loss" class="headerlink" title="Incorporating Task-Dependent Complementary Auxiliary Loss"></a>Incorporating Task-Dependent Complementary Auxiliary Loss</h2><p>对于特定的下游任务，作者提出可以整合额外的误差函数来提高模型行性能。比如说针对聚类任务可以使用重构误差：</p><p>$$<br>\mathcal L_{aux}^{clu}(\mathbf x)=(\mathbf x-\phi^\prime(\phi(\mathbf x;\Theta); \Theta^\prime))^2<br>$$</p><p>其中$\phi(\cdot)$和$\phi^\prime(\cdot):\mathbb R^M\mapsto\mathbb R^D$分别为编码器和解码器。</p><p>对于异常检测任务，可以使用下式：<br>$$<br>\mathcal L_{aux}^{ad}(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2<br>$$</p><p>这一个Loss本来是出现在强化学习的论文中，用来检测一个状态$\mathbf x$出现的频率，如果预测误差较小，说明这个样本之前见过或见过类似的，否则没怎么见过，可以认为是异常。由于本文的目的主要是降维加保留原始空间信息，可以认为使用线性变换的话此目的已经达到了。</p><h2 id="Theoretical-Analysis"><a href="#Theoretical-Analysis" class="headerlink" title="Theoretical Analysis"></a>Theoretical Analysis</h2><h3 id="Using-Linear-Projection"><a href="#Using-Linear-Projection" class="headerlink" title="Using Linear Projection"></a>Using Linear Projection</h3><p>这里讨论使用线性映射的情况，设数据集$\mathcal X\subset\mathbb R^{N\times D}$，映射矩阵$\mathbf A\subset\mathbb R^{K\times D}$为一随机矩阵，映射之后的数据为$\mathbf A\mathcal X^\top$。对于$\epsilon\in(0,\frac{1}{2})$和$K=\frac{20\log n}{\epsilon^2}$，存在$f:\mathbb R^D\mapsto\mathbb R^K$使得对于所有的$\mathbf x_i,\mathbf x_j\in\mathcal X$有：</p><p>$$<br>(1-\epsilon)\parallel\mathbf x_i-\mathbf x_j \parallel^2\leq \parallel f(\mathbf x_i)-f(\mathbf x_j)\parallel^2\leq (1+\epsilon)\parallel\mathbf x_i-\mathbf x_j\parallel^2<br>$$</p><p>如果$\mathbf A$的每个元素独立采样自标准正态分布那么有：</p><p>$$<br>\text{Pr}\left((1-\epsilon)\parallel\mathbf x\parallel^2\leq\parallel\frac{1}{\sqrt{K}}\mathbf A\mathbf x\parallel^2\leq(1+\epsilon)\parallel\mathbf x\parallel^2\right)\geq 1-2e^{\frac{-(\epsilon^2-\epsilon^3)K}{4}}<br>$$</p><p>在该随机映射下有：</p><p>$$<br>\text{Pr}(|\hat{\mathbf x}_i\cdot\hat{\mathbf x}_j-f(\hat{\mathbf x}_i)\cdot f(\hat{\mathbf x}_j)|\geq\epsilon)\leq 4e^{\frac{-(\epsilon^2-\epsilon^3)\cdot K}{4}}<br>$$</p><p>直观的解释就是说使用线性映射的情况下，只要使用的变换矩阵采样自标准正态分布，那么变换之后样本对之间的距离信息能够以一定的概率保留。</p><h3 id="Using-Non-Linear-Projection"><a href="#Using-Non-Linear-Projection" class="headerlink" title="Using Non-Linear Projection"></a>Using Non-Linear Projection</h3><p>这里作者试图说明，在某些条件下，非线性随机映射的作用和核函数接近。对于一个确定的随机映射函数$g:\mathbb R^D\mapsto\mathbb R^K$，在某些特定的条件下，函数$g$和核函数存在下列关系：</p><p>$$<br>k(\mathbf x_i,\mathbf x_j)=\langle\psi(\mathbf x_i),\psi(\mathbf x_j)\rangle\approx g(\mathbf x_i)\cdot g(\mathbf x_j)<br>$$</p><p>这个条件是函数$g$为一个乘以一个线性矩阵$\mathbf A$然后在经过一个具备平移不变性的傅里叶基函数（如cosine）。由于核函数能够保留原始空间的信息，所以作者认为使用非线性函数也能保留原始空间的信息。</p><blockquote><p>PS: 感觉作者在理论部分的讨论还是有点模糊，因为把一个随机的映射作为（伪）监督信息来进行学习，神经网络学到的不也就是随机噪声信息吗？对于这个方法work的原因，我在这里不负责任的分析一下。</p></blockquote><h3 id="Learning-Class-Structure-by-Random-Distance-Prediction"><a href="#Learning-Class-Structure-by-Random-Distance-Prediction" class="headerlink" title="Learning Class Structure by Random Distance Prediction"></a>Learning Class Structure by Random Distance Prediction</h3><p>这一节主要解释为什么神经网络$\phi(\cdot)$学到的要比随机映射$\eta(\cdot)$要好。模型的优化目标可以写成如下的形式：</p><p>$$<br>\mathop{\arg\min}<em>{\Theta}\sum</em>{\mathbf x_i,\mathbf x_j\in\mathcal X}(\phi(\mathbf x_i;\Theta)\cdot\phi(\mathbf x_j;\Theta)-y_{ij})^2<br>$$</p><p>其中$y_{ij}=\eta(\mathbf x_i)\cdot\eta(\mathbf x_j)$。设$\mathbf Y_\eta\in\mathbb R^{N\times N}$为距离矩阵。这个目标函数是在最小化每一对样本在经过$\phi(\cdot)$和$\eta(\cdot)$映射后之间的距离的差距。通过公式(7)和公式(8)我们知道，在合适的条件下，随机映射$\eta(\cdot)$能够保留原始空间的距离信息（即原始空间相近的样本在映射后也相近）。不过，上述公式的成立都依赖于对数据分布的一定假设，当真实的数据不满足条件时，结论就会有所偏差。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Performance-Evaluation-in-Anomaly-Detection"><a href="#Performance-Evaluation-in-Anomaly-Detection" class="headerlink" title="Performance Evaluation in Anomaly Detection"></a>Performance Evaluation in Anomaly Detection</h2><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/3G7DNKjwfQkiIz4.png" srcset="/img/loading.gif" alt=""></p><p>异常分数定义为$\mathcal S(\mathbf x)=(\phi(\mathbf x;\Theta)-\eta(\mathbf x))^2$。</p><h3 id="Comparison-to-the-State-of-the-art-Competing-Methods"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/8Ie2Q3mpdPHtrYF.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/07/20/OEcQSvZmfBz1ACt.png" srcset="/img/loading.gif" alt=""></p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p><img src="https://i.loli.net/2020/07/20/7GtKlN8q5Mvygre.png" srcset="/img/loading.gif" alt=""></p><h2 id="Performance-Evaluation-in-Clustering"><a href="#Performance-Evaluation-in-Clustering" class="headerlink" title="Performance Evaluation in Clustering"></a>Performance Evaluation in Clustering</h2><h3 id="Experimental-Settings-1"><a href="#Experimental-Settings-1" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><img src="https://i.loli.net/2020/07/20/9xW12MVkoXgFZ6J.png" srcset="/img/loading.gif" alt=""></p><h3 id="Comparison-to-the-State-of-the-art-Competing-Methods-1"><a href="#Comparison-to-the-State-of-the-art-Competing-Methods-1" class="headerlink" title="Comparison to the State-of-the-art Competing Methods"></a>Comparison to the State-of-the-art Competing Methods</h3><p><img src="https://i.loli.net/2020/07/20/pUZ64aX1xWiLf2q.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/07/20/VrnXuJsymiMItUf.png" srcset="/img/loading.gif" alt="image-20200720014002063"></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Representation Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Representation Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Effective End-to-end Unsupervised Outlier Detection via Linear Priority of Discriminative Network</title>
    <link href="/2020/07/14/Effective-End-to-end-Unsupervised-Outlier-Detection-via-Linear-Priority-of-Discriminative-Network/"/>
    <url>/2020/07/14/Effective-End-to-end-Unsupervised-Outlier-Detection-via-Linear-Priority-of-Discriminative-Network/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文针对无监督异常检测提出了$E^3\space{Outlier}$。作者使用自监督学习的方法，通过构建有监督任务在没有标签的情况下学习高层语义特征。PS：这篇文章的方法和NIPS18上的<em>Deep Anomaly Detection Using Geometric Transformations</em>（后面简称GEOM）颇为相似，但是不知为啥没有在实验中进行比较。后面我会分析一些两篇文章方法上的异同。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Surrogate-Supervision-Based-Effective-Representation-Learning-for-UOD"><a href="#Surrogate-Supervision-Based-Effective-Representation-Learning-for-UOD" class="headerlink" title="Surrogate Supervision Based Effective Representation Learning for UOD"></a>Surrogate Supervision Based Effective Representation Learning for UOD</h2><p>这里作者提到了使用重构的模型来进行异常检测的不足：重构模型采用像素级别的损失函数（如mean square error），而这太过于严格和细节，并不能学到高层语义特征。</p><p>为此，作者提出了<em>surrogate supervision based discriminative network</em> (SSD)。具体操作和GEOM类似，首先预定义大小为$K$的几何变换集合$\mathcal O={O(\cdot|y)}<em>{y=1}^K$。对每一个样本$\mathbf x$，在经过$K$个集合变换之后会得到$K$个变换后的样本（第$y$个变换产生的样本即记为$\mathbf x^{(y)}=O(\mathbf x|y)$），每个样本对应的pseudo label即为变换的序号或者说种类。之后在新的数据集上（大小为原来的$K$倍）训练$K$分类网络。网络的输出为$P(\mathbf x^{(y^\prime)}|\boldsymbol\theta)=[P^{(y)}(\mathbf x^{(y^\prime)}|\boldsymbol\theta)]</em>{y=1}^K$，每个维度代表输入样本对应的变换的概率。总的损失函数为：<br>$$<br>\min_\theta\frac{1}{N}\sum_{i=1}^{N}\mathcal L_{SS}(\mathbf x_i|\theta)<br>$$</p><p>其中$\mathcal L_{SS}(\mathbf x_i|\theta)$代表每个样本对应的Loss，这个Loss可以由分类器在$K$个变换上的交叉熵损失来确定：</p><p>$$<br>\mathcal L_{SS}(\mathbf x_i|\boldsymbol\theta)=-\frac{1}{K}\sum_{y=1}^K\log(P^{(y)}(\mathbf x_i^{(y)}|\boldsymbol\theta))=-\frac{1}{K}\sum_{y=1}^K\log(P^{(y)}(O(\mathbf x_i|y)|\boldsymbol\theta))<br>$$<br><img src="https://i.loli.net/2020/07/14/ULAdYpzsoGfFwtD.png" srcset="/img/loading.gif" alt=""></p><p>变换集合$\mathcal O$由一系列基本变换的组合确定。作者将这些基本变换分为了：1) 旋转 2) 翻转 3) 平移，包括横向和纵向 4) Patch置换（参考图1(a)中的Patch Re-arranging）。最终的变换集合$\mathcal O$由三个子集组成，分别是$\mathcal O_{RA}$（代表Regular Affine，其中每个变换为旋转$90°$的倍数、翻转、横向平移和纵向平移这四个基本变换的叠加），$\mathcal O_{IA}$（代表Irregular Affine，其中每个变换为进行$30°$的倍数且不为$90°$的倍数角度的旋转、翻转这两个基本变换的叠加）和$\mathcal O_{PR}$（只包含Patch Re-arranging）。</p><p>为了验证SSD学到的特征的有效性，作者将CAE提取的特征和SSD提取的特征分别用孤立森林进行异常检测，发现SSD效果更好（见图1(b)）。</p><p>到这里为止本文和GEOM基本没有大的区别。值得注意的是在所采用的几何变换中，采用了非线性变换（进行$30°$的倍数且不为$90°$的倍数角度的旋转）。而在GEOM中，提到过使用非线性变换的话效果会比较差，至于具体的影响如何，可能需要实验来确定。</p><h2 id="Inlier-Priority-The-Foundation-of-End-to-end-UOD"><a href="#Inlier-Priority-The-Foundation-of-End-to-end-UOD" class="headerlink" title="Inlier Priority: The Foundation of End-to-end UOD"></a>Inlier Priority: The Foundation of End-to-end UOD</h2><p>在这里作者主要对在训练集包含少量异常的情况下做出的理论分析，作者将其称为<em>Inlier Priority</em>，原句如下：</p><blockquote><p><em>Inlier Priority</em>: Despite that inliers/outliersare indiscriminately fed into SSD for training, SSD will prioritize the minimization of inliers’ loss.</p></blockquote><h3 id="Priority-by-Gradient-Magnitude"><a href="#Priority-by-Gradient-Magnitude" class="headerlink" title="Priority by Gradient Magnitude"></a>Priority by Gradient Magnitude</h3><p>对于第$c$个类来说，设<code>softmax</code>层和倒数第二层之间的权重矩阵为$\mathbf w_c=[w_{s,c}]^{(L+1)}<em>{s=1}$，损失函数记为$\mathcal L$，梯度记为$\nabla</em>{\mathbf w_c}\mathcal L=[\nabla_{w_{s,c}}\mathcal L]^{(L+1)}<em>{s=1}$。设训练集$X^{(c)}$包含$N</em>{in}$个正常样本，$N_{out}$个异常样本。记正常样本和异常样本对应的梯度分别为$\parallel\nabla^{(in)}<em>{\mathbf w_c}\mathcal L\parallel$和$\parallel\nabla^{(out)}</em>{\mathbf w_c}\mathcal L\parallel$，在网络只有一个隐层且采用<code>Sigmoid</code>作为激活函数时，两者梯度的期望之比有如下关系：</p><p>$$<br>\frac{E(\parallel\nabla^{(in)}<em>{\mathbf w_c}\mathcal L\parallel^2)}{E(\parallel\nabla^{(out)}</em>{\mathbf w_c}\mathcal L\parallel^2)}\approx\frac{N^2_{in}}{N^2_{out}}<br>$$</p><p>在训练集中，正常样本和异常样本的数量是极不均衡的，$N_{in}\gg N_{out}$，所以有$E(\parallel\nabla^{(in)}<em>{\mathbf w_c}\mathcal L\parallel^2)\gg E(\parallel\nabla^{(out)}</em>{\mathbf w_c}\mathcal L\parallel^2)$。</p><p>在使用更复杂的网络时，作者通过实验展示了正常样本和异常样本对应的梯度大小的比较：</p><p><img src="https://i.loli.net/2020/07/16/iPa7h9HWqrnZvgx.png" srcset="/img/loading.gif" alt=""></p><h3 id="Priority-by-Network-Updating-Direction"><a href="#Priority-by-Network-Updating-Direction" class="headerlink" title="Priority by Network Updating Direction"></a>Priority by Network Updating Direction</h3><p>这里作者通过梯度更新的方向来进行了理论上的解释。对于一个Batch的数据$X$，梯度为$-\nabla_\theta\mathcal L(X)=-\frac{1}{N}\sum_i\nabla_\theta\mathcal L(\mathbf x_i)$，如果将该梯度在Batch中某一样本$\mathbf x_i$对应的梯度的方向上进行分解$-\nabla_\theta\mathcal L(\mathbf x_i):d_i=-\nabla_\theta\mathcal L(X)\cdot\frac{-\nabla_\theta\mathcal L(\mathbf x_i)}{\parallel -\nabla_\theta\mathcal L(\mathbf x_i)\parallel}$，这代表了总的Loss在多大程度上减小样本$\mathbf x_i$对应的Loss，由于一个Batch即包含正常样本，也可能包含异常样本，所以作者将两者对应的梯度方向贡献进行了可视化：</p><p><img src="https://i.loli.net/2020/07/16/U5fVk8YOEGPx3Q7.png" srcset="/img/loading.gif" alt=""></p><p>可以看到随着训练的进行，正常样本对应的贡献更高。</p><p>PS: 我以为作者会对基于几何变换的异常检测为什么有效做一些理论上的解释，不过却没有。这里只是对在训练集包含少量异常的情况下做出的理论分析，而这个实际上直觉上就很显然了。</p><h2 id="Scoring-Strategies-for-UOD"><a href="#Scoring-Strategies-for-UOD" class="headerlink" title="Scoring Strategies for UOD"></a>Scoring Strategies for UOD</h2><p>作者采用了三种方法来计算异常分数：</p><h3 id="Pseudo-Label-based-Score-PL"><a href="#Pseudo-Label-based-Score-PL" class="headerlink" title="Pseudo Label based Score (PL)"></a>Pseudo Label based Score (PL)</h3><p>对于一个测试样本$\mathbf x$，对其进行$K$个几何变换，通过分类器会得到$K$个输出，对于第$k$个输出，我们只取其第$k$个分量，最后把他们加起来除以$K$：</p><p>$$<br>S_{pl}(\mathbf x)=\frac{1}{K}\sum_{y=1}^K P^{(y)}(\mathbf x^{(y)}|\boldsymbol\theta)<br>$$</p><h3 id="Maximum-Probability-based-Score-MP"><a href="#Maximum-Probability-based-Score-MP" class="headerlink" title="Maximum Probability based Score (MP)"></a>Maximum Probability based Score (MP)</h3><p>这里稍有不同，对于第$k$个输出，我们取其值最大的分量，而不是第$k$个分量：</p><p>$$<br>S_{mp}(\mathbf x)=\frac{1}{K}\sum_{y=1}^K\max_t P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta)<br>$$</p><h3 id="Negative-Entropy-based-Score-NE"><a href="#Negative-Entropy-based-Score-NE" class="headerlink" title="Negative Entropy based Score (NE)"></a>Negative Entropy based Score (NE)</h3><p>作者认为，标签为One-Hot向量，分类器的输出分布越“尖峰”就越接近于正常样本，而越“平均”就越接近于异常样本，所以作者提出使用熵来描述分类器输出的“尖锐度”：<br>$$<br>S_{ne}(\mathbf x)=-\frac{1}{K}\sum_{y=1}^K H(P(\mathbf x^{(y)}|\boldsymbol\theta))=\frac{1}{K}\sum_{y=1}^K\sum_{t=1}^K P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta)\log(P^{(t)}(\mathbf x^{(y)}|\boldsymbol\theta))<br>$$<br>这里作者对第一种方法得到的结果进行了可视化：</p><p><img src="https://i.loli.net/2020/07/16/PgzqXIdJ67s3BtG.png" srcset="/img/loading.gif" alt=""></p><p>PS：对比NIPS18 的Dirichlet Normality Score</p><ol><li>也用到了全部$K$个维度的信息</li><li>相当于对分类器的输出做了迪利克雷分布的先验假设，然后通过训练集的输出估计分布参数。因为直觉上对于正常分布来说，分类器的输出分布形状上都类似一个尖峰，但对于不同的数据集来说具体形状还是会有所差异</li></ol><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Experiment-Setup"><a href="#Experiment-Setup" class="headerlink" title="Experiment Setup"></a>Experiment Setup</h2><p> 数据集用到了MNIST, Fashion-MNIST (F-MNIST) , CIFAR10, SVHN和CIFAR100。为了模拟无监督异常检测的环境，人为在训练集中加入异常样本，异常的比例$\rho$从$5%$到$25%$以$5%$的步长递增。评测标准采用AUPR和AUROC。</p><h2 id="UOD-Performance-Comparison-and-Discussion"><a href="#UOD-Performance-Comparison-and-Discussion" class="headerlink" title="UOD Performance Comparison and Discussion"></a>UOD Performance Comparison and Discussion</h2><p>下表展示了模型性能对比结果：</p><p><img src="https://i.loli.net/2020/07/16/G3agKPuJBowFmIW.png" srcset="/img/loading.gif" alt=""></p><p>下图展示了在不同的Outlier Ratio下的性能对比：</p><p><img src="https://i.loli.net/2020/07/16/h6iYjBkrwQdFvMJ.png" srcset="/img/loading.gif" alt=""></p><p>下图展示了在不同的变换集合，网络结构，异常分数的条件下的性能：</p><p><img src="https://i.loli.net/2020/07/16/waWAi7zI3QpOcf6.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Self-Supervised Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PRML Notes 1.1: Probability Distributions - Binary and Multinomial Variables</title>
    <link href="/2020/06/22/PRML-Notes-1-1-Probability-Distributions-Binary-and-Multinomial-Variables/"/>
    <url>/2020/06/22/PRML-Notes-1-1-Probability-Distributions-Binary-and-Multinomial-Variables/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>这是PRML (Pattern Recognition and Machine Learning) 第二章<code>Probability Distributions</code>笔记的第一部分，主要包括<code>2.1. Binary Variables</code>和<code>2.2. Multinomial Variables</code>这两节。</p><h1 id="Probability-Distributions-for-Binary-Variables"><a href="#Probability-Distributions-for-Binary-Variables" class="headerlink" title="Probability Distributions for Binary Variables"></a>Probability Distributions for Binary Variables</h1><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>这一节主要针对二值随机变量的建模，即$x\in{0,1}$。这里可以想象为我们有一个硬币，$x=1$代表正面朝上，而$x=0$代表反面朝上，并且正面朝上的概率为$\mu$，即：<br>$$<br>p(x=1|\mu)=\mu<br>$$<br>其中$0\leqslant \mu \leqslant 1$。$x$的概率分布可以写为：<br>$$<br>\text{Bern}(x|\mu)=\mu^x(1-\mu)^{1-x}<br>$$<br>也就是我们熟知的<strong>伯努利分布 (Bernoulli Distribution)</strong>。其均值和方差分别为：<br>$$<br>\begin{align}<br>\mathbb E[x]&amp;=\mu\<br>\text{var}[x] &amp;= \mu(1-\mu)<br>\end{align}<br>$$<br>现在来考虑参数估计任务。假设我们正在进行一个投硬币的实验，每一次投币都服从伯努利分布且相互独立，我们将每次采集到的观测值组成数据集$\mathcal D={x_1,\cdots,x_N}$，则似然函数为：<br>$$<br>p(\mathcal D|\mu)=\prod_{n=1}^N p(x_n|\mu)=\prod_{n=1}^N \mu^{x_n}(1-\mu)^{1-x_n}<br>$$<br>如果采用极大似然估计的话，我们可以最大化似然函数，这等价于最大化对数似然：<br>$$<br>\ln p(\mathcal D|\mu)=\sum_{n=1}^{N}\ln p(x_n|\mu)=\sum_{n=1}^N{x_n\ln\mu+(1-x_n)\ln(1-\mu)}<br>$$<br>令其导数为0得到极值点：<br>$$<br>\mu_{ML}=\frac{1}{N}\sum_{n=1}^N x_n<br>$$<br>这相当于样本均值，不过这样做会有严重的问题。假设我们的数据集为$\mathcal D={1,1,1}$，也就是说我们只收集到了三个样本，并且都是正例，我们会得到$\mu_{ML}=1$，而这显然是严重过拟合的。稍后我们会说说如何应对这种情况（加入先验）。</p><h2 id="Binomial-Distribution"><a href="#Binomial-Distribution" class="headerlink" title="Binomial Distribution"></a>Binomial Distribution</h2><p>我们同样可以对多次伯努利实验进行概率建模。记$m$为成功的次数，$N$为数据集大小，可知这个概率应该与$\mu^m(1-\mu)^{N-m}$成正比。乘以标准化系数后即我们熟知的<strong>二项分布 (Binomial Distribution)</strong>：<br>$$<br>\text{Bin}(m|N,\mu)=\binom{N}{m}\mu^m(1-\mu)^{N-m}<br>$$</p><p>其中：<br>$$<br>\binom{N}{m}=\frac{N!}{(N-m)!m!}<br>$$<br>其均值和方差分别为：<br>$$<br>\begin{align}<br>\mathbb E[m]&amp;=N\mu\<br>\text{var}[m]&amp;=N\mu(1-\mu)<br>\end{align}<br>$$</p><h2 id="Beta-Distribution"><a href="#Beta-Distribution" class="headerlink" title="Beta Distribution"></a>Beta Distribution</h2><p>现在我们来讨论如何解决刚才提到的最大似然估计过拟合问题。为了解决这个问题，我们使用贝叶斯的思路，对$\mu$引入了先验分布$p(\mu)$。而这个分布需要具有良好的解释性和数学性质。</p><p>根据贝叶斯定理：<br>$$<br>p(\mu|\mathcal D)=\frac{p(\mathcal D|\mu)p(\mu)}{p(\mathcal D)}<br>$$<br>而$p(\mathcal D)=\int_0^1 p(\mathcal D|\mu)p(\mu)\mathrm d\mu$只受数据集影响，而数据集是固定的，所以为常数，因此$p(\mu|\mathcal D)\propto p(\mathcal D|\mu)p(\mu)$。而似然函数为$\mu^x(1-\mu)^{1-x}$的乘积，如果先验也采用$\mu$和$1-\mu$的幂的乘积的形式，那么后验分布也将和先验形式相同，这种性质在统计学中被称为<strong>先验共轭 (conjugacy)</strong>。</p><p>这里我们直接给出这个先验分布，再来分析它的性质。这个分布叫做<strong>Beta分布 (Beta Distribution)</strong>$P(\mu|a,b)\sim \text{Beta}(a,b)$：<br>$$<br>\begin{align}<br>\text{Beta}(\mu|a,b) &amp;= \frac{\Gamma(a+b)}{\Gamma(a\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\ &amp;= \frac{1}{B(a,b)}\mu^{a-1}(1-\mu)^{b-1}<br>\end{align}<br>$$<br>$B(\boldsymbol \alpha,\beta)$称为B函数，为一个标准化函数：<br>$$<br>\begin{align}<br>B(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}<br>\end{align}<br>$$<br>其目的是为了使整个概率分布积分等于1而存在的。Gamma函数的定义为：<br>$$<br>\Gamma(x)=\int_0^{\infty}s^{x-1}e^{-s}\mathrm d s<br>$$<br>Gamma函数有一个性质：</p><p>$$<br>\Gamma(x+1)=x\Gamma(x)<br>$$<br>证明为：<br>$$<br>\begin{align<em>}<br>\Gamma(x+1) &amp;= \int_{0}^{\infty} {s^{x} e^{-s} ds} \<br>&amp;= \big[s^{x} (-e^{-s})\big] \big|<em>{0}^{\infty} - \int</em>{0}^{\infty} {(x s^{x-1}) (-e^{-s}) ds} \<br>&amp;= (0 - 0) + x \int_{0}^{\infty} {s^{x-1} e^{-s} ds} \<br>&amp;= x \Gamma(x)<br>\end{align</em>}<br>$$</p><p>除此之外：</p><p>$$<br>\Gamma(1)=1\<br>\Gamma(\frac{1}{2})=\sqrt{\pi}<br>$$</p><p>可以验证：<br>$$<br>\int_0^1\text{Beta}(\mu|a,b)\mathrm d\mu=1<br>$$</p><p>Beta分布的均值和方差为：</p><p>$$<br>\mathbb E[\mu]=\frac{a}{a+b}\<br>\text{var}[\mu]=\frac{ab}{(a+b)^2(a+b+1)}<br>$$</p><p>因为后验分布与先验和似然函数的乘积成比例，那么：<br>$$<br>p(\mu|m,l,a,b)\propto\mu^{m+a-1}(1-\mu)^{l+b-1}<br>$$</p><p>其中$l=N-m$。乘上标准化因子，就得到：<br>$$<br>p(\mu|m,l,a,b)=\frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1}<br>$$<br>得到的仍然是Beta分布，相当于把$a\rightarrow{m+a}$，$b\rightarrow{l+b}$。同时不难发现，参数$a$和$b$都有比较直观的意义。$a$可以看作是历史记录中，成功的次数，$b$可以看作是历史记录中失败的次数，比如$a=2$，$b=3$，根据经验成功的概率应该在$\frac{2}{2+3}=0.4$左右，即我们的先验为成功的概率为$0.4$（见下图左下角的子图）。如果在实验中，又进行了$7$次实验，其中$m=6$，$l=1$，由于成功的次数变多了，$a=2+6=8$，$b=3+1=4$，直觉上来说我们对成功概率的估计应当相应提高，大概为$\frac{8}{8+4}\approx 0.67$左右。这时的Beta分布如右下角的图的样子，也印证了我们的直觉。</p><img src="https://i.loli.net/2020/06/25/3hcj18ELXl4iWy6.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>以下为不同参数对应的Beta分布的互动演示：</p><div><iframe width="650px" height="450px" frameborder="0" style="dispaly:block；" src="http://qfxiao.me/html/beta_distribution_vis.html"></iframe></div><p>最后，Beta还有一个有趣的应用就是，如果我们不断接收到新的观测数据，那么旧的后验分布则可以作为新的先验分布将参数更新下去 。这相当于说，基于已有的观测数据，我们提出一个先验Beta分布，然后根据新得到的一批观测数据，用先验Beta分布计算一个似然函数，将似然函数和先验Beta分布乘起来，归一化后得到了新的后验分布，只要不断有新的观测数据接收到，就可以把后验分布作为新的先验，不断更新下去。这样做的优势是对于大数据集，我们不需要整个数据集，而是只需要一批一批的更新即可。</p><h1 id="Probability-Distributions-for-Multinomial-Variables"><a href="#Probability-Distributions-for-Multinomial-Variables" class="headerlink" title="Probability Distributions for Multinomial Variables"></a>Probability Distributions for Multinomial Variables</h1><h2 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h2><p>前面我们讨论了二值随机变量，现在我们将其扩展到多值变量。设一个$K$维向量$\mathbf x$，当$x_k$为$1$的时候其他元素都为$0$，如$K=6,x_3=1$时$\mathbf x$表示为$\mathbf x=(0,0,1,0,0,0)^\top$。如果$p(x_k=1)=\mu_k$，那么$\mathbf x$的概率分布为：<br>$$<br>p(\mathbf x|\boldsymbol \mu)=\prod_{k=1}^{K}\mu_k^{x_k}<br>$$<br>$\mu_k$满足$\sum_k \mu_k=1$和$\mu_k\geqslant 0$，该分布被称作是<strong>Categorical Distribution</strong>。易知其均值为：<br>$$<br>\begin{align}<br>\mathbb E[\mathbf x|\boldsymbol \mu]=\sum_{\mathbf x}p(\mathbf x|\boldsymbol \mu)\mathbf x=\boldsymbol \mu<br>\end{align}<br>$$<br>假设我们有大小为$N$的数据集$\mathcal D$，每个样本服从该分布且相互独立，那么似然函数：<br>$$<br>p(\mathcal D|\boldsymbol \mu)=\prod_{n=1}^N\prod_{k=1}^K \mu_k^{x_{nk}}=\prod_{k=1}^K \mu_k^{\sum_n x_{nk}}=\prod_{k=1}^K\mu_k^{m_k}<br>$$<br>其中$m_k=\sum_n x_{nk}$，即$x_k=1$的数量。为了最大化对数似然同时保证$\sum_k \mu_k=1$，我们可以用拉格朗日乘子法：<br>$$<br>\sum_{k=1}^K m_k\ln \mu_k+\lambda\left(\sum_{k=1}^K\mu_k-1\right)<br>$$<br>我们得到$\mu_k=-m_k/\lambda$。通过$\sum_k \mu_k=1$得出$\lambda=-N$，故最后我们有：<br>$$<br>\mu_k^{ML}=\frac{m_k}{N}<br>$$</p><p>这相当于是$x_k=1$的数量除以总数。</p><h2 id="Multinomial-Distribution"><a href="#Multinomial-Distribution" class="headerlink" title="Multinomial Distribution"></a>Multinomial Distribution</h2><p>类似的，我们可以对多次实验进行建模，假设进行$N$次独立实验，概率分布可以写为：</p><p>$$<br>\text{Mult}(m_1,m_2,\cdots,m_K|\boldsymbol\mu,N)=\binom{N}{m_1m_2\cdots m_K}\prod_{k=1}^K\mu_k^{m_k}<br>$$</p><p>这也是我们熟知的<strong>多项分布 (Multinomial Distribution)</strong>，其中$\binom{N}{m_1m_2\cdots m_K}$为正则化因子：<br>$$<br>\binom{N}{m_1m_2\cdots m_K}=\frac{N!}{m_1!m_2!\cdots m_K!}<br>$$<br>注意$\sum\limits_{k=1}^K m_k=N$。</p><h2 id="Dirichlet-Distribution"><a href="#Dirichlet-Distribution" class="headerlink" title="Dirichlet Distribution"></a>Dirichlet Distribution</h2><p>有了前面Beta的启发，我们同样可以对多项分布的参数$\mu_k$建立共轭先验。首先根据似然函数，我们知道先验应当与$\mu_k$的幂的乘积成比例：</p><p>$$<br>p(\boldsymbol \mu|\boldsymbol \alpha) \propto \prod_{k=1}^{K}\mu_k^{a_{k-1}}<br>$$</p><p>其中$0\leqslant \mu_k\leqslant 1$且$\sum_k\mu_k=1$。和Beta分布不同，由于要满足$\sum\mu_k=1$，所以${\mu_k}$的取值会位于$K-1$的单纯型上，如下图所示：</p><img src="https://i.loli.net/2020/06/25/N8CSMvmlRz91Gqy.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>加上标准化因子，我们就得到了所谓的先验分布，称之为<strong>迪利克雷分布 (Dirichlet Distribution)</strong>：<br>$$<br>\text{Dir}(\boldsymbol \mu|\boldsymbol\alpha)=\frac{\Gamma(\alpha_0)}{\Gamma(\alpha_1)\cdots\Gamma(\alpha_K)}\prod_{k=1}^K\mu_k^{a_{k-1}}<br>$$</p><p>其中$\Gamma(\cdot)$为Gamma函数，$\alpha_0=\sum\limits_{k=1}^K\alpha_k$。下图为不同条件下的迪利克雷分布的可视化：</p><p><img src="https://i.loli.net/2020/06/25/amGtuvPNoOM7kWZ.png" srcset="/img/loading.gif" alt=""></p><p>$\boldsymbol \mu$的后验与先验和似然函数的乘积成正比：</p><p>$$<br>p(\boldsymbol\mu|\mathcal D,\boldsymbol\alpha)\propto p(\mathcal D|\boldsymbol\mu)p(\boldsymbol\mu|\boldsymbol\alpha)\propto\prod_{k=1}^K \mu_k^{\alpha_k+m_k-1}<br>$$</p><p>不难验证：</p><p>$$<br>\begin{align}<br>p(\boldsymbol\mu|\mathcal D,\boldsymbol\alpha) &amp;= \text{Dir}(\boldsymbol\mu|\boldsymbol\alpha+\mathbf m)\<br>&amp;=\frac{\Gamma(\alpha_0+N)}{\Gamma(\alpha_1+m_1)\cdots\Gamma(\alpha_K+m_K)}\prod_{k=1}^K\mu_k^{\alpha_k+m_k-1}<br>\end{align}<br>$$</p><p>即后验同样为迪利克雷分布。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Statistics</tag>
      
      <tag>Probability</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets</title>
    <link href="/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/"/>
    <url>/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/</url>
    
    <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1><p>本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的<em>time-aware shapelet</em>，并且定义了<em>shapelet evolution graph</em>来捕获Shapelet在时间维度上的动态变化。</p><p><a href="https://arxiv.org/abs/1911.04143" target="_blank" rel="noopener">📰Get Paper</a></p><h1 id="preliminaries">Preliminaries</h1><p>时间序列集合<span class="math inline">\(T=\{t_1,\cdots,t_{|T|}\}\)</span>包含若干条时序数据<span class="math inline">\(t=\{x_1,\cdots,x_n\}\)</span>。一个<span class="math inline">\(t\)</span>的片段<span class="math inline">\(s\)</span>是<span class="math inline">\(t\)</span>的一个连续子序列。如果<span class="math inline">\(t\)</span>能被切分成<span class="math inline">\(m\)</span>个长度都为<span class="math inline">\(l\)</span>的片段，那么我们就有<span class="math inline">\(t=\{\{x_{l*k+1},\cdots,x_{l*k+l}\},0\leq k\leq m-1\}\)</span>。两个长度相等的片段之间距离很好度量，直接计算欧式距离即可，那么两个片段长度不相等的情况呢？这就需要对其（Alignment）的概念。</p><blockquote><p><strong>Definition 1 </strong> <strong><em>Alignment</em></strong>. 给定两个长度分别为<span class="math inline">\(l_i\)</span>和<span class="math inline">\(l_j\)</span>的序列<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，一个<em>alignment</em> <span class="math inline">\(a=(a_1,a_2)\)</span>是一个满足以下条件的长度为<span class="math inline">\(p\)</span>的下标序列： <span class="math display">\[1\leq a_k(1)\leq\cdots\leq a_k(p)=l_k,\\a_k(n+1)-a_k(n)\leq 1,\\\text{for }k=i,j,\text{ and }1\leq n\leq p-1\]</span></p></blockquote><p>上述公式可能比较抽象，其实看了下图就不难理解：</p><p><img src="https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png" srcset="/img/loading.gif" style="zoom:67%;" /></p><p>片段<span class="math inline">\(s_i\)</span>中的某个点<span class="math inline">\(a\)</span>，与片段<span class="math inline">\(s_j\)</span>中的某个点<span class="math inline">\(b\)</span>形成对应，然后在<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>之间连一条虚拟的线（不能与已有的线交叉），一直这么做直到短的那个片段中的每个点都找到对应，就是一个合理的<em>alignment</em>。对于两个长度不一样的片段<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，会有很多种<em>alignment</em>。我们把<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>所有可能的<em>alignment</em>记为<span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>。在定义了<em>alignment</em>之后就可以定义DTW了。DTW (<em>Dynamic Time Warping</em>) 定义为在给定一个预定义的距离度量<span class="math inline">\(\tau\)</span>和所有可能的<em>alignment</em> <span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>的情况下，最小的距离<span class="math inline">\(\tau\)</span>： <span class="math display">\[d_\text{DTW}(s_i,s_j)=\min_{a\in\mathcal{A}(s_i,s_j)}\tau(s_i,s_j|a)\]</span></p><p>进一步的，因为时间序列<span class="math inline">\(t\)</span>也可以看作是一个片段，我们可以定义一个子序列<span class="math inline">\(s\)</span>和时间序列<span class="math inline">\(t\)</span>之间的距离度量： <span class="math display">\[D(s,t)=\min_{1\leq k\leq m} d(s,s_k)\]</span></p><p>这里<span class="math inline">\(\boldsymbol s_k\)</span>为时序<span class="math inline">\(\boldsymbol t\)</span>分解成的片段。之后Shapelet可以通过片段与时序的距离定义为最具有辨识度的有代表性的片段：</p><blockquote><p><strong>Definition 2 </strong> <strong>Shapelet. </strong>一个Shapelet <span class="math inline">\(\boldsymbol v\)</span>是对于特定类别时序的最具有代表性的片段。考虑时序分类任务，给定时序集合<span class="math inline">\(T\)</span>，可以通过与<span class="math inline">\(\boldsymbol v\)</span>相似或不相似而分成两个子集合，与<span class="math inline">\(\boldsymbol v\)</span>相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量小，与<span class="math inline">\(\boldsymbol v\)</span>不相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量大，此时损失函数可以形式化为： <span class="math display">\[\mathcal L=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))\]</span></p></blockquote><p><span class="math inline">\(\mathcal L\)</span>描述了在shapelet <span class="math inline">\(\boldsymbol v\)</span>下正负样本集的相异性。<span class="math inline">\(S_{*}(\boldsymbol v,T)\)</span>表示特定时序集合与<span class="math inline">\(\boldsymbol v\)</span>的距离集合，<span class="math inline">\(g(\cdot,\cdot)\)</span>为接受两个有限集合为输入的可微函数，并且能够度量两个集合的距离。</p><h1 id="framework">Framework</h1><p>本文主要是提出了一种时间序列表示学习方法。基于Shapelet在不同的时间片段上的作用是不同的观察，作者为不同的时间片段赋予了不同的Shapelet，而不是像传统方法一样整个时序对应一个Shapelet。接着基于这些Shapelet作者构造了图，并通过图嵌入得到了嵌入向量，作为时序的表示。</p><p><img src="https://i.loli.net/2020/06/25/mKJH4c2EMAljavG.png" srcset="/img/loading.gif" style="zoom:80%;" /></p><h2 id="time-aware-shapelet-extraction">Time-Aware Shapelet Extraction</h2><p>第一步是捕获Shapelet在时间维度上的动态影响。我们定义了两个参数来定量的测量shapelet在不同时间上的动态性。第一个是局部因子<span class="math inline">\(\boldsymbol w_n\)</span>，用来控制shapelet内部<span class="math inline">\(n\)</span>个元素的权重，那么shapelet <span class="math inline">\(\boldsymbol v\)</span>和片段<span class="math inline">\(\boldsymbol s\)</span>的距离为： <span class="math display">\[\begin{align}\hat{d}(\boldsymbol v,\boldsymbol s|\boldsymbol w) &amp;= \tau(\boldsymbol v,\boldsymbol s|\boldsymbol a^*,\boldsymbol w)\\&amp; = \left(\sum_{k=1}^{p}\boldsymbol w_{\boldsymbol a^*_1(k)}\cdot(\boldsymbol v_{\boldsymbol a^*_1(k)}-\boldsymbol s_{\boldsymbol a^*_2(k)})^2\right)^{\frac{1}{2}}\end{align}\]</span> 其中<span class="math inline">\(\boldsymbol a^*\)</span>为DTW距离下的最佳对齐。</p><p>第二个是全局因素<span class="math inline">\(\boldsymbol u_m\)</span>，这主要是通过对不同片段<span class="math inline">\(\boldsymbol s\)</span>施加不同的权重实现的，于是shapelet <span class="math inline">\(\boldsymbol v\)</span>和时间序列<span class="math inline">\(\boldsymbol t\)</span>的距离可以重写为： <span class="math display">\[\hat{D}(\boldsymbol v,\boldsymbol t|\boldsymbol w,\boldsymbol u)=\min_{1\leq k\leq m}\boldsymbol u_k\cdot\hat{d}(\boldsymbol v,\boldsymbol s_k|\boldsymbol w)\]</span> 其中<span class="math inline">\(\boldsymbol t\)</span>被分割为<span class="math inline">\(m\)</span>个片段：<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>。对于分类任务，具体的来说，我们先生成一堆Shapelet候选集，然后通过有监督的方法来挑选最佳的Shapelet和对应的参数<span class="math inline">\(\boldsymbol w\)</span>和<span class="math inline">\(\boldsymbol u\)</span>。</p><p>计算shapelet候选集的算法如下：</p><p><img src="https://i.loli.net/2020/06/25/srW4Shk79XBFL3U.png" srcset="/img/loading.gif" /></p><p>在获取了Shapelet候选集合之后，我们有带有标签的时序集合<span class="math inline">\(T\)</span>，对于每一个Shapelet我们可以优化：</p><p><span class="math display">\[\hat{\mathcal L}=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))+\lambda\parallel \boldsymbol w\parallel+\epsilon\parallel \boldsymbol u\parallel\]</span></p><p>来获取最优的<span class="math inline">\(\hat{\boldsymbol w}\)</span>和<span class="math inline">\(\hat{\boldsymbol u}\)</span>。然后，我们可以挑选出使得<span class="math inline">\(\hat{\mathcal L}\)</span>最小的前<span class="math inline">\(K\)</span>个Shapelet。整个过程的算法流程如下：</p><p><img src="https://i.loli.net/2020/06/25/5b2TcjuBzlIFrPm.png" srcset="/img/loading.gif" /></p><h2 id="shapelet-evolution-graph">Shapelet Evolution Graph</h2><p>在获取了Shapelet之后，为了捕获Shapelet之间的相关性，我们定义了<em>Shapelet Evolution Graph</em>。</p><blockquote><p><strong>Definition 3 Shapelet Evolution Graph. </strong> <em>Shapelet Evolution Graph</em>为一个有向带权图<span class="math inline">\(G=(V,E)\)</span>，<span class="math inline">\(V\)</span>为<span class="math inline">\(K\)</span>个Shapelet，每条带有权重<span class="math inline">\(w_{ij}\)</span>的边<span class="math inline">\(e_{ij}\in E\)</span>代表两个Shapelet <span class="math inline">\(\boldsymbol v_i \in V\)</span>和<span class="math inline">\(\boldsymbol v_j \in V\)</span>被分配给相邻片段的概率。</p></blockquote><h3 id="graph-construction">Graph Construction</h3><p>这里来说一下，建图的具体过程。首先顶点为Shapelet，之后来进行边的构造。对于每一个片段<span class="math inline">\(\boldsymbol s_i\)</span>，我们会计算Shapelet到该片段的距离，距离越近代表这个Shapelet与片段越匹配。之后会设定一个阈值<span class="math inline">\(\delta\)</span>，然后将与片段的距离低于这个阈值的Shapelet分配给这个片段（一个Shapelet可能会分配给多个不同片段）。对于<span class="math inline">\(\boldsymbol s_i\)</span>的所有shapetlet我们记为<span class="math inline">\(\boldsymbol v_{i,*}\)</span>，我们会按照Shape到片段的距离进行归一化：</p><p><span class="math display">\[\boldsymbol p_{i,j}=\frac{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\hat{d}_{i,j}(\boldsymbol v_{i,j},\boldsymbol s_i)}{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\min(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))}\]</span></p><p>其中<span class="math inline">\(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i)=\boldsymbol u_*[i]*\hat{d}(\boldsymbol v_{i,*},\boldsymbol s_i|\boldsymbol w_*)&lt;\delta\)</span>。这样对于每个片段<span class="math inline">\(\boldsymbol s_i\)</span>所分配的Shapelet对应的<span class="math inline">\(\boldsymbol p\)</span>之和会等于<span class="math inline">\(1\)</span>。对每一对相邻的片段<span class="math inline">\((\boldsymbol s_i,\boldsymbol s_{i+1})\)</span>的Shapelet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>和<span class="math inline">\(\boldsymbol v_{i+1,k}\)</span>，我们创建一条连接<span class="math inline">\(\boldsymbol v_{*,j}\)</span>和<span class="math inline">\(\boldsymbol v_{*,k}\)</span>的边<span class="math inline">\(e_{j,k}\)</span>，权重为<span class="math inline">\(\boldsymbol p_{i,j}\cdot\boldsymbol p_{i+1,k}\)</span>。最后，所有重复的边会被合并。</p><p><img src="https://i.loli.net/2020/07/07/FzGEbWJflHmQa9R.png" srcset="/img/loading.gif" style="zoom: 33%;" /></p><p>如上图所示，假设有两个片段，每个片段分配了<span class="math inline">\(3\)</span>个Shapelet，Shapelet <span class="math inline">\(B\)</span>在片段<span class="math inline">\(1\)</span>对应的概率是<span class="math inline">\(p_{12}\)</span>，Shapelet <span class="math inline">\(C\)</span>在片段<span class="math inline">\(2\)</span>对应的概率是<span class="math inline">\(p_{23}\)</span>，那么由于片段<span class="math inline">\(1\)</span>和<span class="math inline">\(2\)</span>是相邻片段，会在<span class="math inline">\(B\)</span>和<span class="math inline">\(C\)</span>之间连一条边，边的权重为<span class="math inline">\(p_{12}*p_{23}\)</span>。</p><p>建图的算法流程图如下：</p><p><img src="https://i.loli.net/2020/06/25/aq9tGuApSbiC67c.png" srcset="/img/loading.gif" /></p><h2 id="representation-learning">Representation Learning</h2><p>之后，我们使用DeepWalk算法来获取获取每个结点（Shapelet）的嵌入表示。对于时序<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>即对应的Shapelet <span class="math inline">\(\{\boldsymbol v_{1,*},\cdots, v_{m,*}\}\)</span>和对应的概率<span class="math inline">\(\{\boldsymbol p_{1,*},\cdots,\boldsymbol p_{m,*}\}\)</span>，每个Shaplet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>的表示记为<span class="math inline">\(\boldsymbol \mu(\boldsymbol v_{i,j})\)</span>。片段<span class="math inline">\(\boldsymbol s_i\)</span>对应的嵌入向量为对应的Shapelet嵌入向量与对应的概率值加权求和：</p><p><span class="math display">\[\boldsymbol\Phi_i=\left(\sum_j p_{i,j}\cdot\boldsymbol \mu(\boldsymbol v_{i,j})\right),\space 1\leq i \leq m\]</span></p><p>算法流程如下：</p><p><img src="https://i.loli.net/2020/06/25/O5exTgsVLuRWQ42.png" srcset="/img/loading.gif" /></p><h1 id="experiments">Experiments</h1><h2 id="experimental-setup">Experimental Setup</h2><p>文中用了<em>Earthquakes</em> (EQS)、<em>WormsTwoClass</em> (WTC)、<em>Strawberry</em> (STB)、<em>Electricity Consumption Records</em> (ECR)和<em>Network Traffic Flow</em> (NTF) 这五个数据集，其中后两个为作者自己收集的数据集。五个数据集对应的统计信息如下：</p><p><img src="https://i.loli.net/2020/06/25/zHjTKkUJB8fGwdi.png" srcset="/img/loading.gif" /></p><p>文中与多个Baseline进行了比较，包括:</p><ul><li><strong>Distance-based Models: </strong>文中使用了不同的距离度量与基于1-NN的模型进行组合，包括Euclidean Distance (ED)、Dynamic Time Warping (DTW)、Weighted DTW (WDTW)、Complexity-Invariant Distance (CID) 和 Derivative DTW (DDTW)；</li><li><strong>Feature-based Models: </strong>文中分别使用了提取特征（均值、标准差等）和原始序列来训练XGBoost。除此之外，还使用了 Bag-of-Patterns (BoP)、Time Series Forest (TSF)、Elastic Ensembles (EE) 和 基于SAX的 Vector Space Model (SAXVSM)；</li><li><strong>Shapelet-based Models: </strong>这部分模型包括 Learn Time Series Shapelets (LS)、Fast Shapelets (FS)、和 Learned Pattern Similarity (LPS)；</li><li><strong>Deep Learning Models: </strong>这部分模型包括MLP、LSTM和VAE。</li></ul><h2 id="comparison-results">Comparison Results</h2><p>对于前三个公共数据集评测标准采用Accuracy，后两个数据集因为样本类比不均衡，所以采用了Precision、Recall和F1作为评测标准。结果如下：</p><p><img src="https://i.loli.net/2020/06/25/jxKFpDVXdmc5tbE.png" srcset="/img/loading.gif" style="zoom:67%;" /></p><p>在EQS数据集上，Time2Graph打败了所有Baseline，而在WTC和STB这两个数据集上也达到了较好的效果。在ECR和NTF这两个真实数据集上，Time2Graph在F1上打败了所有Baseline。</p><h2 id="parameter-analysis">Parameter Analysis</h2><p>本节对Shapelet的数量<span class="math inline">\(K\)</span>、嵌入维度<span class="math inline">\(B\)</span>和片段长度<span class="math inline">\(l\)</span>进行了参数分析。结果如下：</p><p><img src="https://i.loli.net/2020/06/25/hPfqAvNnOlEBQuw.png" srcset="/img/loading.gif" /></p><h2 id="case-study-of-time-aware-shapelets">Case Study of Time-Aware Shapelets</h2><p>本节作者对提出的<em>Time-Aware Shapetlet</em>进行了细致的探究。第一个问题是不同Shapelet的区分能力是否不同？下图(a)里，作者在使用Shapelet进行二分类的任务中，将Shapelet按Loss（图中灰色的线）进行排序，并且绘制了对应的正负样本距离的KL散度（橘红色的点）。可以看到，在Loss曲线和KL散度呈反比关系。KL散度越高，我们可以认为该Shapelet的区分度越高，这说明不同Shapelet的区分度的确不同，并且这会与最终效果直接挂钩。图(b)展示了不同Shapelet的均值和方差（原文没有说清楚是什么的均值和方差）。</p><p>除此之外，作者和流行的Shapelet提取算法<em>LS</em>进行了比较，如图(c)和图(d)。从图中可以看到对于不同时间，本文的算法提取的Shapelet的确是具有时间动态性的。</p><p><img src="https://i.loli.net/2020/06/25/ed5PwksC2l3OWE8.png" srcset="/img/loading.gif" /></p><h2 id="case-study-of-the-shapelet-evolution-graph">Case Study of the Shapelet Evolution Graph</h2><p>本节作者对<em>Shapelet Evolution Graph</em>进行了细致的探究。下图分别为一月份和七月份的<em>Shapelet Evolution Graph</em>。在一月，45号Shapelet的度较大，而且对应的时间因素在一月和二月也较大（图中深色部分）。说明45号Shapelet在一月份具有代表性。而在七月，45号Shapelet的重要性降低，而42号Shapelet在七月的重要性很高。</p><p><img src="https://i.loli.net/2020/06/25/N2Vij8ODQaRuALJ.png" srcset="/img/loading.gif" /></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Time Series Modeling</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Shapelet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Generative Probabilistic Novelty Detection with Adversarial Autoencoders</title>
    <link href="/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/"/>
    <url>/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这篇文章介绍了一种基于概率分布的异常检测方法。其基本思想是假设正常样本服从定义在流形$M$上的分布，而对于任意一点$\bar x$，通过投影到流形$M$上$x^\parallel$，可以分解为平行于切空间的部分$x^\parallel$和正交与切空间的部分$x^\bot$。原始的坐标$\bar x$被转换到$x^\parallel$局部坐标系中，然后似然通过转换后的坐标系进行计算。</p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Generative-Probabilistic-Novelty-Detection"><a href="#Generative-Probabilistic-Novelty-Detection" class="headerlink" title="Generative Probabilistic Novelty Detection"></a>Generative Probabilistic Novelty Detection</h2><p>我们假设训练数据$x_1,\cdots,x_N$，其中$x_i\in\mathbb{R}^m$，从一个分布采样的来，并带有随机噪声$\xi$：<br>$$<br>x_i=f(z_i)+\xi_i, \space\space\space i=1,\cdots,N<br>$$<br>其中$z_i\in\mathbb{R}^n$，$f:\Omega\mapsto\mathbb{R}^m$定义了一个$n$维带参流形$\mathcal{M}\equiv f(\Omega)$。注意这里噪声的加入使得样本的值域扩展到了整个实数空间。同时假设存在$g:\mathbb{R}^m\mapsto\mathbb{R}^n$，对任意$x\in\mathcal{M}$都有$f(g(x))=x$。$f$和$g$后面会通过神经网络实现。</p><p>对于一个测试样本$\bar{x}\in\mathbb{R}^m$，我们可以得到其在$M$上的投影，这是通过逆变换$\bar z = g(\bar x)$得到对应$z$的然后再通过$\bar x^{\parallel}=f(\bar z)$得到。$f$在$\bar z$的一阶泰勒展开为：<br>$$<br>f(z)=f(\bar z)+J_f(\bar z)(z-\bar z)+O(\parallel z-\bar z\parallel ^2)<br>$$<br><img src="https://i.loli.net/2020/06/25/oi9xKMO3ID7jANJ.png" srcset="/img/loading.gif" style="zoom:67%;" /></p><p>其中$J_f(\bar z)$为$f$在点$\bar z$的雅各比矩阵。$\mathcal T=\text{span}(J_f(\bar z))$代表点$\bar z$处由$J_f(\bar z)$的$n$个独立向量组成的切空间。通过对$J_f(\bar z)$进行奇异值分解$J_f(\bar z)=U^\parallel SV^\top$。<br>$$<br>\bar w=U^\top\bar x=\left[\begin{matrix}U^{\parallel^\top}\bar x\ U^{\bot^\top}\bar x\end{matrix}\right]=\left[\begin{matrix}\bar w^\parallel\ \bar w^\bot\end{matrix}\right]<br>$$<br>坐标$\bar w$可以分解为平行于$\mathcal T$和正交于$\mathcal T$两部分。</p><p>定义在施加变换前后的坐标系上的概率分布$p_X(x)$和$p_W(w)$是等价的，不过对于$p_W(w)$，我们假设平行部分和正交部分是独立的，即：<br>$$<br>p_X(x)=p_W(w)=p_W(w^\parallel,w^\bot)=p_{W^\parallel}(w^\parallel)p_{W^\bot}(w^\bot)<br>$$<br>这一假设的依据是随机噪声部分假设主要是往流形之外偏离的，即与$\mathcal T$正交，所以$W^\bot$主要是反映噪声的部分。而噪声与样本分布相独立的假设是合理的。于是，异常分数可以定义为：<br>$$<br>p_X(\bar x)=p_{W^\parallel}(\bar w^\parallel)p_{W^\bot}(\bar w^\bot)=\begin{cases}\geq \gamma \Rightarrow \text{Inlier}\&lt;\gamma\Rightarrow\text{Outlier}\end{cases}<br>$$</p><h2 id="Computing-the-Distribution-of-Data-Samples"><a href="#Computing-the-Distribution-of-Data-Samples" class="headerlink" title="Computing the Distribution of Data Samples"></a>Computing the Distribution of Data Samples</h2><p>上面的异常分数需要计算$p_{W^\parallel}(\bar w^\parallel)$和$p_{W^\bot}(\bar w^\bot)$。给定测试样本$\bar x$，投影到流形$\bar x^\parallel=f(g(\bar x))$。$\bar w^\parallel$可以重写为$\bar w^\parallel=U^{\parallel^\top}\bar x=U^{\parallel^\top}(\bar x-\bar x^{\parallel})+U^{\parallel^\top}\bar x^\parallel=U^{\parallel^\top}\bar x^\parallel$，即我们假设$U^{\parallel^\top}(\bar x-\bar x^\parallel)\approx 0$。于是有$w^\parallel(z)=U^{\parallel^\top}f(\bar z)+SV^\top(z-\bar z)+O(\parallel z-\bar z\parallel^2)$。</p><p>如果$Z$为定义在流形上的概率分布，那么：<br>$$<br>p_{W^\parallel}(w^\parallel)=|\text{det}S^{-1}|p_Z(z)<br>$$<br>$p_{W^\bot}(w^\bot)$由半径为$\parallel w^\bot\parallel$的超球体$\mathcal S^{m-n-1}$来进行估计：<br>$$<br>p_{W^\bot}(w^\bot)\approx\frac{\Gamma(\frac{m-n}{2})}{2\pi^{\frac{m-n}{2}}\parallel w^\bot\parallel^{m-n}}p_{\parallel W^\bot\parallel}(\parallel w^\bot\parallel)<br>$$</p><p>其中$\Gamma(\cdot)$代表Gamma函数。</p><h2 id="Manifold-Learning-with-Adversarial-Autoencoders"><a href="#Manifold-Learning-with-Adversarial-Autoencoders" class="headerlink" title="Manifold Learning with Adversarial Autoencoders"></a>Manifold Learning with Adversarial Autoencoders</h2><p>为了学习映射$f$和$g$，我们使用了AAE框架，如下图所示：</p><img src="https://i.loli.net/2020/06/25/sQhO3D4gKJqBPXv.png" srcset="/img/loading.gif" style="zoom: 67%;" /><p>除了常规的AAE外，我们还为$x$添加了一个额外的判别器。</p><h3 id="Adversarial-Losses"><a href="#Adversarial-Losses" class="headerlink" title="Adversarial Losses"></a>Adversarial Losses</h3><p>对于隐变量$z$，对抗损失函数为：<br>$$<br>\mathcal L_{adv-d_z}(x,g,D_z)=E[\log(D_z(\mathcal N(0,1)))]+E[\log(1-D_z(g(x)))]<br>$$<br>对于样本$x$，对抗损失函数为：<br>$$<br>\mathcal L_{adv-d_x}(x,D_x,f)=E[\log(D_x(x))]+E[\log(1-D_x(f(\mathcal N(0,1))))]<br>$$</p><h3 id="Autoencoder-Loss"><a href="#Autoencoder-Loss" class="headerlink" title="Autoencoder Loss"></a>Autoencoder Loss</h3><p>$$<br>\mathcal L_\text{error}(x,g,f)=-E_z[\log(p(f(g(x))|x))]<br>$$</p><h3 id="Full-Objective"><a href="#Full-Objective" class="headerlink" title="Full Objective"></a>Full Objective</h3><p>$$<br>\mathcal L(x,g,D_z,D_x,f)=\mathcal L_{adv-d_z}+\mathcal L_{adv-d_x}+\lambda \mathcal L_\text{error}<br>$$</p><p>下图为模型重构的例子：</p><img src="https://i.loli.net/2020/06/25/i7ytlgjoIbYV6uF.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul><li>*<em>MNIST. *</em> 手册数字识别数据集。</li><li>*<em>The Coil-100. *</em>包含7200张100个不同物体的不同角度的图片。</li><li>*<em>Fashion-MNIST. *</em> 手册数字识别数据集彩色版。</li><li>*<em>Others. *</em> 前三个数据集都是采用一个类作为inlier，而其他类作为outlier。在这一设置中inlier采样自数据集CIFAR-10(CIFAR-100)，而outlier采样自TinyImageNet、LSUN和iSUN。</li></ul><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="MNIST-Dataset"><a href="#MNIST-Dataset" class="headerlink" title="MNIST Dataset"></a>MNIST Dataset</h3><p><img src="https://i.loli.net/2020/06/25/5a71oidmK2ZGLyh.png" srcset="/img/loading.gif" alt=""></p><img src="https://i.loli.net/2020/06/25/4lcGeHDrhbdKN5W.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Coil-100-Dataset"><a href="#Coil-100-Dataset" class="headerlink" title="Coil-100 Dataset"></a>Coil-100 Dataset</h3><img src="https://i.loli.net/2020/06/25/ofVGBgR7a3WmyvU.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Fashion-MNIST"><a href="#Fashion-MNIST" class="headerlink" title="Fashion-MNIST"></a>Fashion-MNIST</h3><p><img src="https://i.loli.net/2020/06/25/avURoBw6ny8SIEq.png" srcset="/img/loading.gif" alt=""></p><h3 id="CIFAR-10-CIFAR-100"><a href="#CIFAR-10-CIFAR-100" class="headerlink" title="CIFAR-10 (CIFAR-100)"></a>CIFAR-10 (CIFAR-100)</h3><img src="https://i.loli.net/2020/06/25/piteKy1m9kvQ6EU.png" srcset="/img/loading.gif" style="zoom: 67%;" /><h3 id="Ablation"><a href="#Ablation" class="headerlink" title="Ablation"></a>Ablation</h3><p><img src="https://i.loli.net/2020/06/25/xgni9wBtYkheGZq.png" srcset="/img/loading.gif" alt=""></p><img src="https://i.loli.net/2020/06/25/idhqkCbAKvzMt68.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>GAN</tag>
      
      <tag>Novelty Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Estimate the Implicit Likelihoods of GANs with Application to Anomaly Detection</title>
    <link href="/2020/06/06/Estimate-the-Implicit-Likelihoods-of-GANs-with-Application-to-Anomaly-Detection/"/>
    <url>/2020/06/06/Estimate-the-Implicit-Likelihoods-of-GANs-with-Application-to-Anomaly-Detection/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><h2 id="Flow-based-Models-Recap"><a href="#Flow-based-Models-Recap" class="headerlink" title="Flow-based Models Recap"></a>Flow-based Models Recap</h2><h3 id="Jacobian-Matrix-and-Determinant"><a href="#Jacobian-Matrix-and-Determinant" class="headerlink" title="Jacobian Matrix and Determinant"></a>Jacobian Matrix and Determinant</h3><p>设函数$f:\mathbb{R}^n\mapsto\mathbb{R}^m$，由$f$的一阶偏导数组成的矩阵叫做Jacobian矩阵：<br>$$<br>\mathbf J=\left[<br>\begin{matrix}<br>\frac{\partial f_1}{\partial x_1} &amp;\cdots &amp;\frac{\partial f_1}{\partial x_n}\<br>\vdots &amp;\ddots &amp;\vdots\<br>\frac{\partial f_m}{\partial x_1}&amp; \dots&amp; \frac{\partial f_m}{\partial x_n}<br>\end{matrix}<br>\right]<br>$$</p><h3 id="Change-of-Variable-Theorem"><a href="#Change-of-Variable-Theorem" class="headerlink" title="Change of Variable Theorem"></a>Change of Variable Theorem</h3><p>给定已知概率分布的随机变量$z\sim\pi(z)$，新随机变量由可逆映射$f$给出$x=f(z)$，$z=f^{-1}(x)$。由于：<br>$$<br>\int p(x)\mathrm{d}x=\int \pi(z)\mathrm d z=1<br>$$<br>所以$p(x)$可以由下式得到：<br>$$<br>p(x)=\pi(z)\left|\frac{\mathrm d z}{\mathrm d x}\right|=\pi(f^{-1}(x))\left|\frac{\mathrm d f^{-1}}{\mathrm d x}\right|=\pi(f^{-1}(x))|(f^{-1})^\prime(x)|<br>$$<br>$\frac{\mathrm d f^{-1}}{\mathrm d x}$相当于对逆函数$f^{-1}$求导，而$z=f^{-1}(x)$。</p><p>对于多变量的情况：<br>$$<br>\mathbf z\sim \pi(\mathbf z), \mathbf x=f(\mathbf z),\mathbf z = f^{-1}(\mathbf x)\<br>p(\mathbf x) = \pi(\mathbf z)\left|\text{det}\frac{\mathrm d \mathbf z}{\mathrm d \mathbf x}\right|= \pi(f^{-1}(\mathbf x))\left|\text{det}\frac{\mathrm d f^{-1}}{\mathrm d \mathbf x}\right|<br>$$<br>$\left|\text{det}\frac{\mathrm d f^{-1}}{\mathrm d \mathbf x}\right|$为逆函数Jacobian矩阵行列式的绝对值。</p><h2 id="Deep-Generative-Models-as-Manifolds"><a href="#Deep-Generative-Models-as-Manifolds" class="headerlink" title="Deep Generative Models as Manifolds"></a>Deep Generative Models as Manifolds</h2><p>一个深度生成模型可以表示为从低维隐空间$\mathcal Z \subseteq R^d$映射到流形$\mathcal M\subseteq R^D$的嵌入函数$g:\mathcal Z\rightarrow \mathcal X$，$D \ll d$。通常假设$g$为光滑映射，那么$\mathcal M$为一个嵌入流形。$g$在$z\in\mathcal Z$的雅各比矩阵$\mathbf J_g(z)$提供了在$x=g(z)\in\mathcal X$处的切空间，即$\mathbf J_g:T_z\mathcal Z\rightarrow T_x\mathcal X$。这个映射不是满射，并且值域限制在流形$\mathcal M$在$x=g(z)$的切空间，记为$T_x\mathcal M$。$\mathcal M$与真实数据流形接近，即$\mathcal M_{data}$。</p><p>考虑一个定义在隐空间$\mathcal Z$每一点$z$上的Riemannian metric：<br>$$<br>\mathbf M(z)=\mathbf J_g(z)^\top\mathbf J_g(z)<br>$$<br>给定两个切空间向量$u,v\in T_z\in\mathcal Z$，他们的内积定义为$&lt;u,v&gt;=u^\top \mathbf M(z)v$。</p><p>考虑一个光滑曲线$\gamma:t\in[a,b]\rightarrow\mathcal Z$，<br>$$<br>L(\gamma)=\int^b_a\sqrt{\hat{\gamma}(t)^\top M_{\gamma(t)}\hat{\gamma}(t)}\mathrm d t<br>$$</p><h2 id="Change-of-Variable-on-Manifolds"><a href="#Change-of-Variable-on-Manifolds" class="headerlink" title="Change of Variable on Manifolds"></a>Change of Variable on Manifolds</h2><p>在流形上的<strong>Change of Variable Theorem</strong>是类似的：</p><p>$$<br>p_\mathcal{X}(x)=p_\mathcal{Z}(g^{-1}(x))\text{det}(\mathbf J_g(g^{-1}(x))^\top\mathbf J_g(g^{-1}(x)))^{-\frac{1}{2}}<br>$$</p><p>我们假设隐空间分布$p_\mathcal{Z}$服从标准正态先验分布$N(0,\mathbf I_d)$，于是我们可以计算出$x$的似然：</p><p>$$<br>\log(p_\mathcal{X}(g(z)))=\log(p_\mathcal{Z}(z))-\frac{1}{2}\log(\text{det}(\mathbf J_g(z)^\top\mathbf J_g(z)))<br>$$</p><p>通常我们没法知道真实世界中$\mathcal M_{data}$的切空间维度是多少，设定$d=\text{dim}\mathcal Z&gt;T_x\mathcal M_{data}$会导致$\mathbf J_g$不是满秩矩阵，这时$\text{det}(\mathbf J_g(z)^\top\mathbf J_g(z))=0$，即无法应用上式计算似然。</p><h2 id="Density-Estimation-with-Neural-Networks"><a href="#Density-Estimation-with-Neural-Networks" class="headerlink" title="Density Estimation with Neural Networks"></a>Density Estimation with Neural Networks</h2><h2 id="Anomaly-Detection-with-Generative-Models"><a href="#Anomaly-Detection-with-Generative-Models" class="headerlink" title="Anomaly Detection with Generative Models"></a>Anomaly Detection with Generative Models</h2><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><p>对于GAN模型，给定隐变量$z$和生成器$g$，我们可以通过公式(8)计算生成样本$g(z)$的对数似然，为了保证Jacobian矩阵为满秩，我们可以选定较低的隐变量维度$d$，不过这样会伤害GAN模型的性能。为了解决这个问题，我们需要使用一个<em>inference network</em>来将$x$映射回$z$，</p><h2 id="The-Variance-Network-of-the-Generator"><a href="#The-Variance-Network-of-the-Generator" class="headerlink" title="The Variance Network of the Generator"></a>The Variance Network of the Generator</h2><p>文中对生成器$g$进行了扩展：</p><p>$$<br>f(z) = g(z) + \sigma(z)\odot\epsilon,\<br>g:\mathcal Z\rightarrow\mathcal X, \sigma:\mathcal Z\rightarrow\mathbb{R},\epsilon\sim N(0,\mathbf I_D)<br>$$</p><p>$g$代表均值，$\sigma$代表方差，实际上$\mathbb E_{\epsilon\sim N(0,\mathbf I_D)}f(z)=g(z)$。为了保证方差在少样本或无样本的区域更大，方差网络采用RBF网络实现。</p><blockquote><p>RBF网络：<br>$$<br>h(x)=\exp\left(-\frac{(x-c)^2}{r^2}\right)<br>$$<br><img src="https://i.loli.net/2020/06/25/ho5FJsOBjxi2G78.png" srcset="/img/loading.gif" style="zoom: 80%;" /></p><img src="https://i.loli.net/2020/06/25/rtRLwyK2VigOvTh.png" srcset="/img/loading.gif" style="zoom: 50%;" /></blockquote><p>首先，从隐空间采样大量的样本，之后使用<strong>K-means</strong>算法将其分为$K$个聚簇，$c_k$为第$k$个簇的中心，$C_k$为第$k$个簇的样本数量。对于任何样本$x$，为了计算其对应的方差，需要用一个<em>inference network</em> $h$来将其映射到隐空间，即$z=h(x)$。RBF网络通过输入$z$到每个簇中心的距离来返回$x$对应的方差，RBF函数由下式给出：<br>$$<br>\sigma(z)=(\mathbf W^2\mathbf v(z))^{-\frac{1}{2}},\<br>v_k(z) = \exp(-\lambda_k\parallel z-c_k\parallel^2_2), \space k=1,\cdots,K\<br>\lambda_k=\frac{1}{2}\left(\frac{a}{|C_k|}\sum_{z_j\in C_k}\parallel z_j-c_k\parallel_2\right)^{-2}<br>$$</p><p>其中$\alpha$为核的超参数，$\mathbf W$为模型参数。给定生成器$g$，我们可以通过最小化$f(z)$和$x$之间的距离来优化参数$\mathbf W$。</p><p>$$<br>\begin{align}<br>\bar{\mathbf M}^z_f&amp;=\mathbb E_{\epsilon\sim N(0,\mathbf I_D)}\mathbf J_f^\top(z)\mathbf J_f(z)\<br>&amp;=\mathbf J_g^\top(z)\mathbf J_g(z)+\mathbf J_\sigma^\top(z)\mathbf J_\sigma(z)<br>\end{align}<br>$$</p><blockquote><p>*<em>LEMMA 1. *</em> 对于$K\geq \text{dim}(\mathcal Z)+1$和满秩矩阵$\mathbf W^2$，$\bar{\mathbf M}<em>f^z$为一个满秩矩阵。生成样本的对数似然由下式给出：<br>$$<br>\mathbb E</em>{\epsilon\sim N(0,\mathbf I_D)}\log(p_\mathcal{X}(f(z)))=\log(p_\mathcal{Z}(z))-\frac{1}{2}\log(\text{det}(\bar{\mathbf M}_f^z))<br>$$</p></blockquote><h2 id="The-Inference-Network-Learning"><a href="#The-Inference-Network-Learning" class="headerlink" title="The Inference Network Learning"></a>The Inference Network Learning</h2><img src="https://i.loli.net/2020/06/25/AZfIrq2v8RVipj1.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>$$<br>\max_{h,\sigma}\mathbb E_{x\sim p_{data}(x)}\left[\log(p(x|z))|_{z=h(x)}\right]<br>$$</p><p>$p(x|z)$</p><p>$$<br>\max_{h,\sigma}\mathbb E_{x\sim p_{data}(x), z=h(x)}\left[\log(p(x|z))-\text{KL}\right]<br>$$</p><blockquote><p>*<em>LEMMA 2. *</em><br>$$<br>f(z)\sim GP(g(z), \Lambda_\sigma)<br>$$</p></blockquote><p>$$<br>L_{h,\sigma}=\mathbb E_{x\sim p_{data}}\left[\sum_{i=1}^D[-\frac{1}{2}(g_i(h(x))-x_i)^2/\sigma_i^2(h(x))-\log\sigma_i(h(x))]-\text{KL}(q(z|x)\parallel p(z))\right]<br>$$</p><h2 id="Stabilize-Training"><a href="#Stabilize-Training" class="headerlink" title="Stabilize Training"></a>Stabilize Training</h2><p>$$<br>\min_{g,h}\mathbb E_{z\sim p(z)}[\parallel z-h(g(z))\parallel^2]<br>$$</p><h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><img src="https://i.loli.net/2020/06/25/PjJF9wBM2XS38TQ.png" srcset="/img/loading.gif" style="zoom: 80%;" /><blockquote><p>*<em>LEMMA 3. *</em> </p></blockquote><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><img src="https://i.loli.net/2020/06/25/GlqvJFOtEnbNoUP.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/Z8yDQU9McsT5GXI.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/NmBten8igTUV76L.png" srcset="/img/loading.gif" style="zoom:67%;" /><p><img src="https://i.loli.net/2020/06/25/8phKZkiRxdLyBT6.png" srcset="/img/loading.gif" alt=""></p><img src="https://i.loli.net/2020/06/25/noBqN9gWfPuFy8w.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/sJnwi5RzLAU3D6x.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/OvtLenWDSEi37lX.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/TIJbpsvGkwz3rVF.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Classification-based Anomaly Detection for General Data</title>
    <link href="/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/"/>
    <url>/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文主要是对<a href="http://qfxiao.me/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/">NIPS18这篇异常检测文章</a>的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：</p><ul><li>*<em>Reconstruction Methods： *</em>这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误差。</li><li>*<em>Distributional Methods： *</em>这一部分方法将异常检测看作是密度估计问题。通过对正常样本的分布进行估计，异常样本在该正常分布下的似然将会很低。</li><li>*<em>Classification-based Methods： *</em>这一部分方法主要是指的单分类方法和通过几何变换构造分类任务的方法。本文使用的就是这类方法。</li></ul><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Classification-based-Anomaly-Detection"><a href="#Classification-based-Anomaly-Detection" class="headerlink" title="Classification-based Anomaly Detection"></a>Classification-based Anomaly Detection</h2><p>假设所有数据位于空间$R^L$内，而正常数据位于子空间$X\subset R^L$内。我们假设所有的异常样本位于$X$之外。为了检测异常，我们希望学习一个分类器$C$使得对于所有的$x\in X$有$C(x)=1$，而对所有的$x\in R^L\backslash X$有$C(x)=0$。</p><p>单分类方法的思想是直接学习$P(x\in X)$，代表的方法有One-Class SVM，DSVDD等。传统的OC-SVM直接在原始空间或者核空间学习分类器。比较新的方法，如Deep-SVDD则是先将样本转换到一个特征空间，然后在这个特征空间上学习使得半径$R$最小的超球体（球心$c_0$），来覆盖住所有正常样本。异常的判定则通过计算$\parallel f(x)-c_0\parallel^2-R^2$来实现。不过学习一个好的样本到特征空间的变换并不是一件容易的事情，比如说$f(x)=0, \forall x \in X$就是一个使得超球体最小的解。所以需要很多trick来避免诸如此类的情况。</p><p><em>Geometric-transformation classification</em> (GEOM) 则将数据空间$X$通过$M$个几何变换转换到一系列子空间$X_1,\cdots,X_M$。之后训练一个分类器来预测样本$T(x,m)$对应的几何变换的种类$m$。转换后的正常图片空间记为$\cup_m X_m$，所以该方法尝试估计以下条件概率：<br>$$<br>P(m^\prime|T(x,m))=\frac{P(T(x,m)\in X_{m^\prime})P(m^\prime)}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})P(\tilde{m})}-\frac{P(T(x,m)\in X_{m^\prime})}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})}<br>$$</p><p>对于异常的样本$x\in R^L\backslash X$，在经过几何变换之后，都不会位于正确的子空间中，即$T(x,m)\in R^L\backslash X_m$。之后，使用$P(m|T(x,m))$来判定异常。</p><p>作者认为，这种方法的问题是分类器$P(m^\prime|T(x,m))$只在正常数据上训练，而对于异常样本的异常分数会出现方差很大的问题。</p><p>一种解决方式是加入异常样本进行训练，但是作者认为在有的任务中标签很难获取，于是作者使用了另外一种方法来解决这个问题。</p><h2 id="Distance-based-Multiple-Transformation-Classification"><a href="#Distance-based-Multiple-Transformation-Classification" class="headerlink" title="Distance-based Multiple Transformation Classification"></a>Distance-based Multiple Transformation Classification</h2><p>和GEOM一样，先对每个样本进行$M$个几何变换，然后学习一个特征提取器$f(x)$，将$X_m$映射到特征空间。之后和OC-SVM类似，假设特征${f(x)|x\in X_m}$为球心为$c_m=\frac{1}{N}\sum_{x\in X} f(T(x,m))$的超球体。样本属于某一类$m^\prime$的概率由下式给出：</p><p>$$<br>P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2}}{\sum_{\bar m}e^{-\parallel f(T(x,m))-c_{\bar m}\parallel^2}}<br>$$</p><p>目标函数采用的是Triplet Loss：</p><p>$$<br>L=\sum_i\max(\parallel f(T(x_i,m))-c_m\parallel^2+s-\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2,0)<br>$$</p><p>$\parallel f(T(x_i,m))-c_m\parallel^2$相当于最小化了类内距离，$\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2$最大化了每个类对应的集簇间距离。在检测阶段，为了避免一些数值问题，作者做了一些平滑操作：</p><p>$$<br>\tilde P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2+\epsilon}}{\sum_{\tilde m}e^{-\parallel f(T(x,m))-c_{\tilde m}\parallel^2+M\cdot\epsilon}}<br>$$</p><p>最后的评判分数由下式给出：</p><p>$$<br>Score(x)=-\log P(x\in X)=-\sum_m\log \tilde{P}(T(x,m)\in X_m)=-\sum_m\log\tilde{P}(m|T(x,m))<br>$$</p><p>算法流程图如下：</p><img src="https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Parameterizing-the-Set-of-Transformations"><a href="#Parameterizing-the-Set-of-Transformations" class="headerlink" title="Parameterizing the Set of Transformations"></a>Parameterizing the Set of Transformations</h2><p>在GEOM中，由于使用的几何变换都是针对图像的，所以对于其他类型的数据并不适用。本文中作者对非图像数据设计了以下变换：</p><p>$$<br>T(x,m)=W_mx+b_m<br>$$</p><p>不同的参数$W_m$和$b_m$即为不同的几何变换，可以考虑采用随机采样的方式。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Image-Experiments"><a href="#Image-Experiments" class="headerlink" title="Image Experiments"></a>Image Experiments</h2><p>对于图像数据的异常检测实验，作者采用了CIFAR10、FasionMNIST这两个数据集，实验结果如下：</p><img src="https://i.loli.net/2020/06/24/j4Y29tB6k1Aipgo.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/24/D3opwrLnSGmcsyM.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Tabular-Data-Experiments"><a href="#Tabular-Data-Experiments" class="headerlink" title="Tabular Data Experiments"></a>Tabular Data Experiments</h2><p>对于非图像数据，作者采用了几个小的数据集：Arrhythmia、Thyroid、KDD和KDDRev。采用的Baseline包括OC-SVM、E2E-AE、LOF、DAGMM和FB-AE (Feature Bagging Autoencoder)。对于几何变换的参数，采样自标准正态分布。结果如下：</p><img src="https://i.loli.net/2020/06/24/e6PfIDOVwlzrSWi.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h1><p>结合<a href="https://openreview.net/forum?id=H1lK_lBtvS" target="_blank" rel="noopener">OpenReview</a>上的一些讨论，这里提出一些问题和总结：</p><ul><li>KDD数据集太简单了，正常、异常样本能够很容易被分开；</li><li>对于图像数据作者只使用了CIFAR10和FashionMNIST这两个比较小的数据集，而在GEOM中还使用了CIFAR100和CatsVsDogs。并且GEOM原文中提到数据集（指图像大小）越大，GEOM的优势就越明显，所以在本文的实验中只使用这两个数据集说服力略显不够；</li><li>关于评测标准的问题，作者在图像数据中用的是AUROC，而非图像数据用的是F1 score。像AUPR、AUROC这种评测标准往往更加全面，而F1 score依赖于阈值的选取。如果是遍历阈值找到最好的那个F1 score，则无法全面考察模型的鲁棒性，模型有可能只是在特定的阈值下表现很好，而阈值稍微偏差一下性能可能就会大幅下降。我看到的大多数异常检测文章都是使用AUROC或者F1加上AUROC作为评测指标；</li><li>文中在第二节“CLASSIFICATION-BASED ANOMALY DETECTION”的末尾两段关于GEOM方法的缺点说的很模糊。异常分数的方差大到底指的是什么；</li><li>关于作者提出的变换$T(x,m)=W_mx+b_m$并没有用到图像数据的实验上，而且在实验中$b_m$这个参数实际上是被忽略掉了的，$b_m$的作用究竟如何不得而知。而且GEOM中的几何变换的Motivation在原文中是做了实验充分讨论了的，GEOM的作者认为这些几何变换保留了图像的高阶语义信息。而本文中的变换中的参数只是随机采样而来，并不存在说保留原始数据中的结构信息。如果忽略掉这一层变换，那就类似于加了神经网络提取特征的OC-SVM。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面向OpenPAI的Docker镜像配置及OpenPAI基本使用方法</title>
    <link href="/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <url>/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>实验室服务器集群采用OpenPAI来进行GPU资源的管理，而OpenPAI采用了Docker作为基础，即代码都放在Docker容器中运行。由于Docker的使用、Docker镜像的配置都有一定的门槛，所以这里写一篇Tutorial来进行介绍。本文不是网上资料的拼凑，而是经过本人走弯路踩坑形成的”Best practice”。主要内容包括Docker的介绍、Docker的基本使用、如何配置自己的Docker镜像以及OpenPAI平台的基本使用，但不包括Docker和OpenPAI的安装。</p><blockquote><p>2020.8.1 Update: 加入通过HDFS读取容器保存的文件的方法</p></blockquote><h1 id="Docker-from-Scratch"><a href="#Docker-from-Scratch" class="headerlink" title="Docker from Scratch"></a>Docker from Scratch</h1><p>要理解Docker是什么，从虚拟机开始讲可能会比较好理解。虚拟机大家可能都很熟悉了，比如说我用的系统是Windows，但我需要Linux系统来作为一个Flask编写的网站的服务器，但是又不想单独安装Linux系统，于是可以使用虚拟机来解决这个问题。安装VMWare Workstation，去官网下载Ubuntu系统镜像，然后在VMWare中安装好系统，然后从头配置Flask相关环境。实际上我需要的仅仅是一个Flask运行环境而已，而使用虚拟机却需要如此“大费周章”，这时Docker出现了，网上有大量现成的Flask Docker镜像，配置好了你所需的Flask环境，你只需要下载这些镜像，然后运行它，你就得到了一个Flask运行环境，而与你当前使用的系统无关。如果你需要一个Tomcat的运行环境，那么去找一个Tomcat的Docker镜像就行。Docker将需求或者说服务绑定在了Docker镜像中（<strong>轻量化</strong>，一个需求对应一个Docker镜像，每个镜像都很小），你有什么需求，去找相应的镜像即可（或者自己写一个），镜像的运行是以虚拟机的形式存在，所以他们之间也是互不干扰的。同时，你在写好一个Docker镜像之后，你还可以<strong>分享</strong>给别人，这样其他人就不用重新配置，直接运行你给他的镜像即可。Docker有两个比较关键的概念：</p><ul><li><strong>镜像 Images：</strong> 这里的镜像不是指我们安装系统时下载的ISO镜像，Docker镜像就是把你需要的东西（一个系统+需要的服务）集中到一起，相当于做菜的菜谱；</li><li><strong>容器 Containers：</strong> 如果一个Docker镜像启动了，那么就会有一个Docker容器产生，相当于按照菜谱做出来的菜。</li></ul><img src="https://i.loli.net/2020/06/24/H2x9mnPwkVQyO6p.png" srcset="/img/loading.gif" alt="img" style="zoom: 33%;" /><img src="https://i.loli.net/2020/06/24/7k6S3yecX2lbvQY.png" srcset="/img/loading.gif" alt="img" style="zoom: 33%;" /><p>这一节我们先不讨论如何自己写Docker镜像，只是先讨论Docker的基本操作。</p><h2 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h2><p>Docker新安装好当然是没有什么镜像的，首先我们使用<code>docker pull hello-world</code>来下载一个测试镜像。</p><blockquote><p>拉取镜像 <code>docker pull &lt;image_name&gt;</code></p></blockquote><p>在输入之后，Docker会自动在远程服务器上查找对应的镜像进行下载。由于我的电脑上已经有这个镜像了，所以显示是下面的样子：</p><p><img src="https://i.loli.net/2020/06/24/rvqcAwzOYJtF6T8.png" srcset="/img/loading.gif" alt=""></p><p>接下来，我们输入<code>docker run hello-world</code>运行这个镜像。</p><blockquote><p>运行镜像<code>docker run &lt;image_name&gt;</code></p></blockquote><p>可以看到，Docker输出了一些信息就自己退出了，这和我们理解的虚拟机不太一样。在Docker里面，我们既可以创建一个完整的系统，用户在运行之后就可以正常使用这个操作系统，也可以创建一个简单的服务，默认运行完一些指令就退出了。这里的<code>hello-world</code>镜像这是输出了一些信息后就自动退出了，因为这就是这个镜像的全部内容。</p><p><img src="https://i.loli.net/2020/06/24/Zb1VKjFyMh8gHf2.png" srcset="/img/loading.gif" alt=""></p><p>我们尝试来运行一个完整的系统，先用<code>docker pull ubuntu</code>拉取Ubuntu Docker镜像：</p><p><img src="https://i.loli.net/2020/06/24/zEerb2gPwYWX8O7.png" srcset="/img/loading.gif" alt=""></p><p>接下来我们使用：</p><p><img src="https://i.loli.net/2020/06/24/6cMz1WGH4fgpBsS.png" srcset="/img/loading.gif" alt=""></p><blockquote><p><code>-it</code>的意思是什么？根据<code>docker run --help</code>：</p><pre><code class="hljs routeros">-i, --interactive                    Keep STDIN open even <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> attached    --ip string                      IPv4<span class="hljs-built_in"> address </span>(e.g., 172.30.100.104)    --ip6 string                    <span class="hljs-built_in"> IPv6 address </span>(e.g., 2001:db8::33)    --ipc string                     IPC mode <span class="hljs-keyword">to</span> use    --isolation string               Container isolation technology    --kernel-memory bytes            Kernel memory limit-t, --tty                            Allocate a pseudo-TTY    --ulimit ulimit                  Ulimit options (default [])Copy</code></pre><p>其实<code>-it</code>是<code>-i</code>和<code>-t</code>的合并写法，意思是运行后进入这个容器并且启用shell，不然运行之后就会放到后台而不会进入容器中。而<code>--rm</code>则代表容器退出之后会被删除（镜像不会被删除），每次运行实际上会创建一个新的容器，如果不加<code>--rm</code>或退出之后不手动删除的话会看到一堆停止运行的容器。</p></blockquote><p>输入<code>cat /etc/issue</code>可以看到默认拉取的是最新的Ubuntu 20.04 LTS：</p><p><img src="https://i.loli.net/2020/06/24/wldBMFtx3eIk98C.png" srcset="/img/loading.gif" alt=""></p><h1 id="Build-Customized-Docker-Images"><a href="#Build-Customized-Docker-Images" class="headerlink" title="Build Customized Docker Images"></a>Build Customized Docker Images</h1><p>如果没有现成的Docker镜像能满足我们的需求，我们可以考虑自己写一个。要自定义一个Docker镜像需要两步，第一步是编写Dockerfile，第二步是使用<code>docker build</code>命令构建镜像。Dockerfile可以看作是一个脚本，描述了我们构建镜像所需要的全部命令，比如要构建一个用于Python科学计算的Docker镜像，我们需要在Dockerfile中编写安装Python的命令，安装Numpy、Scipy等常用包的命令等等。我们先来上手编写Dockerfile，这里我准备写一个包含<a href="https://hexo.io/" target="_blank" rel="noopener">hexo博客框架</a>的镜像，这个框架需要node作为基础环境，不过我们不需要在Dockerfile里写安装node的命令。因为类似于<code>C++</code>或<code>Python</code>中的对象的继承，Dockerfile也可以“继承”，这意味着我们不必从头写起。我们先来看一下完整的Dockfile和效果，再来一一解释。</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> node--------------------------------------------------------------<span class="hljs-keyword">RUN</span><span class="bash"> npm install -g hexo-cli</span><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">4000</span><span class="hljs-keyword">CMD</span><span class="bash"> hexo init blog &amp;&amp; <span class="hljs-built_in">cd</span> blog &amp;&amp; hexo generate &amp;&amp; hexo serverCopy</span></code></pre><p>运行结果如下所示，可以看到Docker按照我们写的Dockerfile一行一行的进行镜像的构建：</p><p><img src="https://i.loli.net/2020/06/24/tZ3JW4SPNhxUwEn.png" srcset="/img/loading.gif" alt=""></p><p>现在来解释Docerfile里的内容。<code>FROM &lt;docker image&gt;</code>表示继承其他的镜像，这里我们使用node官方的镜像。接下来是安装hexo，<code>RUN &lt;command&gt;</code>表示执行命令，这里我们直接用<code>npm install -g hexo-cli</code>进行安装。由于要浏览博客网页需要开放端口，而Docker容器运行的时候和外部主机是完全隔断的，要使外部主机访问Docker容器端口，需要暴露端口。<code>EXPOSE &lt;port&gt;</code>代表暴露端口，这里用的是4000端口。之后是创建博客和启动本地服务，<code>CMD &lt;command&gt;</code>和<code>RUN &lt;command&gt;</code>的区别是RUN会在构建的时候执行，而CMD是在容器启动之后才会执行。<code>hexo init blog &amp;&amp; cd blog &amp;&amp; hexo generate &amp;&amp; hexo server</code>分别代表初始化博客、进入博客所在文件夹、生成博客网站、启动本地服务器。更多指令可以参考<a href="https://docs.docker.com/engine/reference/builder/" target="_blank" rel="noopener">官方文档</a>。</p><p>然后我们使用<code>docker build -t test_hexo .</code>命令构建镜像。</p><blockquote><p>构建镜像 <code>docker build -t &lt;image_name&gt; &lt;direcotry&gt;</code></p></blockquote><p>运行镜像：</p><p><img src="https://i.loli.net/2020/06/24/m4FSe15kMIDCHXy.png" srcset="/img/loading.gif" alt=""></p><p>可以看到容器启动后开始执行博客初始化。</p><p><img src="https://i.loli.net/2020/06/24/BEdibvgPTMz4sn8.png" srcset="/img/loading.gif" alt=""></p><p>最后在<code>locahost:4000</code>上启动了一个本地服务器，在浏览器中输入这个地址，可以看到刚刚构建好的博客：</p><p><img src="https://i.loli.net/2020/06/24/vmSUb5QH6l4afzF.png" srcset="/img/loading.gif" alt=""></p><p>值得注意的是，在Dockerfile中我们暴露了4000端口，使用<code>-p</code>标签可以达到同样的效果：<code>docker run -p &lt;docker_port&gt;:&lt;local_port&gt; &lt;image_name&gt;</code>。比如<code>docker run -p 9999:8888 xxxx</code>代表将Docker容器中的9999端口转发到外部主机的8888端口。如果你是在远程服务器上使用的Docker，那么端口只是被转发到了远程服务器上，还得手动将远程服务器再转发到你本机上才能直接在本机浏览器上看到页面。</p><h2 id="Build-Docker-Images-with-Aliyun-Container-Registry"><a href="#Build-Docker-Images-with-Aliyun-Container-Registry" class="headerlink" title="Build Docker Images with Aliyun Container Registry"></a>Build Docker Images with Aliyun Container Registry</h2><p>因为某些原因，如果在构建镜像的时候需要通过<code>apt-get update</code>更新源，会发现无论如何都会卡住。这个时候可以使用<a href="https://cr.console.aliyun.com/" target="_blank" rel="noopener">阿里云容器镜像服务</a>，在阿里的服务器上构建好镜像，再拉取到自己的机器上。注册好帐号之后，点击创建镜像仓库：</p><p><img src="https://i.loli.net/2020/06/24/u4DGHv3En1iLI5z.png" srcset="/img/loading.gif" alt=""></p><p>这里仓库类型如果没有特殊需求建议使用公开，然后填写一些基本信息：</p><p><img src="https://i.loli.net/2020/06/24/Qipw5hAg136afnL.png" srcset="/img/loading.gif" alt=""></p><p>之后设置代码源，其实就是告诉阿里云从哪儿获取Dockerfile，我这里用的是Github，所以需要先在阿里云中关联Github账号，然后在Github中创建一个用来放Dockerfile的仓库。构建设置里有一个“海外机器构建”，这正是我们使用阿里云容器服务的主要目的，勾选。</p><p><img src="https://i.loli.net/2020/06/24/ksvZJG9lKfdh6aR.png" srcset="/img/loading.gif" alt=""></p><p>镜像仓库创建好之后，点进去，在构建页面点击添加规则：</p><p><img src="https://i.loli.net/2020/06/24/irBm3QcqjVhGMsv.png" srcset="/img/loading.gif" alt=""></p><p>按下图进行设置即可，镜像版本就是你想要的镜像名字：</p><p><img src="https://i.loli.net/2020/06/24/7pAFvM8CJQbq6mU.png" srcset="/img/loading.gif" alt=""></p><p>点击“立即构建”：</p><p><img src="https://i.loli.net/2020/06/24/GlMwqDInL7zVOpf.png" srcset="/img/loading.gif" alt=""></p><p>等待一段时间后，如果构建成功，便可以进行拉取了，在镜像仓库的基本信息页面可以看到地址：</p><p><img src="https://i.loli.net/2020/06/24/57jmEv8PYkr2nQG.png" srcset="/img/loading.gif" alt=""></p><p>将阿里云上的镜像拉取到本机之后一般会想要对镜像改名，可以使用<code>docker tag &lt;old_name&gt; &lt;new_name&gt;</code>。</p><h1 id="Build-Docker-Images-for-Deep-Learning"><a href="#Build-Docker-Images-for-Deep-Learning" class="headerlink" title="Build Docker Images for Deep Learning"></a>Build Docker Images for Deep Learning</h1><h2 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h2><p>在Docker中配置适用于OpenPAI的深度学习镜像不是一件容易的事，会有很多的坑，这里专门说一下如何配置。推荐在阿里云容器镜像服务中进行构建，会少很多麻烦。</p><p>第一步是初始镜像，由于需要用到CUDA，这里可以根据自己的需求（比如不同CUDA版本支持的GPU驱动版本不一样，还有Tensorflow不同版本对CUDA和cuDNN要求也不一样）从Nvidia的Dockerhub<a href="https://hub.docker.com/r/nvidia/cuda" target="_blank" rel="noopener">官方页面</a>选择合适的CUDA和cuDNN版本：</p><p><img src="https://i.loli.net/2020/06/24/pftdhmHiWkTq8Fj.png" srcset="/img/loading.gif" alt=""></p><p>这里我们选择CUDA10.1 + cuDNN7：</p><pre><code class="hljs angelscript">FROM nvidia/cuda:<span class="hljs-number">10.1</span>-cudnn7-devel-ubuntu18<span class="hljs-number">.04</span>Copy</code></pre><p>这一条主要是解决乱码问题以及定义用到的软件包的版本，这里Miniconda版本设置为4.5.4的原因是这是最后一个自带Python3.6的版本，我在这儿为了稳定所以用了Python3.6，大家也可以安装最新版的Miniconda：</p><pre><code class="hljs routeros">ENV <span class="hljs-attribute">LANG</span>=C.UTF-8 <span class="hljs-attribute">LC_ALL</span>=C.UTF-8ENV <span class="hljs-attribute">HADOOP_VERSION</span>=2.7.2LABEL <span class="hljs-attribute">HADOOP_VERSION</span>=2.7.2ENV <span class="hljs-attribute">MINICONDA_VERSION</span>=4.5.4Copy</code></pre><p>接下来安装必须的包，大家可以根据需求自行调整，<code>-y</code>标签代表Yes，即自动同意安装：</p><pre><code class="hljs livescript">RUN DEBIAN_FRONTEND=noninteractive &amp;&amp; <span class="hljs-string">\</span>    apt-get -y update &amp;&amp; <span class="hljs-string">\</span>    apt-get -y install build-essential <span class="hljs-string">\</span>        wget <span class="hljs-string">\</span>        git <span class="hljs-string">\</span>        curl <span class="hljs-string">\</span>        unzip <span class="hljs-string">\</span>        automake <span class="hljs-string">\</span>        openjdk-<span class="hljs-number">8</span>-jdk <span class="hljs-string">\</span>        openssh-server <span class="hljs-string">\</span>        openssh-client <span class="hljs-string">\</span>        lsof <span class="hljs-string">\</span>        libcupti-dev &amp;&amp; <span class="hljs-string">\</span>    apt-get clean &amp;&amp; <span class="hljs-string">\</span>    rm -rf <span class="hljs-regexp">/var/lib/apt/lists/</span>*Copy</code></pre><p>安装Miniconda并设置环境变量，<code>-b</code>标签可以让Miniconda无交互自动安装：</p><pre><code class="hljs awk">RUN wget --quiet https:<span class="hljs-regexp">//</span>repo.anaconda.com<span class="hljs-regexp">/miniconda/</span>Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh &amp;&amp; <span class="hljs-regexp">/bin/</span>bash Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.sh -b -p <span class="hljs-regexp">/opt/mi</span>niconda \&amp;&amp; rm Miniconda3-<span class="hljs-variable">$&#123;MINICONDA_VERSION&#125;</span>-Linux-x86_64.shENV PATH <span class="hljs-regexp">/opt/mi</span>niconda<span class="hljs-regexp">/bin:$PATHCopy</span></code></pre><p>安装Hadoop，OpenPAI平台会用到：</p><pre><code class="hljs awk">RUN wget -qO- http:<span class="hljs-regexp">//</span>archive.apache.org<span class="hljs-regexp">/dist/</span>hadoop<span class="hljs-regexp">/common/</span>hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span><span class="hljs-regexp">/hadoop-$&#123;HADOOP_VERSION&#125;.tar.gz | \</span><span class="hljs-regexp">    tar xz -C /u</span>sr<span class="hljs-regexp">/local &amp;&amp; \</span><span class="hljs-regexp">    mv /u</span>sr<span class="hljs-regexp">/local/</span>hadoop-<span class="hljs-variable">$&#123;HADOOP_VERSION&#125;</span> <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/hadoopCopy</span></code></pre><p><code>ENV</code>的作用是配置环境变量。配置JAVA和Hadoop环境变量：</p><pre><code class="hljs routeros">ENV <span class="hljs-attribute">JAVA_HOME</span>=/usr/lib/jvm/java-8-openjdk-amd64 \    <span class="hljs-attribute">HADOOP_INSTALL</span>=/usr/local/hadoop \    <span class="hljs-attribute">NVIDIA_VISIBLE_DEVICES</span>=allENV <span class="hljs-attribute">HADOOP_PREFIX</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \    <span class="hljs-attribute">HADOOP_BIN_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/bin \    <span class="hljs-attribute">HADOOP_SBIN_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/sbin \    <span class="hljs-attribute">HADOOP_HDFS_HOME</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span> \    <span class="hljs-attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/lib/native \    <span class="hljs-attribute">HADOOP_OPTS</span>=<span class="hljs-string">"-Djava.library.path=<span class="hljs-variable">$&#123;HADOOP_INSTALL&#125;</span>/lib/native"</span>Copy</code></pre><p>设置PATH环境变量：</p><pre><code class="hljs elixir">ENV PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/nvidia/bin</span><span class="hljs-symbol">:/usr/local/cuda/bin</span><span class="hljs-symbol">:/usr/local/sbin</span><span class="hljs-symbol">:/usr/local/bin</span><span class="hljs-symbol">:/usr/sbin</span><span class="hljs-symbol">:/usr/bin</span><span class="hljs-symbol">:/sbin</span><span class="hljs-symbol">:/bin</span><span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>HADOOP_BIN_DIR&#125;<span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>HADOOP_SBIN_DIR&#125; \LD_LIBRARY_PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/extras</span><span class="hljs-regexp">/CUPTI/lib</span><span class="hljs-symbol">:/usr/local/cuda/extras/CUPTI/lib64</span><span class="hljs-symbol">:/usr/local/nvidia/lib</span><span class="hljs-symbol">:/usr/local/nvidia/lib64</span><span class="hljs-symbol">:/usr/local/cuda/lib64</span><span class="hljs-symbol">:/usr/local/cuda/targets/x86_64-linux/lib/stubs</span><span class="hljs-symbol">:</span><span class="hljs-variable">$&#123;</span>JAVA_HOME&#125;/jre/lib/amd64/serverCopy</code></pre><p>完整的Dockerfile如下：</p><pre><code class="hljs crystal">FROM nvidia/<span class="hljs-symbol">cuda:</span><span class="hljs-number">10.1</span>-cudnn7-devel-ubuntu18.<span class="hljs-number">0</span>4ENV LANG=C.UTF-<span class="hljs-number">8</span> LC_ALL=C.UTF-<span class="hljs-number">8</span>ENV HADOOP_VERSION=<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span>LABEL HADOOP_VERSION=<span class="hljs-number">2.7</span>.<span class="hljs-number">2</span>ENV MINICONDA_VERSION=<span class="hljs-number">4.5</span>.<span class="hljs-number">4</span>RUN DEBIAN_FRONTEND=noninteractive &amp;&amp; \    apt-get -y update &amp;&amp; \    apt-get -y install build-essential \        wget \        git \        curl \        unzip \        automake \        openjdk-<span class="hljs-number">8</span>-jdk \        openssh-server \        openssh-client \        lsof \        libcupti-dev &amp;&amp; \    apt-get clean &amp;&amp; \    rm -rf /var/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">apt</span>/<span class="hljs-title">lists</span>/*</span>RUN wget --quiet <span class="hljs-symbol">https:</span>/<span class="hljs-regexp">/repo.anaconda.com/miniconda</span><span class="hljs-regexp">/Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh &amp;&amp; /bin</span><span class="hljs-regexp">/bash Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh -b -p /opt</span><span class="hljs-regexp">/miniconda \</span><span class="hljs-regexp">&amp;&amp; rm Miniconda3-$&#123;MINICONDA_VERSION&#125;-Linux-x86_64.sh</span><span class="hljs-regexp">ENV PATH /opt</span><span class="hljs-regexp">/miniconda/bin</span>:$PATH    RUN wget -qO- <span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/archive.apache.org/dist</span><span class="hljs-regexp">/hadoop/common</span><span class="hljs-regexp">/hadoop-$&#123;HADOOP_VERSION&#125;/hadoop</span>-$&#123;HADOOP_VERSION&#125;.tar.gz | \    tar xz -C /usr/local &amp;&amp; \    mv /usr/local/hadoop-$&#123;HADOOP_VERSION&#125; /usr/local/hadoop    ENV JAVA_HOME=<span class="hljs-regexp">/usr/lib</span><span class="hljs-regexp">/jvm/java</span>-<span class="hljs-number">8</span>-openjdk-amd64 \    HADOOP_INSTALL=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/hadoop \</span><span class="hljs-regexp">    NVIDIA_VISIBLE_DEVICES=all</span><span class="hljs-regexp"></span><span class="hljs-regexp">ENV HADOOP_PREFIX=$&#123;HADOOP_INSTALL&#125; \</span><span class="hljs-regexp">    HADOOP_BIN_DIR=$&#123;HADOOP_INSTALL&#125;/bin</span> \    HADOOP_SBIN_DIR=$&#123;HADOOP_INSTALL&#125;/sbin \    HADOOP_HDFS_HOME=$&#123;HADOOP_INSTALL&#125; \    HADOOP_COMMON_LIB_NATIVE_DIR=$&#123;HADOOP_INSTALL&#125;/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">native</span> \</span>    HADOOP_OPTS=<span class="hljs-string">"-Djava.library.path=$&#123;HADOOP_INSTALL&#125;/lib/native"</span>ENV PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/nvidia/bin</span>:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/bin</span>:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/sbin:/usr</span><span class="hljs-regexp">/local/bin</span>:<span class="hljs-regexp">/usr/sbin</span>:<span class="hljs-regexp">/usr/bin</span>:<span class="hljs-regexp">/sbin:/bin</span>:$&#123;HADOOP_BIN_DIR&#125;:$&#123;HADOOP_SBIN_DIR&#125;:$PATH \LD_LIBRARY_PATH=<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/extras</span><span class="hljs-regexp">/CUPTI/lib</span>:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/extras</span><span class="hljs-regexp">/CUPTI/lib</span>64:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/nvidia/lib</span>:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/nvidia/lib</span>64:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/lib</span>64:<span class="hljs-regexp">/usr/local</span><span class="hljs-regexp">/cuda/targets</span><span class="hljs-regexp">/x86_64-linux/lib</span><span class="hljs-regexp">/stubs:$&#123;JAVA_HOME&#125;/jre</span><span class="hljs-regexp">/lib/amd</span>64/serverCopy</code></pre><p>建议先把这一部分进行构建，作为基础镜像，后面要配置其他环境（如安装Pytorch框架登），就不用重复构建这部分，还减少了出错的可能性。这里说一下，启动带CUDA的Docker镜像需要在<code>docker run</code>加上额外的参数<code>--runtime nvidia</code>。</p><p>接下来安装深度学习框架。</p><h2 id="Configure-PyTorch"><a href="#Configure-PyTorch" class="headerlink" title="Configure PyTorch"></a>Configure PyTorch</h2><p>假设上面的镜像我们命名为xiaoqinfeng/base，那么构建PyTorch的Dockerfile可以像下面这么写：</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> xiaoqinfeng/base<span class="hljs-keyword">RUN</span><span class="bash"> pip install -U pip</span><span class="hljs-keyword">RUN</span><span class="bash"> pip install numpy scipy pandas matplotlib tqdm</span><span class="hljs-keyword">RUN</span><span class="bash"> pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.htmlCopy</span></code></pre><p>因为这里我用的CUDA10.1，其他版本的CUDA安装指令可能不太一样，具体可以参考<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">官网</a>。</p><h2 id="Configure-Tensorflow"><a href="#Configure-Tensorflow" class="headerlink" title="Configure Tensorflow"></a>Configure Tensorflow</h2><p>如果是安装Tensorflow，那么构建Tensorflow的Dockerfile可以像下面这么写：</p><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> xiaoqinfeng/base<span class="hljs-keyword">RUN</span><span class="bash"> pip install -U pip</span><span class="hljs-keyword">RUN</span><span class="bash"> pip install numpy scipy pandas matplotlib tqdm tensorflow-gpuCopy</span></code></pre><p>这里会自动安装最新版本的Tensorflow2。Tensorflow不同版本对CUDA和cuDNN版本甚至Python版本的支持都不太一样，可以参考<a href="https://www.tensorflow.org/install/source#linux" target="_blank" rel="noopener">官网</a>的说明。</p><h1 id="Deep-Learning-with-OpenPAI"><a href="#Deep-Learning-with-OpenPAI" class="headerlink" title="Deep Learning with OpenPAI"></a>Deep Learning with OpenPAI</h1><h2 id="What-is-OpenPAI"><a href="#What-is-OpenPAI" class="headerlink" title="What is OpenPAI"></a>What is OpenPAI</h2><p>OpenPAI是一个分布式深度学习计算资源管理平台，对于我们用户来说，只需要定义好Docker镜像，然后编写好任务设置，提交到平台之后，平台便会自动分配计算资源来运行任务。</p><p>OpenPAI界面：</p><img src="https://i.loli.net/2020/06/24/CDrZjgYR7lNcieh.png" srcset="/img/loading.gif" style="zoom: 50%;" /><img src="https://i.loli.net/2020/06/24/FGJpVCbls7YP4aM.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>下面我们来讲讲怎么向OpenPAI平台提交任务。</p><h2 id="Submit-Jobs-to-OpenPAI"><a href="#Submit-Jobs-to-OpenPAI" class="headerlink" title="Submit Jobs to OpenPAI"></a>Submit Jobs to OpenPAI</h2><h3 id="Pack-Code-amp-Data-Files"><a href="#Pack-Code-amp-Data-Files" class="headerlink" title="Pack Code &amp; Data Files"></a>Pack Code &amp; Data Files</h3><p>假设你已经完成了代码的编写和测试，你的目录结构可能看起来是这样：</p><pre><code class="hljs css">.├── <span class="hljs-selector-tag">README</span><span class="hljs-selector-class">.md</span>├── <span class="hljs-selector-tag">data</span>│   └── <span class="hljs-selector-tag">dataset</span><span class="hljs-selector-class">.csv</span>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span>└── <span class="hljs-selector-tag">src</span>    ├── <span class="hljs-selector-tag">data</span><span class="hljs-selector-class">.py</span>    └── <span class="hljs-selector-tag">net</span><span class="hljs-selector-class">.pyCopy</span></code></pre><p>因为OpenPAI会创建一个虚拟容器来运行你的代码，所以你的数据和代码必须要以某种方式传送到OpenPAI上的虚拟容器中。我们先来打包，在代码目录下执行<code>tar -cvf files.tar ./</code>。之后，运行<code>python -m http.server &lt;port&gt;</code>。打开浏览器输入<code>&lt;server_ip&gt;:&lt;port&gt;</code>应该就能看到你的文件了：</p><p><img src="https://i.loli.net/2020/06/24/Cbgiw3XKnGYsNHp.png" srcset="/img/loading.gif" alt=""></p><p>由于这个http进程需要一直运行，所以建议使用<code>screen</code>放到后台执行。</p><h3 id="Configure-Tasks"><a href="#Configure-Tasks" class="headerlink" title="Configure Tasks"></a>Configure Tasks</h3><p>像OpenPAI提交任务可以采用网页提交也可以使用VSCode插件，这里我们采用网页提交。登入OpenPAI界面，点击Submit Job：</p><p><img src="https://i.loli.net/2020/06/24/bhXAcJfOmo8RtT2.png" srcset="/img/loading.gif" alt=""></p><p>可以看到提交任务的界面：</p><p><img src="https://i.loli.net/2020/06/24/KME8GuN49gyY1ph.png" srcset="/img/loading.gif" alt=""></p><p>Job name大家可以自己设置。在Command一栏，是执行任务所需的全部命令，首先我们要做的就是将代码数据压缩包下载到容器中并解压：</p><pre><code class="hljs elixir">wget &lt;server_ip&gt;<span class="hljs-symbol">:&lt;port&gt;/files</span>.tartar -xvf files.tarCopy</code></pre><p>然后是运行代码，假设我这里的任务比较简单，只有一行main.py的调用：</p><pre><code class="hljs css"><span class="hljs-selector-tag">python</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.pyCopy</span></code></pre><p>如果任务的执行比较复杂，也只需把命令填到Command里即可，OpenPAI会自动执行。接下来是设置配置，可以选GPU的数量，内存大小等等：</p><img src="https://i.loli.net/2020/06/24/T7ryOxjpJP4FWYR.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>然后是镜像的选择：</p><img src="https://i.loli.net/2020/06/24/3n7SpNlsLjBRvgE.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>要注意在本机上构建好镜像之后，需要把镜像重命名为<code>&lt;repository_address&gt;/&lt;image_name&gt;</code>的格式（我们的<code>&lt;repository&gt;</code>是<code>lin-ai-27:5000</code>，假设我的镜像名是<code>xiaoqinfeng/pytorch</code>，那就是改成<code>lin-ai-27:5000/xiaoqinfeng/pytorch</code>），然后执行<code>docker push</code>推送到Docker镜像服务器上才能在OpenPAI上使用。</p><p>提交之后，可以在Jobs界面看到任务的运行情况：</p><img src="https://i.loli.net/2020/06/24/ZD4cUgOCIqnyHdB.png" srcset="/img/loading.gif" style="zoom: 50%;" /><h1 id="Misc"><a href="#Misc" class="headerlink" title="Misc"></a>Misc</h1><h2 id="Store-Files-in-Containers"><a href="#Store-Files-in-Containers" class="headerlink" title="Store Files in Containers"></a>Store Files in Containers</h2><p>我们往往需要在程序运行的时候保存文件，如checkpoints等。在OpenPAI上执行程序的话文件是保存在程序中的，如果我们想要在运行完之后把文件复制到本地电脑上呢？这个时候就需要在任务的配置文件里加上复制文件到HDFS的语句。首先确认你的HDFS的URL：如<code>hdfs://172.31.246.52:9000/你的OpenPAI用户名/</code>。</p><p>如果要创建文件夹，则可以使用<code>hdfs dfs -mkdir -p &lt;HDFS URL&gt;+&lt;New Folder&gt;</code>。这里<code>&lt;New Folder&gt;</code>是你要创建的的文件夹的路径，用起来和Linux的<code>mkdir</code>命令其实是差不多的。</p><p>要复制文件（夹）则使用<code>hdfs dfs -cp &lt;Source Dir&gt; &lt;Dest Dir&gt;</code>。</p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Misc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
      <tag>Tensorflow</tag>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ubuntu20.04LTS 深度学习环境配置 CUDA10.2 + cuDNN7.6.5 + Tensorflow + Pytorch</title>
    <link href="/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA10-2-cuDNN7-6-5-Tensorflow-Pytorch/"/>
    <url>/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA10-2-cuDNN7-6-5-Tensorflow-Pytorch/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Ubuntu的最新LTS版本也更新到了20.04，在给新机器配置深度学习环境的时候发现比以前容易了许多，特此写一篇Tutorial。这里的安装方法只针对Ubuntu20.04LTS，对于其他版本的系统可能不太适用。</p><h1 id="Install-GPU-Drivers"><a href="#Install-GPU-Drivers" class="headerlink" title="Install GPU Drivers"></a>Install GPU Drivers</h1><p>这里假设安装系统之后已经做好了必要的配置（安装常用软件依赖、修改国内源等）。Ubuntu20.04中GPU驱动可以直接通过GUI界面安装，十分方便，方法是找到软件与更新 (Software &amp; Updates)，在附加驱动 (additional drivers) 选项卡中选择驱动版本，一般是选择“专有，tested” (proprietary, tested) 那个，之后点Apply Changes，重启。</p><p><img src="https://i.loli.net/2020/06/24/xevtVosYOH7D68I.png" srcset="/img/loading.gif" alt=""></p><h1 id="Install-CUDA-amp-cuDNN"><a href="#Install-CUDA-amp-cuDNN" class="headerlink" title="Install CUDA &amp; cuDNN"></a>Install CUDA &amp; cuDNN</h1><p>这里选择apt-get的方式安装CUDA：</p><pre><code class="hljs bash">sudo apt-get install nvidia-cuda-toolkit</code></pre><p>输入<code>nvcc --version</code>可以测试是否安装成功，输入<code>nvidia-smi</code>可以看到GPU信息和CUDA版本。</p><p>之后安装cuDNN，进入<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">官网</a>，选择Download cuDNN：</p><p><img src="https://i.loli.net/2020/06/24/VYBRoINFDC9ObA1.png" srcset="/img/loading.gif" alt=""></p><p>会要求登录，如果没有账号的注册一个即可。在这里根据CUDA版本选择适合的cuDNN，我这里是CUDA10.2。我们选择deb包的方式安装，下载下图中圈出来的三个deb包，依次用<code>sudo dpkg -i xxx.deb</code>命令安装。</p><p><img src="https://i.loli.net/2020/06/24/qcDG5t3JY6vfoQM.png" srcset="/img/loading.gif" alt=""></p><h1 id="Configure-Python"><a href="#Configure-Python" class="headerlink" title="Configure Python"></a>Configure Python</h1><p>为了更好地管理Python包和虚拟环境，我们需要安装Anaconda。使用Anaconda之后，我们可以创建虚拟环境，虚拟环境之间互不干扰。做科学实验我们一般需要安装大量的Python包，有的包之间甚至还有冲突，如果我们把他们都安装在同一个环境下就会难以管理，甚至出冲突。而有了虚拟环境之后，我们可以把不同需求放在不同虚拟环境中，比如深度学习开发放在一个虚拟环境中（安装Tensorflow等），网站开发放在一个虚拟环境中（安装Flask等）。Anaconda默认自带大量的包，不过我们一般会创建新的虚拟环境去安装新的包，所以这里我们选用Miniconda。Miniconda和Anaconda唯一的区别是不会自带大量Python包，这里大家自行选择。Anaconda国内镜像下载地址为：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/，Miniconda国内镜像下载地址为：https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/。" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/，Miniconda国内镜像下载地址为：https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/。</a></p><p>比如说我们下载的是<code>Miniconda3-py38_4.8.2-Linux-x86_64.sh</code>，执行<code>bash Miniconda3-py38_4.8.2-Linux-x86_64.sh</code>即可安装。显示一大屏用户协议哪儿按<code>q</code>可以直接跳过，其他选项的默认的输入<code>yes</code>即可。在提示是否需要conda init的时候记得输入<code>yes</code>。</p><p>安装成功之后，重开一个终端，可以看到现在处于<code>base</code>环境中：</p><p><img src="https://i.loli.net/2020/06/24/giml1UKzWuyqTjr.png" srcset="/img/loading.gif" alt=""></p><p>我们先配置一下国内镜像，执行</p><pre><code class="hljs bash">vim ~/.condarc</code></pre><p>然后粘贴下列文本使用清华源：</p><pre><code class="hljs less"><span class="hljs-attribute">channels</span>:  - defaults<span class="hljs-attribute">show_channel_urls</span>: true<span class="hljs-attribute">channel_alias</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda</span><span class="hljs-attribute">default_channels</span>:  - <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span>  - <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free</span>  - <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span>  - <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro</span>  - <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><span class="hljs-attribute">custom_channels</span>:  <span class="hljs-attribute">conda-forge</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span>  <span class="hljs-attribute">msys2</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span>  <span class="hljs-attribute">bioconda</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span>  <span class="hljs-attribute">menpo</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span>  <span class="hljs-attribute">pytorch</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span>  <span class="hljs-attribute">simpleitk</span>: <span class="hljs-attribute">https</span>:<span class="hljs-comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span></code></pre><p>之后我们输入<code>conda create -n &lt;your_name&gt;</code>创建一个新的虚拟环境，如果需要指定Python版本，则<code>conda create --n &lt;your_name&gt; python=&lt;python_version&gt;</code>。之后输入<code>conda activate &lt;your_name&gt;</code>进入虚拟环境，如果需要退出，则使用<code>conda deactivate</code>。</p><p>安装常用包：</p><pre><code class="hljs bash">conda install --yes numpy scipy pandas matplotlib tqdm pip jupyter</code></pre><p><code>--yes</code>的作用是手动输入<code>y</code>来确认是否安装，这里列出的是一些最常用的Python包，大家可以根据自己的需求自行调整。<code>conda install</code>为Anaconda中安装Python包的方式。</p><h1 id="Install-PyTorch"><a href="#Install-PyTorch" class="headerlink" title="Install PyTorch"></a>Install PyTorch</h1><p>这里来安装PyTorch环境，推荐使用<code>conda create -n pytorch</code>创建一个专有虚拟环境，然后使用<code>conda install</code>安装常用包。对于安装PyTorch，我们可以使用<code>conda</code>也可以使用<code>pip</code>安装。<code>pip</code>是另外一个安装Python包的工具，由于不检查依赖所以比<code>conda</code>安装速度快，而且包的数量比<code>conda</code>多，使用也更广泛。同样<code>pip</code>也可以使用国内镜像加速下载，详见<a href="https://mirrors.tuna.tsinghua.edu.cn/help/pypi/。" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/help/pypi/。</a></p><p>对于CUDA10.2，官方给出的用<code>conda</code>安装PyTorch的命令是：</p><pre><code class="hljs bash">conda install pytorch torchvision cudatoolkit=10.2 -c pytorch</code></pre><p>用<code>pip</code>安装PyTorch的命令是：</p><pre><code class="hljs bash">pip install torch torchvision</code></pre><p>对于其他版本的CUDA安装命令可能不一样，可以去<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">官网</a>查看。</p><p>可以使用以下命令来测试GPU版本的PyTorch是否正常工作：</p><pre><code class="hljs bash">python -c <span class="hljs-string">"import torch; print(torch.cuda.is_available())"</span></code></pre><h1 id="Install-Tensorflow"><a href="#Install-Tensorflow" class="headerlink" title="Install Tensorflow"></a>Install Tensorflow</h1><p>安装Tensorflow环境同样推荐创建一个专有虚拟环境。对于Tensorflow2的安装，使用<code>pip</code>十分方便，使用</p><pre><code class="hljs bash">pip install tensorflow tensorflow-gpu</code></pre><p>即可。要安装其他版本的Tensorflow可以使用<code>pip install tensorflow==&lt;tf_version&gt; tensorflow-gpu==&lt;tf_version&gt;</code>来指定版本。不过不同版本的Tensorflow要求的CUDA版本都有所不同，可以参考<a href="https://www.tensorflow.org/install/source#linux" target="_blank" rel="noopener">官网</a>的说明。</p><p>可以使用以下命令来测试GPU版本的Tensorflow是否正常工作：</p><pre><code class="hljs bash">python -c <span class="hljs-string">"import tensorflow as tf; tf.config.list_physical_devices('GPU')"</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Misc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
      <tag>Tensorflow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Anomaly Detection Using Geometric Transformations</title>
    <link href="/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/"/>
    <url>/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>本文考虑针对图像的异常检测。记$\mathcal X$为所有自然图像的空间，$X\subseteq\mathcal X$为正常图像集合。给定数据集$S\subseteq X$，异常检测的目的是学习一个分类器$h_S(x):\mathcal X\rightarrow{0,1}$，其中$h_S(x)=1\Leftrightarrow x\in X$。</p><p>为了兼顾查准率和查全率，常用的设置是学习一个打分函数$n_S(x):\mathcal X\rightarrow\mathbb R$，分数越高代表样本属于$X$的概率越大。之后，通过设定阈值，便可以构建异常分类器：<br>$$<br>\begin{align}<br>h_S^\lambda(x)=<br>\begin{cases}<br>1 &amp; n_S(x)\leq\lambda\<br>0 &amp; n_S(x)&lt;\lambda<br>\end{cases}<br>\end{align}<br>$$</p><h2 id="Discriminative-Learning-of-an-Anomaly-Scoring-Function-Using-Geometric-Transformations"><a href="#Discriminative-Learning-of-an-Anomaly-Scoring-Function-Using-Geometric-Transformations" class="headerlink" title="Discriminative Learning of an Anomaly Scoring Function Using Geometric Transformations"></a>Discriminative Learning of an Anomaly Scoring Function Using Geometric Transformations</h2><p>有初始数据集$S$，几何变换集合$\mathcal T$，通过对$S$中每个样本施加这$|\mathcal T|$个几何变换得到新数据集记为$S_\mathcal{T}$，且$S_\mathcal{T}$中每个样本的标签为变换的序号。之后，在$S_\mathcal{T}$上训练一个$|\mathcal T|$分类器。在测试阶段，对测试样本同样施加$|\mathcal T|$个几何变换，分类器会给出经过$\mathrm{softmax}$的输出向量，最终的异常分数由经过输出的向量构造的分布对数似然得来。</p><h3 id="Creating-and-Learning-the-Self-Labeled-Dataset"><a href="#Creating-and-Learning-the-Self-Labeled-Dataset" class="headerlink" title="Creating and Learning the Self-Labeled Dataset"></a>Creating and Learning the Self-Labeled Dataset</h3><p>设$\mathcal T={T_0,T_1,\cdots,T_{k-1}}$为几何变换集合，$1\leq i\leq k-1,\space T_i:\mathcal X\rightarrow \mathcal X$，且$T_0(x)=x$。$S_\mathcal{T}$定义为：</p><p>$$<br>S_\mathcal T={(T_j(x),j):x\in S,T_j\in\mathcal T}<br>$$<br>对于每个$x\in S$，$j$为$T_j(x)$的标签。我们直接学习一个$K$类分类器$f_\theta$，来预测输入样本对应的几何变换种类，这相当于是一个图像分类问题。</p><img src="https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Dirichlet-Normality-Score"><a href="#Dirichlet-Normality-Score" class="headerlink" title="Dirichlet Normality Score"></a>Dirichlet Normality Score</h3><p>接下来要做的是如何定义异常分数，记为$n_S(x)$，这是文中的一个重要的部分。设几何变换集合$\mathcal T={T_0,T_1,\cdots,T_{k-1}}$，且$k$分类器$f_\theta$在$S_\mathcal{T}$上完成训练。对于任意一个样本$x$，令$\mathbf y(x)=\text{softmax}(f_{\theta}(x))$，即分类器$f_\theta$输出的$\text{softmax}$之后的向量。异常分数$n_S(x)$定义为：</p><p>$$<br>n_S(x)=\sum\limits_{i=0}^{k-1}\log p(\mathbf y(T_i(x))|T_i)<br>$$</p><p>该异常分数定义为每个类别上，在几何变换$T_i$的条件下，输出的$\mathbf y$的对数似然之和。在文中，作者假设$\mathbf y(T_i(x)|T_i$服从迪利克雷分布：$\mathbf y(T_i(x))|T_i\sim\text{Dir}(\boldsymbol \alpha_i)$，其中$\boldsymbol \alpha_i\in\mathbb R^k_+$，$x\sim p_X(x)$，$i\sim\text{Uni}(0,k-1)$，而$p_X(x)$代表正常样本的真实数据分布。于是：</p><p>$$<br>n_S(x)=\sum_{i=0}^{k-1}\left[\log\Gamma(\sum_{j=0}^{k-1}[\tilde{\boldsymbol\alpha}<em>i]_j)-\sum</em>{j=0}^{k-1}\log\Gamma([\tilde{\boldsymbol\alpha}<em>i]_j)+\sum</em>{j=0}^{k-1}([\tilde{\boldsymbol\alpha}_i]_j-1)\log\mathbf y(T_i(x))_j\right]<br>$$</p><p>因为$\tilde{\alpha}<em>i$相对于$x$来说是常数，所以可以直接忽略，于是式子简化为：<br>$$<br>n_S(x)=\sum</em>{i=0}^{k-1}\sum_{j=0}^{k-1}([\tilde{\boldsymbol\alpha}<em>i]_j-1)\log\mathbf y(T_i(x))_j=\sum</em>{i=0}^{k-1}(\tilde{\boldsymbol \alpha}_i-1)\cdot\log\mathbf y(T_i(x))<br>$$</p><p>注意这里的每个$\boldsymbol \alpha_i$都是一个向量，即对于每个变换$i$，都对应一个迪利克雷分布，其参数为$\boldsymbol\alpha_i$；在对训练集进行第$i$个几何变换之后，我们得到了${T_i(x)}$，然后分类器$f_\theta(\cdot)$的输出$\mathbf y(T_i(x))$相当于迪利克雷分布的观测值，我们需要根据观测值来估计参数$\boldsymbol \alpha_i$，然后根据这个参数来计算$n_S(x)$。对于$\boldsymbol\alpha_i$，可以知道其第$i$个分量应该是相对比较大的，下面是运行官方代码得到的$\boldsymbol\alpha_i$的结果（$i=69$，$i$从$0$开始，总共为$72$维），可以看到第$69$个分量是最大的。</p><pre><code class="hljs bash">[INFO] value of mle_alpha_t: [ 0.10228925  0.08997199  0.13083569  0.10862965  0.09811163  0.08527119  0.17637901  0.27628416  0.12873376  0.19197053  0.11587154  0.09873095  0.12700618  0.07688542  0.10488203  0.12499191  0.11637607  0.07739511  0.13049147  0.51031647  0.20546597  0.15558449  0.09288609  0.12134945  0.09324992  0.14650162  0.16281216  0.11827823  0.08214853  0.15618336  0.28129761  0.45293697  0.11485838  1.78598954  0.16556983  0.1141158  0.10909459  0.13916602  0.11563799  0.07309986  0.11049714  0.12974086  0.15930642  0.13714361  0.13938356  0.70619553  0.11174039  0.07201538  0.16626109  0.12153727  0.09548811  0.07940956  0.15832209  0.11035474  0.12487912  0.16937875  0.23212662  0.37041831  0.08557451  0.0839439  0.09924258  0.39766872  0.14917286  0.08704662  0.09554555  0.31047109  0.24504759  0.16812463  0.11508187 63.98878807  0.12971073  0.07972932]</code></pre><p>下图也展示了对于每个变换$i$，$\mathbf y(T_i(x)|T_i$分布的情况：</p><img src="https://i.loli.net/2020/06/23/fLkst4i7Hu6PhQl.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>作者还给出了一种简化的形式，$\hat{n}<em>S(x)=\frac{1}{k}\sum^{k-1}</em>{j=0}[\mathbf y(T_j(x))]_j$。相当于说，对于每个变换$T_i$分类器都会给出一个$\text{softmax}$向量，取其第$i$个分量$[\mathbf y(T_j(x))]_j$，然后把每个变换对应的$[\mathbf y(T_j(x))]_j$加起来。</p><p>整个算法的流程如下：</p><img src="https://i.loli.net/2020/06/23/z8MpdeoD6ZGavlN.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>这里结合作者的源代码简单说一下检测阶段的流程。</p><hr><pre><code class="hljs python"><span class="hljs-keyword">for</span> t_ind <span class="hljs-keyword">in</span> range(transformer.n_transforms):        observed_dirichlet = mdl.predict(transformer.transform_batch(observed_data, [t_ind] * len(observed_data)), batch_size=<span class="hljs-number">1024</span>)</code></pre><p>在训练好模型之后，对于训练集的所有样本，对其进行$K$个几何变换之后，得到$K$个样本${T_i(x)}$，对于所有第$i$个几何变换对应的样本${T_i(x)}$，通过分类器$f_\theta$会给出输出$\mathbf y(T_i(x))$。这里对应算法中的第$7-8$行，这个<code>observed_dirichlet</code>就是$S_i$。</p><hr><pre><code class="hljs python">log_p_hat_train = np.log(observed_dirichlet).mean(axis=<span class="hljs-number">0</span>)alpha_sum_approx = calc_approx_alpha_sum(observed_dirichlet)alpha_0 = observed_dirichlet.mean(axis=<span class="hljs-number">0</span>) * alpha_sum_approx</code></pre><p>之后这部分主要对应算法中的$9-11$行。作者把所有的第$i$个变换，分类器的输出的集合（也就是变量<code>observed_dirichlet</code>）记为$S_i$，$\bar s$为$S_i$的平均，$\bar l$为$S_i$对数的平均（变量<code>log_p_hat_train</code>），初始值$\tilde{\alpha}_i$由$\bar s\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}$给出（变量<code>alpha_0</code>）。函数<code>calc_approx_alpha_sum</code>实现的是算法中第$11$行的$\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}$，代码如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calc_approx_alpha_sum</span><span class="hljs-params">(observations)</span>:</span>    N = len(observations)    f = np.mean(observations, axis=<span class="hljs-number">0</span>)    <span class="hljs-keyword">return</span> (N * (len(f) - <span class="hljs-number">1</span>) * (-psi(<span class="hljs-number">1</span>))) / (        N * np.sum(f * np.log(f)) - np.sum(f * np.sum(np.log(observations), axis=<span class="hljs-number">0</span>)))</code></pre><hr><pre><code class="hljs python">mle_alpha_t = fixed_point_dirichlet_mle(alpha_0, log_p_hat_train)</code></pre><p>这里对应算法中的$12-14$行，即重复$\tilde\alpha_i\leftarrow\Psi^{-1}\left(\Psi(\sum_j[\alpha_i]_j)+\bar l\right)$来估计$\alpha$，函数<code>fixed_point_dirichlet_mle</code>代码如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fixed_point_dirichlet_mle</span><span class="hljs-params">(alpha_init, log_p_hat, max_iter=<span class="hljs-number">1000</span>)</span>:</span>    alpha_new = alpha_old = alpha_init    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(max_iter):        alpha_new = inv_psi(psi(np.sum(alpha_old)) + log_p_hat)        <span class="hljs-keyword">if</span> np.sqrt(np.sum((alpha_old - alpha_new) ** <span class="hljs-number">2</span>)) &lt; <span class="hljs-number">1e-9</span>:            <span class="hljs-keyword">break</span>        alpha_old = alpha_new    <span class="hljs-keyword">return</span> alpha_new</code></pre><p>$\Psi^{-1}(\cdot)$是通过数值方法来估计的：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">inv_psi</span><span class="hljs-params">(y, iters=<span class="hljs-number">5</span>)</span>:</span>    <span class="hljs-comment"># initial estimate</span>    cond = y &gt;= <span class="hljs-number">-2.22</span>    x = cond * (np.exp(y) + <span class="hljs-number">0.5</span>) + (<span class="hljs-number">1</span> - cond) * <span class="hljs-number">-1</span> / (y - psi(<span class="hljs-number">1</span>))    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(iters):        x = x - (psi(x) - y) / polygamma(<span class="hljs-number">1</span>, x)    <span class="hljs-keyword">return</span> x</code></pre><hr><p>最后，在得到对$\alpha$的估计之后，可以来计算测试样本的分数了。这里对应的是算法中的第$16$行。</p><pre><code class="hljs python">x_test_p = mdl.predict(transformer.transform_batch(x_test, [t_ind] * len(x_test)), batch_size=<span class="hljs-number">1024</span>)scores += dirichlet_normality_score(mle_alpha_t, x_test_p)</code></pre><p>函数<code>dirichlet_normality_score</code>代码如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dirichlet_normality_score</span><span class="hljs-params">(alpha, p)</span>:</span>    <span class="hljs-keyword">return</span> np.sum((alpha - <span class="hljs-number">1</span>) * np.log(p), axis=<span class="hljs-number">-1</span>)</code></pre><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><p>文中用到了如下的Baseline：</p><ul><li><strong>One-class SVM. **单类支持向量机，作者使用了三个变体，分别为</strong>RAW-OC-SVM<strong>——使用原始数据作为输入，</strong>CAE-OC-SVM<strong>——使用一个卷积自编码器来获得低维表示作为输入和</strong>E2E-OC-SVM<strong>——全名为</strong>One-Class Deep Support Vector Data Description**；</li><li>*<em>Deep structured energy-based models. *</em></li><li>*<em>Deep Autoencoding Gaussian Mixture Model. *</em></li><li>*<em>Generative Adversarial Networks. *</em></li></ul><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>文中用到了一下几个数据集：</p><ul><li><strong>CIFAR-10</strong></li><li><strong>CIFAR-100</strong></li><li><strong>Fashion-MNIST</strong></li><li><strong>CatsVsDogs</strong></li></ul><p>在实验中所有图片都被归一化到$[-1,1]$的范围。</p><h2 id="Experimental-Protocol"><a href="#Experimental-Protocol" class="headerlink" title="Experimental Protocol"></a>Experimental Protocol</h2><p>设数据集有$C$个类，我们会进行$C$次实验，在第$c$次实验 ($1\leq c \leq C$)中我们会将第$c$个类作为正常样本，而其他类作为异常样本。在训练阶段，训练集只包含正常样本，而在测试阶段则会有正常样本和异常样本。在获得异常分数之后，阈值$\lambda$则根据ROC曲线下面积选择。</p><p>实验中使用的几何变换基于以下三种基变换：</p><ul><li>*<em>Horizontal flip: *</em> 记为$T_b^{flip}(x)$，$b\in{T,F}$代表是否翻转；</li><li>*<em>Translation: *</em> 记为$T_{s_h,s_w}^{trans}(x)$，其中$s_h,s_w\in{-1,0,1}$。在长宽两个维度上位移分别为$0.25$高度和$0.25$宽度，这两个维度发生位移的方向由$s_h$和$s_w$决定，当$s_h=s_w=0$时代表不移动；</li><li>*<em>Rotation by multiples 90 degrees: *</em> 记为$T_k^{rot}(x)$，$k\in{0,1,2,3}$。旋转$k\times90$度。</li></ul><p>将三种基变换叠加有：<br>$$<br>\mathcal T=\left{<br> T_k^{rot}\circ T_{s_h,s_w}^{trans}\circ T_b^{flip} : \begin{matrix}<br> b &amp;\in {T,F}\<br> s_h,s_w&amp;\in{-1,0,1}\<br> k&amp;\in{0,1,2,3}<br> \end{matrix}<br>\right}<br>$$<br>最终几何变换种数为$2\times3\times3\times4=72$种。</p><p>分类器模型使用的是<strong>Wide Residual Network</strong>，优化器为Adam，Batch size为128，训练轮数为200。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>下面是不同方法在不同数据集上的实验结果：</p><p><img src="https://i.loli.net/2020/06/24/gHZohrvz9MGYmxi.png" srcset="/img/loading.gif" alt=""></p><p>评测标准使用的是AUROC。作者关于结果的分析主要有以下几点：</p><ol><li>在绝大多数情况下，我们的算法都比Baseline要好，而且是越大的数据集效果越好。CatsVsDogs数据集每张图片的大小比其他几个数据集都要大，而Baseline在这个数据集上的结果都在$50%$或不到$50%$，这基本等同于瞎猜；</li><li>在CIFAR-100数据集里，由于将这100类聚合为了20类，所以存在类内样本差异大的问题。比如在类$5$、类$7$和类$13$上，模型表现就不够好；</li><li>在Fashion-MNIST数据集上几乎所有方法（除了DAGMM）都表现很好。</li></ol><h2 id="On-the-Intuition-for-Using-Geometric-Transformations"><a href="#On-the-Intuition-for-Using-Geometric-Transformations" class="headerlink" title="On the Intuition for Using Geometric Transformations"></a>On the Intuition for Using Geometric Transformations</h2><p>这里作者对所选用的几何变换做了一些解释。实验中选用的三种基本几何变换都是可逆的线性几何变换（且为双射），作者也试过一些复杂的非线性变换，如高斯模糊、锐化、伽马校正等等，但是效果并不好。</p><p>作者认为分类器能够分辨不同变换的能力与最终性能成正比，为了验证这一点，进行了$3$个实验。从MNIST数据集选择一个数字作为正常样本，几何变换只采用两个，然后选择另一个数字作为异常样本，结果如下：</p><ul><li>*<em>Normal digit: 8，Anomaly: 3，Transformations: Identity and horizontal flip. *</em>由于数字$8$是对称的，所以要让分类器分辨原始的$8$和翻转之后的$8$是很难的，AUROC只有$0.646$；</li><li>*<em>Normal digit: 3，Anomaly: 8，Transformations: Identity and horizontal flip. *</em>这里把$3$作为正常样本，由于$3$不是对称的，所以两种变换是可以分辨的，AUROC达到了$0.957$；</li><li>*<em>Normal digit: 8，Anomaly: 3，Transformations: Identity and translation by 7 pixels. *</em>同样是把$8$作为正常样本，但变换用的是平移，AUROC达到了$0.919$。</li></ul><p>除此之外，作者还设计了一个实验，目的是测试什么样的图像会获得较高的分数$n_S(x)$。在给定训练好的分类器的情况下，优化输入的图像，目标函数是最大化分数$n_S(x)$。下图为实验结果：</p><p><img src="https://i.loli.net/2020/06/24/8Pi4EKCRuBXrYgp.png" srcset="/img/loading.gif" alt=""></p><p>在左图中，将数字$3$作为正常样本训练的分类器、原始输入为数字$0$的图片时，随着优化的进行，图片慢慢地变得像数字$3$。在右图中，同样是将数字$3$作为正常样本训练的分类器，不过原始输入也是数字$3$，这时图像却没有怎么变化。</p><h1 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h1><ul><li>文中提到的在CIFAR100数据的实验上，由于类间差异比较大导致效果较差，那么很自然地，不同的变换样本对应的集簇实际上应当足够分开，集簇内的样本要足够进，这样对于分类器来说才能比较好的分类。不过采用的几何变换并没有针对这一点进行特别设计；</li><li>文中强调了所使用的变换为几何变换，其实除此之外，所使用的变换还都是可以用矩阵表示的可逆的变换。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cross-dataset Time Series Anomaly Detection for Cloud Systems</title>
    <link href="/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/"/>
    <url>/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文介绍了一种用于云计算平台的时间序列异常检测框架。为了解决标签不足的问题，文中使用了迁移学习的方法，即在有标签的source domain上训练模型，在没有标签的target domain上检测。同时，文中还使用了主动学习的方法来挑选最有价值的无标签样本进行标记。</p><p><a href="https://www.usenix.org/system/files/atc19-zhang-xu.pdf" target="_blank" rel="noopener">📰Get Paper</a></p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>针对云计算平台数据的异常检测通常是应用在云监控数据，如KPI、CPU使用率、系统负载等时序数据上。和传统的异常检测不一样的是，时序异常检测往往更难，文中总结了以下几个挑战：</p><ul><li>异常特征的差异性。在不同的云服务系统中，对异常的容忍度是不同的，所以对每个场景或系统组件设置准确的阈值来进行异常检测是十分困难的；</li><li>时间依赖性。该异常检测问题处理的是时间序列数据，而传统的异常检测并不会考虑时间依赖性；</li><li>无监督学习的性能问题。无监督的异常检测方法的性能有限，会带来大量的误报；</li><li>有监督学习需要大量标签。</li></ul><h1 id="Proposed-Approach"><a href="#Proposed-Approach" class="headerlink" title="Proposed Approach"></a>Proposed Approach</h1><p>为了解决上述挑战，文中提出了一个时间序列异常检测框架ATAD (Active Transfer Anomaly Detection)。该框架结合了迁移学习技术和主动学习技术，示意图如下：</p><img src="https://i.loli.net/2020/06/25/jOB4rC2gnH9VcQW.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>未标记数据$T_u$是我们要检测的目标数据 (target domain)，标记数据$T_l$是我们的源数据 (source domain)，可以是开源数据或者是其他系统的监控数据。</p><h2 id="Transfer-Learning-Component"><a href="#Transfer-Learning-Component" class="headerlink" title="Transfer Learning Component"></a>Transfer Learning Component</h2><p>在应用迁移学习时，我们需要考虑以下几个因素：</p><ul><li>我们处理的是时间序列数据，即在不同的时间点上样本之间不是相互独立的。为了解决这个问题，我们提取了不同的特征，每一个时间点被转换为了高维的特征向量，且每个时间点附近的背景信息被保存在了特征向量之中；</li><li>时间序列的粒度。粗粒度的迁移学习不利于发现异常，本文采用细粒度，即数据点级别的迁移学习；</li><li>迁移学习需要source domain和target domain具有潜在的相似性，所以我们需要对source domain中的样本进行过滤。</li></ul><img src="https://i.loli.net/2020/06/25/aM7Qvt6DwGXnThm.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Feature-Identification"><a href="#Feature-Identification" class="headerlink" title="Feature Identification"></a>Feature Identification</h3><p>这一节描述特征工程中用到的特征。在提取特征之前，文中使用了离散傅里叶变换来识别时间序列的周期$p$，并为后面滑动窗口的大小原则作参考。</p><h4 id="Statistical-Features"><a href="#Statistical-Features" class="headerlink" title="Statistical Features"></a>Statistical Features</h4><p>统计特征包含了一些基本的统计信息，如均值、方差等，用到的特征如下表所示：</p><img src="https://i.loli.net/2020/06/25/jI9EbCy1XueDViw.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>表中的统计特征都是基于大小等于周期$p$的滑动窗口的。</p><h4 id="Forecasting-Error-Features"><a href="#Forecasting-Error-Features" class="headerlink" title="Forecasting Error Features"></a>Forecasting Error Features</h4><p>使用预测特征的理由是如果一个数据点偏离预测值很远，那么它很有可能是异常。文中使用了多种时间序列预测模型，如SARIMA、Holt、Holt-Winters、STL等。最终的预测结果使用下式来加权集成：<br>$$<br>\hat{Y}<em>t=\sum\limits</em>{m=1}^{M}\frac{\hat{Y}<em>{m,t}}{M-1}\left(1-\frac{RMSE</em>{m,t}}{\sum\limits_{n=1}^M RMSE_{n,t}}\right)<br>$$<br>$M$代表$M$个不同模型，$RMSE_{m,t}$代表模型$m$在时间$t$的$RMSE$，$\hat{Y}_t$是在时间$t$的最终预测结果。之后，使用下表中的Metrics来计算不同预测特征：</p><img src="https://i.loli.net/2020/06/25/wRmfHj5xFcsLIXp.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>同样的，上述特征都是基于窗口的。</p><h4 id="Temporal-Features"><a href="#Temporal-Features" class="headerlink" title="Temporal Features"></a>Temporal Features</h4><p>这一部分是一些时间序列相关特征：</p><img src="https://i.loli.net/2020/06/25/mnBrzjfgV716yiR.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>最后，总共提取了37个特征，并且每个特征都进行了正则化。</p><h3 id="The-Transfer-between-Source-Domain-and-Target-Domain"><a href="#The-Transfer-between-Source-Domain-and-Target-Domain" class="headerlink" title="The Transfer between Source Domain and Target Domain"></a>The Transfer between Source Domain and Target Domain</h3><p>本文结合了基于实例的迁移学习(<strong>Instance-based Transfer Learning</strong>)和基于特征的迁移学习(<strong>Feature-based Transfer Learning</strong>)。</p><p>首先，source domain中的数据差异性是比较大的，所以我们需要选择与target domain相似的样本。</p><p>基于实例的迁移学习(<strong>Instance-based Transfer Learning</strong>)的思想是选择source domain中与target domain相似的样本。对于source domain，在将时间序列$T_l$转换为特征$F_l$之后，本文使用$K-means$算法将$F_l$分成若干个簇。每个簇$F_l^i, i\in[1,K]$是$F_l$的不重叠子集。为了选择合适的样本，我们计算了target domain中的样本和每个簇中心点的欧几里得距离，然后样本会和距离最近的簇$F_l^i$联系起来。</p><p>之后，为了使source domain和target domain在特征空间的差别更小，作者在每个簇上使用了<strong>CORrelation ALignment</strong> (CORAL) 算法。CORAL是一种领域适应算法 (<strong>Domain Adaption</strong>)，其基本思想是对source domain和target domain进行线性变换使其二阶统计信息（即协方差矩阵）的差别最小化：<br>$$<br>\min_A\parallel A^\top C^i_lA-C^i_u\parallel_F^2<br>$$</p><p>在最后一步，作者在每一个sub source domain $\hat{F}_l^i$训练了有监督模型（随机森林或SVM），所以最后我们得到了$K$个基模型。</p><h2 id="Active-Learning-Component"><a href="#Active-Learning-Component" class="headerlink" title="Active Learning Component"></a>Active Learning Component</h2><p>由于数据的差异性和复杂性太大，仅仅使用迁移学习的技术不足以达到很好的效果。在ATAD中，作者使用了主动学习技术来用较少的成本标注最有价值的样本来提升性能。本文中使用基于<strong>Uncertainty</strong>和<strong>Context Diversity</strong>的主动学习。</p><h3 id="Uncertainty"><a href="#Uncertainty" class="headerlink" title="Uncertainty"></a>Uncertainty</h3><p>大多数主动学习算法使用不确定性 (Uncertainty) 来作为选择要标记的样本的准则。<br>$$<br>Uncertainty=-|Prob(Normal)-Prob(Anomaly)|<br>$$<br>其中的$Prob$由基模型给出。</p><h3 id="Context-Diversity"><a href="#Context-Diversity" class="headerlink" title="Context Diversity"></a>Context Diversity</h3><p>多样性 (Diversity) 也是一个选择要标记样本的重要参考。如果有两个相似的样本，那么就没有必要将他们都标记。</p><p>时间上相邻的样本往往也是相似的。</p><p>具体的来说，我们对所有样本按照<strong>Uncertainty</strong>排序，然后进行一次扫描，如果当前样本在候选集中某个样本的<strong>Context</strong>之中，我们则忽略当前样本，因为这代表当前样本和候选集中的那个样本是相似的。如果不在<strong>Context</strong>之中，我们则将该样本加入候选集中。</p><p>判断是否在某个样本的<strong>Context</strong>中，如下图所示，直接判断是否落在区间$[t-\alpha,t+\alpha]$中就是了。</p><img src="https://i.loli.net/2020/06/25/nci9PvGDEdjky5R.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>主动学习模块的算法流程图如下图所示：</p><img src="https://i.loli.net/2020/06/25/RqonKfQS3IWw6Gb.png" srcset="/img/loading.gif" style="zoom: 80%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>在实验部分，作者试图回答以下问题：</p><ol><li>ATAD的效果如何？</li><li>迁移学习模块的有效性如何？</li><li>主动学习模块的有效性如何？</li><li>ATAD在基于公开数据时对公司内部数据检测效果如何？</li></ol><h2 id="Dataset-and-Setup"><a href="#Dataset-and-Setup" class="headerlink" title="Dataset and Setup"></a>Dataset and Setup</h2><p>下表是用到的数据集的一些基本信息：</p><img src="https://i.loli.net/2020/06/25/HDNGCrYOxezLwaB.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Evaluation-Metric"><a href="#Evaluation-Metric" class="headerlink" title="Evaluation Metric"></a>Evaluation Metric</h2><p>评测标准使用的是F1-score：<br>$$<br>F1=\frac{2\cdot P\cdot R}{P+R}, \space P=\frac{TP}{TP+FP}, \space R=\frac{TP}{TP+FN}<br>$$</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="RQ1-How-effective-is-ATAD"><a href="#RQ1-How-effective-is-ATAD" class="headerlink" title="RQ1: How effective is ATAD?"></a>RQ1: How effective is ATAD?</h3><p>Baseline包括孤立森林、K-Sigma、S-H-ESD和随机森林。</p><p>最终结果如下表所示：</p><img src="https://i.loli.net/2020/06/25/HMneBzlkR7Qg4TN.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>为了评测ATAD利用标签的能力，我们比较了RF在达到和ATAD相似F1 score情况下所需标签的数量，如下表所示：</p><img src="https://i.loli.net/2020/06/25/fcoXhCL43yVwYes.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="RQ2-How-effective-is-the-Transfer-Learning-Component"><a href="#RQ2-How-effective-is-the-Transfer-Learning-Component" class="headerlink" title="RQ2:    How  effective  is  the  Transfer  Learning Component?"></a>RQ2:    How  effective  is  the  Transfer  Learning Component?</h3><p>我们从以下两个方面来探究模型迁移知识的能力：</p><ul><li>使用文中所用到的特征的重要性</li><li>本模型迁移知识的能力</li></ul><p>对于第一点，作者提出传统的方法一般只提取了统计特征，而本文还提取了多种其他特征。作者对提取不同特征进行了比较试验，结果如下表所示：</p><img src="https://i.loli.net/2020/06/25/QV2eWzoOxGS6qJd.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>除此之外，作者还展示了不同数据集下前10有效的特征：</p><img src="https://i.loli.net/2020/06/25/QXYcP9V3xmJeIq5.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>对于第二点，作者比较了是否使用文中的领域适应算法CORAL，在达到相似F1 score下所需的标签数，如下表所示：</p><img src="https://i.loli.net/2020/06/25/JKFf4XngPBdGm3V.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="RQ3-How-effective-is-the-Active-Learning-component"><a href="#RQ3-How-effective-is-the-Active-Learning-component" class="headerlink" title="RQ3:  How effective is the Active Learning component?"></a>RQ3:  How effective is the Active Learning component?</h3><p>为了验证本文所用的主动学习的有效性，作者进行了对比试验。第一个模型 (Supervised model) 使用全部标签但不使用迁移学习训练，第二个 (Naïve) 为只使用主动学习而不使用迁移学习，第三个为本文提出的模型。结果如下图所示，为了达到相似的性能，不同模型需要的标签数。</p><img src="https://i.loli.net/2020/06/25/jcXphwBmR8J6SeU.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>下表展示了使用不同主动学习策略 (U - conventional uncertainty method, UCD - 本文使用的方法, random - 随机选择) 进行标记得到的结果：</p><img src="https://i.loli.net/2020/06/25/pe24P9gFJfQVrKM.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>同时作者还对不同$\alpha$的选择进行了实验：</p><img src="https://i.loli.net/2020/06/25/ifRhv85IqaVw7gx.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="RQ4-How-effective-is-ATAD-in-detecting-anomalies-in-a-company’s-local-dataset-based-on-public-datasets"><a href="#RQ4-How-effective-is-ATAD-in-detecting-anomalies-in-a-company’s-local-dataset-based-on-public-datasets" class="headerlink" title="RQ4: How effective is ATAD in detecting anomalies in a company’s local dataset based on public datasets?"></a>RQ4: How effective is ATAD in detecting anomalies in a company’s local dataset based on public datasets?</h3><p>这里作者对比了不同方法在微软内部数据集上的结果：</p><img src="https://i.loli.net/2020/06/25/5oi3rcGugKXmTha.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Transfer Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection</title>
    <link href="/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/"/>
    <url>/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文提出了一种针对高维数据异常检测的表示学习方法。文中提出了<strong>RAMODO</strong>框架，一种基于排序的结合表示学习和异常检测的无监督框架。除此之外，基于<strong>RAMODO</strong>，文中还提出了基于此框架的模型<strong>REPEN</strong>。</p><p><a href="https://arxiv.org/pdf/1806.04808" target="_blank" rel="noopener">Paper📰</a></p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="The-Proposed-Framework-RAMODO"><a href="#The-Proposed-Framework-RAMODO" class="headerlink" title="The Proposed Framework: RAMODO"></a>The Proposed Framework: <strong>RAMODO</strong></h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>我们的目的是为高维数据学习低维表示，同时在学到的低维表示中能够更好地进行异常检测。设有数据集$\mathcal{X}={\mathbf x_1,\mathbf x_2,\cdots, \mathbf x_N}$ ($\mathbf x_i\in \mathbb{R}^D$) 和一个基于随机距离的异常检测器$\phi:\mathcal{X}\mapsto \mathbb{R}$，我们的目标是学习一个表示函数$f:\mathcal{X}\mapsto\mathbb{R}^M (M\ll D)$使得对于所有异常样本$\mathbf x_i$和正常样本$\mathbf x_j$都有$\phi(f(\mathbf x_i))&gt;\phi(f(\mathbf x_j))$。</p><h3 id="Ranking-Model-based-Representation-Learning-Framework"><a href="#Ranking-Model-based-Representation-Learning-Framework" class="headerlink" title="Ranking Model-based Representation Learning Framework"></a>Ranking Model-based Representation Learning Framework</h3><p><strong>RAMODO</strong>基于<em>pairwise ranking model<em>。第一步是通过一定的预处理算法（原文中称为</em>outlier thresholding<em>）将数据划分为inlier候选集和outlier候选集；第二步通过随机从inlier候选集采样$n$个样本生成query set $(\mathbf x_i,\cdots,\mathbf x_{i+n-1})$，从inlier候选集采样一个样本生成</em>positive example</em> $(\mathbf x^+)$，从outlier候选集采样一个样本生成<em>negative example</em> $(\mathbf x^-)$，将三者组合生成 <em>metatriplet</em> $T=(&lt;\mathbf x_i,\cdots,\mathbf x_{i+n-1}&gt;,\mathbf x^+,\mathbf x^-)$；第三步通过神经网络$f$学习表示；第四步通过<em>outlier score-based ranking loss</em> $L(\phi(f(\mathbf x^+)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;),\phi(f(\mathbf x^-)|&lt;f(\mathbf x_i),\cdots,f(\mathbf x_{i+n-1})&gt;))$来进行优化，其中$\phi(\cdot|\cdot)$为基于距离的异常检测器。</p><p><img src="https://i.loli.net/2020/06/25/4I7fx5ZjBhueUDz.png" srcset="/img/loading.gif" alt=""></p><h2 id="A-RAMODO-Instance-REPEN"><a href="#A-RAMODO-Instance-REPEN" class="headerlink" title="A RAMODO Instance: REPEN"></a>A <strong>RAMODO</strong> Instance: <strong>REPEN</strong></h2><p><strong>REPEN</strong>为<strong>RAMODO</strong>的实例模型，使用Sp作为异常检测器。</p><h3 id="Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality"><a href="#Outlier-Thresholding-Using-State-of-the-art-Detectors-and-Cantelli’s-Inequality" class="headerlink" title="Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality"></a>Outlier Thresholding Using State-of-the-art Detectors and Cantelli’s Inequality</h3><p>第一步使用Sp作为基础获得初始anomaly score：</p><blockquote><p><strong>Definition 1</strong> (<em>Sp-based Outlier Scoring</em>). 给定样本$x_i$，Sp 以以下方式定义该样本的异常程度：<br>$$<br>r_i=\frac{1}{m}\sum\limits_{j=1}^m nn_dist(\mathbf x_i|\mathcal{S}_j)<br>$$<br>其中$\mathcal S_j\subset \mathcal X$为数据集随机采样的子集，$m$为集成大小，$nn_dist(\cdot|\cdot)$为$\mathcal S_j$中最近邻居的距离。</p></blockquote><p>接着通过<em>Cantelli’s Inequality</em>来定义<em>Pseudo Outlier</em>：</p><blockquote><p><em><em>Definition 2 *</em>(*Cantelli’s Inequality-based Outlier Thresholding</em>). 给定异常分数向量$\mathbf r\in\mathbb R^N$，更高异常分数代表更高的可能性为异常，设$\mu$和$\delta^2$分别为均值和方差，<em>Outlier</em>候选集由以下方式确定：<br>$$<br>\mathcal{O}={\mathbf x_i|r_i \geq \mu + \alpha\delta}, \space\forall \mathbf x_i\in\mathcal X, \space r_i\in\mathbf r<br>$$<br>其中$\alpha\geq 0$为自定义的阈值。</p></blockquote><p><em>Inlier</em>候选集$\mathcal I=\mathcal X\backslash \mathcal O$。</p><h3 id="Triplet-Sampling-Based-on-Outlier-Scores"><a href="#Triplet-Sampling-Based-on-Outlier-Scores" class="headerlink" title="Triplet Sampling Based on Outlier Scores"></a>Triplet Sampling Based on Outlier Scores</h3><p>首先，从$\mathcal I$采样一定数量的样本组成<em>query set</em>，每个样本被采样的概率与其对应的异常分数有关：</p><p>$$<br>p(\mathbf x_i)=\frac{\mathbb Z-r_i}{\sum_{t=1}^{|\mathcal I|}[\mathbb Z-r_t]}<br>$$</p><p>其中$\mathbb Z=\sum_{t=1}^{|\mathcal I|}r_t$。</p><p>之后从<em>inlier set<em>中均匀随机采样一个</em>positive sample</em> $\mathbf x^+$。最后从<em>outlier set<em>中根据以下概率采样一个</em>negative sample</em> $\mathbf x^-$：<br>$$<br>p(\mathbf x_j)=\frac{r_j}{\sum_{t=1}^{|\mathcal O|}r_t}<br>$$</p><h3 id="A-Shallow-Data-Representation"><a href="#A-Shallow-Data-Representation" class="headerlink" title="A Shallow Data Representation"></a>A Shallow Data Representation</h3><p>单层神经网络用来获得浅层的表示：</p><blockquote><p><em><em>Definition 3 *</em>(*Single-layer Fully-connected Representations</em>) 给定输入$x$，<br>$$<br>f_\Theta(\mathbf x)={\psi(\mathbf w_1^\top\mathbf x),\psi(\mathbf w_2^\top\mathbf x),\cdots,\psi(\mathbf w_M^\top\mathbf x)}<br>$$<br>其中$\psi(\cdot)$为激活函数，$\mathbf w$为权重矩阵。</p></blockquote><h3 id="Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores"><a href="#Ranking-Loss-Using-Random-Nearest-Neighbor-Distance-based-Outlier-Scores" class="headerlink" title="Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores"></a>Ranking Loss Using Random Nearest Neighbor Distance-based Outlier Scores</h3><p>设$\mathcal{Q}=&lt;f_\Theta(\mathbf x_i),\cdots,f_\Theta(\mathbf x_{i+n-1})&gt;$为<em>query set</em>，给定样本$\mathbf x$，<strong>REPEN</strong>根据最近邻距离定义了$f_\Theta(\mathbf x)$的异常程度：<br>$$<br>\phi(f_\Theta(\mathbf x)|\mathcal{Q})=nn_dist(f_\Theta(\mathbf x)|\mathcal Q)<br>$$<br>因此，给定三元组$T=(\mathcal Q,f_\Theta(\mathbf x^+),f_\Theta(\mathbf x^-))$，我们的目标是学得表示$f(\cdot)$使得：<br>$$<br>nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)&lt;nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)<br>$$<br>损失函数：<br>$$<br>J(\Theta;T)=L(\phi(f_\Theta(\mathbf x^+)|\mathcal Q),\phi(f_\Theta(\mathbf x^-)|\mathcal Q))=\\max{0, c+nn_dist(f_\Theta(\mathbf x^+)|\mathcal Q)-nn_dist(f_\Theta(\mathbf x^-)|\mathcal Q)}<br>$$<br>其中$c$为边界参数。给定一系列三元组，最终优化目标如下：<br>$$<br>\mathop{\text{arg min}}\limits_{\Theta}\frac{1}{|\mathcal{T}|}\sum\limits_{i=1}^{|\mathcal T|}J(\Theta;T_i)<br>$$</p><h3 id="The-Algorithm-and-Its-Time-Complexity"><a href="#The-Algorithm-and-Its-Time-Complexity" class="headerlink" title="The Algorithm and Its Time Complexity"></a>The Algorithm and Its Time Complexity</h3><p><img src="https://i.loli.net/2020/06/25/eYtKHBJ7szCgjNa.png" srcset="/img/loading.gif" alt=""></p><h3 id="Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling"><a href="#Leveraging-A-Few-Labeled-Outliers-to-Improve-Triplet-Sampling" class="headerlink" title="Leveraging A Few Labeled Outliers to Improve Triplet Sampling"></a>Leveraging A Few Labeled Outliers to Improve Triplet Sampling</h3><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><ul><li>AD：网络广告检测</li><li>LC：肺癌疾病监测</li><li>p53：异常蛋白质活动检测</li><li>R8：文本分类</li><li>News20：文本分类</li><li>URL：异常网址检测</li><li>Webspam：Pascal Large Scale LearningChallenge</li></ul><h2 id="Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features"><a href="#Effectiveness-in-Real-world-Data-with-Thousands-to-Millions-of-Features" class="headerlink" title="Effectiveness in Real-world Data with Thousands to Millions of Features"></a>Effectiveness in Real-world Data with Thousands to Millions of Features</h2><p>作者分别使用原始特征和<em>REPEN</em>学到的特征进行异常检测，IMP代表性能提升比例，SU代表加速比例。</p><p><img src="https://i.loli.net/2020/06/25/mvUiE1NzyTwOgV8.png" srcset="/img/loading.gif" alt=""></p><h2 id="Comparing-to-State-of-the-art-Representation-Learning-Competitors"><a href="#Comparing-to-State-of-the-art-Representation-Learning-Competitors" class="headerlink" title="Comparing to State-of-the-art Representation Learning Competitors"></a>Comparing to State-of-the-art Representation Learning Competitors</h2><ul><li>*<em>AE: *</em>自编码器</li><li><em><em>HLLE: *</em> *Hessian Locally Linear Embedding</em></li><li><em><em>SRP: *</em> *Sparse Random Projection</em></li><li><em><em>CoP: *</em> *Coherent Pursuit</em></li></ul><p><img src="https://i.loli.net/2020/06/25/yQumCRNrHAheJ34.png" srcset="/img/loading.gif" alt=""></p><h2 id="The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge"><a href="#The-Capability-of-Leveraging-Labeled-Outliers-as-Prior-Knowledge" class="headerlink" title="The Capability of Leveraging Labeled Outliers as Prior Knowledge"></a>The Capability of Leveraging Labeled Outliers as Prior Knowledge</h2><p><img src="https://i.loli.net/2020/06/25/NOLfKQd2u1JMPtp.png" srcset="/img/loading.gif" alt=""></p><h2 id="Sensitivity-Test-w-r-t-the-Representation-Dimension"><a href="#Sensitivity-Test-w-r-t-the-Representation-Dimension" class="headerlink" title="Sensitivity Test w.r.t. the Representation Dimension"></a>Sensitivity Test w.r.t. the Representation Dimension</h2><p><img src="https://i.loli.net/2020/06/25/BoGjY5SEu6vrK3X.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/Rlx7Df9Hvsjp2Eg.png" srcset="/img/loading.gif" alt=""></p><p>文中提到了对于R8、URL、News20这三个数据集在维度$M=1$的时候表现和其他维度一样好，作者给出的解释是在这几个数据集中异常部分是线性可分的，所以1维就足够了，另一个解释是优化问题。</p><h2 id="Scalability-Test"><a href="#Scalability-Test" class="headerlink" title="Scalability Test"></a>Scalability Test</h2><p><img src="https://i.loli.net/2020/06/25/1JfUclWyFYgLdNp.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Representation Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Weakly-supervised Anomaly Detection</title>
    <link href="/2020/03/30/Deep-Weakly-supervised-Anomaly-Detection/"/>
    <url>/2020/03/30/Deep-Weakly-supervised-Anomaly-Detection/</url>
    
    <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1><p>在文献中，因为标注成本的昂贵，无监督方法占据了异常检测的主要位置。然而，在现实生活中，我们可能会有少量标签，如何利用这部分标签信息就成为了一个问题，作者将其称之为<em>anomaly-informed modeling</em>。作者提出了两点挑战：</p><ol type="1"><li>少量标签可能无法提供所有类型异常的信息；</li><li>大部分无标签数据为正常样本，但其中包含少部分异常（污染）。</li></ol><p>作者提出了基于pairwise relation learning的方法来解决这些问题。文章的主要贡献如下：</p><ol type="1"><li>提出了一种基于pairing-based data augmentation和ordinal regression来进行弱监督异常检测的框架</li><li>基于该框架提出了PReNet，一种基于双流ordinal regression的网络</li><li>从理论和实践角度分析了方法的有效性</li><li>在40个真实数据集上进行了完善的实验</li></ol><h1 id="proposed-method">Proposed Method</h1><h2 id="learning-anomaly-scores-by-predicting-pairwise-relation">Learning Anomaly Scores by Predicting Pairwise Relation</h2><h3 id="problem-formulation">Problem Formulation</h3><p>给定数据集<span class="math inline">\(\mathcal{X}=\{\mathbf{x}_1,\mathbf {x}_2,\cdots,\mathbf{x}_N,\mathbf{x}_{N+1},\cdots,\mathbf{x}_{N+K}\}\)</span>，包含两部分，一部分是五标签数据<span class="math inline">\(\mathcal{U}=\{\mathbf{x}_1,\mathbf {x}_2,\cdots,\mathbf{x}_N\}\)</span>，另一部分是有标签异常数据<span class="math inline">\(\mathcal{A}=\{\mathbf{x}_{N+1},\cdots,\mathbf{x}_{N+K}\}\)</span>，其中<span class="math inline">\(K\ll N\)</span>。我们的任务目标是学习一个打分函数<span class="math inline">\(\phi:\mathcal{X}\mapsto \mathbb{R}\)</span>，使得对任任意异常样本的打分高于任意正常样本。</p><p>在这个Formulation里，作者将关系学习和异常打分统一了起来。首先，输入的数据集不再是原始样本，而是样本对。样本对包含三种：<em>anomaly-anomaly</em>，<em>anomaly-unlabeled</em>，<em>unlabeled-unlabeled</em>，记为<span class="math inline">\(C_{\{\mathbf{a},\mathbf{a}\}}\)</span>，<span class="math inline">\(C_{\{\mathbf{a},\mathbf{u}\}}\)</span>，<span class="math inline">\(C_{\{\mathbf{u},\mathbf{u}\}}\)</span>。每一个样本对包含一个标签<span class="math inline">\(y\)</span>，表示该pair对应的异常分数，整个输入数据集<span class="math inline">\(\mathcal{P}=\{\{\mathbf{x}_i,\mathbf{x}_j,y_{ij}\}|\mathbf{x}_i,\mathbf{x}_j\in\mathcal{X} \space\text{and}\space y_{ij}\in\mathbb{N}\}\)</span>。因为有<span class="math inline">\(y_{\{\mathbf a,\mathbf a\}}&gt;y_{\{\mathbf a,\mathbf u\}}&gt;y_{\{\mathbf u,\mathbf u\}}\)</span>，所以对关系的学习也是对异常打分的学习。</p><h3 id="the-instantiated-model-prenet">The Instantiated Model: PReNET</h3><p>下图为模型示意图，<strong>Data Augmentation</strong>模块负责产生pair数据，<strong>End-to-End Anomaly Score Learner <span class="math inline">\(\phi\)</span></strong> 模块负责关系学习（异常打分）。</p><p><img src="https://i.loli.net/2020/06/25/6ZF3w9v1Lux5t4Q.png" srcset="/img/loading.gif" style="zoom:67%;" /></p><h4 id="data-argumentation-by-pairing">Data Argumentation by Pairing</h4><p>数据的产生分为两步：</p><ol type="1"><li>从<span class="math inline">\(\mathcal{A}\)</span>和<span class="math inline">\(\mathcal{U}\)</span>上随机采样，组成pair；</li><li>对每个pair打上次序(ordinal class feature) 标签<span class="math inline">\(\mathbf{y}\)</span>。</li></ol><p>部分<span class="math inline">\(C_{\{\mathbf{a},\mathbf{u}\}}\)</span>和<span class="math inline">\(C_{\{\mathbf{u},\mathbf{u}\}}\)</span>可能包含异常污染，因为在<span class="math inline">\(\mathcal{U}\)</span>中可能会有未标记的异常样本。</p><h4 id="end-to-end-anomaly-score-learner">End-to-End Anomaly Score Learner</h4><p>令<span class="math inline">\(\mathcal{Z}\in\mathbb{R}^M\)</span>为中间表示空间，那么<strong>Score Learner</strong>可以拆解为特征学习<span class="math inline">\(\psi(\cdot;\Theta_r):\mathcal{X}\mapsto \mathcal{Z}\)</span>和打分函数<span class="math inline">\(\eta((\cdot,\cdot);\Theta_s):(\mathcal{Z},\mathcal{Z})\mapsto\mathbb{R}\)</span>两部分，两部分都由神经网络组成。</p><h4 id="ordinal-regression">Ordinal Regression</h4><p>损失函数定义为： <span class="math display">\[L\left(\phi((\mathbf x_i,\mathbf x_j);\Theta),y_{ij}\right)=|y_{ij}-\phi((\mathbf x_i,\mathbf x_j);\Theta)|\]</span> 采用绝对值而不是均方误差的原因是为了减少异常污染的影响。默认<span class="math inline">\(y_{\{\mathbf a,\mathbf a\}}=8\)</span>，<span class="math inline">\(y_{\{\mathbf a,\mathbf u\}}=4\)</span>，<span class="math inline">\(y_{\{\mathbf u,\mathbf u\}}=0\)</span>。最后的优化函数可以写为： <span class="math display">\[\mathop{\text{argmin}}\limits_{\Theta}\frac{1}{|\mathcal{B}|}\sum\limits_{\{\mathbf x_i,\mathbf x_j, y_{ij}\}\in\mathcal{B}}|y_{ij}-\phi((\mathbf x_i,\mathbf x_j);\Theta)|+\lambda R(\Theta)\]</span> <span class="math inline">\(\mathcal{B}\)</span>为一个batch，<span class="math inline">\(R(\Theta)\)</span>为正则项。</p><h3 id="anomaly-detection-using-prenet">Anomaly Detection Using PReNet</h3><h4 id="training-stage">Training Stage</h4><p>训练流程如下图所示：</p><p><img src="https://i.loli.net/2020/06/25/oR6uTL3c7HMpwD4.png" srcset="/img/loading.gif" style="zoom: 80%;" /></p><p>为了保证训练样本类别的平衡，<span class="math inline">\(\frac{|\mathcal{B}|}{2}\)</span>的样本采样自<span class="math inline">\(C_{\{\mathbf u,\mathbf u\}}\)</span>，采样自<span class="math inline">\(C_{\{\mathbf a,\mathbf u\}}\)</span>和<span class="math display">\[C_{\{\mathbf a,\mathbf a\}}\]</span>的样本都占<span class="math inline">\(\frac{|\mathcal{B}|}{4}\)</span>。</p><h4 id="anomaly-scoring-stage">Anomaly Scoring Stage</h4><p>在测试阶段，给定测试样本<span class="math inline">\(\mathbf{x}_k\)</span>，先分别从<span class="math inline">\(\mathcal{A}\)</span>和<span class="math inline">\(\mathcal{U}\)</span>采样，然后定义以下<em>anomaly score</em>： <span class="math display">\[s_{\mathbf{x}_k}=\frac{1}{2E}\left[\sum\limits_{i=1}^E\phi((\mathbf a_i,\mathbf x_k);\Theta^*)+\sum\limits_{j=1}^E\phi((\mathbf x_k,\mathbf u_j);\Theta^*)\right]\]</span> <span class="math inline">\(\mathbf a_i\)</span>和<span class="math inline">\(\mathbf u_j\)</span>为随机采样得到的异常样本和正常样本，采样大小<span class="math inline">\(E\)</span>默认为30。</p><h1 id="experiments">Experiments</h1><p>实验部分主要是回答以下四个问题：</p><ol type="1"><li>在有限的标签异常情况下，PReNet能否有效地检测已知和未知的异常；</li><li>在不同数量标签异常的情况下，PReNet的表现如何；</li><li>PReNet对异常污染的鲁棒性如何；</li><li>PReNet不同组件的重要性如何。</li></ol><h2 id="datasets">Datasets</h2><p>实验一共用到了40个数据集，其中12个用来评测算法检测已知的异常的能力（如Table 2所示），28个用来评测算法检测未知的异常的能力（如Table 3所示）。</p><h2 id="competing-methods-and-parameter-settings">Competing Methods and Parameter Settings</h2><p>用到的baseline有以下几个：</p><ul><li>DevNet：同一作者在KDD2019提出的异常检测框架</li><li>Deep support vector data description (DSVDD)：深度支持向量数据描述</li><li>Prototypical network： few-shot classification中的一种模型</li><li>iForest：孤立森林</li></ul><h2 id="performance-evaluation-metrics">Performance Evaluation Metrics</h2><p>用到的Metrics为AUC-ROC和AUC-PR。</p><h2 id="detection-of-known-anomalies">Detection of Known Anomalies</h2><p>在本实验中，异常污染的比例（2%）和有标记异常样本的数量（60）是固定的，下表为实验结果：</p><p><img src="https://i.loli.net/2020/06/25/BfhVE9z8DWipAM6.png" srcset="/img/loading.gif" style="zoom: 80%;" /></p><h2 id="detection-of-unknown-anomalies">Detection of Unknown Anomalies</h2><p>在本实验中，异常污染的比例（2%）和有标记异常样本的数量（60）同样是固定的，下表为实验结果：</p><p><img src="https://i.loli.net/2020/06/25/9GM8XTYiSLUn2Ar.png" srcset="/img/loading.gif" style="zoom:80%;" /></p><p><img src="https://i.loli.net/2020/06/25/4RxrGZWLqHNnXco.png" srcset="/img/loading.gif" style="zoom:80%;" /></p><h2 id="availability-of-known-anomalies">Availability of Known Anomalies</h2><p>本实验主要是研究不同数量标注异常样本的条件下，算法的性能如何。异常污染的比例固定（2%），标注异常的数量从15到120变化。实验结果如下：</p><p><img src="https://i.loli.net/2020/06/25/x4Hf3lU5JO71bvo.png" srcset="/img/loading.gif" style="zoom:80%;" /></p><h2 id="further-analysis-of-prenet">Further Analysis of PReNet</h2><h3 id="tolerance-to-anomaly-contamination-in-unlabeled-data">Tolerance to Anomaly Contamination in Unlabeled Data</h3><p>本实验主要研究不同异常污染比例下，算法的性能，即探究算法对异常污染的鲁棒性。标注异常样本的数量恒定（60），异常污染比例在<span class="math inline">\(\{0\%,2\%,5\%,10\%\}\)</span>中变化。实验结果如下所示：</p><p><img src="https://i.loli.net/2020/06/25/TGYCJUs8LlmreNV.png" srcset="/img/loading.gif" style="zoom:80%;" /></p><h3 id="ablation-study">Ablation Study</h3><p>这一节是消融实验，分别设置了四个变体：</p><ul><li><strong>BOR: </strong>损失函数替换成了二值回归<em>Binary Ordinal Regression</em>；</li><li><strong>OSNet: </strong>将双流结构简化为单流；</li><li><strong>LDM: </strong>将网络中的隐藏层去除；</li><li><strong>A2H: </strong>加入了额外的隐藏层，并且加入了<span class="math inline">\(\ell_2\)</span>-norm防止过拟合。</li></ul><p><img src="https://i.loli.net/2020/06/25/oR7qlZWfepFT8jK.png" srcset="/img/loading.gif" style="zoom:80%;" /></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Discovering Physical Concepts with Neural Networks</title>
    <link href="/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/"/>
    <url>/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>如题目所示，本文的目的是利用神经网络来发掘物理概念。其思路是从实验数据学到表示，然后用学到的表示来回答物理问题，由此物理概念可以从学到的表示来提取出。作者进行了4个实验：</p><ol><li>在阻尼振动实验中，模型学到了相关的物理参数；</li><li>在角动量守恒实验中，模型预测了质点的运动；</li><li>给定量子系统的观测数据，模型正确的识别出了量子状态的自由度；</li><li>给定从地球观测的太阳和火星的位置时间序列数据，模型发现了日心说模型。</li></ol><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><p>作者在附录中对神经网络的基础知识进行了介绍，这里不再赘述，只截取了一些相对前沿的内容。</p><img src="https://i.loli.net/2020/06/25/yh5Wj9AQmd6nsFC.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Variational-Autoencoders"><a href="#Variational-Autoencoders" class="headerlink" title="Variational Autoencoders"></a>Variational Autoencoders</h2><p>本文用到的模型基础是VAE：</p><img src="https://i.loli.net/2020/06/25/zCnYjVEZHdbqAD3.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Representation-Learning"><a href="#Representation-Learning" class="headerlink" title="Representation Learning"></a>Representation Learning</h3><p><em>Representation learning</em>的主要目标是将数据映射到一个隐向量 (encoder)，为了保证隐向量包含了所有相关信息， 那么应该能够从隐向量还原原数据 (decoder)。传统的Autoencoder是这个思想的最简单实现，而VAE则将AE和<em>Variational Inference</em>结合了起来，是一种经典的生成式模型。现在很多研究关注<em>Disentangled Representation Learning</em>，也就是说我们希望模型能够无监督地学习数据，从中学到有意义的表示。</p><h3 id="boldsymbol-beta-VAE"><a href="#boldsymbol-beta-VAE" class="headerlink" title="$\boldsymbol \beta$-VAE"></a>$\boldsymbol \beta$-VAE</h3><p>$\beta$-VAE是一种特殊的VAE，也是一个经典的<em>Disentangled Representation Learning</em>模型，它和VAE主要的区别是对KL散度一项加上了权重$\beta$进行调节：<br>$$<br>C_\beta(x)=-\left[\mathbb{E}_{z\sim p_\phi(z|x)}\log p_\theta(x|z)\right] + \beta D_\text{KL}\left[p_\phi(z|x)\parallel h(z)\right]<br>$$<br>如果假设$p_\phi(z|x)=\mathcal{N}(\mu,\sigma)$，那么损失函数可以进行简化：<br>$$<br>C_\beta(x)=\parallel \hat{x} - x \parallel^2_2-\frac{\beta}{2}\left(\sum\limits_i\log(\sigma_i^2)-\mu_i^2-\sigma_i^2\right)+C<br>$$</p><h1 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h1><h2 id="Network-Structure-SciNet"><a href="#Network-Structure-SciNet" class="headerlink" title="Network Structure: SciNet"></a>Network Structure: <em>SciNet</em></h2><p>模仿物理学家建模物理问题的过程，作者提出了<em>SciNet</em>，如下图所示：</p><img src="https://i.loli.net/2020/06/25/uWd1lOUFxXgQJ7f.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>物理学家在建模物理问题的时候，往往是从一些实验数据出发，根据物理常识提取更加精练的表示，然后用学到的表示来回答物理问题。</p><p>对于单纯的输入输出问题，<em>SciNet</em>可以看作是一个映射，$F:\mathcal{O}\times\mathcal{Q}\rightarrow\mathcal{A}$。$\mathcal{O}$是可能的实验数据集合，$\mathcal{Q}$是可能的问题集合，$\mathcal{A}$是可能的答案集合。可以将其分为两个步骤：编码过程$E:\mathcal{O}\rightarrow\mathcal{R}$从实验数据学到表示，解码过程$D:\mathcal{R}\times \mathcal{Q}\rightarrow \mathcal{A}$根据给定的问题从表示来回答问题。由此，$F(o,q)=D(E(o),q)$。在实现方面，<em>SciNet</em>采用的是全连接网络。</p><h2 id="Training-and-Testing-SciNet"><a href="#Training-and-Testing-SciNet" class="headerlink" title="Training and Testing SciNet"></a>Training and Testing <em>SciNet</em></h2><p>用来训练的数据形式为$(o,q,a_{cor}(o,q))$，观测$o$和问题$q$分别从观测集$\mathcal{O}$和问题集$\mathcal{Q}$选出，$a_{cor}(o,q)$为对应的正确答案。在训练过程中，我们希望准确度尽量高，并且学到<em>minimal uncorrelated representations</em>。为此，作者采用<em>disentangling variational autoencoder</em>作为模型。</p><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>在文中，作者进行了4个实验来验证模型的有效性。</p><h2 id="Damped-Pendulum"><a href="#Damped-Pendulum" class="headerlink" title="Damped Pendulum"></a>Damped Pendulum</h2><p>阻尼振动实验：</p><ul><li><p>任务：预测一维阻尼振动在不同时间的位置。</p></li><li><p>物理模型：$-kx-b\dot{x}=m\ddot{x}$，$k$为弹性模量，$b$为阻尼系数，通解为$x(t)=A_0e^{-\frac{b}{2m}t}\cos(\omega t+\delta_0), \space \omega=\sqrt{\frac{k}{m}}\sqrt{1-\frac{b^2}{4mk}}$</p></li><li><p>观测数据：位置时间序列数据$o=[x(t_i)]_{i\in{1,\cdots,50}}\in\mathbb{R}^{50}$，时间间隔相等，质量$m=1\text{kg}$，振幅$A_0=1\text{m}$，相位$\delta_0=0$，弹性模量$k\in[5,10]\text{kg}/\text{s}^2$，阻尼系数$b\in[0.5,1]\text{kg}/\text{s}$。</p></li><li><p>问题：预测$q=t_\text{pred}\in\mathbb{R}$</p></li></ul><p><img src="https://i.loli.net/2020/06/25/yWGzxo4eFKmABul.png" srcset="/img/loading.gif" alt=""></p><p>隐变量大小设置为3，结果如下图所示：</p><img src="https://i.loli.net/2020/06/25/Q4PKa3pm2htekqd.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>(b)中的三幅图分别是学到的三个隐变量和我们感兴趣的参数$k$和$b$的关系图。第一幅图中变量$1$与$b$几乎完全线性相关，与$k$基于线性无关，变量$2$只和$k$相关。变量$3$几乎为一个常数，故不提供额外的信息。由此作者认为<em>SciNet</em>学到了我们关心的两个参数的知识。</p><h2 id="Conservation-of-Angular-Momentum"><a href="#Conservation-of-Angular-Momentum" class="headerlink" title="Conservation of Angular Momentum"></a>Conservation of Angular Momentum</h2><p>角动量守恒实验：</p><ul><li>任务：预测一个由长度为$r$的绳子捆绑着的旋转质点在位置$(0,r)$经一个自由质点撞击后的位置</li><li>物理模型：给定撞击之前的角动量，自由质点撞击之后的速度，旋转质点在撞击之后在时间$t_\text{pred}^\prime$的位置可以由角动量守恒定律给出：</li></ul><p>$$<br>J=m_\text{rot}r^2\omega-rm_\text{free}(\mathbf{v}_\text{free})_x=m_\text{rot}r^2\omega^\prime-rm_\text{free}(\mathbf{v}^\prime_\text{free})_x=J^\prime<br>$$</p><ul><li>观测数据：在撞击之前两个质点的位置数据$o=[(t_i^\text{rot},q_\text{rot}(t_i^\text{rot})),(t_i^\text{free},q_\text{free}(t_i^\text{free}))]_{i\in{1,\cdots,5}}$，质量为固定值，半径$r$也为固定值。数据添加高斯噪声。</li><li>问题：预测撞击之后自由质点在时间$t_\text{pred}^\prime$的位置</li></ul><p><img src="https://i.loli.net/2020/06/25/SKfJLxl1QmuzFt9.png" srcset="/img/loading.gif" alt=""></p><p>实验室意图如下：</p><img src="https://i.loli.net/2020/06/25/qimk9ZYBe7UPs3z.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>实验结果表明<em>SciNet</em>能够正确预测质点撞击之后的位置，同时对噪音鲁棒。根据(b)，隐变量和角动量存在线性相关关系，作者认为<em>SciNet</em>学到了守恒的动量这一概念。</p><h2 id="Representation-of-Qubits"><a href="#Representation-of-Qubits" class="headerlink" title="Representation of Qubits"></a>Representation of Qubits</h2><p>量子比特实验：</p><ul><li>任务：预测在$n=1,2$的纯$n$量子位状态$\psi\in\mathbb{C}^{2^n}$下任何二进制投影测量$\omega\in\mathbb{C}^{2^n}$的测量概率。</li><li>物理模型：在执行测量$\omega\in\mathbb{C}^{2^n}$的状态$\psi\in\mathbb{C}^{2^n}$下测量0的概率$p(\omega,\psi)$由$p(\omega,\psi)=|\left&lt;\omega,\psi\right&gt;|^2$给定</li><li>观测数据：状态$\psi: o=[p(\alpha_i,\psi)]<em>{i\in{i,\cdots,n_1}}$的操作参数化：表示一组固定的随机二元射影测量值$\mathcal{M}_1={\alpha_1,\cdots,\alpha</em>{n_1}}$（一个量子位$n_1 = 10$，两个量子位$n_1 = 30$）</li><li>问题：对于固定的一组随机二元射影测量$\mathcal{M}<em>2={\beta_1,\cdots,\beta</em>{n_2}}$，测量$\omega:q=[p(\beta_i,\omega)]_{i\in{1,\cdots,n_2}}$的Operational参数化（一个量子位$n_2 = 10$，两个量子位$n_2 = 30$）</li></ul><p><img src="https://i.loli.net/2020/06/25/8lY1LBsQCZUwX2I.png" srcset="/img/loading.gif" alt=""></p><p>实验结果如下：</p><img src="https://i.loli.net/2020/06/25/ZTRKfzb63Jrvk5C.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>通过实验发现，<em>SciNet</em>可以在不提供先验物理知识的条件下确定表述状态$\psi$最小的参数数量。同时，<em>SciNet</em>还能分辨<em>tomographically complete</em>和<em>tomographically incomplete</em>。</p><h2 id="Heliocentric-Model-of-the-Solar-System"><a href="#Heliocentric-Model-of-the-Solar-System" class="headerlink" title="Heliocentric Model of the Solar System"></a>Heliocentric Model of the Solar System</h2><p>日心说模型：</p><ul><li>问题：在给定初始条件下预测相对与地球的太阳和火星的角度$\theta_M(t)$和$\theta_S(t)$</li><li>物理模型：地球和火星围绕太阳以一定角速度做近似圆周运动</li><li>观测数据：给定初始角度，随机选择周周期的哥白尼的观测数据</li></ul><p><img src="https://i.loli.net/2020/06/25/vXl3Ae4RpzibrmY.png" srcset="/img/loading.gif" alt=""></p><p>模型的实现稍有变化，如下图所示：</p><img src="https://i.loli.net/2020/06/25/XnsYqcRS6izZGEm.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>这样，对于不同时间都对应一个隐变量$r(t_i)$，而且隐变量是时间依赖的，对于一个隐变量$r(t_i)$有一个解码器来输出答案。</p><img src="https://i.loli.net/2020/06/25/az3UmkchyFWevP7.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>实验结果表示，<em>SciNet</em>不仅正确预测了太阳和火星相对地球的角度，同时隐变量揭示了火星和地球相对太阳的角度。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Misc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transfer Anomaly Detection by Inferring Latent Domain Representations</title>
    <link href="/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/"/>
    <url>/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>作者提出了一种利用迁移学习提升target domain异常检测性能的算法。文中指出现有的基于迁移学习的异常检测算法需要对每个 target domain 进行单独训练，这样做会带来很大的计算开销。本文通过<em>latent domain vectors</em>来实现无需重新训练的异常检测。<em>latent domain vectors</em>是domain的一种隐含表示，通过该domain中的正常样本得到。在本文中，<em>anomaly score function</em>通过Auto-encoder得到。</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><h2 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h2><p>令$\mathbf{X}<em>d^+:={\mathbf{x}^+</em>{dn}}^{N^+<em>d}</em>{n=1}$为第$d$个domain的异常样本集，$\mathbf{x}_{dn}^+\in\mathbb{R}^M$为其中第$n$个样本的$M$维特征向量，$N^+_d$为第$d$个domain异常样本的数量。</p><p>类似的，令$\mathbf{X}<em>d^-:={\mathbf{x}^-</em>{dn}}^{N^-<em>d}</em>{n=1}$为第$d$个domain的正常样本集。我们假设对于每个domain都有$N^+_d\ll N^-_d$，且特征向量维度都为$M$。</p><p>假设在 source domain $D_S$都有正常样本和异常样本，记为${\mathbf{X}^+<em>d\cup\mathbf{X}_d^-}^{D_S}</em>{d=1}$，在 target domain $D_T$只有正常样本${\mathbf{X}<em>d^-}^{D_S+D_T}</em>{d=D_S+1}$。我们的目标是得到一个对于 target domain 合适的 domain-specific 的异常打分函数。</p><img src="https://i.loli.net/2020/06/25/KW2YgScfVZN7Fjz.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Domain-specific-Anomaly-Score-Function"><a href="#Domain-specific-Anomaly-Score-Function" class="headerlink" title="Domain-specific Anomaly Score Function"></a>Domain-specific Anomaly Score Function</h2><p>我们基于Auto-encoder定义异常打分函数。对于每个domain，我们假设存在一个$K$维的隐变量$\mathbf{z}<em>d\in\mathbb{R}^K$。对于第$d$个 domain，异常打分函数定义如下：<br>$$<br>s_\theta(\mathbf{x}</em>{dn}|\mathbf{z}<em>d):=\parallel\mathbf{x}</em>{dn}-G_{\theta_G}(F_{\theta_F}(\mathbf{x}_{dn},\mathbf{z}_d))\parallel^2<br>$$<br>其中参数$\theta:=(\theta_G,\theta_F)$在所有 domain 之间共享。</p><h2 id="Models-for-Latent-Domain-Vectors"><a href="#Models-for-Latent-Domain-Vectors" class="headerlink" title="Models for Latent Domain Vectors"></a>Models for Latent Domain Vectors</h2><p>隐变量$\mathbf{z}_d$是无法观测到的，只能通过数据来估计。首先$\mathbf{z}_d$在$\mathbf{X}_d^-$条件下的条件分布假设为高斯分布：</p><p>$$<br>q_\theta(\mathbf{z}<em>d|\mathbf{X}_d^-):=\mathcal{N}(\mathbf{z}_d|\mu_\phi(\mathbf{X}_d^-),\text{diag}(\sigma_\phi^2(\mathbf{X}_d^-)))<br>$$<br>其中均值$\mu_\phi(\mathbf{X}_d^-)\in\mathbb{R}^K$和方差$\sigma^2_\phi(\mathbf{X}_d^-)\in\mathbb{R}^K</em>+$由神经网络建模，且在所有 domain 之间共享。在$\mathbf{X}_d^-$给定的时候，我们便能够推断出该 domain 对应的隐变量，</p><p>$q_\phi$的输入为正常样本的集合，故神经网络需要满足<em>permutation invariant</em>。$\tau(\mathbf{X}<em>d^-)=\rho(\sum</em>{n=1}^{N_d^-}\eta(\mathbf{x}_{dn}^-))$，其中$\tau(\mathbf{X}_d^-)$表示$\mu_\phi(\mathbf{X_d^-})$或$\ln\sigma_\phi^2(\mathbf{X}_d^-)$，$\rho$和$\eta$为神经网络，</p><h2 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h2><p>目标函数由anomaly score函数和隐变量组成。第$d$个domain在对应的隐变量$\mathbf{z}_d$条件下的目标函数为：</p><p>$$<br>L_d(\theta|\mathbf{z}<em>d):=\frac{1}{N_d^-}\sum\limits</em>{n=1}^{N_d^-}s_\theta(\mathbf{x}<em>{dn}^-|\mathbf{z}_d)-\frac{\lambda}{N_d^-N_d^+}\sum\limits</em>{n,m=1}^{N_d^-,N_d^+}f(s_\theta(\mathbf{x}<em>{dm}^+|\mathbf{z}_d)-s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}_d))<br>$$</p><p>其中$\lambda\geq 0$为超参数，$f$为sigmoid函数。公式的第一项表示第$d$个domain正常样本对应的<em>anomaly score</em>。第二项为可微分的AUC。异常样本的<em>anomaly score</em>应当大于正常样本，所以对任何$\mathbf x_{dm}^+\in\mathbf X_d^+, \mathbf x_{dn}^-\in\mathbf X_d^-$有$s_\theta(\mathbf x_{dm}^+|\mathbf z_d)&gt;s_\theta(\mathbf x_{dn}^-|\mathbf z_d)$。第二项$\frac{\lambda}{N_d^-N_d^+}\sum\limits_{n,m=1}^{N_d^-,N_d^+}f(s_\theta(\mathbf{x}<em>{dm}^+|\mathbf{z}_d)-s_\theta(\mathbf{x}</em>{dn}^-|\mathbf{z}<em>d))$的取值范围是$[0,1]$，当所有的$s_\theta(\mathbf{x}</em>{dm}^+|\mathbf{z}<em>d)\gg s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}<em>d)$时该项为1，当所有的$s_\theta(\mathbf{x}</em>{dm}^+|\mathbf{z}<em>d)\ll s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}<em>d)$时该项为0，所以最小化该项的相反数相当于鼓励$s_\theta(\mathbf{x}</em>{dm}^+|\mathbf{z}<em>d)\gg s_\theta(\mathbf{x}</em>{dm}^-|\mathbf{z}_d)$。</p><p>因为隐变量$\mathbf z_d$包含不确定性，我们应该在目标函数里考虑这一点：<br>$$<br>\mathcal{L}<em>d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z_d}))<br>$$</p><p>第一项是$L_d(\theta|\mathbf z_d)$关于$q_\phi(\mathbf z_d|\mathbf X_d^-)$的期望，第二项是$q_\phi(\mathbf z_d|\mathbf X_d^-)$和$p(\mathbf z_d):=\mathcal{N}(\boldsymbol 0,\boldsymbol I)$的KL散度。第一项可以用<em>monte carlo</em>估计$\mathbb{E}<em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]\approx\frac{1}{L}\sum</em>{\ell=1}^L L_d(\theta|\mathbf z_d^{(\ell)})$，除此之外还需要用到<em>reparametrization trick</em>。</p><p>对于第$d$个target domain，因为没有异常样本（假设），所以$L_d(\theta|\mathbf{z}<em>d):=\frac{1}{N_d^-}\sum\limits</em>{n=1}^{N_d^-}s_\theta(\mathbf{x}<em>{dn}^-|\mathbf{z}_d)$，有：<br>$$<br>\mathcal{L}_d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}<em>d|\mathbf{X}_d^-)}\left[\frac{1}{N_d^-}\sum\limits</em>{n=1}^{N_d^-}s_\theta(\mathbf{x}_{dn}^-|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z}_d))<br>$$</p><p>所以总的损失函数为各domain对应的损失函数之和$\mathcal{L}(\theta,\phi):=\sum_{d=1}^{D_S+D_T}\alpha_d\mathcal{L}_d(\theta,\phi)$。</p><h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>训练好之后，domain-specific的<em>anomaly score</em>可以由下式计算出：</p><p>$$<br>s(\mathbf{x}<em>{d^\prime}):=\int s</em>{\theta_<em>}(\mathbf{x_{d^\prime}}|\mathbf{z}<em>{d^\prime})q</em>{\phi_</em>}(\mathbf{z}<em>{d^\prime}|\mathbf{X}</em>{d^\prime}^-)\mathrm{d}\mathbf{z}<em>{d^\prime}\approx\frac{1}{L}\sum\limits</em>{\ell=1}^L s_{\theta_*}(\mathbf{x}<em>{d^\prime}|\mathbf{z}</em>{d^\prime}^{(\ell)})<br>$$</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>实验包含五个数据集，第一个是合成数据集。如下图(a)所示，围绕$(0,0)$有$8$个圈，每个圈包含了一个内圈作为异常样本，第$7$个圈被选为target domain，其余的为source domain。第二个是MNIST-r，是加入旋转的MNIST，包含6个domain，其中数字“4”被选为异常样本，其余为正常。第三个为Anuran Calls，包含5个domain。第四个是Landmine，主要用在多任务学习中。第五个是IoT，网络流量数据，包含8个domain。</p><img src="https://i.loli.net/2020/06/25/6WLAfMwJPuN5Ov9.png" srcset="/img/loading.gif" style="zoom:50%;" /><h2 id="Comparison-Methods"><a href="#Comparison-Methods" class="headerlink" title="Comparison Methods"></a>Comparison Methods</h2><p>对比的baseline包括NN（普通多层神经网络），NNAUC（加入可微分AUC作为损失函数），AE（普通Autoencoer），AEAUC（加入可微分AUC的AE），OSVM（单类支持向量机），CCSA，TOSVM和OTL。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>4个真实数据集的结果如下：</p><img src="https://i.loli.net/2020/06/25/nfkwTVexRNqyFMY.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/QaMskTZALyeiFI1.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/F7VTyeHMz8mK2uJ.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/B32UmgXcwGhZYk1.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>表5为考虑隐变量不确定性的ablation study。将原来的公式$\mathcal{L}<em>d(\theta,\phi):=\mathbb{E}</em>{q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)}\left[L_d(\theta|\mathbf{z}_d)\right]+\beta D_\text{KL}(q_\phi(\mathbf{z}_d|\mathbf{X}_d^-)\parallel p(\mathbf{z_d}))$中$q_\phi(\mathbf z_d|\mathbf X_d^-)$用迪利克雷分布$q_\phi(\mathbf z_d|\mathbf X_d^-)=\delta(\mathbf z_d-\mu_\phi(\mathbf X_d^-))$代替并且去掉KL散度。</p><img src="https://i.loli.net/2020/06/25/yUHcTBzixsMlY7f.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>表6展示了不同异常比例对效果的影响。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Transfer Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Anomaly Detection with Deviation Networks</title>
    <link href="/2020/02/24/Deep-Anomaly-Detection-with-Deviation-Networks/"/>
    <url>/2020/02/24/Deep-Anomaly-Detection-with-Deviation-Networks/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文关注<code>Deep Anomaly Detection</code>，也就是用深度学习的方法来进行异常检测。文中提到现有的<code>Deep Anomaly Detection</code>存在两个弊端：一个是采用深度学习方法来进行特征学习，然后通过下游任务得到<code>Anomaly Score</code>，相比文中End-to-End的<code>Anomaly Score</code>学习，存在优化不充分的风险；另一个是现有的方法主要是无监督学习，无法利用已知的信息（如少量标签）。为此，本文提出了一种端到端的异常检测框架，来解决上述问题。</p><p>本文的主要贡献如下：</p><ul><li>提出了一种端到端的异常检测框架，直接学习<code>Anomaly Score</code>并且可以利用已知信息；</li><li>基于提出的框架，文中提出了一种实例方法 (DevNet)。</li></ul><img src="https://i.loli.net/2020/06/25/XT7fqQRWEOuocgy.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h1><h2 id="End-To-End-Anomaly-Score-Learning"><a href="#End-To-End-Anomaly-Score-Learning" class="headerlink" title="End-To-End Anomaly Score Learning"></a>End-To-End Anomaly Score Learning</h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>为了区别于传统的两阶段异常检测（先学习特征表示，然后在学到的特征上定义一个<code>anomaly measure</code>来得到<code>anomaly score</code>），作者对端到端的异常检测问题重新进行形式化。</p><p>给定$N+K$个样本$\mathcal{X}={\boldsymbol x_1,\boldsymbol x_2,\cdots,\boldsymbol x_N,\boldsymbol x_{N+1},\cdots,\boldsymbol x_{N+K}}$，其中$\boldsymbol x_i\in\mathbb{R}^D$，无标签样本集$\mathcal{U}={\boldsymbol x_1,\boldsymbol x_2,\cdots,\boldsymbol x_N}$，有标签样本集$\mathcal{K}={\boldsymbol x_{N+1},\cdots,\boldsymbol x_{N+K}}$，且$K\ll N$。异常检测的目标是学习一个<code>anomaly scoring function</code>$\phi:\mathcal{X}\mapsto\mathbb{R}$使得$\phi(\boldsymbol x_i)&gt;\phi(\boldsymbol x_j)$，其中$\boldsymbol x_i$为异常样本，$\boldsymbol x_j$为正常样本。</p><h3 id="The-Proposed-Framework"><a href="#The-Proposed-Framework" class="headerlink" title="The Proposed Framework"></a>The Proposed Framework</h3><p>为了解决这个问题，文中提出了一种通用异常检测框架，模型框架如下图所示：</p><p>模型框架如下图所示：</p><img src="https://i.loli.net/2020/06/25/ZuE1mb2Ytv6Jdl7.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>主要包含三个部分：</p><ol><li><em>anomaly scoring network</em>. 图中左边的部分，一个函数$\phi$，输入样本$\mathbf{x}$，输出<code>anomaly score</code></li><li><em>reference score generator</em>. 图中右边的部分。只有一个<em>anomaly scoring network</em>并不能进行训练，需要训练的目标。为此加入<em>reference score generator</em>，输入为随机选择的$l$个正常样本，输出<code>reference score</code>（这$l$个正常样本<code>anomaly score</code>的均值，记为$\mu_\mathcal{R}$）</li><li><em>deviation loss</em>. $\phi(\mathbf{x})$，$\mu_\mathcal{R}$及对应的标准差$\sigma_\mathcal{R}$作为<code>deviation loss</code>函数的输入。因为$\mu_\mathcal{R}$和$\sigma_\mathcal{R}$对应正常样本集的均值和方差，那么异常样本的<code>anomaly score</code>应该和$\mu_\mathcal{R}$差别比较大，而正常样本则应该接近$\mu_\mathcal{R}$。</li></ol><h2 id="Deviation-Networks"><a href="#Deviation-Networks" class="headerlink" title="Deviation Networks"></a>Deviation Networks</h2><p>下面是上述三个部件的具体实现。</p><h3 id="End-To-End-Anomaly-Scoring-Network"><a href="#End-To-End-Anomaly-Scoring-Network" class="headerlink" title="End-To-End Anomaly Scoring Network"></a>End-To-End Anomaly Scoring Network</h3><p>记$\mathcal{Q}\in\mathbb{R}^M$为中间表示空间，<code>anomaly scoring network</code>$\phi(\cdot;\Theta):\mathcal{X}\mapsto\mathbb{R}$可以定义为数据表示学习$\psi(\cdot;\Theta_t):\mathcal{X}\mapsto\mathcal{Q}$和异常分数学习$\eta(\cdot;\Theta_s):\mathcal{Q}\mapsto\mathbb{R}$两阶段的组合，其中$\Theta={\Theta_t,\Theta_s}$。</p><p>$\psi(\cdot;\Theta_t)$可以用一个$H$层神经网络来实现：<br>$$<br>\mathrm{q}=\psi(\mathbf{x};\Theta_t)<br>$$<br>其中$\mathbf{x}\in\mathcal{X}$，$\mathrm{q}\in\mathcal{Q}$。</p><p>$\eta(\cdot;\Theta_s)$可以用一个单层的神经网络来实现：<br>$$<br>\eta(\mathrm q;\Theta_s)=\sum\limits_{i=1}^M w_i^oq_i+w_{M+1}^o<br>$$<br>其中$\mathrm q\in\mathcal Q$，$\Theta_s={\mathbf{w}^o}$。</p><p>所以有：<br>$$<br>\phi(\mathbf{x};\Theta)=\eta(\psi(\mathbf{x};\Theta_t);\Theta_s)<br>$$</p><h3 id="Gaussian-Prior-based-Reference-Scores"><a href="#Gaussian-Prior-based-Reference-Scores" class="headerlink" title="Gaussian Prior-based Reference Scores"></a>Gaussian Prior-based Reference Scores</h3><p>有两种方法来获得$\mu_\mathcal{R}$，一种是data-driven，一种是prior-driven。如果是data-driven的话则采用另一个神经网络，文中表示为了更好的解释性和计算效率，所以采用的是prior-driven。<br>$$<br>\begin{align}<br>r_1,r_2,\cdots,r_l\sim \mathcal{N}(\mu,\sigma^2),\<br>\mu_\mathcal{R}=\frac{1}{l}\sum\limits_{i=1}^l r_i<br>\end{align}<br>$$<br>在文中，采用的prior是标准高斯分布。</p><h2 id="Z-Score-Based-Deviation-Loss"><a href="#Z-Score-Based-Deviation-Loss" class="headerlink" title="Z-Score Based Deviation Loss"></a>Z-Score Based Deviation Loss</h2><p><em>anomaly scoring network</em>的优化目标可以定义为Z-Score的方式：<br>$$<br>dev(\boldsymbol x)=\frac{\phi(\boldsymbol x;\Theta)-\mu_{\mathcal{R}}}{\sigma_{\mathcal{R}}}<br>$$<br>$dev(\boldsymbol x)$可以看作是样本偏离标准的程度，而我们肯定希望异常样本偏离标准越大，正常样本越接近标准。文中采用的损失函数是<code>Contrastive Loss</code>：<br>$$<br>L(\phi(\boldsymbol x;\Theta),\mu_\mathcal{R},\sigma_\mathcal{R})=(1-y)|dev(\boldsymbol x)| + y \max(0, a - dev(\boldsymbol x))<br>$$<br><code>Contrastive Loss</code>的直观解释可以看下图：</p><img src="https://i.loli.net/2020/06/25/aPbSipCsk2JwNcD.png" srcset="/img/loading.gif" style="zoom: 33%;" /><p>对于负例（正常），优化过程将他们尽量向原点靠近，对于正例（异常），优化过程将他们拉向边界。</p><h2 id="The-DevNet-Algorithm"><a href="#The-DevNet-Algorithm" class="headerlink" title="The DevNet Algorithm"></a>The DevNet Algorithm</h2><p><code>DevNet</code>的算法流程图如下：</p><img src="https://i.loli.net/2020/06/25/km9H5DoNRbOQ784.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Interpretability-of-Anomaly-Scores"><a href="#Interpretability-of-Anomaly-Scores" class="headerlink" title="Interpretability of Anomaly Scores"></a>Interpretability of Anomaly Scores</h2><p>因为<em>reference score generator</em>选择的是确定的高斯分布，于是可以用概率论给出一些解释性。作者给出了一个结论，</p><blockquote><p><strong>PROPOSITION</strong>： 设$\boldsymbol x\in\mathcal{X}$，$z_p$为$\mathcal{N}(\mu,\sigma^2)$的分位数，那么$\phi(\boldsymbol x)$在区间$\mu\pm z_p\sigma$的概率为$2(1-p)$。</p></blockquote><p>例如，假设$p=0.95$，那么$z_{0.95}=1.96$，表示异常分数高于1.96的样本将以0.95的置信度为异常。</p><h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><p>实验用到了9个数据集，4个Baseline (REPEN，DSVDD，FSNET，iForest)，以及ROC和PR曲线两种评测标准。</p><h2 id="Effectiveness-in-Real-world-Data-Sets"><a href="#Effectiveness-in-Real-world-Data-Sets" class="headerlink" title="Effectiveness in Real-world Data Sets"></a>Effectiveness in Real-world Data Sets</h2><h3 id="Experiment-Settings"><a href="#Experiment-Settings" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h3><p>这一个实验主要是为了验证算法在真实场景下的效果，即大量无标签数据和极少量标签数据。训练集包含两部分，一部分是无标签数据$\mathcal{U}$,包含$2%$的异常样本，另一部分是有标签数据$\mathcal{K}$，由随机采样$0.005%-1%$的训练数据和$0.08%-6%$的异常样本组成。</p><h3 id="Findings"><a href="#Findings" class="headerlink" title="Findings"></a>Findings</h3><p>实验结果如下表所示：</p><img src="https://i.loli.net/2020/06/25/DKqxJROngML8IS2.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>从结果上看来，本文提出的方法在所有数据集上都比Baseline好，说明<code>DevNet</code>端到端直接优化<code>Anomaly Score</code>的方式是有效的。</p><h2 id="Data-Efficiency"><a href="#Data-Efficiency" class="headerlink" title="Data Efficiency"></a>Data Efficiency</h2><h3 id="Experiment-Settings-1"><a href="#Experiment-Settings-1" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h3><p>这一个实验主要是为了探究基于深度的异常检测方法的<em>data efficiency</em>。和上一个实验一样，无标签数据集包含$2%$的异常，而有标签的异常数量从$5$到$120$不等。本实验试图回答以下两个问题：</p><ul><li><code>DevNet</code>的<em>data efficiency</em>如何？</li><li>基于深度的方法在多大程度上能够利用标签信息？</li></ul><h3 id="Findings-1"><a href="#Findings-1" class="headerlink" title="Findings"></a>Findings</h3><p>在几个基于深度的Baseline中，<code>DevNet</code>的效果是最好的，同时在有标签异常非常有限的情况下，<code>DevNet</code>也能很好的利用标签信息，达到更好的效果。</p><img src="https://i.loli.net/2020/06/25/iIWGBPosKCuxbRF.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Robustness-w-r-t-Anomaly-Contamination"><a href="#Robustness-w-r-t-Anomaly-Contamination" class="headerlink" title="Robustness w.r.t. Anomaly Contamination"></a>Robustness w.r.t. Anomaly Contamination</h2><h3 id="Experiment-Settings-2"><a href="#Experiment-Settings-2" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h3><p>在第一个实验中，无标签数据集$\mathcal{U}$包含的是固定的异常比例$2%$，而在这个实验中，作者测试了从$0%$到$20%$之间不同异常比例来测试算法的鲁棒性（即使$\mathcal{U}$中包含异常，由于没有标签，在训练的时候仍然假设都为正常来进行训练）。本实验试图回答以下问题：</p><ul><li>基于深度的异常检测方法的鲁棒性如何？</li><li>当训练集中异常污染的比例较高的时候基于深度的方法能否打败无监督的方法？</li></ul><h3 id="Findings-2"><a href="#Findings-2" class="headerlink" title="Findings"></a>Findings</h3><p>下图为实验结果：</p><img src="https://i.loli.net/2020/06/25/JCnIjLOc84RFP2V.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>从结果上来看，<code>DevNet</code>比其他基于深度的方法鲁棒性更好，同时在高异常污染的情况下仍然比纯无监督方法效果要好。</p><h2 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h2><p>本实验设置了<code>DevNet</code>的三个变体（默认的<code>DevNet-Def</code>为单层隐层加上一个输出层）来进行消融实验，分别是：</p><ul><li><code>DevNet-Rep</code>，去掉了<em>anomaly scoring network</em>网络的输出层，对应<em>end-to-end learning of anomaly scores</em>和<em>deviation loss</em>；</li><li><code>DevNet-Linear</code>，去掉了网络中的非线性层，对应<em>learning of non-linear features</em>；</li><li><code>DevNet-3HL</code>，隐层数量为3层。</li></ul><p>对比结果如下：</p><img src="https://i.loli.net/2020/06/25/5LcyAwGMB8gb2UP.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>通过实验可以发现，<code>DevNet-Rep</code>说明了<em>end-to-end learning of anomaly scores</em>和<em>deviation loss</em>的有效性，而<code>DevNet-Linear</code>说明了<em>learning of non-linear features</em>的重要性。<code>DevNet-3HL</code>说明了加深网络并不总能带来性能的提升。</p><h2 id="Scalability-Test"><a href="#Scalability-Test" class="headerlink" title="Scalability Test"></a>Scalability Test</h2><p>这一个实验使用合成的数据来测试算法对大规模数据的处理能力，分别从<em>Data Size</em>和<em>Data Dimensionality</em>两方面来测试。结果如下：</p><img src="https://i.loli.net/2020/06/25/5gbPdJkB47e3FsV.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>可以看出，<code>DevNet</code>对<em>Data Size</em>并不敏感，同时，面对高维数据，<code>DevNet</code>也没有表现出劣势。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Geant4 安装教程与调试环境配置</title>
    <link href="/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
    <url>/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Geant4安装的教程很多，版本都很旧了，这里写一个新版本（10.6）基于Ubuntu的安装教程，并且开启CLion IDE调试。</p><h1 id="Step-1-Download-Packages"><a href="#Step-1-Download-Packages" class="headerlink" title="Step 1: Download Packages"></a>Step 1: Download Packages</h1><p>首先进入官网(<a href="http://geant4.web.cern.ch/support/download" target="_blank" rel="noopener">http://geant4.web.cern.ch/support/download</a>)下载源代码（推荐tar.gz格式）及数据文件，解压。新建一个文件夹专门用来放<code>Geant4</code>相关文件，新建data，source，build文件夹，将Geant4的文件复制进来并按如下结构组织：</p><pre><code class="hljs bash">.├── build├── data│   ├── G4ABLA3.1│   ├── G4EMLOW7.9│   ├── G4ENSDFSTATE2.2│   ├── G4INCL1.0│   ├── G4NDL4.6│   ├── G4PARTICLEXS2.1│   ├── G4PII1.3│   ├── G4SAIDDATA2.0│   ├── G4TENDL1.3.2│   ├── PhotonEvaporation5.5│   ├── RadioactiveDecay5.4│   └── RealSurface2.1.1└── <span class="hljs-built_in">source</span>    └── geant4.10.06</code></pre><p><img src="https://i.loli.net/2020/06/25/OuZaAJ3WyEYwsG7.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/R5Tmk68AhPbaDHY.png" srcset="/img/loading.gif" alt=""></p><h1 id="Step-2-Install-Dependencies"><a href="#Step-2-Install-Dependencies" class="headerlink" title="Step 2: Install Dependencies"></a>Step 2: Install Dependencies</h1><p>安装编译所需环境：</p><pre><code class="hljs bash">sudo apt-get install build-essential cmake</code></pre><p>安装相关依赖：</p><pre><code class="hljs bash">sudo apt-get install libgl1-mesa-dev libglu1-mesa-dev libxt-dev libxmu-dev libxi-dev zlib1g-dev libgl2ps-dev libexpat1-dev libxerces-c-dev</code></pre><p>如果要用到QT需要单独安装QT。</p><h1 id="Step-3-Compile"><a href="#Step-3-Compile" class="headerlink" title="Step 3: Compile"></a>Step 3: Compile</h1><p>进入build文件夹，用cmake命令：</p><pre><code class="hljs bash">cmake ../<span class="hljs-built_in">source</span>/geant4.10.06/ -DCMAKE_BUILD_TYPE=DEBUG -DGEANT4_USE_GDML=ON -DGEANT4_USE_OPENGL_X11=ON -DGEANT4_USE_RAYTRACER_X11=ON -DGEANT4_BUILD_MULTITHREADED=ON</code></pre><p>其中<code>../source/geant4.10.06/</code>替换成换成（如果版本不一样）你自己的Geant4源代码所在目录，需要QT则加上<code>-DGEANT4_USE_QT=ON</code>。如果不需要调试则把<code>-DCMAKE_BUILD_TYPE=DEBUG</code>改成<code>-DCMAKE_BUILD_TYPE=RELEASE</code>。<code>-DGEANT4_BUILD_MULTITHREADED=ON</code>是多线程，视情况开启。</p><p>完成之后开始编译：</p><pre><code class="hljs bash">make -jX</code></pre><p><code>-jX</code>为多线程编译，如<code>-j8</code>。</p><p>编译完成之后进行安装：</p><pre><code class="hljs bash">sudo make install</code></pre><h1 id="Step-4-Configure"><a href="#Step-4-Configure" class="headerlink" title="Step 4: Configure"></a>Step 4: Configure</h1><p>安装的默认路径在<code>/usr/local/share/Geant4-10.6.0</code>，将下载的数据文件复制到该文件夹：</p><pre><code class="hljs bash">sudo cp -r ./data/ /usr/<span class="hljs-built_in">local</span>/share/Geant4-10.6.0/</code></pre><p>之后，在<code>~/.bashrc</code>里添加<code>/usr/local/share/Geant4-10.6.0/geant4make/geant4make.sh</code>，如果你的版本和我的不一样，相应修改即可。</p><h1 id="Step-5-CLion-Configuration"><a href="#Step-5-CLion-Configuration" class="headerlink" title="Step 5: CLion Configuration"></a>Step 5: CLion Configuration</h1><p>最后我们来配置CLion环境，配好之后可以在IDE中编写<code>Geant4</code>代码，还可以断点调试，非常方便。安装CLion的过程这里省略，打开一个<code>Geant4</code>自带的例子或者自己新建一个项目，打开<code>Edit Configurations</code>。</p><p><img src="https://i.loli.net/2020/06/25/W1xXHUqIvofyKQk.png" srcset="/img/loading.gif" alt=""></p><p>随便打开一个终端，输入一下命令获取环境变量：</p><pre><code class="hljs bash">env | grep G4</code></pre><p>在<code>Environment variables</code>填入刚才获取的环境变量（复制之后按一下粘贴就可以了），然后把<code>Working directory</code>设置成当前文件夹。</p><p><img src="https://i.loli.net/2020/06/25/HrslFTOau51y8tX.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/5UKaCgvnWjYmNTG.png" srcset="/img/loading.gif" alt=""></p><p>现在就大功告成了！</p>]]></content>
    
    
    <categories>
      
      <category>Technical Notes</category>
      
      <category>Misc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Geant4</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Complementary Set Variational Autoencoder for Supervised Anomaly Detection</title>
    <link href="/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"/>
    <url>/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。</p><h1 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h1><h2 id="Conventional-VAE"><a href="#Conventional-VAE" class="headerlink" title="Conventional VAE"></a>Conventional VAE</h2><p>首先回顾一下原始的VAE。</p><p>原始VAE中的损失函数为：<br>$$<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})=\mathbb{E}<em>{q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})}[\log p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})]-\text{KL}[q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi}\parallel p(\boldsymbol{z}))]<br>$$<br>原文中作者证明了$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\leq\log p(\boldsymbol{x};\boldsymbol{\theta})$，所以$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})$可以看作是数据分布$p(\boldsymbol{x})$对数似然的一个下界。$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})$又被称为证据下界 (ELBO)。$\mathbb{E}</em>{q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})}[\log p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})]$中的期望一般用蒙特卡洛来进行估计：<br>$$<br>\begin{align}<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\simeq&amp; \frac{1}{L}\sum\limits_l\log p(\boldsymbol{x}|\boldsymbol{z}^{(l)};\boldsymbol{\theta})-\text{KL}[q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})\parallel p(\boldsymbol{z})],\<br>\boldsymbol{z}^{(l)}&amp;\sim q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi}), \space l\in{1,2,\cdots,L}<br>\end{align}<br>$$<br>对于隐变量$\boldsymbol{z}$，一般假设先验服从标准高斯分布，后验服从均值为$\mu$，方差为$\sigma^2$的高斯分布，故KL散度能直接写出解析式：<br>$$<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\simeq \frac{1}{L}\sum\limits_l\log p(\boldsymbol{x}|\boldsymbol{z}^{(l)};\boldsymbol{\theta})-C(-\frac{1}{2}-\log\sigma+\frac{1}{2}\sigma^2+\frac{1}{2}\mu^2)<br>$$<br>使用VAE来做异常检测通常是在正常数据上进行训练，在检测阶段，如果是异常样本，那么VAE不能很好地重构它，这样会导致较大的重构误差。</p><h2 id="Prior-Distribution-for-Anomalies"><a href="#Prior-Distribution-for-Anomalies" class="headerlink" title="Prior Distribution for Anomalies"></a>Prior Distribution for Anomalies</h2><img src="https://i.loli.net/2020/06/25/vrxAzRVCtaE3oLc.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>在原始VAE异常检测中，无论输入样本$\boldsymbol{x}$是否异常，VAE都会使对应编码的后验$p(\boldsymbol{z}|\boldsymbol{x})$服从高斯分布，且施加标准高斯分布的约束。在本文中，作者对异常和正常样本对应的隐变量的先验分布做了不同假设。首先，正常先验依然是标准高斯分布，记为$p_n(\boldsymbol{z})$。而对于异常先验，作者认为异常即为“不正常”，和正常是补集的关系。作者在文中定义异常先验分布$p_a(\boldsymbol{z})$为：<br>$$<br>p_a(\boldsymbol{z})=\frac{1}{Y^\prime}(\max\limits_{\boldsymbol{z}^\prime}p_n(\boldsymbol{z}^\prime)-p_n(\boldsymbol{z}))<br>$$</p><p>其中$Y^\prime$为使$p_a(\boldsymbol{z})$成为一个概率分布的调节因子。实际上，$Y^\prime$往往会成为无限大，因为$p(\boldsymbol z)$在整个定义域上都有定义。为了解决这个问题，作者加入了$p_w(\boldsymbol z)$，一个在每个维度都足够宽的辅助分布：</p><p>$$<br>p_a(\boldsymbol z)=\frac{1}{Y}p_w(\boldsymbol z)\left(\max\limits_{\boldsymbol z^\prime}p_n(\boldsymbol z^\prime)-p_n(\boldsymbol z)\right)<br>$$</p><p>其中$Y$为有限的常数。在文中$p_n(\boldsymbol z)$和$p_w(\boldsymbol z)$都为高斯分布，那么$p_a(\boldsymbol z)$的具体形式为：</p><p>$$<br>p_a(\boldsymbol z)=\frac{1}{Y}\mathcal{N}(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2){\max\limits_{\boldsymbol z^\prime}\mathcal N(\boldsymbol z^\prime;\boldsymbol 0,\boldsymbol 1)-\mathcal N(\boldsymbol z;\boldsymbol 0,\boldsymbol 1)}<br>$$</p><p>其中：</p><p>$$<br>\max\limits_{\boldsymbol z^\prime}\mathcal N(\boldsymbol z^\prime;\boldsymbol 0,\boldsymbol 1)=\frac{1}{\sqrt{2\pi}}<br>$$</p><p>$$<br>Y=\int_{-\infty}^{\infty}p_a(\boldsymbol z)\mathrm{d}\boldsymbol z=\frac{1}{\sqrt{2\pi}}\left{1-\frac{1}{\boldsymbol s^2+1}\right}<br>$$</p><p>$\boldsymbol s^2$为超参数，控制分布的宽度。用文中的先验替换VAE原始的KL散度，可写为：</p><p>$$<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]=\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\frac{\mathcal N(\boldsymbol z;\boldsymbol\mu,\boldsymbol\sigma^2)}{\frac{1}{Y}\mathcal N(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2)\left{\frac{1}{2\pi}-\mathcal N(\boldsymbol z;\boldsymbol0,\boldsymbol 1)\right}}\mathrm{d}\boldsymbol z<br>$$</p><p>展开后：</p><p>$$<br>\begin{align}<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]&amp;=<br>\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\mathcal{N}(\boldsymbol z;\boldsymbol\mu,\boldsymbol\sigma^2)\mathrm{d}\boldsymbol z\<br>&amp;+\log Y\<br>&amp;-\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\mathcal{N}(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2)\mathrm{d}\boldsymbol z\<br>&amp;-\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\left{\frac{1}{\sqrt{2\pi}}-\mathcal{N}(\boldsymbol z;\boldsymbol 0, \boldsymbol 1)\right}\mathrm{d}\boldsymbol z<br>\end{align}<br>$$</p><p>使用泰勒展开，$\log (x+\frac{1}{2\pi})\simeq-\log 2\pi+2\pi x$，KL散度可以用下式估计：</p><p>$$<br>\begin{align}<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]&amp;\simeq\sqrt{\frac{2\pi}{\boldsymbol\sigma^2+1}}\exp\left(\frac{-\boldsymbol\mu^2}{2(\boldsymbol\sigma^2+1)}\right)\<br>&amp;+\frac{\boldsymbol\mu^2+\boldsymbol\sigma^2}{2\boldsymbol s^2}-\log\boldsymbol\sigma+\log\boldsymbol s+\log\left(\sqrt{\boldsymbol s^2+1}-1\right)\<br>&amp;-\frac{\log(\boldsymbol s^2+1)}{2}+\frac{\log(2\pi)-1}{2}<br>\end{align}<br>$$</p><p>下图为一维时$p_n(\boldsymbol z)$和$p_a(\boldsymbol z)$的示例：</p><img src="https://i.loli.net/2020/06/25/QHXo24cKj9uRwzW.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Implementation-of-proposed-method"><a href="#Implementation-of-proposed-method" class="headerlink" title="Implementation of proposed method"></a>Implementation of proposed method</h3><p>文中使用编码器输出的分布$\mathcal{N}(\boldsymbol z;\boldsymbol \mu, \boldsymbol \sigma^2)$与标准正态分布之间的KL散度来作为异常分数。在每一轮的训练过程中，加入一轮使用Anomaly Prior的训练。</p><img src="https://i.loli.net/2020/06/25/wrmzADXtsyuJ6EZ.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h2><p>作者设计了两个Task：</p><ol><li>Task 1. $N$ vs. $\bar{N}$. 将手写数字中的一个作为已知异常，其他作为正常，并加入均匀分布作为未知的异常。</li><li>Task 2. 手写数字被分为3组：已知异常，正常，未知异常。</li></ol><p>细节如下表所示：</p><img src="https://i.loli.net/2020/06/25/ifcIxr9zOpEhksA.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>在实现上，使用Adam优化器，<code>batch_size</code>为100，<code>epochs</code>为200。<code>Encoder</code>和<code>Decoder</code>都由三层感知机组成，超参数$s^2$设置为400。评测标准使用AUC (area under the receiver characteristic curve)。</p><p>下表为实验结果：</p><img src="https://i.loli.net/2020/06/25/YTpO98y1ZPmAK3g.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Anomaly Detection</tag>
      
      <tag>VAE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE</title>
    <link href="/2020/01/06/Unsupervised-Anomaly-Detection-for-Intricate-KPIs-via-Adversarial-Training-of-VAE/"/>
    <url>/2020/01/06/Unsupervised-Anomaly-Detection-for-Intricate-KPIs-via-Adversarial-Training-of-VAE/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="https://ieeexplore.ieee.org/abstract/document/8737430/" target="_blank" rel="noopener">论文📃</a></p><p><a href="https://github.com/yantijin/Buzz" target="_blank" rel="noopener">代码📥</a></p><p>本文介绍了一种利用对抗训练来进行时间序列异常检测的方法<em>Buzz</em>。作者认为在现实中复杂的KPI数据大量存在，这种数据通常带有非高斯分布的噪声，同时数据分布复杂，导致一般的生成式模型无法对数据进行很好的建模，所以作者提出了基于对抗训练的模型。在文中，作者的创新点主要有三个：</p><ol><li>为了处理复杂数据，将数据空间分为多个子空间，在每个子空间上进行距离的度量；</li><li>采用<em>Wasserstein</em>距离度量模型建模的分布和真实分布之间的距离；</li><li>建立了基于对抗训练的<em>Buzz</em>的损失函数和VAE之间的关系。</li></ol><img src="https://i.loli.net/2020/06/25/FwHi7y56njz8R4m.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><h2 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h2><p>对于任意时间$t$，给定历史观察值$x_{t-T+1},\cdots,x_t$，确定异常是否发生(记为$y_t=1$)。通常来收异常检测算法给出的是发生异常的可能性，如$p(y_t=1|x_{t-T+1},\cdots,x_t)$。</p><h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><table><thead><tr><th><strong>Model</strong></th><th><strong>Latent</strong></th><th><strong>Data</strong></th></tr></thead><tbody><tr><td><strong><em>Auto-encoder (AE)</em></strong></td><td><code>None</code></td><td><code>L1Loss</code></td></tr><tr><td><strong><em>Variational Auto-encoder (VAE)</em></strong></td><td><code>KL Divergence</code></td><td><code>Log Likelihood</code></td></tr><tr><td><strong><em>Adversarial Auto-encoder (AAE)</em></strong></td><td><code>Discriminator</code></td><td><code>L1Loss</code></td></tr><tr><td><strong><em>Wasserstein Auto-encoder (WAE)</em></strong></td><td><code>MaxMeanDiscrepancy</code> or <code>Discriminator</code></td><td><code>L1Loss</code></td></tr><tr><td><strong><em>AlphaGAN</em></strong></td><td><code>Discriminator</code></td><td><code>Discriminator</code>+<code>L1Loss</code></td></tr></tbody></table><h2 id="GAN-and-WGAN-GP"><a href="#GAN-and-WGAN-GP" class="headerlink" title="GAN and WGAN-GP"></a>GAN and WGAN-GP</h2><p>原始GAN等价于优化：<br>$$<br>\mathbb{E}<em>{x\sim P_r}\log{\frac{P_r(x)}{\frac{1}{2}\left[P_r(x)+P_g(x)\right]}}+\mathbb{E}</em>{x\sim P_g}\log{\frac{P_g(x)}{\frac{1}{2}\left[P_r(x)+P_g(x)\right]}}<br>$$<br>根据KL散度和JS散度的定义：<br>$$<br>\text{KL}(P_1\parallel P_2)=\mathbb{E}_{x\sim P_1}\log{\frac{P_1}{P_2}}<br>$$</p><p>$$<br>\text{JS}(P_1\parallel P_2)=\frac{1}{2}\text{KL}(P_1\parallel \frac{P_1+P_2}{2})+\frac{1}{2}\text{KL}(P_2\parallel \frac{P_1+P_2}{2})<br>$$</p><p>可重写为：<br>$$<br>2\text{JS}(P_r\parallel P_g)-2\log 2<br>$$<br>当$P_r$与$P_g$的支撑集（support）是高维空间中的低维流形（manifold）时，$P_r$与$P_g$重叠部分测度（measure）为0的概率为1。</p><ul><li>支撑集（support）其实就是函数的非零部分子集，比如<code>ReLU</code>函数的支撑集就是[公式]，一个概率分布的支撑集就是所有概率密度非零部分的集合。</li><li>流形（manifold）是高维空间中曲线、曲面概念的拓广，我们可以在低维上直观理解这个概念，比如我们说三维空间中的一个曲面是一个二维流形，因为它的本质维度（intrinsic dimension）只有2，一个点在这个二维流形上移动只有两个方向的自由度。同理，三维空间或者二维空间中的一条曲线都是一个一维流形。</li><li>测度（measure）是高维空间中长度、面积、体积概念的拓广，可以理解为“超体积”。</li></ul><p><em>Wasserstein</em>距离定义如下：<br>$$<br>W(P_r,P_g)=\inf\limits_{\gamma\sim\prod(P_r,P_g)}\mathbb{E}<em>{(x,y)\sim \gamma}\left[\parallel x-y\parallel\right]<br>$$<br>下确界$\inf$没法直接求解，不过根据相关定理其等价于：<br>$$<br>W(P_r,P_g)=\frac{1}{K}\sup\limits</em>{\parallel f\parallel_L\leq K}\mathbb{E}<em>{x\sim P_r}[f(x)]-\mathbb{E}</em>{x\sim P_g}[f(x)]<br>$$<br><em>Lipschitz</em>连续是指存在一个常数$K\geq 0$使得定义域内任意两个元素$x_1$和$x_2$都满足：<br>$$<br>|f(x_1)-f(x_2)|\leq K|x_1-x_2|<br>$$<br>WAN的损失函数：<br>$$<br>\mathcal{L}=\mathop{\mathbb{E}}\limits_{\mathbf{x}\sim\mathbb{P}<em>g}\left[D({\mathbf{x}})\right]-\mathop{\mathbb{E}}\limits</em>{\mathbf{x}\sim\mathbb{P}<em>r}\left[D(\mathbf{x})\right]<br>$$<br>WGAN-GP的损失函数为：<br>$$<br>\mathcal{L}=\mathop{\mathbb{E}}\limits</em>{\tilde{\mathbf{x}}\sim\mathbb{P}<em>g}\left[D(\tilde{\mathbf{x}})\right]-\mathop{\mathbb{E}}\limits</em>{\mathbf{x}\sim\mathbb{P}<em>r}\left[D(\mathbf{x})\right] + \lambda\mathop{\mathbb{E}}\limits</em>{\hat{\mathbf{x}}\sim\mathbb{P}<em>{\hat{\mathbf{x}}}}\left[(\parallel\nabla</em>{\hat{\mathbf{x}}}D(\hat{\mathbf{x}})\parallel_2-1)^2\right]<br>$$</p><h1 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h1><p>下图为<em>Buzz</em>的总体流程：</p><img src="https://i.loli.net/2020/06/25/aGPdzq8TVS6fetJ.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>数据会首先进行一些预处理，之后进行训练。在检测阶段会根据异常分数来判定异常。</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>在文中，最关键的两个创新点分别是<em>Wasserstein</em>距离和对数据分布进行分区的方法。</p><ul><li><p>在使用距离度量方面， 因为<em>Wasserstein</em>在WGAN中取得了很好的效果，是一种鲁棒的距离度量，所以作者在文中采用了<em>Wasserstein</em>距离来衡量生成的分布和真实的分布之间的距离，并由此引入了对抗训练；</p></li><li><p>在分区方法方面，作者认为原始数据过于复杂，所以将数据空间$\mathcal{X}$进行划分，然后在每个子空间上使用<em>Wasserstein</em>度量距离，而总体的距离由每个分区的距离的期望求得。</p></li></ul><p>作者还发现，当划分地越来越细时，总体距离接近于特定形式的VAE的重构误差项。</p><img src="https://i.loli.net/2020/06/25/knzq4yPaBrXWgeI.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h2><p>下图为模型的网络结构：</p><img src="https://i.loli.net/2020/06/25/Qrgpuh4Iw7YTlny.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><h3 id="Objective-Function"><a href="#Objective-Function" class="headerlink" title="Objective Function"></a>Objective Function</h3><p>先定义一些符号：</p><ul><li>$b$和$s$分别为Batch的大小和邻居的大小，数据集按$s$进行切分，然后随机打乱，每个Batch包含$b$个$s$，之后$s/=2,b*=2$；</li><li>$\mathcal{W}={w_1,w_2,\cdots,w_b}$为一个Batch，且满足每个$w_i$是$s$的倍数；</li><li>$w\in\mathcal{W}$的邻域集(neighborhood set)为一个时间上的partition，记为${w,w+1,\cdots,w+s-1}$</li><li>$\mathbf{x}^{(w)},\mathbf{x}^{(w+1)},\cdots,\mathbf{x}^{(w+s-1)}$为在空间$\mathcal{X}$上的一个partition，记为$S_w$，其中$\mathbf{x}^{(w)}$表示以$w$为结尾的时间窗口。</li></ul><p><em>Buzz</em>的损失函数和WGAN-GP类似，但做了一些改进，由下面四部分组成，下面分别解释。</p><p>第一个是每一个partition的$\mathbf{z}$后验的KL散度：<br>$$<br>\mathcal{K} = \frac{1}{bs}\sum\limits_{w\in\mathcal{W}}\sum\limits_{i=1}^{s-1}\text{KL}\left[q_\phi(\mathbf{z}|\mathbf{x})\parallel\mathcal{N}(\mathbf{0},\mathbf{1})\right]<br>$$</p><p>第二个在训练时是一个常数：<br>$$<br>Z(\lambda) = \frac{\Gamma(W)}{\Gamma(\frac{W}{2})}2\pi^{\frac{W}{2}}\lambda^{-W}<br>$$</p><p>其中$\Gamma$是<em>Gamma</em>函数。</p><p>第三个是<em>Wasserstein</em>距离：<br>$$<br>\mathcal{T}(F,w)=\frac{1}{bs}\sum\limits_{i=1}^{s-1}\mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x}^{w+i})}\left[F(\mathbf{x}^{(w+i)})-F(G(\mathbf{z}))\right]<br>$$</p><p>第四个是<em>Gradient Penalty</em>：</p><p>$$<br>\mathcal{R}(F,w)=\frac{1}{bs}\sum\limits_{i=1}^{s-1}\mathbb{E}<em>{q_\phi(\mathbf{z}|\mathbf{x}^{(w+i)})}\left[\mathbb{E}</em>{\varepsilon\sim[0,1]}(\parallel\nabla_{\hat{\mathbf{x}}}(\hat{\mathbf{x}})\parallel-\mathbf{1})^2\right]<br>$$</p><p>其中$\hat{\mathbf{x}}=\varepsilon \mathbf{x}^{w+i}+(1-\varepsilon)G(\mathbf{z})$为生成数据与真实数据的插值。</p><blockquote><p>原始的WGAN-GP的损失函数为：<br>$$<br>L=\mathop{\mathbb{E}}\limits_{\tilde{\mathbf{x}}\sim\mathbb{P}<em>g}\left[D(\tilde{\mathbf{x}})\right]-\mathop{\mathbb{E}}\limits</em>{\mathbf{x}\sim\mathbb{P}<em>r}\left[D(\mathbf{x})\right] + \lambda\mathop{\mathbb{E}}\limits</em>{\hat{\mathbf{x}}\sim\mathbb{P}<em>{\hat{\mathbf{x}}}}\left[(\parallel\nabla</em>{\hat{\mathbf{x}}}D(\hat{\mathbf{x}})\parallel_2-1)^2\right]<br>$$<br>其中$\mathbb{P}<em>g$为生成器的分布，$\mathbb{P}_r$为真实分布，$\mathbb{P}</em>{\hat{\mathbf{x}}}$为真实数据和生成数据插值得到的分布。</p></blockquote><p>$$<br>\hat{\mathcal{L}}<em>{Buzz}=-\lambda\sup\limits_F\left[\sum\limits</em>{w\in\mathcal{W}}(\left|\mathcal{T}(F,w)\right|-\eta\mathcal{R}(F,w))\right]-\mathcal{K}-\log Z(\lambda)<br>$$</p><h3 id="Training-Procedure"><a href="#Training-Procedure" class="headerlink" title="Training Procedure"></a>Training Procedure</h3><p><em>Buzz</em>的训练过程与WGAN-GP类似，</p><h2 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h2><p>文中假设解码器的输出服从如下分布：</p><p>$$<br>p_\theta(\mathbf{x}|\mathbf{z})=\frac{1}{Z(\lambda)}\exp{-\lambda\parallel\mathbf{x}-G(\mathbf{z})\parallel}<br>$$</p><p>作者定义异常分数为：<br>$$<br>\mathcal{S}=\log p_\theta(\mathbf{x})-\log p_\theta(\bar{\mathbf{x}})<br>$$<br>其中$\bar{\mathbf{x}}$为经过MCMC填充后的样本。</p><p>异常分数也可以展开为：<br>$$<br>\log\frac{1}{L}\sum\limits_{l=1}^L\left[\frac{p_\theta(\mathbf{x}|\mathbf{z^{(l)}})p_\theta(\mathbf{z}^{(l)})}{q_\phi(\mathbf{z}^{(l)}|\bar{\mathbf{x}})}\right]-\log\frac{1}{L}\sum\limits_{l=1}^L\left[\frac{p_\theta(\bar{\mathbf{x}}|\mathbf{z}^{(l)})p_\theta(\mathbf{z}^{(l)})}{q_\phi(\mathbf{z}^{(l)}|\bar{\mathbf{x}})}\right]<br>$$</p><p>最终算法流程图为：</p><img src="https://i.loli.net/2020/06/25/Y3NLjRiaWO5eHGT.png" srcset="/img/loading.gif" style="zoom:80%;" /><h2 id="Theoretical-Analysis"><a href="#Theoretical-Analysis" class="headerlink" title="Theoretical Analysis"></a>Theoretical Analysis</h2><p>在理论分析中，作者主要是想建立$\mathcal{L}<em>{Buzz}$和VAE的损失函数$\mathcal{L}</em>{vae}$之间的联系，损失函数$\mathcal{\hat{L}}_{Buzz}$为：</p><p>$$<br>\hat{\mathcal{L}}<em>{Buzz}=-\lambda\sup\limits_F\left[\sum\limits</em>{w\in\mathcal{W}}(\left|\mathcal{T}(F,w)\right|-\eta\mathcal{R}(F,w))\right]-\mathcal{K}-\log Z(\lambda)<br>$$</p><p>为了便于分析，去掉<em>Gradient Penalty</em>的部分，公式可简化为：</p><p>$$<br>\mathcal{L}<em>{Buzz}=-\lambda\mathbb{E}</em>{p(w)}W^1\left[P(\mathbf{x}|w)\parallel P(\mathbf{y}|w)\right]-\mathcal{K}-\log Z(\lambda)<br>$$</p><p>实际上$Z(\lambda)=\mathfrak{S}_W\Gamma(W)\lambda^{-W}$，其中$\mathfrak{S}_W$为$W$维单位球的表面积。</p><blockquote><p>$n$维空间单位球表面积公式：<br>$$<br>\omega_n=\frac{2\pi^{\frac{n}{2}}}{\Gamma(\frac{n}{2})}<br>$$</p></blockquote><p>而$W^1\left[P(\mathbf{x}|w)\parallel P(\mathbf{y}|w)\right]$为<em>Wasserstein</em>距离：<br>$$<br>W^1\left[P(\mathbf{x}|w)\parallel P(\mathbf{y}|w)\right]=\sup\limits_{Lip(f)\leq 1}\left{\int_\mathcal{X}f(\mathbf{x})p(\mathbf{x}|w)\mathrm{d}\mathbf{x}-\int_\mathcal{X}f(\mathbf{y})p(\mathbf{y}|w)\mathrm{d}\mathbf{y}\right}<br>$$</p><h3 id="Lemma-1"><a href="#Lemma-1" class="headerlink" title="Lemma 1"></a>Lemma 1</h3><p>通过设定具体形式的后验分布，VAE的损失函数可以写为：</p><blockquote><p>设$\mathbf{x}$的后验分布$p(\mathbf{x}|\mathbf{z})=\frac{1}{Z(\lambda)}\exp{-\lambda\parallel\mathbf{x}-G(\mathbf{z})\parallel}$，那么VAE的损失函数为：<br>$$<br>\mathcal{L}<em>{vae}=\lambda\mathbb{E}</em>{p(w)}\left[\mathbb{E}<em>{p(\mathbf{x}|w)}\mathbb{E}</em>{p_G(\mathbf{y}|\mathbf{x})}-\parallel\mathbf{x}-\mathbf{y}\parallel\right]-\mathcal{K}-\log{Z(\lambda)}<br>$$</p></blockquote><p>后验分布实际上是一个Laplace分布：</p><blockquote><p><strong>Laplace Distribution</strong>:<br>$$<br>f(x|\theta,\lambda)=\frac{1}{2\lambda}\exp{\left(-\frac{|x-\theta|}{\lambda}\right)}<br>$$</p></blockquote><p>可以直接把后验分布带入VAE的损失函数就得到了。</p><h3 id="Lemma-2"><a href="#Lemma-2" class="headerlink" title="Lemma 2"></a>Lemma 2</h3><p>$S_w$定义为数据空间$\mathcal{X}$的一个partition，而$S={(\mathbf{x}_1,\mathbf{x}_2)| \exists w, \mathbf{x}_1\in S_w,\mathbf{x}_2\in S_w}$。</p><blockquote><p>当$G,\phi,\lambda$固定时，$S\downarrow$有$\mathcal{L}_{Buzz}\downarrow$</p></blockquote><h3 id="Lemma-3"><a href="#Lemma-3" class="headerlink" title="Lemma 3"></a>Lemma 3</h3><blockquote><p>$\max\mathcal{L}<em>{Buzz}\geq\max{\mathcal{L}</em>{vae}}$，同时，当$S\downarrow\text{diag}{\mathcal{X}}$时$\max\mathcal{L}<em>{Buzz}\downarrow\max\mathcal{L}</em>{vae}$</p></blockquote><img src="https://i.loli.net/2020/06/25/XM2xwBbOLzikhoc.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Lemma-4"><a href="#Lemma-4" class="headerlink" title="Lemma 4"></a>Lemma 4</h3><blockquote><p>令$p^\prime_G(\mathbf{y}|\mathbf{x})$表示$\mathbb{E}<em>{q</em>{\phi^\prime}}\left[p_G(\mathbf{y}|\mathbf{z})\right]$。如果$(G,\phi,\lambda)$是一个解，那么存在$(G,\phi^\prime,\lambda)$使得：<br>$$<br>\mathbb{E}<em>{p(\mathbf{x}|w)}\mathbb{E}</em>{p_G^\prime(\mathbf{y}|\mathbf{x})}\parallel\mathbf{x}-\mathbf{y}\parallel=W^1\left[P(\mathbf{x}|w)\parallel P_G(\mathbf{y}|w)\right]<br>$$<br>此时$\mathcal{L}<em>{Buzz}-\mathcal{L}</em>{vae}^\prime=\mathcal{K}^\prime-\mathcal{K}$，其中$\mathcal{L}^\prime,\mathcal{K}^\prime$分别为$(G,\phi^\prime,\lambda)$时的$\mathcal{L}$和$\mathcal{K}$。</p></blockquote><p>$$<br>\mathcal{L}^\dagger_{Buzz}=\mathbb{E}<em>{p(\mathbf{x})}\left[\mathbb{E}</em>{q_{\phi^\prime}(\mathbf{z}|\mathbf{x})}\log_{p_\theta}(\mathbf{x}|\mathbf{z})\right]-\min\limits_{\bar{\phi}\sim\phi^\prime}\bar{\mathcal{K}}<br>$$</p><h3 id="Lemma-5"><a href="#Lemma-5" class="headerlink" title="Lemma 5"></a>Lemma 5</h3><p>这里主要是想证明</p><blockquote><p>对于固定的$w$，令：<br>$$<br>\mathcal{F}={f|Lip(f)\leq 1}, \space \mathcal{F}^<em>=\left{f|<em>{S_w}\bigg|Lip(f|</em>{S_w})\leq 1\right}<br>$$<br>有$\sup_{f\in\mathcal{F}}\mathcal{T}(f)=\sup_{f|_{S_w}\in\mathcal{F}^</em>}\mathcal{T}^*\left(f|_{S_w}\right)$。</p></blockquote><h3 id="Theorem-6"><a href="#Theorem-6" class="headerlink" title="Theorem 6"></a>Theorem 6</h3><blockquote><p>$\mathcal{L}<em>{Buzz}$的对偶形式为：<br>$$<br>\mathcal{L}</em>{Buzz}=-\lambda\sup\limits_{Lip(F;S)\leq 1}\mathbb{E}_{p(w)}\mathcal{T}^*(F)-\mathcal{K}-\log Z(\lambda)<br>$$</p></blockquote><p>近似的$\mathcal{L}<em>{Buzz}$的对偶形式为：<br>$$<br>\bar{\mathcal{L}}</em>{Buzz}=-\lambda\sup\limits_{Lip(F;S)\leq 1}\mathbb{E}_{p(w)}\mathcal{T}(F)-\mathcal{K}-\log Z(\lambda)<br>$$</p><h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><img src="https://i.loli.net/2020/06/25/GEi3zfeAgXVsvBN.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/7EkhRGNvIsSmwn6.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/yTIhoZb1kVOf4Mv.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>VAE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Variational Approaches for Auto-Encoding Generative Adversarial Networks</title>
    <link href="/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/"/>
    <url>/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/</url>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文揭示了对抗生成网络（Generative Adversarial Networks, GAN）和变分自编码器（Variational Auto-encoders, VAE）之间的联系，并据此提出了一种将两者结合的新模型。文中主要是将不可解的似然函数和未知的后验分布用一个非确定的分布（Immplicit Distribution）替代，并加入判别器来使得该分布逼近真实的分布。通过这个方法，作者将VAE中的损失函数进行了替换，变成了GAN中的“生成-判别”模式。</p><p><a href="https://arxiv.org/abs/1706.04987" target="_blank" rel="noopener">原文</a></p><h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><p>本文有如下贡献：</p><ul><li>本文提出变分推断（Variational Inference）也能通过对非确定分布的估计应用在GAN中；</li><li>基于似然的模型（Likelihood-based Models）和非似然模型（Likelihood-free Models）能够通过对抗学习结合起来；</li><li>作者根据文中提出的新观点修改了VAE的损失函数，将其称之为Auto-encoding GAN ($\alpha$-GAN)，并提出了对应的实用的改进；</li><li>本文与众多State-of-Art模型进行了对比</li></ul><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Overcoming-Intractability-in-Generative-Models"><a href="#Overcoming-Intractability-in-Generative-Models" class="headerlink" title="Overcoming Intractability in Generative Models"></a>Overcoming Intractability in Generative Models</h2><h3 id="Latent-Variable-Models"><a href="#Latent-Variable-Models" class="headerlink" title="Latent Variable Models"></a>Latent Variable Models</h3><p>隐变量模型通过隐变量的形式描述了数据的产生过程。最简单的形式是假设隐变量$\mathbf{z}$服从一个先验分布$\mathbf{z}\sim p(\mathbf{z})$，而数据$\mathbf{x}$从条件分布$p(\mathbf{x}|\mathbf{z})$抽样产生。通常来说描述$p(\mathbf{x}|\mathbf{z})$的模型称为生成器$\mathcal{G}_\theta(\mathbf{z})$，带有可优化的参数$\theta$，而$\mathbf{z}$通常假设为正态分布$\mathbf{z}\sim\mathcal{N}(\mathbf{0},\mathbf{I})$。</p><p>文中区分了两种隐变量模型，一种是<em>Implicit Latent Variable Models</em>，一种是<em>Prescribed Latent Variable Models</em>。文中的描述不太清楚，个人认为两者的区别是前者图模型中的$\mathbf{x}$不是一个随机变量，在优化的时候需要用一个刻画生成的$\mathbf{x}$和真实的$\mathbf{x}$的差别的函数$\delta(\mathbf{x}-\mathcal{G}_\theta(\mathbf{z}))$，而后者图模型中$\mathbf{x}$是一个随机变量，这样可以写出似然函数用极大似然估计。</p><p>无论是GAN还是VAE都需要通过边缘分布$p_\theta(\mathbf{x})$来刻画建模的好坏，比如说根据$p_\theta(\mathbf{x})$与真实分布$p^<em>_\theta(\mathbf{x})$之间的KL散度$\text{KL}\left[p_\theta(\mathbf{x})\parallel p_\theta^</em>(\mathbf{x})\right]$。但通常情况下$p_\theta(\mathbf{x})$都是不可解的，而GAN和VAE通过不同的途径解决了这个问题。</p><h3 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h3><p>GAN没有直接计算$p_\theta(\mathbf{x})$，而是使用了一个判别器来判别样本是从$p_\theta(\mathbf{x})$还是$p_\theta^<em>(\mathbf{x})$采样得到的，如果判别器无法进行区分，那我们认为此时$p_\theta(\mathbf{x})\approx p_\theta^</em>(\mathbf{x})$。</p><p>令随机变量$y\in{0,1}$，$y=1$表示样本$\mathbf{x}$来自真实分布，$y=0$表示样本$\mathbf{x}$来自生成分布，而判别器的输出为$\mathbf{x}$来自真实分布的概率$\mathcal{D}<em>\phi(\mathbf{x})=p(y=1|\mathbf{x})$。GAN通过对来自真实分布和生成分布的样本求二元交叉熵来作为判别器损失函数：<br>$$<br>\textbf{Discriminator Loss: }\mathbb{E}</em>{p^*(\mathbf{x})}[-\log\mathcal{D}<em>\phi(\mathbf{x})]+\mathbb{E}</em>{p_\theta(\mathbf{x})}[-\log(1-\mathcal{D}_\phi(\mathbf{x}))]<br>$$</p><p>生成器将最大化判别器对生成样本判定为真的概率作为损失函数，同时还有一个等价的但在实践中表现更好的替代版本：</p><p>$$<br>\textbf{Generator Loss: }\mathbb{E}<em>{p_\theta(\mathbf{x})}[\log(1-\mathcal{D}_\phi(\mathbf{x}))];\textbf{ Alternative Loss: }\mathbf{E}</em>{p_\theta(\mathbf{x})}[-\log\mathcal{D}_\phi(\mathbf{x})]<br>$$</p><h3 id="The-Density-Ratio-Trick"><a href="#The-Density-Ratio-Trick" class="headerlink" title="The Density Ratio Trick"></a>The Density Ratio Trick</h3><p>令$p^<em>(\mathbf{x})=p(\mathbf{x}|y=1)$，$p_\theta(\mathbf{x})=p(\mathbf{x}|y=0)$。定义*Density Ratio</em> $r_\phi(\mathbf{x})$为真实分布和生成分布之间的比例：</p><p>$$<br>r_\phi(\mathbf{x})=\frac{p^*(\mathbf{x})}{p_\theta(\mathbf{x})}=\frac{p(\mathbf{x}|y=1)}{p(\mathbf{x}|y=0)}=\frac{p(y=1|\mathbf{x})}{p(y=0|\mathbf{x})}=\frac{\mathcal{D}_\phi(\mathbf{x})}{1-\mathcal{D}_\phi(\mathbf{x})}<br>$$</p><p>上式表明了<em>Density Ratio*的计算可以仅通过从两个分布上采样得到的样本加上一个二分类器$\mathcal{D}_\phi(\mathbf{x})$实现（假设$p(y=0)=p(y=1)$）。更深入的说，对于不可解的分布$p_\theta^</em>(\mathbf{x})$，我们可以通过计算<em>Density Ratio*来了解我们近似的分布$p_\theta(\mathbf{x})$和真实的$p_\theta^</em>(\mathbf{x})$之间的相对性。而且我们只需要能够在两个分布上进行采样，并且训练一个判别器即可。因为判别器是一个普通的分类器，所以大量的主流分类器都可以使用。</p><h3 id="Variational-Inference"><a href="#Variational-Inference" class="headerlink" title="Variational Inference"></a>Variational Inference</h3><p>现在来看VAE，另一种解决不可解分布的方法是近似。<em>Variational Inference</em>通过引入一个变分分布$q_\eta(\mathbf{z}|\mathbf{x})$推出了不可解的$\mathbf{x}$的对数似然的下界（常被称为证据下界ELBO）：</p><p>$$<br>\log p_\theta(\mathbf{x})=\log\int p_\theta(\mathbb{x}|\mathbb{z})p(\mathbf{z})\text{d}\mathbf{z}\geq \mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log p_\theta(\mathbf{x}|\mathbf{z})\right]-\text{KL}\left[q_\eta(\mathbf{z}|\mathbf{x})\parallel p(\mathbf{z})\right]=\mathcal{F}(\boldsymbol{\theta}, \boldsymbol{\eta})<br>$$</p><p>VAE是<em>Variational Inference</em>的一种实现，变分分布通过一个神经网络进行建模，并且建立起了完整的可优化的模型。</p><h3 id="Synthetic-Likelihood"><a href="#Synthetic-Likelihood" class="headerlink" title="Synthetic Likelihood"></a>Synthetic Likelihood</h3><p>当似然函数未知（GAN中没有显式的似然函数，而VAE中有）的时候，<em>Variational Inference*便无法直接使用。对于没有显式的似然函数的情况，以VAE的ELBO的第一项为例，假设$p_\theta(\mathbf{x}|\mathbf{z})$分布的具体形式未知，我们只有从$p_\theta(\mathbf{x}|\mathbf{z})$采样得到的样本，如何计算$\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})]$呢？一个方法是乘以$p_\theta^</em>(\mathbf{x})$再除以$p_\theta^*(\mathbf{x})$：</p><p>$$<br>\mathbb{E}<em>{q_\eta(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})]=\mathbb{E}</em>{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{p_\theta(\mathbf{x}|\mathbf{z})}{p^<em>(\mathbf{x})}\right]+\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}[\log p^</em>(\mathbf{x})]<br>$$</p><p>公式(5)中的第一项包括了合成似然$R(\theta)=\frac{p_\theta(\mathbf{x}|\mathbf{z})}{p^*(\mathbf{x})}$，优化$R(\theta)$相当于优化$\log p_\theta(\mathbf{x}|\mathbf{z})$。第二项与生成网络的参数$\theta$无关，所以在优化的时候可以忽略。</p><h2 id="A-Fusion-of-Variational-and-Adversarial-Learning"><a href="#A-Fusion-of-Variational-and-Adversarial-Learning" class="headerlink" title="A Fusion of Variational and Adversarial Learning"></a>A Fusion of Variational and Adversarial Learning</h2><p>GAN和VAE分别从不同的角度解决了生成模型的推断问题，我们下面从VAE出发，考虑将两者结合起来。</p><h3 id="Implicit-Variational-Distributions"><a href="#Implicit-Variational-Distributions" class="headerlink" title="Implicit Variational Distributions"></a>Implicit Variational Distributions</h3><p>变分推断<strong>Variational Inference</strong>的主要任务就是确定$q_\eta(\mathbf{z}|\mathbf{x})$，通常的做法如<strong>Mean-field Variational Inference</strong>会假设一个简单的分布，如高斯分布。在本文中不对$q_\eta(\mathbf{z}|\mathbf{x})$的形式作假设，仅假设其为一个隐含的分布。运用上文提到的<em>Density Ratio Trick</em>，我们可以将VAE损失函数中的第二项改写为：</p><p>$$<br>-\text{KL}[q_\eta(\mathbf{z}|\mathbf{x})\parallel p(\mathbf{z})]=\mathbb{E}<em>{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{p(\mathbf{z})}{q_\eta(\mathbf{z}|\mathbf{x})}\right]\approx\mathbb{E}</em>{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}{1-\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}\right]<br>$$</p><p>文中引入了一个隐变量分类器（Latent Classifier）$\mathcal{C}_{\boldsymbol{\omega}}(\mathbf{z})$，用来判别$\mathbf{z}$是从编码网络还是从标准高斯分布中采样得到的（猜测这样做的好处是不用再对$\mathbf{z}$的后验做高斯分布的假设了，也不需要在变分网络输出形成的高斯分布上采样得到$\mathbf{z}$了，这样重参数技巧也省了）。具体实现上，期望可以用蒙特卡洛方法（采样多次取均值）进行计算。</p><h3 id="Likelihood-Choice"><a href="#Likelihood-Choice" class="headerlink" title="Likelihood Choice"></a>Likelihood Choice</h3><p>对于VAE损失函数第一项，对应生成网络，我们可以选择对$p(\mathbf{x}|\mathbf{z})$分布的具体形式做假设， 这样对应<em>Likelihood-based<em>的情况。文中选择的是</em>Zero-mean Laplace Distribution</em> $p_\theta(\mathbf{x}|\mathbf{z})\propto\exp(-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1)$（不就是$L_1$ Loss吗？？？）。</p><p>对于<em>Likelihood-free</em>的情况，可以继续使用上面提到的<em>Density Ratio Trick</em>，这时需要加一个一个判别器。</p><p>$$<br>\mathbb{E}<em>{q_\eta(\mathbf{z}|\mathbf{x})}\left[-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1\right]\space\space\text{  or  }\space\space\mathbb{E}</em>{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}{1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}\right]<br>$$</p><p>对于两种选择，前者对应VAE，好处是不会出现模式崩溃的情况，后者对应GAN，容易出现模式崩溃的情况，但是可以使用对抗学习的方式（这是优点？？？），本文选择两种都用（我全都要.jpg）。</p><h3 id="Hybrid-Loss-Functions"><a href="#Hybrid-Loss-Functions" class="headerlink" title="Hybrid Loss Functions"></a>Hybrid Loss Functions</h3><p>将前面的讨论结合起来，最后的损失函数就是：</p><p>$$<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\eta})=\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1+\log\frac{\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}{1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}+\log\frac{\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}{1-\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}\right]<br>$$</p><p>最后模型包含四个网络：生成网络$p_\theta(\mathbf{x}|\mathbf{z})$、推断网络$q_\eta(\mathbf{z}|\mathbf{x})$以及两个判别器$\mathcal{C}_{\boldsymbol{\omega}}$和$\mathcal{D}_\phi$，作者将其命名为$\alpha$-GAN。</p><p>算法流程如下：</p><img src="https://i.loli.net/2020/06/25/hkIY9xuDWl4GbLz.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Improved-Techniques"><a href="#Improved-Techniques" class="headerlink" title="Improved Techniques"></a>Improved Techniques</h3><p>作者为了改进模型的稳定性和效率，将生成器的Loss中的$-\log(1-\mathcal{D}_\phi)$修改为了$\log\mathcal{D}_\phi-\log(1-\mathcal{D}_\phi)$，并声称这样能提供非饱和（Non-saturating）的梯度：</p><p>$$<br>\textbf{Generator Loss: } \mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1-\log\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))+\log(1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z})))\right]<br>$$</p><p>作者认为在生成器损失函数中加入$\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1$能够在一定程度防止模式崩溃。</p><p>除此之外，作者发现将真实样本（原文是The Samples）作为生成的样本输入到判别器中能够提升性能。作者给出的解释是根据Jensen不等式：$\log p_\theta(\mathbf{x})=\log\int p_\theta(\mathbf{x}|\mathbf{z})p(\mathbf{z})\text{d}\mathbf{z}\geq \mathbb{E}_{p(\mathbf{z})}[\log p_\theta(\mathbf{x}|\mathbf{z})]$，</p><p>[TODO]</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>[TODO]</p><img src="https://i.loli.net/2020/06/25/TKt3yUwPDQm4MeV.png" srcset="/img/loading.gif" style="zoom: 50%;" /><img src="https://i.loli.net/2020/06/25/5jg9wNMoXuTzeVY.png" srcset="/img/loading.gif" style="zoom: 50%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>[TODO]</p><h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><p>本文使用了几种不同的评测生成模型的方法：</p><ul><li>*<em>Inception Score: *</em></li><li>*<em>Multi-scale Structural Similarity (MS-SSIM): *</em></li><li>*<em>Independent Wasserstein Critic: *</em></li></ul><h2 id="Results-on-ColorMNIST"><a href="#Results-on-ColorMNIST" class="headerlink" title="Results on ColorMNIST"></a>Results on ColorMNIST</h2><img src="https://i.loli.net/2020/06/25/QRBKHn51fxO2WUq.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/kM4lrsBVSDKaJwW.png" srcset="/img/loading.gif" style="zoom: 50%;" /><h2 id="Results-on-CelebA"><a href="#Results-on-CelebA" class="headerlink" title="Results on CelebA"></a>Results on CelebA</h2><img src="https://i.loli.net/2020/06/25/mzdjY67uH9pZ1ny.png" srcset="/img/loading.gif" style="zoom:50%;" /><h2 id="Results-on-CIFAR-10"><a href="#Results-on-CIFAR-10" class="headerlink" title="Results on CIFAR-10"></a>Results on CIFAR-10</h2><img src="https://i.loli.net/2020/06/25/nDGgM6AHVyKwIam.png" srcset="/img/loading.gif" style="zoom: 50%;" /><img src="https://i.loli.net/2020/06/25/K1RQdMyj8zbqlCJ.png" srcset="/img/loading.gif" style="zoom:50%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>GAN</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
      <tag>Variational Inference</tag>
      
      <tag>VAE</tag>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Anomaly Detection in Streams with Extreme Value Theory</title>
    <link href="/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/"/>
    <url>/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文基于<strong>Extreme Value Theory</strong>提出了一种不需要手动设置阈值也不需要对数据分布作任何假设的时间序列异常检测方法。除此之外，本方法可以用在通用的自动阈值选择的场合中。</p><p><a href="https://www.kdd.org/kdd2017/papers/view/anomaly-detection-in-streams-with-extreme-value-theory" target="_blank" rel="noopener">原文</a></p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>在很多情况下我们需要进行阈值的选择。阈值的选择可以通过实验的方法或者对数据分布进行假设的方法来得到，不过这样做通常不准确。借助<strong>Extreme Value Theory</strong>我们可以在不需要对原始数据的分布作很强的假设的情况下，推断我们想要的极端事件的分布（在异常检测中就是异常值）。</p><p>下面给出一些数学符号，$X$为随机变量，$F$为累积分布函数，即$F(x)=\mathbb{P}(X\leq x)$。记$F$的“末尾”分布$\bar{F}(x)=1-F(x)=\mathbb{P}(X&gt;x)$。对于一个随机变量$X$和给定的概率$q$，记$z_q$为在$1-q$水平的分位数，即$z_q$为满足$\mathbb{P}(X\leq z_q)\geq 1-q$最小的值。</p><h2 id="Extreme-Value-Distributions"><a href="#Extreme-Value-Distributions" class="headerlink" title="Extreme Value Distributions"></a>Extreme Value Distributions</h2><p><strong>Extreme Value Theory</strong>主要是为了找出极端事件发生的规律，有学者证明，在很弱的条件下，所有极端事件都服从一个特定的分布，而不管原始分布如何。具体形式如下：</p><p>$$<br>G_\gamma:x\mapsto \exp(-(1+\gamma x)^{-\frac{1}{\gamma}}), \space\space\space\space\space\gamma\in\mathbb{R}, \space\space\space\space\space 1+\gamma x&gt;0<br>$$</p><p>其中$\gamma$称为<strong>Extreme Value Index</strong>，由原始分布决定。</p><p>更严谨的说法是Fisher-Tippett-Gnedenko定理（极值理论第一定理）：</p><blockquote><p>*<em>THEOREM: *</em>(Fisher-Tippett-Gnedenko). 令$X_1,X_2,\cdots,X_n,\cdots$为独立同分布的随机变量序列，$M_n=\max {X_1,\cdots,X_n}$。如果实数对序列$(a_n,b_n)$存在且满足$a_n&gt;0$和$\lim\limits_{n\rightarrow \infty}P\left(\frac{M_n-b_n}{a_n}\leq x\right)=F(x)$，其中$F$为非退化分布函数，那么$F$属于Gumbel、Fréchet或Weibull分布族（或总称Generalized Extreme Value Distribution）中的一种。</p></blockquote><p>这是一个反直觉的结论，但是想到当事件发生变得极端时，即$\mathbb{P}(X&gt;x)\rightarrow 0$，$\bar{F}(x)=\mathbb{P}(X&gt;x)$分布的形状其实并没有很多种选择。Table 1展示了几种不同分布对应的$\gamma$：</p><p><img src="https://i.loli.net/2020/06/24/jyhoWZGc2gFTrJv.png" srcset="/img/loading.gif" alt=""></p><p>Figure 1展示了几种不同$\gamma$情况下的“末尾”分布：</p><p><img src="https://i.loli.net/2020/06/24/4rmZL1AMcBJ2Vzq.png" srcset="/img/loading.gif" alt=""></p><h2 id="Power-of-EVT"><a href="#Power-of-EVT" class="headerlink" title="Power of EVT"></a>Power of EVT</h2><p>根据<strong>Extreme Value Theory</strong>，我们可以在原始分布未知的情况下计算极端事件的概率。但是$\bar{G}_\gamma$分布中参数$\gamma$是未知的，我们需要一种高效的方法来进行估计。<strong>The Peaks-Over-Threshold</strong> (POT) 方法是本文介绍的一种方法。</p><p><img src="https://i.loli.net/2020/06/24/hX2T1IkMAqfioZl.png" srcset="/img/loading.gif" alt=""></p><h2 id="Peaks-Over-Threshold-Approach"><a href="#Peaks-Over-Threshold-Approach" class="headerlink" title="Peaks-Over-Threshold Approach"></a>Peaks-Over-Threshold Approach</h2><p>POT方法依赖于Pickands-Balkema-De Haan定理（极值理论第二定理），维基百科版：</p><blockquote><p>考虑一个未知分布$F$和随机变量$X$，我们的目标是估计$X$在超过确定阈值$u$下的条件分布$F_u$，定义为：<br>$$<br>F_u(y)=P(X-u\leq y|X&gt;u)=\frac{F(u+y)-F(u)}{1-F(u)}<br>$$<br>其中$0\leq y\leq x_F-u$，$x_F$为$F$的右端点。$F_u$描述了超过特征阈值$u$的分布，称为<strong>Conditional Excess Distribution Function</strong>。</p><p>*<em>STATEMENT: *</em>(Pickands-Balkema-De Haan). 设$(X_1,X_2,\cdots)$为独立同分布随机变量序列，$F_u$为相应的Conditional Excess Distribution Function。对于一大类的$F$和很大的$u$，$F_u$能够很好的被Generalized Pareto Distribution所拟合：<br>$$<br>F_u(y)\rightarrow G_{k,\sigma}(y),\space\space \text{as } u\rightarrow \infty<br>$$<br>其中：<br>$$<br>G_{k,\sigma}(y)=<br>\begin{cases}<br>1-(1+ky/\sigma)^{-1/k}, &amp;\text{if }k\neq 0\<br>1-e^{-y/\sigma}, &amp;\text{if }k=0<br>\end{cases}<br>$$<br>当$k\geq 0$时$\sigma&gt;0, y\geq 0$，$k&lt;0$时$0\leq y\leq -\sigma/k$。</p></blockquote><p>论文中给出的定理如下：</p><blockquote><p>*<em>THEOREM: *</em>(Pickands-Balkema-De Haan). 累积概率密度函数$F\in\mathcal{D}<em>\gamma$当且仅当函数$\sigma$存在时，对所有$x\in\mathbb{R}$在$1+\gamma x&gt;0$的条件下有：<br>$$<br>\frac{\bar{F}(t+\sigma(t)x)}{\bar{F}(t)}\mathop{\rightarrow}\limits</em>{t\rightarrow\tau}(1+\gamma x)^{-\frac{1}{\gamma}}<br>$$</p></blockquote><p>上式可以写成如下形式：<br>$$<br>\bar{F}<em>t(x)=\mathbb{P}(X-t&gt;x|X&gt;t)\mathop{\sim}\limits</em>{t\rightarrow\tau}\left(1+\frac{\gamma x}{\sigma(t)}\right)^{-\frac{1}{\gamma}}<br>$$<br>该式表明$X$超过阈值$t$的概率（写为$X-t$）服从<strong>Generalized Pareto Distribution</strong> (GPD)，参数为$\gamma$和$\sigma$。POT主要是拟合GPD而不是EVT分布。</p><p>如果我们要估计参数$\hat{\gamma}$和$\hat{\sigma}$，分位数可以通过下式计算得到：<br>$$<br>z_q\simeq t+\frac{\hat{\sigma}}{\hat{\gamma}}\left(\left(\frac{qn}{N_t}\right)^{-\hat{\gamma}}-1\right)<br>$$</p><p>其中$t$是一个“很高”的阈值，$q$是给定的概率值，$n$是所有观测样本的数量，$N_t$是peaks的数量，即$X_i&gt;t$的数量。为了进行高效的参数估计，文中使用了极大似然估计。</p><h2 id="Maximum-Likelihood-Estimation"><a href="#Maximum-Likelihood-Estimation" class="headerlink" title="Maximum Likelihood Estimation"></a>Maximum Likelihood Estimation</h2><p>设$X_1,\cdots,X_n$为独立同分布的随机变量，概率密度函数记为$f_\theta$，$\theta$为分布中的参数，那么似然函数可以写为：</p><p>$$<br>\mathcal{L}(X_1,\cdots,X_n;\theta)=\prod\limits_{i=1}^n f_\theta(X_i)<br>$$</p><p>在极大似然估计中，我们需要找到合适的参数使得似然函数最大化。在我们的问题中，似然函数如下：<br>$$<br>\log\mathcal{L}(\gamma,\sigma)=-N_t\log\sigma-\left(1+\frac{1}{\gamma}\right)\sum\limits_{i=1}^{N_t}\log\left(1+\frac{\gamma}{\sigma}Y_i\right)<br>$$<br>其中$Y_i&gt;0$表示$X_i$超过阈值$t$的部分。</p><p>文中使用了<strong>Grimshaw’s Trick</strong>来将含两个参数的优化问题转换为只含一个参数的优化问题。记$\ell(\gamma,\sigma)=\log\mathcal{L}(\gamma,\sigma)$，对于所有极值来说有$\nabla \ell(\gamma, \sigma)=0$。Grimshaw’s Trick表明对于满足$\nabla \ell(\gamma, \sigma)=0$的一对$(\gamma^<em>,\sigma^</em>)$，$x^<em>=\frac{\gamma^</em>}{\sigma^<em>}$为等式$u(X)v(X)=1$的解，其中：<br>$$<br>\begin{align}<br>u(x)&amp;=\frac{1}{N_t}\sum\limits_{i=1}^{N_t}\frac{1}{1+xY_i}\<br>v(x)&amp;=1+\frac{1}{N_t}\sum\limits_{i=1}^{N_t}\log(1+xY_i)<br>\end{align}<br>$$<br>在找到满足该等式的解$x^</em>$后，我们可以得到$\gamma^<em>=v(x^</em>)-1$和$\sigma^<em>=\gamma^</em>/x^*$，于是问题就变成了如何寻找方程的所有根。</p><p>因为$\log$的存在，所以有$1+xY_i&gt;0$。而$Y_i$是正数，所以$x^*$的范围一定在$\left(-\frac{1}{Y^M},+\infty\right)$，其中$Y^M=\max Y_i$。</p><p>Grimshaw（作者参考的一篇<a href="https://www.tandfonline.com/doi/abs/10.1080/00401706.1993.10485040" target="_blank" rel="noopener">论文</a>）还给出了一个上界：<br>$$<br>x^*_{\text{max}}=2\frac{\bar{Y}-Y^m}{(Y^m)^2}<br>$$<br>其中$Y^m=\min Y_i$，$\bar{Y}$为$Y_i$的均值。详细的优化方法会在下文讨论。</p><p>背景部分到此结束，接下来的部分就是作者提出的新方法。</p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><p>Extreme Value Theory给出了在对原始分布未知的情况下估计使得$\mathbb{P}(X&gt;z_q)&lt;q$的$z_q$的方法。</p><p>本文据此提出了时间序列流的异常检测方法。首先根据已知的观测值$X_1,\cdots,X_n$得到阈值$z_q$，然后根据数据的特性运用两种不同方法来更新$z_q$。对于平稳时间序列，使用SPOT；对于非平稳时间序列，使用DSPOT。</p><h2 id="Initialization-Step"><a href="#Initialization-Step" class="headerlink" title="Initialization Step"></a>Initialization Step</h2><p>在进行异常检测之前，需要根据已有的观测数据进行$z_q$的估计。给定$n$个观测值$X_1,\cdots,X_n$和一个固定的概率值$q$，我们的目标是估计阈值$z_q$使得$\mathbb{P}(X&gt;z_q)&lt;q$。其主要流程是首先设定一个较大的阈值$t$，然后通过拟合GPD分布来计算$z_q$。过程如下图所示：</p><p><img src="https://i.loli.net/2020/06/24/fzeC8vuDtA6mEdl.png" srcset="/img/loading.gif" alt=""></p><p>算法流程如下所示：</p><p><img src="https://i.loli.net/2020/06/24/AEQpnZPiW3C4mr7.png" srcset="/img/loading.gif" alt=""></p><p>$Y_t$代表大于$t$的观测值的集合，GPD分布的拟合使用了前文提到的Grimshaw’s Trick。</p><h2 id="Finding-Anomalies-in-a-Stream"><a href="#Finding-Anomalies-in-a-Stream" class="headerlink" title="Finding Anomalies in a Stream"></a>Finding Anomalies in a Stream</h2><p>通过Initialization Step使用POT算法得到的$z_q$，我们定义其为”Normality Bound”，用于后面的检测。在后面的步骤中，我们会根据新得到的观测值来更新$z_q$。</p><h3 id="Stationary-Case"><a href="#Stationary-Case" class="headerlink" title="Stationary Case"></a>Stationary Case</h3><p>我们首先来讨论时间序列没有时间依赖性的情况（$X_1,\cdots,X_n$之间独立同分布）。通过POT算法对所有观测值得到$z_q$之后，Streaming POT (SPOT) 算法会检查$X_n$之后的值（数据流场景，$X_1,\cdots,X_n$是历史数据，还会有新的数据进来），如果大于$z_q$，则将$X_i$加入异常点集合中；如果大于$t$但小于$z_q$，则将$X_i$加入观测值集合中，更新$z_q$；其他情况我们$X_i$是正常情况。算法流程图如下：</p><p><img src="https://i.loli.net/2020/06/24/h5yKnlCAYxbHu2R.png" srcset="/img/loading.gif" alt=""></p><h3 id="Drifting-Case"><a href="#Drifting-Case" class="headerlink" title="Drifting Case"></a>Drifting Case</h3><p>SPOT算法只适用于平稳分布的情况，但在现实生活中这样的假设过强了。于是作者提出了能处理时间依赖性的Streaming POT with Drift (DSPOT) 算法。</p><p><img src="https://i.loli.net/2020/06/25/O49XwQvVGH7k1ri.png" srcset="/img/loading.gif" alt=""></p><p>在DSPOT中，我们不使用$X_i$的绝对值，而是用相对值$X^\prime_i=X_i-M_i$，其中$M_i$是$i$时刻的局部特征，如Figure 4所示。最简单的实现是使用局部均值，即$M_i=(1/d)\cdot\sum\limits_{k=1}^d X_{i-k}^<em>$，$X_{i-1}^</em>,\cdots,X_{i-d}^*$是长度为$d$的窗口。我们假设$X^\prime_i$服从平稳分布的假设。</p><p>算法流程图如下所示：</p><p><img src="https://i.loli.net/2020/06/25/P6hOsD9dnNIHvUV.png" srcset="/img/loading.gif" alt=""></p><h2 id="Numerical-Optimization"><a href="#Numerical-Optimization" class="headerlink" title="Numerical Optimization"></a>Numerical Optimization</h2><p>现在剩下的问题就是优化了，前文已经提到对GPD的拟合已经被优化成一个参数的优化问题，下面将会详细讨论优化算法。</p><h3 id="Reduction-of-the-Optimal-Parameters-Search"><a href="#Reduction-of-the-Optimal-Parameters-Search" class="headerlink" title="Reduction of the Optimal Parameters Search"></a>Reduction of the Optimal Parameters Search</h3><p>前文已经得到了一个初步的$x^<em>$的Bound，即$x^</em>&gt;-\frac{1}{Y^M}$和$x^*\leq 2\frac{\bar{Y}-Y^m}{(Y^m)^2}$，下面将给出一个更严格的Bound。</p><blockquote><p><em><em>PROPOSITION: *</em>如果$x^</em>$是$u(x)v(x)=1$的解，那么：<br>$$<br>x^<em>\leq 0 \text{ or } x^</em>\geq 2\frac{\bar{Y}-Y^m}{\bar{Y}Y^m}<br>$$</p></blockquote><p>证明见论文原文。</p><p>这样$x^<em>$的范围就进一步缩小了，于是有$u(x)v(X)=1$的解$x^</em>$在以下范围之内：<br>$$<br>\left(-\frac{1}{Y^M},0\right]\text{ and }\left[2\frac{\bar{Y}-Y^m}{\bar{Y}Y^m},2\frac{\bar{Y}-Y^m}{(Y^m)^2}\right]<br>$$</p><h3 id="How-Can-We-Maximize-the-Likelihood-Function"><a href="#How-Can-We-Maximize-the-Likelihood-Function" class="headerlink" title="How Can We Maximize the Likelihood Function?"></a>How Can We Maximize the Likelihood Function?</h3><p>接下来是优化的具体实现问题。文中首先设定了一个很小的值$\epsilon&gt;0\space(\sim 10^{-8})$，然后在下面的范围内寻找函数$w:x\mapsto u(x)v(x)-1$的根：<br>$$<br>\left[-\frac{1}{Y^M}+\epsilon,-\epsilon\right]\text{ and }\left[2\frac{\bar{Y}-Y^m}{\bar{Y}Y^m},2\frac{\bar{Y}-Y^m}{(Y^m)^2}\right]<br>$$<br>作者没有使用现有的寻找函数根的算法，而是转换为如下优化问题：<br>$$<br>\min\limits_{x_1,\cdots,x_k\in I}\sum\limits_{i=1}^k w(x_k)^2<br>$$<br>其中$I$就是$x^*$的Bound。该问题是一个很典型的优化问题，可以被很多成熟的算法所解决。</p><h3 id="Initial-Threshold"><a href="#Initial-Threshold" class="headerlink" title="Initial Threshold"></a>Initial Threshold</h3><p>在算法的Initialization Step，需要事先设定一个阈值$t$，如果设定的太大，那么$Y_t$的数量就会很少。作者给出的建议是保证$t&lt;z_q$，即$t$对应的概率值应该小于$1-q$。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>在实验部分，作者在合成数据和真实数据上试验了SPOT算法和DSPOT算法的有效性。</p><h2 id="D-SPOT-Reliability"><a href="#D-SPOT-Reliability" class="headerlink" title="(D)SPOT Reliability"></a>(D)SPOT Reliability</h2><p>作者首先在合成数据上验证SPOT的有效性。具体做法是使用高斯分布生成数据（高斯分布的分位数能够直接计算），然后将SPOT得出的$z_q$和理论值进行对比。误差定义如下：<br>$$<br>\text{error rate}=\left|\frac{z^{\text{SPOT}}-z^{\text{th}}}{z^{\text{th}}}\right|<br>$$<br>下图是采用不同数量观测值的结果：</p><p><img src="https://i.loli.net/2020/06/25/GXlu2MAJaoqxyd4.png" srcset="/img/loading.gif" alt=""></p><h2 id="Finding-Anomalies-with-SPOT"><a href="#Finding-Anomalies-with-SPOT" class="headerlink" title="Finding Anomalies with SPOT"></a>Finding Anomalies with SPOT</h2><p>在这一节作者在真实数据集上进行了实验以验证SPOT算法的有效性，结果如下图：</p><p><img src="https://i.loli.net/2020/06/25/wTkZxKarFVDOlp6.png" srcset="/img/loading.gif" alt=""></p><p>在文中作者说算法的True Positive达到了$86%$，False Positive小于$4%$。</p><p><img src="https://i.loli.net/2020/06/25/RcUnwtHud7DjNXv.png" srcset="/img/loading.gif" alt=""></p><h2 id="Finding-Anomalies-with-DSPOT"><a href="#Finding-Anomalies-with-DSPOT" class="headerlink" title="Finding Anomalies with DSPOT"></a>Finding Anomalies with DSPOT</h2><p>在这一节作者使用DSPOT在真实数据集上进行了实验。窗口大小$d=450$，预设的风险概率值$q=10^{-3}$。结果如下图所示：</p><p><img src="https://i.loli.net/2020/06/25/lIxqpnGtL7feVKs.png" srcset="/img/loading.gif" alt=""></p><p>在图中可以看出在$8000$ Minutes之后上界显著提高，作者分析了原因，认为是因为超过阈值$t$的点$Y_t$的存储是全局的，在前$8000$ Minutes算法存储了很多较高的$Y_t$值，而在$8000$ Minutes之后，真实数据的趋势开始下降，但算法仍是根据全局的$Y_t$来进行$z_q$的计算（这一段没有特别明白）。作者给出的修正方法是只保存固定数量的Peaks。</p><p>下图是作者在股票数据上得到的实验结果：</p><p><img src="https://i.loli.net/2020/06/25/VeEo8OPbzyUxXrR.png" srcset="/img/loading.gif" alt=""></p><h2 id="Performances"><a href="#Performances" class="headerlink" title="Performances"></a>Performances</h2><p>作者还验证了算法的时间效率。</p><p><img src="https://i.loli.net/2020/06/25/Egh7CxsU2TtL6az.png" srcset="/img/loading.gif" alt=""></p><p>表中T代表的是每个Iteration的时间，M代表的是Peaks的比例，”bi-“前缀代表的是同时计算上界和下界。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Statistics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>An Introduction to Variational Autoencoders</title>
    <link href="/2019/10/22/An-Introduction-to-Variational-Autoencoders/"/>
    <url>/2019/10/22/An-Introduction-to-Variational-Autoencoders/</url>
    
    <content type="html"><![CDATA[<h1 id="Deep-Generative-Models"><a href="#Deep-Generative-Models" class="headerlink" title="Deep Generative Models"></a>Deep Generative Models</h1><p>生成模型是指一系列用于随机生成可观测数据的模型。假设在一个高维空间$\mathcal{X}$中，存在一个随机向量$\mathbf{X}$服从一个未知的分布$p_r(x),x\in \mathcal{X}$。生成模型就是根据一些可观测的样本$x^{(1)},x^{(2)},\cdots,x^{(N)}$来学习一个参数化的模型$p_\theta(x)$来近似未知分布$p_r(x)$。</p><p>生成模型主要用于密度估计和样本生成。</p><hr><p>密度估计即给定一组数据$\mathcal{D}={x^{(i)}},1\leq i\leq N$，假设他们都是从相同的概率密度函数$p_r(x)$独立产生的。密度估计就是根据数据集$\mathcal{D}$来估计其概率密度函数$p_r(x)$。</p><p>如果将生成模型用于监督学习，那么就是输出标签的条件概率分布$p(y|x)$，根据贝叶斯公式：</p><p>$$p(y|x)=\frac{p(x,y)}{\sum_y p(x,y)}$$</p><p>问题就变为了联合概率$p(x,y)$的密度估计问题。</p><hr><p>样本生成即根据给定的概率分布$p_\theta(x)$生成一些服从这个分布的样本，即采样。在含隐变量的生成模型中，生成$x$的过程一般包含两步：</p><ol><li>根据隐变量的分布$p_\theta(z)$采样得到$z$；</li><li>根据条件分布$p_\theta(x|z;\theta)$进行采样得到$x$。</li></ol><p>所以在生成模型中的重点是估计条件分布$p(x|z;\theta)$。</p><h1 id="Parameter-Estimation-for-Hidden-Variable-with-EM-Algorithm"><a href="#Parameter-Estimation-for-Hidden-Variable-with-EM-Algorithm" class="headerlink" title="Parameter Estimation for Hidden Variable with EM Algorithm"></a>Parameter Estimation for Hidden Variable with EM Algorithm</h1><p>如果图模型中存在隐变量，就需要使用EM算法进行参数估计。</p><p>在一个包含隐变量的图模型中，令$\mathbf{X}$为可观测变量集合，$\mathbf{Z}$为隐变量集合，则一个样本$x$的边际似然函数为：</p><p>$$p(x;\theta)=\sum_z p(x,z;\theta)$$</p><p>给定包含$N$个训练样本的训练集$\mathcal{D}={x^{(n)}},1\leq i\leq N$，则训练集的对数边际似然为：</p><p>$$\begin{align}\mathcal{L}(\mathcal{D};\theta)&amp;=\frac{1}{N}\sum_{n=1}^N \log p(x^{(n)};\theta)\&amp;=\frac{1}{N}\sum_{n=1}^N \log \sum_z p(x^{(n)},z;\theta)\end{align}$$</p><hr><p>这时，只要最大化整个训练集的对数边际似然$\mathcal{L}(\mathcal{D};\theta)$，即可估计出最优的参数$\theta^*$。不过在计算梯度的时候，需要在对数函数内部进行求和或积分计算。为了更好的计算$\log p(x;\theta)$，我们引入一个额外的变分函数$q(z)$，$q(z)$为定义在隐变量$z$上的分布。样本$x$的对数边际似然函数为：</p><p>$$\begin{align}\log p(x;\theta)&amp;=\log \sum_z q(z)\frac{p(x,z;\theta)}{q(z)}\&amp;\geq\sum_z q(z)\log \frac{p(x,z;\theta)}{q(z)}\&amp;\triangleq ELBO(q,x;\theta)\end{align}$$</p><p>其中$ELBO(q,x;\theta)$为对数边际似然函数$\log p(x;\theta)$的下界，称为证据下界。公式中使用了Jensen不等式(即对于凹函数$g$，有$g(\mathbb{E}[x])\geq\mathbb{E}[g(X)]$)。在这里，$\frac{p(x,z;\theta)}{q(z)}$可视为$q(z)$的函数，记为$f(q(z))$，那么$f(q(z))$的期望即$\mathbb{E}[f(q(z))]=\sum_z q(z)f(q(z))=\sum_z q(z)\frac{p(x,z;\theta)}{q(z)}$。而根据Jensen不等式，有$g(\mathbb{E}[f(q(z))])\geq\mathbb{E}[g(f(q(z)))]\Leftrightarrow g(\sum_z q(z)\frac{p(x,z;\theta)}{q(z)})\geq \sum_z q(z)g(\frac{p(x,z;\theta)}{q(z)})$，在这里$g$就是对数函数。</p><hr><p>根据Jensen不等式取等的条件：$\frac{p(x,z;\theta)}{q(z)}=c$，$c$为常数，有：</p><p>$$\begin{align}\sum_z p(x,z;\theta)&amp;=c\sum_z q(z)\\Leftrightarrow\sum_z p(x,z;\theta)&amp;=c\cdot1\end{align}$$</p><p>因此：</p><p>$$\begin{align}q(z)&amp;=\frac{p(x,z;\theta)}{\sum_z p(x,z;\theta)}\&amp;=\frac{p(x,z;\theta)}{p(x;\theta)}\&amp;=p(z|x;\theta)\end{align}$$</p><p>所以，当且仅当$q(z)=p(z|x;\theta)$时，$\log p(x;\theta)=ELBO(q,x;\theta)$。</p><hr><p>于是最大化对数边际似然函数$\log p(x;\theta)$的过程可以分解为两个步骤：</p><ol><li>先找到近似分布$q(z)$使得$\log p(x;\theta)=ELBO(q,x;\theta)$；</li><li>再寻找参数$\theta$最大化$ELBO(q,x;\theta)$。</li></ol><p>这就是期望最大化(Expectation-Maximum,EM)算法。</p><hr><p>EM算法通过迭代的方法，不断重复直到收敛到某个局部最优解。在第$t$步更新时，E步和M步分别为：</p><ol><li><p>E步：固定参数$\theta_t$，找到一个分布使$ELBO(q,x;\theta_t)$最大，即等于$\log p(x;\theta_t)$：$q_{t+1}(z)=\text{arg}_q \max ELBO(q,x;\theta_t)$；</p></li><li><p>M步：固定$q_{t+1}(z)$，找到一组参数使得证据下界最大，即：$\theta_{t+1}=\text{arg}<em>\theta\max ELBO(q</em>{t+1},x;\theta)$。</p></li></ol><hr><p>对数边际似然也可以通过信息论的视角来进行分解：</p><p>$$\begin{align}\log p(x;\theta)&amp;=\sum_z q(z)\log p(x;\theta)\&amp;=\sum_z q(z)(\log p(x,z;\theta)-\log p(z|x;\theta))\&amp;=\sum_z q(z)\log\frac{p(x,z;\theta)}{q(z)}-\sum_z q(z)\log\frac{p(z|x;\theta)}{q(z)}\&amp;=ELBO(q,x;\theta)+D_{KL}(q(z)\parallel p(z|x;\theta))\end{align}$$</p><p>其中$D_{KL}(q(z)\parallel p(z|x;\theta))$</p><h1 id="Generative-Model-with-Hidden-Variable"><a href="#Generative-Model-with-Hidden-Variable" class="headerlink" title="Generative Model with Hidden Variable"></a>Generative Model with Hidden Variable</h1><p>假设一个生成模型包含不可观测的隐变量，其中可观测变量$x$为一个高维空间中的随机向量，而不可观测的隐变量$z$为一个相对低维空间中的随机向量。</p><p>这个生成模型的联合概率密度函数可以表达为：</p><p>$$p(x,z;\theta)=p(x|z;\theta)p(z;\theta)$$</p><p>其中$p(z;\theta)$为隐变量$z$的先验概率分布；$p(x|z;\theta)$为已知$z$条件下$x$的概率分布。通常情况下，我们可以假设$p(z;\theta)$和$p(x|z;\theta)$服从某种带参的分布族，其形式已知，而参数可以通过最大似然来进行估计。</p><p>给定一个样本$x$，其对数边际似然$\log p(x;\theta)$可以分解为：</p><p>$$\log p(x;\theta)=ELBO(q,x;\theta,\phi)+D_{KL}(q(z;\phi)\parallel p(z|x;\theta))$$</p><p>其中$q(z;\phi)$为额外引入的变分密度函数，$ELBO(q,x;\theta,\phi)$为证据下界：</p><p>$$ELBO(q,x;\theta,\phi)=\mathbb{E}_{z\sim q(z;\phi)}[\log{\frac{p(x,z;\theta)}{q(z;\phi)}}]$$</p><p>最大化$\log p(x;\theta)$可以用EM算法来求解：</p><ul><li><strong>E-step:</strong> 寻找一个密度函数$q(z;\phi)$使其等于或接近于后验密度函数$p(z|x;\theta)$;</li><li><strong>M-step:</strong> 保持$q(z;\phi)$固定，寻找$\theta$来最大化$ELBO(q,x;\theta,\phi)$。</li></ul><p>在EM算法的每次迭代中，理论上最优的$q(z;\phi)$为隐变量的后验概率密度函数$p(z|x;\theta)$：</p><p>$$p(z|x;\theta)=\frac{p(x|z;\theta)p(z;\theta)}{\int_z p(x|z;\theta)p(z;\theta)\text{d}z}$$</p><p>后验密度函数$p(z|x;\theta)$的计算是一个统计推断的问题，在一般情况下$p(x|z;\theta)$也比较难以计算。</p><h1 id="Variational-Autoencoder"><a href="#Variational-Autoencoder" class="headerlink" title="Variational Autoencoder"></a>Variational Autoencoder</h1><p>变分自编码器(Variational Autoencoder, VAE)的主要思想是利用神经网络来分别建模两个复杂的条件概率密度函数：</p><ol><li><p>用神经网络来产生变分分布$q(z;\phi)$，称为推断网络。推断网络的输入为$x$，输出为变分分布$q(z|x;\phi)$；</p></li><li><p>用神经网络来产生概率分布$p(x|z;\theta)$，称为生成网络。生成网络的输入为$z$，输出为概率分布$p(x|z;\theta)$。</p><p><img src="https://i.loli.net/2020/06/24/B1d9UtTzNfjG6e2.png" srcset="/img/loading.gif" alt=""></p></li></ol><p>VAE的图模型如下图所示：</p><p><img src="https://i.loli.net/2020/06/24/GAhy281seQ3tbZT.png" srcset="/img/loading.gif" alt=""></p><h2 id="Variational-Network"><a href="#Variational-Network" class="headerlink" title="Variational Network"></a>Variational Network</h2><p>假设$q(z|x;\phi)$是服从对角化协方差的高斯分布：</p><p>$$q(z|x;\phi)=\mathcal{N}(z;\mu_I,\sigma^2_I I)$$</p><p>其中$\mu_I$和$\sigma_I^2$是高斯分布的均值和方差，可以通过推断网络$f_I(x;\phi)$来预测：</p><p>$$<br>\left[\begin{matrix}\mu_I\\sigma_I\end{matrix}\right]=f_I(x;\phi)<br>$$<br>推断网络$f_I(x;\phi)$可以是一般的全连接网络或卷积网络，比如一个两层的神经网络：</p><p>$$\begin{align}h&amp;=\sigma(W^{(1)}x+b^{(1)})\\mu_I&amp;=W^{(2)}h+b^{(2)}\\sigma_I&amp;=\text{softplus}(W^{(3)}h+b^{(3)})\end{align}$$</p><p>其中所有网络参数${W^{(1)},W^{(2)},W^{(3)},b^{(1)},b^{(2)},b^{(3)}}$即对应了变分参数$\phi$。</p><hr><p>推断网络的目标是使得$q(z|x;\phi)$来尽可能接近真实的后验$p(z|x;\theta)$，需要找到变分参数$\phi^*$来最小化两个分布的KL散度：</p><p>$$\phi^*=\text{arg}<em>\phi\min{D</em>{KL}(q(z|x;\phi)\parallel p(z|x;\theta))}$$</p><p>由于$p(z|x;\theta)$未知，故KL散度无法直接计算，不过由于$D_{KL}(q(z|x;\phi)\parallel p(z|x;\theta))=\log p(x;\theta)-ELBO(q,x;\theta,\phi)$，所以可以直接最大化证据下界，有：</p><p>$$\phi^*=\text{arg}_\phi\max{ELBO(q,x;\theta,\phi)}$$</p><h2 id="Generative-Network"><a href="#Generative-Network" class="headerlink" title="Generative Network"></a>Generative Network</h2><p>生成模型的联合分布可以分解为两部分：隐变量$z$的先验分布$p(z;\theta)$和条件概率分布$p(x|z;\theta)$。为简单起见，一般假设隐变量$z$的先验分布为标准正态分布$\mathcal{N}(z|0,I)$，隐变量每一维之间都是独立的。条件概率分布$p(x|z;\theta)$可以通过生成网络来建模，我们同样用参数化的分布族来表示条件概率分布$p(x|z;\theta)$，这些分布族的函数可以用生成网络计算得到。根据变量$x$的类型不同，可以假设$p(x|z;\theta)$服从不同的分布族。如果$x\in{0,1}^d$是$d$维的二值向量，可以假设$\log p(x|z;\theta)$服从多变量的伯努利分布，即：</p><p>$$\begin{align}p(x|z;\theta)&amp;=\prod\limits_{i=1}^d p(x_i|z;\theta)\&amp;=\prod\limits_{i=1}^d \gamma_i^{x_i}(1-\gamma_i)^{(1-x_i)}\end{align}$$</p><p>如果$x\in\mathbb{R}^d$是$d$维的连续向量，可以假设$p(x|z;\theta)$服从对角化协方差的高斯分布，即：</p><p>$$p(x|z;\theta)=\mathcal{N}(x;\mu_G,\sigma_G^2 I)$$</p><hr><p>生成网络的目标是找到一组$\theta^*$最大化证据下界$ELBO(q,x;\theta,\phi)$：</p><p>$$\theta^*=\text{arg}_\theta\max ELBO(q,x;\theta,\phi)$$</p><h2 id="Model-Combination"><a href="#Model-Combination" class="headerlink" title="Model Combination"></a>Model Combination</h2><p>推断网络和生成网络的目标都是最大化证据下界因此总的目标函数为：</p><p>$$\begin{align}\max_{\theta,\phi}ELBO(q,x;\theta,\phi)&amp;=\max_{\theta,\phi}\mathbb{E}<em>{z\sim q(z;\phi)}[\log\frac{p(x|z;\theta)p(z;\theta)}{q(z;\theta)}]\&amp;=\max</em>{\theta,\phi}\mathbb{E}<em>{z\sim q(z|x;\phi)}[\log p(x|z;\theta)]-D</em>{KL}(q(z|x;\phi)\parallel p(z;\theta))\end{align}$$</p><p>其中先验分布$p(z;\theta)=\mathcal{N}(z|0,I)$。</p><p>公式中$\mathbb{E}_{z\sim q(z|x;\phi)}[\log p(x|z;\theta)]$一般通过采样的方式进行计算，最后取平均值。</p><h2 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h2><p>给定数据集$\mathcal{D}$，包含$N$个从未知数据分布中抽取的独立同分布样本$x^{(1)},x^{(2)},\cdots,x^{(N)}$。变分自编码器的目标函数为：</p><p>$$\mathcal{J}(\phi,\theta|\mathcal{D})=\sum\limits_{n=1}^N(\frac{1}{M}\sum\limits_{m=1}^M\log p(x^{(n)}|z^{(n,m)};\theta)-D_{KL}(q(z|x^{(n)};\phi)\parallel\mathcal{N}(z;0,I)))$$</p><p>如果采用随机梯度下降法，每次从数据集中采一个样本$x$，然后根据$q(z|x;\phi)$采一个隐变量$z$，则目标函数变为：</p><p>$$\mathcal{J}(\phi,\theta|x)=\log p(x|z;\theta)-D_{KL}(q(z|x;\phi)\parallel\mathcal{N}(z;0,I))$$</p><p>假设$q(z|x;\phi)$是正态分布，KL散度可直接算出：</p><p>$$D_{KL}(\mathcal{N}(\mu_1,\Sigma_1)\parallel\mathcal(\mu_2,\Sigma_2))\=\frac{1}{2}(\text{tr}(\sigma_I^2 I)+\mu_I^T\mu_I-d-\log(|\sigma_I^2 I|))$$</p><hr><p>再参数化是将一个参数为$u$的函数$f(u)$，通过一个函数$u=g(v)$，转换为参数为$v$的函数$\hat{f}(v)=f(g(v))$。在变分自编码器中，一个问题是如何求随机变量$z$关于$\phi$的导数。但由于是采样的方式，无法直接刻画$z$和$\phi$之间的函数关系，因此也无法计算导数。</p><p>如果$z\sim q(z|x;\phi)$的随机性独立于参数$\phi$，我们可以通过再参数化的方法来计算导数。假设$q(z|x;\phi)$为正态分布$\mathcal{N}(\mu_I,\sigma^2_I I)$，其中$\mu_I$和$\sigma_I$是推断网络$f_I(x;\phi)$的输出。我们可以通过下面的方式采样$z$：</p><p>$$z=\mu_I+\sigma_I\odot \varepsilon$$</p><p>其中$\varepsilon\sim\mathcal{N}(0,I)$。这样$z$和$\mu_I,\sigma_I$的关系从采样关系变为函数关系。</p><hr><p>如果进一步假设$p(x|z;\theta)$服从高斯分布$\mathcal{N}(x|\mu_G,I)$，其中$\mu_G=f_G(z;\theta)$是生成网络的输出，则目标函数可以简化为：</p><p>$$\mathcal{J}(\phi,\theta|x)=-\parallel x-\mu_G\parallel^2+D_{KL}(\mathcal{N}(\mu_I,\sigma_I)\parallel\mathcal{N}(0,I))$$</p><p>其中第一项可以近似看作是输入$x$的重构正确性，第二项可以看作是正则化项。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
      <tag>Variational Inference</tag>
      
      <tag>VAE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Recurrent Neural Networks for Multivariate Time Series with Missing Values</title>
    <link href="/2019/10/18/Recurrent-Neural-Networks-for-Multivariate-Time-Series-with-Missing-Values/"/>
    <url>/2019/10/18/Recurrent-Neural-Networks-for-Multivariate-Time-Series-with-Missing-Values/</url>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>文中提出了一种可以处理带缺失值多为时间序列的GRU模型：<strong>GRU-D</strong>。本模型不仅可以捕捉时间序列中的长期依赖模式，并且还能利用时间序列中的缺失模式来达到更好的时间序列预测效果。</p><p><a href="https://www.nature.com/articles/s41598-018-24271-9" target="_blank" rel="noopener">原文</a></p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Notations"><a href="#Notations" class="headerlink" title="Notations"></a>Notations</h2><p>记包含$D$个变量的多变量时间序列为$X=(x_1,x_2,\cdots,x_T)^T\in\mathbb{R}^{T\times D}$，其中对于每个$t\in{1,2,\cdots,T},x_t\in\mathbb{R}^D$表示时间序列在时间$t$的观测值，$x_t^d$表示$x_t$的第$d$个成分。记$s_t\in\mathbb{R}$为$t$时刻的时间戳，并假设第一个观测值的时间戳为$0$。对于包含缺失值的时间序列，我们用<strong>Masking Vector</strong> $m_t\in{0,1}$进行标记，同时对每个$x_t^d$维护距离上一个观测值的<strong>Time Interval</strong> $\delta_t^d\in\mathbb{R}$，公式如下：<br>$$<br>m_t^d=\begin{cases}1, &amp;\text{if }x_t^d\text{ is observed}\0, &amp;\text{otherwise}\end{cases}<br>$$</p><p>$$<br>\delta_t^d=\begin{cases}s_t-s_{t-1}+\delta_{t-1}^d, &amp;t&gt;1,m_{t-1}^d=0\s_t-s_{t-1}, &amp;t&gt;1, m_{t-1}^d=1\0, &amp;t=1\end{cases}<br>$$</p><p>下图是一些示例：</p><p><img src="https://i.loli.net/2020/06/25/C4FKQw2AZ9xkalo.png" srcset="/img/loading.gif" alt=""></p><p>在本文中，我们主要关注时间序列的分类问题，即给定数据集$\mathcal{D}={(X_n,s_n,M_n)}_{n=1}^N$，我们要对每个样本的类别进行预测$l_n\in{1,\cdots,L}$。</p><h2 id="GRU-RNN-for-Time-Series-Classification"><a href="#GRU-RNN-for-Time-Series-Classification" class="headerlink" title="GRU-RNN for Time Series Classification"></a>GRU-RNN for Time Series Classification</h2><p>GRU是一种改进版本的RNN，其最大不同是加入了门控机制。GRU单元的结构如下图所示：</p><img src="https://i.loli.net/2020/06/25/wpKQsxEklizVTtm.png" srcset="/img/loading.gif" style="zoom: 33%;" /><p>GRU包含了重置门和更新门，其中重置门$R_t$负责控制上一时间的隐状态$h_{t-1}$有多少部分需要保留，而更新门则决定由$R_t$计算出来的候选隐状态$\tilde{h}<em>t$有多少部分需要保留。最后当前时间的隐状态由$h</em>{t-1}$和$\tilde{h}<em>t$共同算出。GRU的状态更新公式如下：<br>$$<br>\begin{align}<br>R_t&amp;=\sigma(W_rx_t+U_rh</em>{t-1}+b_r)\<br>Z_t&amp;=\sigma(W_zx_t+U_zh_{t-1}+b_z)\<br>\tilde{h}<em>t&amp;=\text{tanh}(Wx_t+U(R_t\odot h</em>{t-1})+b)\<br>h_t&amp;=(1-Z_t)\odot h_{t-1}+Z_t\odot \tilde{h}_t<br>\end{align}<br>$$<br>文中提出了一些处理缺失值的简单方法：</p><ol><li>直接用均值替代：$x_t^d\leftarrow m_t^dx_t^d+(1-m_t^d)\tilde{x}^d$，其中$\tilde{x}^d=\frac{\sum_{n=1}^N\sum_{t=1}^{T_n}m_{t,n}^d x_{t,n}^d}{\sum_{n=1}^N\sum_{t=1}^{T_n}m_{t,n}^d\tilde{x}^d}$。这种方法称为<strong>GRU-Mean</strong>；</li><li>用上一个观测值替代：$x_t^d\leftarrow m_t^d x_t^d+(1-m_t^d)x_{t^\prime}^d$。这种方法称为<strong>GRU-Forward</strong>；</li><li>不填充，将是否缺失，距离上一个观测值的时间作为额外信息输入：$x_t^{(n)}\leftarrow[x_t^{(n)};m_t^{(n)};\delta_t^{(n)}]$。这种方法称为<strong>GRU-Simple</strong>。</li></ol><h3 id="GRU-D-Model-with-Trainable-Decays"><a href="#GRU-D-Model-with-Trainable-Decays" class="headerlink" title="GRU-D: Model with Trainable Decays"></a>GRU-D: Model with Trainable Decays</h3><p>文中提出了时间序列缺失值的两个性质：一个是在上一个观测值距离很远的情况下缺失值倾向于接近一个默认的值，第二个是缺失值的影响会随着时间减弱。为了体现上述两点，文中提出了GPU-D模型，模型框架如下：</p><img src="https://i.loli.net/2020/06/25/aXbS4ADkLfeHPCR.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>在模型中，<strong>Decay Rates</strong>被设定为一个带参数的函数和GRU一起训练：<br>$$<br>\gamma_t=\exp{-\max(0,W_\gamma\delta_t+b_\gamma)}<br>$$</p><p>$$<br>\hat{x}<em>t^d=m_t^dx_t^d+(1-m_t^d)(\gamma</em>{x_t}^dx_{t^\prime}^d+(1-\gamma_{x_t}^d)\tilde{x}^d)<br>$$<br>其中$x_{t^\prime}^d$是第$d$个变量的上一个观测值，$\tilde{x}^d$是第$d$个变量的经验均值。这样$\hat{x}_t^d$就代表经过<strong>Input Decay</strong>的输入。</p><p>文中提到只用<strong>Input Decay</strong>是不够的，除此之外作者还使用了<strong>Hidden State Decay</strong>，即对$h_{t-1}$进行Decay，公式如下：<br>$$<br>\hat{h}<em>{t-1}=\gamma</em>{h_t}\odot h_{t-1}<br>$$<br>用Decay之后的$\hat{x}<em>t$和$\hat{h}</em>{t-1}$替换原始的GRU公式就得到了GRU-D模型：<br>$$<br>\begin{align}<br>R_t&amp;=\sigma(W_r\hat{x}<em>t-U_r\hat{h}</em>{t-1}+V_rm_t+b_r)\<br>Z_t&amp;=\sigma(W_z\hat{x}<em>t+U_z\hat{h}</em>{t-1}+V_zm_t+b_z)\<br>\tilde{h}<em>t&amp;=\text{tanh}(W\hat{x}_t+U(R_t\odot \hat{h}</em>{t-1})+Vm_t+b)\<br>h_t&amp;=(1-z_t)\odot \hat{h}_{t-1}+z_t\odot\tilde{h}_t<br>\end{align}<br>$$</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Baseline-Imputation-Methods"><a href="#Baseline-Imputation-Methods" class="headerlink" title="Baseline Imputation Methods"></a>Baseline Imputation Methods</h2><p>下图为文中比较中用到的Baseline：</p><p><img src="https://i.loli.net/2020/06/25/BFQdwMOXLc15mnl.png" srcset="/img/loading.gif" alt=""></p><h2 id="Baseline-Prediction-Methods"><a href="#Baseline-Prediction-Methods" class="headerlink" title="Baseline Prediction Methods"></a>Baseline Prediction Methods</h2><p>下图为文中用到的用来预测的Baseline：</p><p><img src="https://i.loli.net/2020/06/25/qFxDRBLvNpAIjMs.png" srcset="/img/loading.gif" alt=""></p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>文中用到的数据集如下：</p><ul><li><em>Gesture phase segmentation dataset (Gesture)</em>. </li><li><em>PhysioNet Challenge 2012 dataset (PhysioNet)</em>.</li><li><em>MIMIC-Ⅲ dataset (MIMIC-Ⅲ)</em>. </li></ul><p>下图展示了不同方法在人工合成数据集上的表现：</p><p><img src="https://i.loli.net/2020/06/25/6GVYuxoFP5yHAjf.png" srcset="/img/loading.gif" alt=""></p><p>下表展示了不同模型在预测任务表现的对比：</p><img src="https://i.loli.net/2020/06/25/qTZsgtGewh19Y8V.png" srcset="/img/loading.gif" style="zoom: 67%;" /><p>下表展示了不同方法在MIMIC-Ⅲ和PhysioNet数据集上的多任务表现：</p><p><img src="https://i.loli.net/2020/06/25/dQiqebwYTCVfm5W.png" srcset="/img/loading.gif" alt=""></p><p>下图分别展示了模型学到的<strong>Input Decay</strong>和<strong>Hidden State Decay</strong>：</p><img src="https://i.loli.net/2020/06/25/2F7MrgOXA9nuZqC.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>RNN</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>RNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network</title>
    <link href="/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/"/>
    <url>/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/</url>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文提出了<em>OmniAnomaly</em>：一种针对多变量时间序列的随机循环神经网络异常检测算法。该模型运用了一系列技术来捕捉多变量时间序列的正常模式，并在检测阶段基于重构误差来检测异常，同时本文还提供了一定的理论解释。</p><p><a href="https://www.kdd.org/kdd2019/accepted-papers/view/robust-anomaly-detection-for-multivariate-time-series-through-stochastic-re" target="_blank" rel="noopener">原文</a></p><h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><ol><li>提出了<em>OmniAnomaly</em>，一种基于随机循环神经网络的多变量时间序列异常检测算法；</li><li>提出了针对多变量时间序列异常检测的解释方法；</li><li>通过实验证明了<em>OmniAnomaly</em>中所用的关键技术的有效性，包括GRU，planar NF, stochastic variable connection和adjusted Peaks-Over-Threshold method；</li><li>通过大量的实验我们证明了<em>OmniAnomaly</em>的有效性；</li><li>发布了代码和数据集。</li></ol><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><h2 id="Linear-Gaussian-State-Space-Model"><a href="#Linear-Gaussian-State-Space-Model" class="headerlink" title="Linear Gaussian State Space Model"></a>Linear Gaussian State Space Model</h2><p>状态空间模型（State Space Model, SSM）的概念来自于控制理论，在这里我们主要讨论其在时间序列中的应用。其大概思想是我们认为时间序列在时刻$t$的观测值$z_t$是一个隐含状态$\boldsymbol{l}<em>t$的条件分布$p(z_t|\boldsymbol{l}_t)$，而这个隐含状态$\boldsymbol{l}_t$刻画了时间序列的内在规律，同时隐含状态会随着时间更新，即服从条件分布$p(\boldsymbol{l}_t|\boldsymbol{l}</em>{t-1})$。</p><p>在线性状态空间模型（Linear State Space Model）中我们以如下的方式刻画隐含状态的更新：<br>$$<br>\boldsymbol{l}<em>t=\boldsymbol{F}_t\boldsymbol{l}</em>{t-1}+\boldsymbol{g}_t\varepsilon_t, \space\space\space\varepsilon_t\sim\mathcal{N}(0,1)<br>$$<br>$\boldsymbol{F}_t$为确定的状态转移矩阵，而$\boldsymbol{g}_t\varepsilon_t$则表示了状态转移的随机性。</p><p>观测值$z_t$从隐含状态$\boldsymbol{l}<em>t$计算而来：<br>$$<br>\begin{align}<br>z_t&amp;=y_t+\sigma_t\epsilon_t,\<br>y_t&amp;=\boldsymbol{a}_t^\top\boldsymbol{l}</em>{t-1}+b_t,\<br>\epsilon_t&amp;\sim\mathcal{N}(0,1)<br>\end{align}<br>$$<br>其中$\boldsymbol{a}_t\in\mathbb{R}^L,\sigma_t\in \mathbb{R},b_t\in\mathbb{R}$都是额外的参数。初始状态$\boldsymbol{l}_0$则从一个独立的高斯分布得来，即$\boldsymbol{l}_0\sim N(\boldsymbol\mu_0,\text{diag}(\boldsymbol{\sigma}_0^2))$。</p><p>令参数集合$\Theta_t=(\boldsymbol{\mu}<em>0,\boldsymbol{\Sigma}_0,\boldsymbol{F}_t,\boldsymbol{g}_t,\boldsymbol{a}_t,b_t,\sigma_t),\forall t&gt;0$，一般来说参数集合不会随着时间变化，即每个时刻$t$共享同样的参数$\Theta_t=\Theta,\forall t&gt;0$。对参数的估计可以采用极大似然估计：<br>$$<br>\begin{align}<br>\Theta^*</em>{1:T}&amp;=\arg\max_{\Theta_{1:T}}p(z_{1:T}|\Theta_{1:T}),\<br>\end{align}<br>$$<br>其中：<br>$$<br>\begin{align}<br>p(z_{1:T}|\Theta_{1:T})&amp;=p(z_1|\Theta_1)\prod\limits_{t=2}^T p(z_t|z_{1:t-1},\Theta_{1:t})\<br>&amp;=\int p(\boldsymbol{l}<em>0)\left[\prod\limits</em>{t=1}^T p(z_t|\boldsymbol{l}<em>t)p(\boldsymbol{l}_t|\boldsymbol{l}</em>{t-1})\right]\mathrm{d}\boldsymbol{l}_{0:T}<br>\end{align}<br>$$</p><h2 id="Planar-Normalizing-Flow"><a href="#Planar-Normalizing-Flow" class="headerlink" title="Planar Normalizing Flow"></a>Planar Normalizing Flow</h2><h3 id="Normalizing-Flows"><a href="#Normalizing-Flows" class="headerlink" title="Normalizing Flows"></a>Normalizing Flows</h3><p>VAE采用一个变分分布$q_\phi(z|x)$来近似真实的后验分布$p(z|x)$，并推导出$\log p_\theta(x)$的下界（称为ELBO）来作为优化目标函数：<br>$$<br>\begin{align}<br>\log p_\theta(x)&amp;=\log \int p_\theta(x|z)p(z)\mathrm{d}z\<br>&amp;=\log\int\frac{q_\phi(z|x)}{q_\phi(z|x)}p_\theta(x|z)p(z)\mathrm{d}z\<br>&amp;\geq-D_{KL}[q_\phi(z|x)\parallel p(z)]+\mathbb{E}<em>q[\log p_\theta(x|z)]<br>\end{align}<br>$$<br>$\log p_\theta(x)$与ELBO取等的条件是$D</em>{KL}[q_\phi(z|x)\parallel p(z)]$，表明变分分布完全匹配了真实的后验分布。但在实际应用中，真实的后验分布可能会非常复杂，而我们的变分分布通常是一个确定的较为简单的分布，如高斯分布。这样变分分布可能很难对真实后验分布得到一个很好的拟合。</p><p>一个解决方案是使用标准化流（Normalizing Flows）。标准化流是从一个相对简单的分布出发，执行一系列可逆的映射，将原始简单的分布转化为一个复杂的分布。</p><p>首先考虑一个光滑的、可逆的映射$f:\mathbb{R}^d\mapsto \mathbb{R}^d$，记$g=f^{-1}$，那么$g\circ f(\mathbf{z})=\mathbf{z}$。令$\mathbf{z}^\prime=f(\mathbf{z})$，那么$\mathbf{z}^\prime$的分布为：<br>$$<br>q(\mathbf{z}^\prime)=q(\mathbf{z})\left|\text{det}\frac{\partial f^{-1}}{\partial \mathbf{z}^\prime}\right|=q(z)\left|\text{det}\frac{\partial f}{\partial \mathbf{z}}\right|^{-1}<br>$$<br>式中$q(\mathbf{z}^\prime)=q(z)\left|\text{det}\frac{\partial f}{\partial \mathbf{z}}\right|^{-1}$说明了$\mathbf{z}^\prime$的分布等于$\mathbf{z}$的分布乘上$f$的Jacobian矩阵的行列式的倒数。那么对于映射多次的情况：<br>$$<br>\mathbf{z}<em>K=f_K\circ\cdots\circ f_2\circ f_1(\mathbf{z}_0)<br>$$<br>$\mathbf{z}_K$的分布可以通过链式计算得到：<br>$$<br>\ln q_K(\mathbf{z}_K)=\ln q_0(\mathbf{z}_0)-\sum\limits</em>{k=1}^K\ln\left|\text{det}\frac{\partial f_k}{\partial \mathbf{z}_{k-1}}\right|<br>$$</p><h3 id="Planar-Flows"><a href="#Planar-Flows" class="headerlink" title="Planar Flows"></a>Planar Flows</h3><p>考虑一个变换族：<br>$$<br>f(\mathbf{z})=\mathbf{z}+\mathbf{u}h(\mathbf{w}^\top\mathbf{z}+b)<br>$$<br>其中$\lambda={\mathbf{w}\in \mathbb{R}^d,\mathbf{u}\in\mathbb{R}^d,b\in\mathbb{R}}$为参数集合，$h(\cdot)$为元素级的非线性函数（如各种激活函数）。令$\psi(\mathbf{z})=h^\prime(\mathbf{w}^\top\mathbf{z}+b)\mathbf{w}$，则$f$的Jacobian矩阵行列式绝对值等于：<br>$$<br>\left|\text{det}\frac{\partial f}{\partial \mathbf{z}}\right|=\left|\text{det}(\mathbf{I}+\mathbf{u}\psi(\mathbf{z})^\top)\right|=\left|1+\mathbf{u}^\top\psi(\mathbf{z})\right|<br>$$<br>但是$f$并不保证总是可逆的，如$h(x)=\tanh(x)$时，$f$可逆的条件是$\mathbf{w}^\top \mathbf{u}\geq-1$。</p><p>下面讨论如何保证可逆的条件。考虑将$\mathbf{z}$分解为$\mathbf{z}=\mathbf{z}_\bot+\mathbf{z}_\parallel$，其中$\mathbf{z}_\bot$与$\mathbf{w}$正交，$\mathbf{z}_\parallel$与$\mathbf{w}$平行，那么：<br>$$<br>f(z)=\mathbf{z}_\bot+\mathbf{z}_\parallel+\mathbf{u}h(\mathbf{w}^\top \mathbf{z}_\parallel +b)<br>$$<br>实际上得到$\mathbf{z}_\parallel$之后可以很容易的得到$\mathbf{z}_\bot$，令$\mathbf{y}=f(\mathbf{z})$，有：<br>$$<br>\mathbf{z}_\bot=\mathbf{y}-\mathbf{z}_\parallel-\mathbf{u}h(\mathbf{w}^\top\mathbf{z}_\parallel+b)<br>$$<br>而$\mathbf{z}_\parallel$与$\mathbf{w}$平行，易知$\mathbf{z}_\parallel=\alpha\frac{\mathbf{w}}{\parallel\mathbf{w}\parallel^2}$，其中$\alpha\in\mathbb{R}$。</p><p>对式(16)两边同时乘以$\mathbf{w}^\top$可得：<br>$$<br>\mathbf{w}^\top f(\mathbf{z})=\alpha+\mathbf{w}^\top\mathbf{u} h(\alpha+b)<br>$$<br>当$\alpha+\mathbf{w}^\top\mathbf{u} h(\alpha+b)$对于$\alpha$是非递减函数的时候，$f$是可逆的。因为$\alpha+\mathbf{w}^\top\mathbf{u} h(\alpha+b)$是非递减函数时有$1+\mathbf{w}^\top\mathbf{u}h^\prime(\alpha+b)\geq 0\equiv \mathbf{w}^\top \mathbf{u}\geq -\frac{1}{h^\prime(\alpha + b)}$，而$0\leq h^\prime(\alpha + b) \leq 1$（$\tanh$函数的性质），所以总是有$\mathbf{w}^\top \mathbf{u}\geq-1$。</p><p>对于任意一个$\mathbf{u}$，我们可以通过特定的方式构造一个$\hat{\mathbf{u}}$使得$\mathbf{w}^\top\hat{\mathbf{u}}&gt;-1$，即令$\hat{\mathbf{u}}(\mathbf{w},\mathbf{u})=\mathbf{u}+[m(\mathbf{w}^\top\mathbf{u})-(\mathbf{w}^\top\mathbf{u})]\frac{\mathbf{w}}{\parallel\mathbf{w}\parallel^2}$，其中$m(x)=-1+\log(1+e^x)$。</p><p><img src="https://i.loli.net/2020/06/25/uPyplhWBazROEw4.png" srcset="/img/loading.gif" alt=""></p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h2><p>本文针对的是多变量时间序列$x={x_1,x_2,\cdots,x_N}\in R^{M\times N}$，$N$为时间长度，其中某一时刻的观测值$x_t\in R^M$为一个$M$维的向量。作者使用$x_{t-T:t}\in R^{M\times(T+1)}$来表示$t-T$到$t$之间的时间序列。</p><p><img src="https://i.loli.net/2020/06/25/4eHhs82uOzI5tG3.png" srcset="/img/loading.gif" alt=""></p><h2 id="Overall-Structure"><a href="#Overall-Structure" class="headerlink" title="Overall Structure"></a>Overall Structure</h2><p>算法的总体框架如下图所示：</p><p><img src="https://i.loli.net/2020/06/25/wd8maAoVb3Fk9vP.png" srcset="/img/loading.gif" alt=""></p><p>预处理模块主要是对数据进行标准化以及窗口切分。训练模块则根据输入的数据对正常模式进行捕捉，输出异常分数。在线检测模块则会定期执行。</p><h2 id="Network-Architecture"><a href="#Network-Architecture" class="headerlink" title="Network Architecture"></a>Network Architecture</h2><p>模型的总体结构如下图所示：</p><p><img src="https://i.loli.net/2020/06/25/Lp7D81EvxVsywXQ.png" srcset="/img/loading.gif" alt=""></p><p>在qnet中，首先GRU被用来建模样本的时间依赖关系，之后VAE将样本$\mathbf{x}$映射到隐空间$\mathbf{z}$。文中使用了Linear Gaussian State Space Model来建模隐变量之间的时间依赖关系。除此之外，作者还使用了Planar Normalizing Flow来将隐变量映射到复杂的非高斯分布。在pnet中，隐变量$\mathbf{z}<em>{t-T:t}$被用来重建$\mathbf{x}</em>{t-T:t}$，直观上来说，对样本的好的隐变量表示可以带来更好的重构效果。</p><p>从细节上来说，在时间$t$，qnet的输入为$\mathbf{x}<em>t$和$\mathbf{e}</em>{t-1}$，两者经过GRU Cell之后会产生$t$时间的$\mathbf{e_t}$。$\mathbf{e}<em>t$是GRU捕捉时间依赖性的关键，可以认为它包含了$\mathbf{x}</em>{1:t}$的信息。之后$\mathbf{e}<em>t$会和$\mathbf{z}</em>{t-1}$进行拼接，进入标准的VAE变分网络结构，通过网络输出的参数$\mu_{z_t},\sigma_{z_t}$采样得到隐变量$\mathbf{z}_t^0$，此时隐变量可以说捕捉了时间依赖性。</p><p>网络中涉及到的公式如下所示：</p><p>$$<br>\begin{align}<br>e_t&amp;=(1-c_t^e)\circ\text{tanh}(w^ex_t+u^e(r_t^e\circ e_{t-1})+b^e)+c_t^e\circ e_{t-1}\<br>\mu_{z_t}&amp;=w^{\mu_z}h^\phi([z_{t-1},e_t])+b^{\mu_z}\<br>\sigma_{z_t}&amp;=\text{softplus}(w^{\sigma_z}h^\phi([z_{t-1},e_t])+b^{\sigma_z})+\epsilon^{\sigma_z}<br>\end{align}<br>$$</p><p>其中$r_t^e=\text{sigmoid}(\mathbf{w}^{r^e}\mathbf{x}<em>t+\mathbf{u}^{r^e}\mathbf{e}</em>{t-1}+b^{r^e})$是GRU中的重置门，$c_t^e=\text{sigmoid}(\mathbf{w}^{c^e}\mathbf{x}<em>t+\mathbf{u}^{c^e}\mathbf{e}</em>{t-1}+b^{c^e})$是GRU中的更新门。</p><p>此时$\mathbf{z}_t^0$服从高斯分布，为了拟合复杂的后验分布，我们使用Planar Normalizing Flow来对$\mathbf{z}_t^0$进行变换，最后得到经$K$次变换后的随机变量$\mathbf{z}_t^K$。</p><p>在时间$t$，pnet试图通过$\mathbf{z}<em>t^K$来重构$\mathbf{x}_t$。首先$\mathbf{z}$空间中的变量会根据Linear Gaussian State Space Model来进行“连接“，公式为$\mathbf{z}_t=\mathbf{O}_\theta(\mathbf{T}_\theta\mathbf{z}</em>{t-1}+\mathbf{v}<em>t)+\boldsymbol{\epsilon}_t$，其中$\mathbf{O}_\theta$和$\mathbf{T}_\theta$为状态转移矩阵，$\mathbf{v}_t$和$\boldsymbol{\epsilon}_t$为随机噪声。之后$\mathbf{z}_t$和$\mathbf{d}</em>{t-1}$会作为GRU的输入，产生$\mathbf{d}<em>t$。之后$\mathbf{d}_t$会经过标准VAE中的生成网络，通过网络输出的高斯分布参数$\mu</em>{x_t},\sigma_{x_t}$采样得到重构后的样本$\mathbf{x}^\prime_t$。pnet中涉及到的公式如下所示：<br>$$<br>\begin{align}<br>d_t&amp;=(1-c_t^d)\circ\text{tanh}(w^dz_t+u^d(r_t^d\circ d_{t-1})+b^d)+c_t^d\circ d_{t-1}\<br>\mu_{x_t}&amp;=w^{\mu_x}h^\theta(d_t)+b^{\mu_x}\<br>\sigma_{x_t}&amp;=\text{softplus}(w^{\sigma_x}h^\theta(d_t)+b^{\sigma_x})+\epsilon^{\sigma_x}<br>\end{align}<br>$$</p><p>其中$r_t^d=\text{sigmoid}(\mathbf{w}^{r^d}\mathbf{x}<em>t+\mathbf{u}^{r^d}\mathbf{d}</em>{t-1}+b^{r^d})$是GRU中的重置门，$c_t^d=\text{sigmoid}(\mathbf{w}^{c^d}\mathbf{x}<em>t+\mathbf{u}^{c^d}\mathbf{d}</em>{t-1}+b^{c^d})$是GRU中的更新门。</p><h2 id="Offline-Model-Training"><a href="#Offline-Model-Training" class="headerlink" title="Offline Model Training"></a>Offline Model Training</h2><p>和传统VAE类似，模型的训练可以通过优化ELBO来完成。记长度为$T+1$的输入序列为$\mathbf{x}<em>{t-T:t}$，隐空间变量采样次数为$L$，第$l$个隐空间变量为$\mathbf{l}^{(l)}</em>{t-T:t}$，损失函数可以写成如下形式：</p><p>$$<br>\tilde{\mathcal{L}}(\mathbf{x}<em>{t-T:t})\approx\frac{1}{L}\sum</em>{t=1}^L[\log(p_\theta(\mathbf{x}<em>{t-T:t}|\mathbf{z}</em>{t-T:t}^{(l)}))+\log(p_\theta(\mathbf{z}<em>{t-T:t}^{(l)}))-\log(q_\phi(\mathbf{z}</em>{t-T:t}^{(l)}|\mathbf{x}_{t-T:t}))]<br>$$</p><p>第一项$\log(p_\theta(\mathbf{x}<em>{t-T:t}|\mathbf{z}</em>{t-T:t}^{(l)}))$可以看作是重构误差；第二项$\log(p_\theta(\mathbf{z}<em>{t-T:t}))=\sum</em>{i=t-T}^t \log(p_\theta(\mathbf{z}<em>i|\mathbf{z}</em>{i-1}))$通过Linear Gaussian State Space Model计算；第三项$-\log(q_\phi(\mathbf{z}<em>{t-T:t}|\mathbf{x}</em>{t-T:t}))=-\sum_{i=t-T}^t\log(q_\phi(\mathbf{z}<em>i|\mathbf{z}</em>{i-1},\mathbf{x}_{t-T:i}))$为隐变量$\mathbf{z}$后验分布的估计，同时$\mathbf{z}_i$是经Planar Normalizing Flow转换过的。</p><h2 id="Online-Detection"><a href="#Online-Detection" class="headerlink" title="Online Detection"></a>Online Detection</h2><p>在训练好模型之后，就可以进行异常检测了。在时间$t$，我们通过根据长度为$T+1$的序列$\mathbf{x}<em>{t-T:t}$来重构$\mathbf{x}_t$，并根据重构概率$\log(p_\theta(\mathbf{x}_t|\mathbf{z}</em>{t-T:t}))$来判定异常。定义$\mathbf{x}<em>t$对应的异常分数$S_t=\log(p_\theta(\mathbf{x}_t|\mathbf{z}</em>{t-T:t}))$，高异常分数代表样本$\mathbf{x}_t$能够以大概率重构（因为模型是用正常样本训练，可以认为模型建模的是正常样本的分布，重构概率高就代表符合正常分布）。给定阈值之后便可根据异常分数来进行异常的判定。</p><h2 id="Automatic-Threshold-Selection"><a href="#Automatic-Threshold-Selection" class="headerlink" title="Automatic Threshold Selection"></a>Automatic Threshold Selection</h2><p>在异常检测阶段，需要根据设定的阈值和每个样本的异常分数来判断该样本是否为异常，所以阈值的选择十分重要。文中用到了一种根据<strong>Extreme Value Theory</strong>自动选择阈值的算法。对于一个分布，其中的极端事件往往位于分布的末尾，而Extreme Value Theory第一定理给出不管原始分布如何，这些极端事件的分布服从一个带参的分布族。因此，可以在对数据分布未知的情况下估计极端事件的分布。</p><p>除了Extreme Value Theory第一定理之外，Extreme Value Theory第二定理给出随机变量大于特定阈值$t$的分布可以用Generalized Pareto Distribution来描述。作者使用了基于Extreme Value Theory第二定理的Peaks-Over-Threshold算法来进行阈值的选择。因为Extreme Value Theory第二定理给出随机变量大于特定阈值$t$的分布，而在本文的场景中我们需要刻画的异常点的分布应该是小于一个给定阈值的分布，所以需要修改一下公式。</p><p>对于给定的数据，模型会给出对应的异常分数序列${S_1,S_2,\cdots,S_{N^\prime}}$，给定预先设定的阈值$th$，$S_i$极端部分（即小于$th$的部分）的分布符合Generalized Pareto Distribution，公式如下：<br>$$<br>\bar{F}(s)=P(th-S&gt;s|S&lt;th)\sim(1+\frac{\gamma s}{\beta})^{-\frac{1}{\gamma}}<br>$$</p><p>其中$\gamma$和$\beta$为分布的形状参数，本文使用极大似然估计来对参数进行估计。设参数的估计值分别为$\hat{\gamma}$和$\hat{\beta}$，最终的阈值$th_F$由拟合得到的分布的分位数确定：</p><p>$$<br>th_F\simeq th-\frac{\hat{\beta}}{\hat{\gamma}}((\frac{qN^\prime}{N^\prime_{th}})^{-\hat{\gamma}}-1)<br>$$</p><p>其中$q$为期望$S&lt;th$的概率，$N^\prime$为观测值的数量，$N^\prime_{th}$为$S_i&lt;th$的个数。</p><h2 id="Anomaly-Interpretation"><a href="#Anomaly-Interpretation" class="headerlink" title="Anomaly Interpretation"></a>Anomaly Interpretation</h2><p>$$<br>\log(p_\theta(\mathbf{x}<em>t|\mathbf{z}</em>{t-T:t}))=\sum_{i=1}^M\log(p_\theta(x_t^i|\mathbf{z}_{t-T:t}))<br>$$</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="Datasets-and-Metrics"><a href="#Datasets-and-Metrics" class="headerlink" title="Datasets and Metrics"></a>Datasets and Metrics</h2><h2 id="Overall-Performance"><a href="#Overall-Performance" class="headerlink" title="Overall Performance"></a>Overall Performance</h2><p><img src="https://i.loli.net/2020/06/25/yYLiWfXBDQklbPU.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/HlORKBEu7ij6Vor.png" srcset="/img/loading.gif" alt=""></p><h2 id="Effects-of-Major-Techniques"><a href="#Effects-of-Major-Techniques" class="headerlink" title="Effects of Major Techniques"></a>Effects of Major Techniques</h2><p><img src="https://i.loli.net/2020/06/25/eKXGJ9ZlSmq8r4Q.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/dlibhyOBXNmPrkw.png" srcset="/img/loading.gif" alt=""></p><h2 id="Visualization-on-Z-Space-Representations"><a href="#Visualization-on-Z-Space-Representations" class="headerlink" title="Visualization on Z-Space Representations"></a>Visualization on Z-Space Representations</h2><p><img src="https://i.loli.net/2020/06/25/MQXv5pZAejgVJ9s.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/jCkovq2lWrP6KXy.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/25/JSZuUkzNyci41DA.png" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>VAE</tag>
      
      <tag>RNN</tag>
      
      <tag>Flow-based Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GAIN: Missing Data Imputation using Generative Adversarial Nets</title>
    <link href="/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"/>
    <url>/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/</url>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器$G$从隐空间$Z$生成完整的样本，而判别器$D$则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。</p><p><a href="https://arxiv.org/abs/1806.02920" target="_blank" rel="noopener">原文</a></p><h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><p>考虑一个$d$维的空间$\mathcal{X}=\mathcal{X}_1\times \cdots\times \mathcal{X}_d$，设$\mathbf{X}=(X_1,\cdots,X_d)$维空间$\mathcal{X}$上的随机向量（即理想的完整的时间序列），记其分布为$P(\mathbf{X})$。设$\mathbf{M}=(M_1,\cdots,M_d)$为Mask向量表示$\mathbf{X}$中被观察到的部分。（即标识时间序列哪些部分有缺失），取值为${0,1}^d$。</p><p>对于每一个$i\in{1,\cdots,d}$，我们定义一个新空间$\tilde{\mathcal{X}}=\mathcal{X}\cup{<em>}$，其中$</em>$表示不属于任意$\mathcal{X}<em>i$的一个点。令$\tilde{\mathcal{X}}=\tilde{\mathcal{X}_1}\times\cdots\times\tilde{\mathcal{X}_d}$，同时定义一个新的随机变量（即我们观测到的含有缺失值的时间序列）$\tilde{\mathbf{X}}=(\tilde{X}_1,\cdots,\tilde{X}_d)\in \tilde{\mathcal{X}}$：<br>$$<br>\tilde{X}_i=\begin{cases}X_i,&amp;\text{if } M_i=1\*,&amp;\text{otherwise}\end{cases}<br>$$<br>假设数据集的形式为$\mathcal{D}={(\tilde{x}^i,m^i)}^n</em>{i=1}$，我们的任务是从$P(\mathbf{X}|\tilde{\mathbf{X}}=\tilde{x}^i)$上采样来对缺失值进行填充。</p><h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><p>模型的架构如下图所示：</p><img src="https://i.loli.net/2020/06/25/wCK3J8MoTASrj9Y.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><p>生成器的输入有三项：$\tilde{\mathbf{X}}$，$\mathbf{M}$和随机噪声$\mathbf{Z}$，输出设为$\bar{\mathbf{X}}$。设生成器为映射$G: \tilde{\mathcal{X}}\times{0,1}^d\times[0,1]^d\rightarrow \mathcal{X}$，而$\mathbf{Z}$为$d$维的高斯噪声。生成器的输出和填充后的时间序列定义为：<br>$$<br>\begin{align}<br>\bar{\mathbf{X}}&amp;=G(\tilde{\mathbf{X}},\mathbf{M},(1-\mathbf{M})\odot\mathbf{Z})\<br>\hat{\mathbf{X}}&amp;=\mathbf{M}\odot\tilde{\mathbf{X}}+(1-\mathbf{M})\odot\bar{\mathbf{X}}<br>\end{align}<br>$$<br>$\bar{\mathbf{X}}$即为生成器的直接输出，因为其实有些部分没有缺失，生成器还是会为每个部分输出值。</p><p>$\hat{\mathbf{X}}$为填充后的时间序列，对于缺失的部分采用生成器的输出进行填充。</p><h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><p>和原始的GAN不同的是，我们不需要判断整个样本是真实的或者是生成的，而是需要判断样本的那些部分是真实的或者是生成的，所以判别器为映射$D: \mathcal{X}\rightarrow[0,1]^d$。判别器的具体目标函数将在后面讨论。</p><h3 id="Hint"><a href="#Hint" class="headerlink" title="Hint"></a>Hint</h3><p>Hint是一种提示机值，是一个和$\mathbf{X}$相同维度的随机变量$\mathbf{H}$，其分布依赖于$\mathbf{M}$。$\mathbf{H}$是由用户自己定义的，相当于一种不完整的$\mathbf{M}$，用来作为判别器的额外输入。</p><h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>我们训练判别器最大化正确预测$\mathbf{M}$的概率，而生成器最小化判别器正确预测$\mathbf{M}$的概率，目标函数如下：<br>$$<br>\begin{align}<br>V(D,G)=&amp;\mathbb{E}<em>{\hat{X},M,H}[\mathbf{M}^T\log D(\hat{\mathbf{X}},\mathbf{H})\&amp;+(1-\mathbf{M})^T\log(1-D(\hat{\mathbf{X}},\mathbf{H}))]<br>\end{align}<br>$$<br>按照标准的GAN可以将优化函数写成以下的形式：<br>$$<br>\min_G\max_D V(D,G)<br>$$<br>在这里判别器的任务可以看作是一个二分类，而目标函数就是二值交叉熵的定义，因此可以写为：<br>$$<br>\mathcal{L}(a,b)=\sum\limits</em>{i=1}^d[a_i\log(b_i)+(1-a_i)\log(1-b_i)]<br>$$<br>$\mathbf{M}$可以看作Ground Truth，记$\hat{\mathbf{M}}=D(\hat{\mathbf{X},\mathbf{H}})$，即判别器输出的预测，因此优化函数可以简记为：<br>$$<br>\min_G\max_D\mathbb{E}[\mathcal{L}(\mathbf{M},\hat{\mathbf{M}})]<br>$$</p><h2 id="GAIN-Algorithm"><a href="#GAIN-Algorithm" class="headerlink" title="GAIN Algorithm"></a>GAIN Algorithm</h2><p>下面讨论GAIN算法的训练流程。</p><p>本文通过理论讨论，给出了生成Hint Vector的一个方法，首先定义随机变量$\mathbf{B}=(B_1,\cdots,B_d)\in{0,1}^d$，$\mathbf{B}$通过从${1,\cdots,d}$随机均匀采样一个$k$，然后由下列公式得到：<br>$$<br>B_j=\begin{cases}1, &amp;\text{if }j\neq k\0, &amp;\text{if }j=k\end{cases}<br>$$<br>定义空间$\mathcal{H}={0,0.5,1}^d$，Hint Vector为$\mathbf{H}=\mathbf{B}\odot\mathbf{M}+0.5(1-\mathbf{B})\in\mathcal{H}$。</p><p>判别器的训练过程如下：固定生成器$G$，对一个大小为$k_D$的mini-batch，独立同分布采样$k_D$个$z$和$b$，用来计算$\mathbf{Z}$和$\mathbf{B}$。判别器的损失函数定义如下：<br>$$<br>\mathcal{L}<em>D(m,\hat{m},b)=\sum\limits</em>{i:b_i=0}[m_i\log(\hat{m}<em>i)+(1-m_i)\log(1-\hat{m}_i)]<br>$$<br>判别器的优化函数为：<br>$$<br>\min_D-\sum\limits</em>{j=1}^{k_D}\mathcal{L}_D(m(j),\hat{m}(j),b(j))<br>$$<br>其中$\hat{m}(j)=D(\hat{x}(j),m(j))$。</p><p>在优化了判别器之后，需要优化生成器，对一个大小为$k_G$的mini-batch，生成器的损失函数包含两个部分，一个是在缺失部分的损失：</p><p>$$<br>\mathcal{L}<em>G(m,\hat{m},b)=-\sum\limits</em>{i:b_i=0}(1-m_i)\log(\hat{m}<em>i)<br>$$<br>一个是未缺失部分的损失：<br>$$<br>\mathcal{L}_M(x,x^\prime)=\sum\limits</em>{i=1}^d m_iL_M(x_i,x_i^\prime)<br>$$<br>其中：<br>$$<br>L_M(x_i,x_i^\prime)=\begin{cases}(x_i^\prime-x_i)^2, &amp;\text{if }x_i\text{ is continuours},\-x_i\log(x_i^\prime), &amp;\text{if }x_i\text{ is binary}.\end{cases}<br>$$<br>最终的优化函数为：<br>$$<br>\min_G\sum\limits_{j=1}^{k_G}\mathcal{L}_G(m(j),\hat{m}(j),b(j))+\alpha\mathcal{L}_M(\tilde{x}(j),\hat{x}(j))<br>$$<br>算法流程如下：</p><img src="https://i.loli.net/2020/06/25/znABi6x9mJuvDOX.png" srcset="/img/loading.gif" style="zoom:67%;" /><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>下表为在5个不同数据集上实验，与其他5种方法对比的结果：</p><img src="https://i.loli.net/2020/06/25/EenX2YO8aDxQAk3.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>上图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例、样本数量、特征维度下的对比曲线图。</p><p>下表为使用不同模型对时间序列进行填充之后，使用逻辑回归进行回归任务的性能：</p><img src="https://i.loli.net/2020/06/25/PzeWKdGu4wADshV.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>下图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例下的AUROC曲线图：</p><img src="https://i.loli.net/2020/06/25/IKtoTj8xgG1yJDk.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>下表展示的是作者对时间序列填充算法保持特征-标签关系的能力。作者分别用完整的数据和填充后的数据用逻辑回归模型进行训练，将两者的权重求绝对值和均方根的结果。</p><img src="https://i.loli.net/2020/06/25/uy2jPcnbtSrC6vI.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Time Series Imputation</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series</title>
    <link href="/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/"/>
    <url>/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这篇文章提出了一个基于GAN的时间序列异常检测模型。</p><p><a href="https://arxiv.org/abs/1809.04758" target="_blank" rel="noopener">原文</a></p><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ol><li>提出了基于GAN的时间序列无监督异常检测模型</li><li>我们使用基于LSTM的GAN来对多变量时间序列进行建模</li><li>结合使用了Residual Loss和Discrimination Loss来进行异常的判断</li></ol><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a>Generative Adversarial Networks</h3><h4 id="GANs-In-a-Nutshell-an-extremely-simple-explanation"><a href="#GANs-In-a-Nutshell-an-extremely-simple-explanation" class="headerlink" title="GANs In a Nutshell, an extremely simple explanation"></a>GANs In a Nutshell, an extremely simple explanation</h4><ul><li>我们想要从一个复杂的、高维的数据分布$p_r(x)$上采样得到我们想要的数据点，然而$p_r(x)$无法直接求得</li><li>代替方法：从一个简单的、已知的分布$p_z(z)$上采样，然后学习一个Transformation $G(z): z\rightarrow x$来将$z$映射到$x$</li></ul><img src="https://i.loli.net/2020/06/25/frIYtuao9mexQUT.png" srcset="/img/loading.gif" style="zoom:67%;" /><h4 id="Training-Two-player-Game"><a href="#Training-Two-player-Game" class="headerlink" title="Training: Two-player Game"></a>Training: Two-player Game</h4><ul><li>*<em>Generator Network: *</em> 从随机分布$p_z(z)$采样$z$，通过映射生成样本$x$，这个生成的样本要尽量“真实”。怎么“真实”？优化生成器参数$\theta_G$最大化判别器对生成样本的评分即可</li><li>*<em>Discriminator Network: *</em>接受一个样本$x$，判断其是生成的样本还是真实的样本。在训练阶段，我们是知道一个样本$x$到底是生成的还是真实的，所以优化判别器参数$\theta_D$最小化判别器对生成样本的评分，最大化对真实样本的评分（即最大化分辨真实样本的能力）</li></ul><img src="https://i.loli.net/2020/06/25/ECP2Dkpq6FrSoef.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>形式化的来讲，优化函数如下：</p><p>$$\min\limits_{\theta_G}\max\limits_{\theta_D}V(G,D)=\mathbb{E}<em>{x\sim p</em>{data}(x)\log(\underbrace{D_{\theta{D}}(x)}<em>{判别器对真实样本的评分})}+\mathbb{E}</em>{z\sim p_z(z)}\log(1-\underbrace{D_{\theta_d}(G_{\theta_G}(z))}_{判别器对生成样本的评分})$$</p><p>训练过程如下：</p><img src="https://i.loli.net/2020/06/25/57N4yUrfoS1cBWd.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Long-Short-Time-Memory-Networks"><a href="#Long-Short-Time-Memory-Networks" class="headerlink" title="Long Short Time Memory Networks"></a>Long Short Time Memory Networks</h3><h4 id="Vanilla-Recurrent-Neural-Networks"><a href="#Vanilla-Recurrent-Neural-Networks" class="headerlink" title="Vanilla Recurrent Neural Networks"></a>Vanilla Recurrent Neural Networks</h4><p>普通的神经网络：</p><img src="https://i.loli.net/2020/06/25/U5rxdYR4jKoqQOX.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>概括的来讲，可以涵盖为一个公式$\hat{\mathbf{y}}=f(\mathbf{x})$。对于一个样本$\mathbf{x}$，通过多层神经网络映射，输出$\mathbf{y}$。</p><p>对于RNN，我们处理的是序列数据，也就是说所有样本之间并不是相互独立的。对于一个序列中的一个样本$x_t\in{x_1,x_2,\cdots,x_n}$，将其输入到神经网络的时候，为了建模$x_t$之前的子序列对$x_t$的影响关系，需要将这个子序列的信息也输入到神经网络中，怎么做呢？为每一个样本点保存一个State。即定义$h_t=g(\hat{y_t})=g(f(x_t))$，对于当前样本点，$\hat{y_t}=f(x_t,h_{t-1})$。也就是说神经网络的输入不仅包含了当前样本点的特征，也包含了上一个样本点的“状态”(上一个样本点的“状态”又隐含了上上个样本点的“状态”…)，就像是为网络加上了短期记忆。</p><img src="https://i.loli.net/2020/06/25/cxBk6SQTydsOVYt.png" srcset="/img/loading.gif" style="zoom: 67%;" /><img src="https://i.loli.net/2020/06/25/ODKWYBI83tJXurM.png" srcset="/img/loading.gif" style="zoom: 33%;" /><img src="https://i.loli.net/2020/06/25/jq1LAytRKCub3kX.png" srcset="/img/loading.gif" style="zoom:33%;" /><h4 id="Gradient-Flow-of-Vanilla-RNN"><a href="#Gradient-Flow-of-Vanilla-RNN" class="headerlink" title="Gradient Flow of Vanilla RNN"></a>Gradient Flow of Vanilla RNN</h4><p>下面来进行一些形式化的定义，假设在时刻$t$网络输入特征为$x_t$，输出隐含状态为$h_{t}$，其不仅和当前输入$x_t$有关，还和上一个隐含状态$h_{t-1}$有关：</p><ul><li>当前时刻总的净输入$z_t=Uh_{t-1}+Wx_t+b$</li><li>当前时刻输出隐含状态$h_t=f(z_t)$</li><li>当前时刻输出$\hat{y}_t=Vh_t$</li></ul><p>RNN的梯度更新公式(推导过程比较复杂)：</p><p>$$\frac{\partial{\mathcal{L}}}{\partial U}=\sum\limits_{t=1}^T\sum\limits_{k=1}^t \delta_{t,k}\mathbf{h}_{k-1}^T$$</p><p>$$\frac{\partial{\mathcal{L}}}{\partial{W}}=\sum\limits_{t=1}^T\sum\limits_{k=1}^t \delta_{t,k}x_k^T$$</p><p>$$\frac{\partial\mathcal{L}}{\partial{b}}=\sum\limits_{t=1}^T\sum\limits_{k=1}^t\delta_{t,k}$$</p><p>其中$\delta_{t,k}=\frac{\partial{\mathcal{L}}}{\partial{z_k}}=\text{diag}(f^\prime(z_k))U^T\delta_{t,k+1}$定义为第$t$时刻的损失对第$k$时刻隐藏神经层的净输入$z_k$的导数，且$z_k=Uh_{k-1}+Wx_k+b,1\leq k&lt;t$。</p><p>RNN的梯度流向如下图红箭头所示：</p><img src="https://i.loli.net/2020/06/25/F5xvo9kCiNl8ehZ.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>RNN会遇到梯度消失和梯度爆炸的问题。根据前面的公式，$\delta_{t,k}$实际上是递归定义的，展开得到：</p><p>$$\delta_{t,k}=\prod\limits_{\tau=k}^{t-1}(\text{diag}(f^\prime(z_\tau))U^T)\delta_{t,t}$$</p><p>如果定义$\gamma\cong\parallel\text{diag}(f^\prime(z_\tau))U^T\parallel$，那么$\delta_{t,k}\cong\gamma^{t-k}\delta_{t,t}$。在$t-k$很大时，$\gamma&lt;1$会导致梯度消失，$\gamma&gt;1$时会导致梯度爆炸。</p><img src="https://i.loli.net/2020/06/25/RGW4oVtQ7KEFUCA.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/i4O9kJQpnZ5GYeq.png" srcset="/img/loading.gif" style="zoom:50%;" /><h4 id="Long-Short-Time-Memory"><a href="#Long-Short-Time-Memory" class="headerlink" title="Long Short Time Memory"></a>Long Short Time Memory</h4><p>LSTM是一种解决RNN梯度消失问题的改进版本：</p><img src="https://i.loli.net/2020/06/25/B4NXzb6fSdgGowL.png" srcset="/img/loading.gif" style="zoom:50%;" /><p>在LSTM中，维护了两个State，$c_t$和$h_t$。其中$c_t$由遗忘门$f$与上一个$c_{t-1}$相乘(代表继承上一个Cell的信息并加以一定程度的遗忘)，加上输出门$i$与Gate Gate $g$相乘(Gate Gate代表当前的候选状态，输出门$i$控制当前候选状态有多少信息需要保存)。最后，输出门$o$控制当前时刻的Cell State $c_t$有多少信息需要输出给外部状态$h_t$。</p><p>三个门的计算方式为： </p><p>$$i_t=\sigma(W_ix_t+U_ih_{t-1}+b_i)$$</p><p>$$f_t=\sigma(W_fx_t+U_fh_{t-1}+b_f)$$</p><p>$$o_t=\sigma(W_ox_t+U_oh_{t-1}+b_o)$$</p><img src="https://i.loli.net/2020/06/25/PXQMb9vih1yEKrf.png" srcset="/img/loading.gif" style="zoom:50%;" /><img src="https://i.loli.net/2020/06/25/1zZQqlI6r9Yjp47.png" srcset="/img/loading.gif" style="zoom:50%;" /><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>总体框架图如Fig 1所示：</p><img src="https://i.loli.net/2020/06/25/scEA9Ou1Yi7nThG.png" srcset="/img/loading.gif" style="zoom: 50%;" /><h3 id="GAN-with-LSTM-RNN"><a href="#GAN-with-LSTM-RNN" class="headerlink" title="GAN with LSTM-RNN"></a>GAN with LSTM-RNN</h3><p>网络结构上生成器和判别器都是LSTM，优化函数和普通GAN一样：</p><p>$$\min\limits_G\max\limits_D V(D,G)=\mathbb{E}<em>{x\sim p</em>{data}(x)}[\log D(x)]+\mathbb{E}_{z\sim p_z(z)}[\log (1-D(G(z)))]$$</p><h3 id="GAN-based-Anomaly-Score"><a href="#GAN-based-Anomaly-Score" class="headerlink" title="GAN-based Anomaly Score"></a>GAN-based Anomaly Score</h3><p>在测试阶段，需要使用梯度优化寻找一个使得$G_{rnn}(z)$最接近$X^{test}$的$z^k$：</p><p>$$\min\limits_{Z^k}Error(X^{test},G_{rnn}(Z^k))=1-Similarity(X^{test},G_{rnn}(Z^k))$$</p><p>本文定义了两种Anomaly Score，一种是Residual Loss：</p><p>$$Res(X^{test}<em>t)=\sum\limits</em>{i=1}^n|x^{test,i}<em>t-G</em>{rnn}(Z^{k,i}_t)|$$</p><p>一种是Discrimination Loss，即判别器的输出$D_{rnn}(x_t^{test})$。</p><p>总的Anomaly Score：</p><p>$$S^{test}<em>t=\lambda Res(X^{test}_t)+(1-\lambda)D</em>{rnn}(x^{test}_t)$$</p><h3 id="Anomaly-Detection-Framework"><a href="#Anomaly-Detection-Framework" class="headerlink" title="Anomaly Detection Framework"></a>Anomaly Detection Framework</h3><p>模型的算法流程如下：</p><img src="https://i.loli.net/2020/06/25/84ZCT1JOEru53Ue.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>由于本文是多变量时间序列预测，而且时间序列的长度有可能比较长，作者使用了滑动窗口和PCA来进行预处理。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><img src="https://i.loli.net/2020/06/25/LGsiMw6IjYUtx8T.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection</title>
    <link href="/2019/09/22/ALSR-An-adaptive-label-screening-and-relearning-approach-for-interval-oriented-anomaly-detection/"/>
    <url>/2019/09/22/ALSR-An-adaptive-label-screening-and-relearning-approach-for-interval-oriented-anomaly-detection/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>本文针对面向区间的KPI异常检测提出了Label Screening方法和Relearning Algorithm.</p><p><a href="https://www.sciencedirect.com/science/article/pii/S0957417419304282" target="_blank" rel="noopener">原文</a></p><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ol><li>提出了一种Label Screening方法来对区间内不同重要性进行过滤</li><li>提出了一种Relearning Algorithm来对FP和TP进行Relearning，在不减少Recall的条件下增大Precision</li></ol><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Overall-Structure"><a href="#Overall-Structure" class="headerlink" title="Overall Structure"></a>Overall Structure</h3><p>算法的整体框架如下：</p><p><img src="https://i.loli.net/2020/06/24/yGMWzdgTf43qImp.png" srcset="/img/loading.gif" alt=""></p><h3 id="Label-Screening-Model"><a href="#Label-Screening-Model" class="headerlink" title="Label Screening Model"></a>Label Screening Model</h3><p>预训练的结果被分为$TP_{po},FP_{po},TN_{po},FN_{po}$四类，$TP_{po}$和$FN_{po}$可以被细分如下：<br>$$<br>\begin{align}TP_{po}&amp;=TP_{po,withinT}+TP_{po,afterT}\&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+TP_{po,after,fnl}\end{align}<br>$$</p><p>$$<br>\begin{align}FN_{po}&amp;=FN_{po,withinT}+FN_{po,afterT}\&amp;=FN_{po,withinT,tpl}+FN_{po,,withinT,fnl}+FN_{po,afterT,tpl}+FN_{po,afterT,fnl}\end{align}<br>$$</p><p>其中下标${}<em>{withinT}$代表在异常片段第一个点$T$距离内的所有点，下标${}</em>{afterT}$代表$T$距离之后。下标${}<em>{tpl}$和${}</em>{fnl}$分别代表在异常片段中，包含和不包含$TP_{po,withinT}$的点。</p><p>以TP为例，Point-based的TP包含了在T范围之内的（即在Interval-based的标准中也会被认为是TP的点）和T范围之外的点（即在Interval-based的标准中不认为是TP的点）。而在T范围之外的点又可以细分为该异常片段是否包含$TP_{po,withinT}$的点（即该点在Interval-based的标准中不会被判定为TP，但该异常片段有其点会被判定为TP）。</p><p>类似的，$TP_{io}$和$FN_{io}$可以被分解为：<br>$$<br>\begin{align}TP_{io}&amp;=TP_{po,withinT}+TP_{po,afterT,tpl}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}\&amp;=TP_{po}+FN_{po,withinT,tpl}+FN_{po,afterT,tpl}-TP_{po,afterT,fnl}\end{align}<br>$$</p><p>$$<br>\begin{align}FN_{io}&amp;=FN_{po,withinT,fnl}+FN_{po,afterT,fnl}+TP_{po,afterT,fnl}\&amp;=FN_{po}+TP_{po,afterT,fnl}-FN_{po,withinT,tpl}-FN_{po,afterT,tpl}\end{align}<br>$$</p><p>文中对该部分的分析可以分为以下几点：</p><ol><li>在Interval-oriented的标准中，$FN_{po,tpl}$的点仍会被认为是$TP_{io}$，而$TP_{po,afterT}$（不带${}<em>{tpl}$）不会被认为是$TP</em>{io}$，所以最终$TP_{io}$由所有$TP_{po}$加上那些会被认为是$TP_{io}$的$FN_{po,tpl}$再去掉不带${}<em>{tpl}$的$TP</em>{po,afterT}$组成，即公式(6)</li><li>同时，根据公式(6)，如果$TP_{po}$变为$FN_{po,tpl}$，也不会对最终结果造成影响。但是根据公式(5)和公式(7)，$TP_{po,withinT}$变成$FN_{po,withinT,fnl}$会减小$TP_{io}$同时增大$FN_{io}$</li><li>文章指出，虽然$FN_{po,withinT,tpl}$和$FN_{po,afterT,tpl}$最后都会被认为是$TP_{io}$，但作者假设$FN_{po,withinT,tpl}$更难检测，所以应该保留，而$FN_{po,afterT,tpl}$应该削减</li><li>Label Screening方法去除了$FN_{po,afterT}$的点</li><li>Screened之后的训练集被用来训练DNN主模型，但Label Screening的预测结果也会被保留，和DNN主模型的结果进行组合</li></ol><p>算法流程如下：</p><p><img src="https://i.loli.net/2020/06/24/ZDT5fQNojsXm84q.png" srcset="/img/loading.gif" alt=""></p><h3 id="Relearning-Algorithm"><a href="#Relearning-Algorithm" class="headerlink" title="Relearning Algorithm"></a>Relearning Algorithm</h3><p>Relearning Model的输入是DNN主模型预测出来的异常，其中包括TP和FP。Relearning Model采用的是随机森林，其输入的样本通过采样得到：<br>$$<br>\begin{align}<br>\text{relearning}\space&amp;\text{training set}=\&amp; shuffle{4C\ast\text{randomof}(TP_{po})\&amp;+C\cdot\text{randomof}(FP_{po})+C\cdot\text{randomof}(TN_{po})}<br>\end{align}<br>$$<br>其中$C$为常数。TN和FP都看作是负例(正常样本)，TP看作是正例。</p><p><img src="https://i.loli.net/2020/06/24/qgvINaFu9JLfM4j.png" srcset="/img/loading.gif" alt=""></p><h3 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h3><p>对于一个滑动窗口$x_t={x_{t-w+1},\cdots,x_t}$，异常检测算法的目标是输出检测结果$y_t\in{0,1}$来表示时间$t$是否发生异常。实际上算法输出的是$p_{y_t}\in[0,1]$概率值来表示在时间$t$发生异常的概率。文中三个模型会得到三个输出：$y_{t,ls},y_{t,main},y_{t,re}$。最终结果为：<br>$$<br>y_t=y_{t,ls}\space&amp;\space y_{t,main}\space&amp; \space y_{t,re}<br>$$<br>在绘制PR曲线时，采用的公式为：<br>$$<br>\begin{align}<br>p_{y_t}(th)=&amp;(1-sig(p_{y_t,ls},th))\cdot(p_{y_t,ls})\<br>&amp;+sig(p_{y_t,ls},th)\cdot(1-sig(p_{y_t,main},th))\cdot p_{y_t,main}\<br>&amp;+sig(p_{y_t,ls},th)\cdot sig(p_{y_t,main},th)\cdot p_{y_t,re}\<br>\end{align}<br>$$</p><p>$$<br>y_t(th)=sig(p_{y_t}(th),th)<br>$$</p><p>算法流程如下：</p><p><img src="https://i.loli.net/2020/06/24/LBT59eugKEPymO8.png" srcset="/img/loading.gif" alt=""></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>清华AIOps数据集，选取了25条KPI。</p><h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><ol><li><strong>Missing Data.</strong> 去除。</li><li><strong>Standardization.</strong> Minmax Standardization，Feature Extraction使用的是Standardization后的数据。</li><li><strong>Feature Extraction.</strong> 使用了12种特征。</li></ol><table><thead><tr><th>Group</th><th>Feature Name</th></tr></thead><tbody><tr><td>Values</td><td>The original values standardized</td></tr><tr><td>Statistical Features</td><td>Mean,  Standard Deviation, Range, Difference…</td></tr><tr><td>Fitting Features</td><td>EWMA, AR</td></tr><tr><td>Wavelet Features</td><td>Db2 wavelet decomposition</td></tr></tbody></table><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="AUCPR"><a href="#AUCPR" class="headerlink" title="AUCPR"></a>AUCPR</h3><p><img src="https://i.loli.net/2020/06/24/LAqNMW1zvs8eP7X.png" srcset="/img/loading.gif" alt=""></p><p><img src="https://i.loli.net/2020/06/24/YgRwavDIn7izLPX.png" srcset="/img/loading.gif" alt=""></p><h3 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h3><p><img src="https://i.loli.net/2020/06/24/FM3BUhQXtpo7aiu.png" srcset="/img/loading.gif" alt=""></p><h2 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h2><ol><li>这篇文章的Label Screening方法实际上是在处理样本分类难易度的问题，将异常区间内容易的样本去除了</li><li>对于时间序列的异常检测问题，我们的目标一般是Point-based的异常标签，一个时间点的特征是有限的。如果用窗口的方式，以${x_{t-w+1},\cdots,x_t}$作为时间$t$的输入（当然每个$x_t$可以有多个Channel），然后把预测结果作为时间$t$的输出</li></ol>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications</title>
    <link href="/2019/09/22/Unsupervised-Anomaly-Detection-via-Variational-Auto-Encoder-for-Seasonal-KPIs-in-Web-Applications/"/>
    <url>/2019/09/22/Unsupervised-Anomaly-Detection-via-Variational-Auto-Encoder-for-Seasonal-KPIs-in-Web-Applications/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文提出了Donut，一个基于VAE的无监督时间序列异常检测系统。</p><p><a href="https://dl.acm.org/citation.cfm?id=3185996" target="_blank" rel="noopener">原文</a></p><img src="https://i.loli.net/2020/06/25/aoNWpGDLmJzwXOj.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ol><li>Donut中使用到了三个技巧，包括改进后的ELBO、缺失数据注入和MCMC插值；</li><li>提出基于VAE的异常检测训练既需要正常样本也需要异常样本；</li><li>对Donut提出了在z-空间中基于KDE的理论解释。</li></ol><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h3><p>对于任意时间$t$，给定历史观察值$x_{t-T+1},\cdots,x_t$，确定异常是否发生(记为$y_t=1$)。通常来收异常检测算法给出的是发生异常的可能性，如$p(y_t=1|x_{t-T+1},\cdots,x_t)$。</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>本文的目的是<strong>基于深度生成网络开发具有理论解释性的无监督异常检测算法，并且在有标签的情况下能利用标签信息提升性能</strong>。本文基于VAE来构建模型。</p><img src="https://i.loli.net/2020/06/25/PoKJmnIpEqNdtCe.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Network-Structure"><a href="#Network-Structure" class="headerlink" title="Network Structure"></a>Network Structure</h3><p>算法的总体框架如下图所示：</p><img src="https://i.loli.net/2020/06/25/DFP1boZNzdVG9pH.png" srcset="/img/loading.gif" style="zoom: 80%;" /><p>一共包含了预处理、训练和检测三个部分。</p><p>下图为模型的概率图模型：</p><img src="https://i.loli.net/2020/06/25/HlDXkSeFOruVbac.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>图中双实线的框为本文模型有别于传统VAE的地方，其余地方和VAE一样。先验概率$p_\theta(z)$选为标准正态分布$\mathcal{N}(0,I)$，后验概率$x$和$z$都是对角化高斯分布，即$p_\theta(x|z)=\mathcal{N}(\mu_x,\sigma_x^2 I),q_\phi(z|x)=\mathcal{N}(\mu_z,\sigma_z^2 I)$。如Figure 4所示，推断网络和生成网络中分别都有隐含层$f_\phi(x)$和$f_\theta(z)$对网络的输入进行特征抽取。高斯分布的参数即从这些抽取出来的特征上得到。均值通过线性层得到：$\mu_x=W^T_{\mu_x}f_\theta(z)+b_{\mu_x}, \mu_z=W^T_{\mu_z}f_\theta(x)+b_{\mu_z}$。标准差通过Soft Plus层加一个高斯噪声得到：$\sigma_x=\text{SoftPlus}[W^T_{\sigma_x}f_\theta(z)+b_{\sigma_x}]+\varepsilon，\sigma_x=\text{SoftPlus}[W^T_{\sigma_z}f_\theta(x)+b_{\sigma_z}]+\varepsilon$。</p><p>文中提到因为KPI的局部方差非常小，所以采用直接建模$\sigma_x,\sigma_z$的方式而不是采用对数。除此之外，为了理论上的解释性，文中的神经网络只使用了全连接层。</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>训练可以直接采用经典的SGVB来优化ELBO：<br>$$<br>\begin{align}<br>\log p_\theta(x)&amp;\geq\log p_\theta(x)-\text{KL}[q_\phi(z|x)\parallel p_\theta(z|x)]\<br>&amp;=\mathcal{L}\<br>&amp;=\mathbb{E}<em>{q_\phi(z|x)}[\log p_\theta(x)+\log p_\theta(z|x)-\log q_\phi(z|x)]\<br>&amp;=\mathbb{E}</em>{q_\phi(z|x)}[\log p_\theta(x,z)-\log q_\phi(z|x)]\<br>&amp;=\mathbb{E}<em>{q_\phi(z|x)}[\log p_\theta(x|z)+\log p_\theta(z)-\log q_\phi(z|x)]<br>\end{align}<br>$$<br>但是在实际的训练过程中，训练数据需要保证都是正常样本，但实际上训练样本有可能会包含异常或者是缺失值。一种做法是用缺失值填充的算法来填充这些异常值和缺失值，但作者认为使用缺失值填充算法并不能很好的还原数据的正常模式，从而保证算法的有效性。在文中作者采用了修改ELBO的方法，并将其称之为<strong>Modified ELBO (M-ELBO)</strong>，公式如下：<br>$$<br>\tilde{\mathcal{L}}=\mathbb{E}</em>{q_\phi(z|x)}[\sum\limits_{w=1}^W{\alpha_w\log p_\theta(x_w|z)+\beta\log p_\theta(z)-\log q_\phi(z|x)}]<br>$$<br>其中$\alpha_w$为指示标记，$\alpha_w=1$代表不是异常也不是缺失。$\beta$定义为$\beta=\frac{\sum_{w=1}^W\alpha_w}{W}$。</p><p>在<strong>M-ELBO</strong>中，异常或缺失值对应的$\log p_\theta(x_w|z)$的贡献会被排除，同时$\log p_\theta(z)$在乘以$\beta$后会相应缩小。作者没有修改$\log q_\phi(z|x)$这一项的原因有二：一是$q_\phi(z|x)$仅仅是从$x$到$z$的映射，并不需要考虑“正常模式”；二是$\mathbb{E}_{q_\phi(z|x)}[-\log q_\phi(z|x)]$就是$q_\phi(z|x)$的熵，而这个在后面的理论分析中有特别的含义。</p><p>除此之外还有一种解决方法就是把所有包含异常值和缺失值的窗口去除，这种方法的性能在实验中会进行讨论。</p><p>在文中作者还使用了一种<strong>Missing Data Injection</strong>技术，即在每个Epoch随机的按照一个预设比例$\lambda$将正常的数据设为缺失。作者认为这样有助于性能的提升。</p><h3 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h3><p>在检测阶段，对于一个输入样本，我们需要模型输出其异常的概率。因为我们建模了$p_\theta(x|z)$，一种方法是采样计算$p_\theta(x)=\mathbb{E}<em>{p_\theta(z)}[p_\theta(x|z)]$，但这种方法计算代价十分昂贵。其他的一些方案有计算$\mathbb{E}</em>{q_\phi(z|x)}[p_\theta(x|z)]$或$\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)]$，其中后者被称为”<strong>Reconstruction Probability</strong>“，作者便采用了这种方案。</p><p>同时，作者认为输入的检测样本的缺失值会对结果造成较大偏差，于是使用了一种<strong>MCMC-based Missing Data Imputation</strong>的方法来对检测样本的缺失值进行填充。具体做法是将测试样本分为已观测和缺失两部分$x=(x_o,x_m)$，然后使用训练好的VAE进行重构得到$(x^\prime_o,x^\prime_m)$，然后用$x^\prime_m$替换$x_m$，这样不断循环如下图所示：</p><img src="https://i.loli.net/2020/06/25/wEenLKz4URfm2FN.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>作者使用了$L$个样本来计算<strong>Reconstruction Probability</strong>，虽然得到的输出是针对整个窗口每个点的，但作者只使用最后一个点。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>作者选择了三条KPI作为测试数据，分别记为$\mathcal{A}$，$\mathcal{B}$，$\mathcal{C}$，其基本数据如下表所示：</p><img src="https://i.loli.net/2020/06/25/A9qajrZtmhcvyHW.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h3><p>因为异常检测类别的极不均衡性，传统的性能指标并不太合适（异常样本极少，且异常一般呈连续的片段）。作者认为在实际应用场景中运维人员需要尽量早的获知异常的发生，于是提出了新的评测机制。</p><img src="https://i.loli.net/2020/06/25/6LNwizqrWVe5sRv.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>如上图所示，第一行为真实的标签，第二行为预测的异常概率，第三行为预测的标签。第一行中异常片段被加粗表示，对于每一个异常片段的第一个位置${y}<em>{t^\prime}$，如果预测的标签中存在$\hat{y}</em>{t}$满足$t^\prime&lt;t$且$|t-t^\prime|$小于等于预设的阈值$T$，那么$y_{t^\prime}$对应的整段异常都被认为正确检测，否则整段异常都认为没有被正确检测。然后在此基础上计算F1-score，AUC等指标作为评测手段。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="Overall-Performance"><a href="#Overall-Performance" class="headerlink" title="Overall Performance"></a>Overall Performance</h3><p>下图展示了不同方法在不同数据集上的表现：</p><img src="https://i.loli.net/2020/06/25/2j1Br45MUxTaYEX.png" srcset="/img/loading.gif" style="zoom:67%;" /><h3 id="Effects-of-Donut-Techniques"><a href="#Effects-of-Donut-Techniques" class="headerlink" title="Effects of Donut Techniques"></a>Effects of Donut Techniques</h3><p>为了探究Donut中所做的各种改进的实际作用，作者做了大量对比实验，结果如下图所示：</p><img src="https://i.loli.net/2020/06/25/raHG6Phyxo1j82n.png" srcset="/img/loading.gif" style="zoom:67%;" /><ul><li><strong>M-ELBO</strong> 从图中可以看出<strong>M-ELBO</strong>对性能提升最大。作者在文中提到一开始并没期望<strong>M-ELBO</strong>能带来性能的提升，只是希望它能够Work。这表明在VAE的训练中，只使用正常样本是不够的，也需要加入非正常的信息；</li><li><strong>Missing Data Injection</strong> 该技巧的主要作用是增强<strong>M-ELBO</strong>的效果。从结果上来看作用并不是十分的显著，只是在一些情况下获得了少量的提升；</li><li><strong>MCMC Imputation</strong> 作者认为虽然该技巧只在一部分情况下显著提升了性能，但总体来说值得使用。</li></ul><h3 id="Impact-of-K"><a href="#Impact-of-K" class="headerlink" title="Impact of K"></a>Impact of K</h3><p>该部分作者探究了隐变量$z$的维度$K$对性能的影响，结果如下图：</p><img src="https://i.loli.net/2020/06/25/OXpIRoe4wr7YzuQ.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>从图上来看，对数据集$\mathcal{A}$，$\mathcal{B}$，$\mathcal{C}$最佳的$K$分别是$5$，$4$和$3$，但是设定较大的$K$并不会对性能有严重的损害。作者还发现对于较为平滑的KPI需要较大的$K$。</p><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><h3 id="KDE-Interpretation"><a href="#KDE-Interpretation" class="headerlink" title="KDE Interpretation"></a>KDE Interpretation</h3><p>在这一节作者对<strong>Reconstruction Probability</strong>的意义进行了深入的探讨。首先作者对$q_\phi(z|x)$进行了可视化，在图中作者将时间维度用颜色来表示。如Figure 11(a) 所示，$z$几乎是按照$x$对应的时间呈一个连续的流形分布，作者将这种现象称为<strong>Time Gradient</strong>。即使Donut没有显式的用到时间信息，不过因为实验用到的数据基本是平滑的，所以说相邻的$x$会比较相似，因此经过映射后的$z$也会比较相似。作者据此提出Donut的一个优势便是对于没有见过的后验分布$q_\phi(z|x)$，只要其位于训练过的两个后验之间，也会产生合理的分布。</p><img src="https://i.loli.net/2020/06/25/BHfP5DUZ48ALnma.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>对于异常的样本$x$，假设其对应的正常模式为$\tilde{x}$，作者认为$q_\phi(z|x)$会在某种程度上对正常的$q_\phi(z|\tilde{x})$进行近似。因为模型是用正常样本进行训练的，隐变量$z$的维度通常来说小于样本$x$，这就导致$z$只会保留一部分主要的信息。对于异常样本，其异常模式在编码时就被丢掉了。作者还指出如果$x$包含的异常太多，那么模型将难以对$x$进行还原。</p><img src="https://i.loli.net/2020/06/25/HcX78lUoG4meJq5.png" srcset="/img/loading.gif" style="zoom: 50%;" /><p>基于上述讨论，作者对使用$\mathbb{E}<em>{q_\phi(z|x)}[\log p_\theta(x|z)]$作为<strong>Reconstruction Probability</strong>的意义进行了阐释。设输入样本为$x$，如果其包含异常，假设其对应的正常样本为$\tilde{x}$，那么$q_\phi(z|x)$部分地和$q_\phi(z|\tilde{x})$相似。如果$x$和$\tilde{x}$相似程度高，那么$\log p_\theta(x|z)$就会很大（其中$z\sim q_\phi(z|\tilde{x})$）。$\log p_\theta(x|z)$类似于一个密度估计器，代表$x$在多大程度上与$\tilde{x}$接近，$\mathbb{E}</em>{q_\phi(z|x)}[\log p_\theta(x|z)]$相当于对每一个$z$对应的$\log p_\theta(x|z)$乘以一个权重$q_\phi(z|x)$然后相加。于是作者提出了<strong>Reconstruction Probability</strong>的<strong>KDE Interpretation</strong>:在Donut模型中，<strong>Reconstruction Probability</strong> $\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)]$可以看作是以$q_\phi(z|x)$为权重，$\log p_\theta(x|z)$为核的核密度估计 (Kernel Density Estimation)。</p><p>三维可视化如下图所示：</p><img src="https://i.loli.net/2020/06/25/GeWufVlUDo4QtO6.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>作者还对直接计算$p_\theta(x)=\mathbb{E}_{p_\theta(z)}[p_\theta(x|z)]$进行了质疑，因为这种方法直接求$x$的先验，仅仅考虑了$x$的总体模式，而忽略了$x$的个体模式。</p><h3 id="Find-Good-Posteriors-for-Abnormal-x"><a href="#Find-Good-Posteriors-for-Abnormal-x" class="headerlink" title="Find Good Posteriors for Abnormal $x$"></a>Find Good Posteriors for Abnormal $x$</h3><p>通过上面的讨论我们知道了Donut通过找到$x$的正常后验来估计$x$在多大程度上与$\tilde{x}$相似，在这一节作者讨论了文中使用的不同技巧对找到$x$的后验的作用。对于<strong>Missing Data Injection</strong>作者认为该技巧增强了<strong>M-ELBO</strong>的效果。对于<strong>MCMC Imputation</strong>，作者认为该技巧主要是在检测阶段通过不断迭代提供了更好的后验，如下图所示：</p><img src="https://i.loli.net/2020/06/25/8puDRylqZfQkcN6.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>作者认为，虽然对于包含大量异常的样本，Donut不能很好的还原，但在运维场景中，只要对大段异常的开始阶段进行准确预测即可。</p><h3 id="Causes-of-Time-Gradient"><a href="#Causes-of-Time-Gradient" class="headerlink" title="Causes of Time Gradient"></a>Causes of Time Gradient</h3><p>在这一节作者讨论了<strong>Time Gradient</strong>出现的原因。首先假设$x$都是正常点，这时$x$的ELBO为：<br>$$<br>\begin{align}<br>\mathcal{L}(x)&amp;=\mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)+\log p_\theta(z)-\log q_\phi(z|x)]\<br>&amp;=\mathbb{E}[\log p_\theta(x|z)]+\mathbb{E}[\log p_\theta(z)]+\text{H}[z|x]<br>\end{align}<br>$$<br>第一项表明在$z\sim q_\phi(z|x)$下尽可能重构$x$。第二项表明$q_\phi(z|x)$尽量与$z$的先验$\mathcal{N}(0,I)$接近。第三项为$q_\phi(z|x)$的熵，表明$q_\phi(z|x)$应尽量分散。然而第二项又限制了这种分散的区域，如 Figure 11(c) 所示。同时考虑这三项的话，第一项使得$z$不能自由地分散，对于不相似的$x$其对应的$z$也是不相似的，因为要最大化$x$的重构概率。然而对于相似的$x$来说，其对应的$q_\phi(z|x)$会出现很多重复的部分。当达到平衡时，<strong>Time Gradient</strong>就出现了。</p><img src="https://i.loli.net/2020/06/25/AaC9oNMShBRHFeY.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>在训练过程中，当$x$越不相似，$q_\phi(z|x)$就会相距越远，如上图所示。然而在一开始，参数经过随机初始化，$q_\phi(z|x)$都是随机散乱的，如 Figure 11(b) 所示。随着训练的进行，$q_\phi(z|x)$将会不断优化。由于KPI数据往往是光滑的，那么在时间上相距越远的样本就会越不相似，对应的$q_\phi(z|x)$也会相距更远。这也说明了，训练结束后，时间上相距越远的，$q_\phi(z|x)$也会相距越远，反之亦然。同时这也表明学习率的设置对本模型的稳定性有至关重要的作用。</p><h3 id="Sub-Optimal-Equilibrium"><a href="#Sub-Optimal-Equilibrium" class="headerlink" title="Sub-Optimal Equilibrium"></a>Sub-Optimal Equilibrium</h3><p>上面我们讨论了随着训练进行$q_\phi(z|x)$的演变，作者提出在训练过程中可能会遇到模型收敛到次优的情况，如下图所示：</p><img src="https://i.loli.net/2020/06/25/udigOl3sJGwSaPz.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>第一行展示的是收敛到最优的情况，第二行展示的是收敛到次优的情况。从第二行的第一个图（Step 100）来看，紫色的点开始穿过绿色的点，随着训练的进行，紫色的点开始将绿色的点推开。到Step 5000的时候，绿色的点已经被分成了两半。下图展示了对应的训练误差和验证误差：</p><img src="https://i.loli.net/2020/06/25/23zsxwurICV7aTj.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>这样的现象会导致在两半绿色区域之间的测试样本会被识别为紫色，从而降低性能。作者提出在$K$较大的时候这种现象不容易发生，但这时训练的收敛又会成为一个问题。</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>VAE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Time-Series Anomaly Detection Service at Microsoft</title>
    <link href="/2019/09/22/Time-Series-Anomaly-Detection-Service-at-Microsoft/"/>
    <url>/2019/09/22/Time-Series-Anomaly-Detection-Service-at-Microsoft/</url>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文借鉴计算机视觉中的显著性检测，提出了一种基于Spectral Residual的时间序列异常检测算法。</p><p><a href="https://www.kdd.org/kdd2019/accepted-papers/view/time-series-anomaly-detection-service-at-microsoft" target="_blank" rel="noopener">原文</a></p><p>这篇文章还提出了几个时间序列异常检测落地的难点：</p><ol><li><strong>Lack of Labels.</strong> 在实际生产环境中会产生大量的KPI，而很难对每个KPI进行人工标注。</li><li><strong>Generalization.</strong> 不同KPI所表现出来的模式也不尽相同，如Figure 1所示。现有方法很难在所有模式的KPI上都表现良好。</li><li><strong>Efficiency.</strong> 在实际场景中，会产生大量的时间序列数据，同时对异常检测算法的时间效率有要求。</li></ol><img src="https://i.loli.net/2020/06/25/o21lnTUtcGuwCq6.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul><li>将Visual Saliency Detection的方法引入了时间序列异常检测。</li><li>结合Spectral Residual和CNN提高了异常检测的效果。</li><li>算法具有良好的时间效率和通用性。</li></ul><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Spectral-Residual"><a href="#Spectral-Residual" class="headerlink" title="Spectral Residual"></a>Spectral Residual</h3><p>SR(Spectral Residual)算法主要包含三个步骤：</p><ol><li>通过傅里叶变换得到log amplitude spectrum；</li><li>计算spectral residual；</li><li>通过傅里叶逆变换回到时间域。</li></ol><p>更形式化的表述为如下：</p><p>给定一个序列$\mathbb{x}$，则有：</p><p>$$A(f)=Amplitude(\mathscr{F}(\mathbb{x}))$$</p><p>$$P(f)=Phrase(\mathscr{F}(\mathbb{x}))$$</p><p>$$L(f)=\log(A(f))$$</p><p>$$AL(F)=h_1(f)\cdot L(f)$$</p><p>$$R(f)=L(f)-AL(f)$$</p><p>$$S(\mathbb{x})=\parallel\mathscr{F}^{-1}(\exp(R(f)+iP(f)))\parallel$$</p><p>其中$\mathscr{F}$和$\mathscr{F}^{-1}$分别表示傅里叶变换和傅里叶逆变换；$\mathbb{x}\in \mathbb{R}^{n\times 1}$表示输入序列；$A(f)$为幅度谱，$P(f)$为相位谱，$L(f)$为对数幅度谱，$AL(F)$为均值滤波后的对数幅度谱；$R(f)$为spectral residual；$S(\mathbb{x})$称为saliency map。Figure 4为文中给出的Saliency Map示意图。</p><img src="https://i.loli.net/2020/06/25/OrSlqhBWNdyfEG9.png" srcset="/img/loading.gif" style="zoom:67%;" /><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h3><blockquote><p>给定一系列实数值$\mathbb{x}=x_1,x_2,\cdots,x_n$，时间序列异常检测的任务是产生一个输出序列$\mathbb{y}=y_1,y_2,\cdots,y_n$其中$y_i\in{0,1}$表示$x_i$是否为异常点。</p></blockquote><h3 id="SR"><a href="#SR" class="headerlink" title="SR"></a>SR</h3><p>对于给定序列$\mathbb{x}$，计算Saliency Map $S(\mathbb{x})$，输出序列$O(\mathbb{x})$定义为：</p><p>$$O(x_i)=\begin{cases}1,\quad \text{if}\frac{S(x_i)-\overline{S(x_i)}}{\overline{S(x_i)}}&gt;\tau\\0,\quad \text{otherwise}\end{cases}$$</p><p>其中$S(x_i)$为$x_i$对应的Saliency Map的值，$\overline{S(x_i)}$为$x_i$附近Saliency Map局部均值。</p><hr><p>在实际操作中，FFT是在一个滑动窗口中进行的，文中提到SR方法在点位于窗口中央时效果更好，所以在进行测试的时候，按照如下方法对当前点$x_n$(也就是当前序列最后一个点)之后的点进行预测：</p><p>$$\overline{g}=\frac{1}{m}\sum_{i=1}^m g(x_n,x_{n-i})$$</p><p>$$x_{n+1}=x_{n-m+1}+\overline{g}\cdot m$$</p><p>其中$g(x_i,x_j)$代表$x_i$和$x_j$两点构成的直线的梯度；$\overline{g}$代表所处理的点的平均梯度；$m$为所处理的点的数量。在本文中设置$m=5$。文中发现第一个预测的值很重要，所以直接把$x_{n+1}$赋值$k$次添加到序列的末尾。</p><h3 id="SR-CNN"><a href="#SR-CNN" class="headerlink" title="SR-CNN"></a>SR-CNN</h3><p><img src="https://i.loli.net/2020/06/25/9pEWXRD5JM4umHn.png" srcset="/img/loading.gif" alt=""></p><p>本文提到，仅仅使用一个阈值来进行异常的判断太过简单，于是提出使用一个判别模型来进行异常的判断。由于训练数据没有标签，所以使用如下的公式人工加入异常：</p><p>$$x=(\overline{x}+mean)(1+var)\cdot r+x$$</p><p>其中$\overline{x}$所处理的点的局部均值；$mean$和$var$为当前滑动窗口点的均值和方差；$r\sim \mathcal{N}(0,1)$为服从标准正态分布的噪声。</p><hr><p>对于判别模型使用的是CNN，主要包含两个1维卷积层(kernel size等于窗口大小$w$)和两个全连接层。两个卷积层的channel size分别为$w$和$2w$。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><img src="https://i.loli.net/2020/06/25/dquAjtRpNSY8rLo.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>所用数据集包含清华AIOps竞赛数据、Yahoo和Microsoft的KPI数据。</p><h3 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h3><p>算法准确率方面用了precision，recall和$F_1$-score。</p><img src="https://i.loli.net/2020/06/25/EbcjA8X5fYa6Glz.png" srcset="/img/loading.gif" style="zoom:67%;" /><p>由于在实际场景中KPI的异常往往是以一段一段的形式出现，且并不要求某一个时间点出现异常算法就马上检测出来，只要检测出来的时间在一定的容忍范围内即可。本文使用了一些调整的手段，如Figure 6。对于某一段异常，设段首的异常位于时间点$t_{truth}$，预测为异常的结果中时间在$t_{truth}$之后且距$t_{truth}$最近的时间点设为$t_{predict}$，那么对于一个预先设定的容忍范围$k$，只要$t_{predict}-t_{truth}\leq k+1$那么在预测结果中整段异常就会重置为$1$，否则全部重置为$0$。</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>实验部分使用了两种训练方式，一种是cold-start，即把所有数据都用来测试，另一种是把数据分为训练测试两部分，在训练集上训练，最后在测试集上进行测试。两种方法适用的baseline不同，最后结果如Table 2和Table 3所示：</p><img src="https://i.loli.net/2020/06/25/3L9xe5jJGtnR6AQ.png" srcset="/img/loading.gif" style="zoom: 50%;" /><hr><p>在SR的参数设置上，$h_q(f)$中的$q$为3，局部平均所用的点数目$z$为21，阈值$\tau$为3，估计点的数量$k$为5，滑动窗口的大小$w$在KPI、Yahoo、Microsoft三个数据集上分别为1440、64和30。SR-CNN的$q$，$z$，$k$，$w$设置与SR相同。</p><h3 id="Additional-Experiments-with-DNN"><a href="#Additional-Experiments-with-DNN" class="headerlink" title="Additional Experiments with DNN"></a>Additional Experiments with DNN</h3><p>文中还对有监督的情况进行了测试，具体做法是从时间序列提取特征，然后将Saliency Map也作为特征引入，构造一个有监督的Neural Network进行测试。</p><p>提取的特征如Table 5所示：</p><img src="https://i.loli.net/2020/06/25/4flipKbc1OtVGg9.png" srcset="/img/loading.gif" style="zoom: 50%;" /><hr><p>神经网络的结构为两层全连接层，并添加了Dropout Ratio为0.5的Dropout Layer。两个Layer使用了$L_1=L_2=0.0001$的正则化。同时为了处理样本不平衡的情况使用了过采样来使正负样本的比例为$1:2$。结构如Figure 7所示：</p><img src="https://i.loli.net/2020/06/25/bxeluFBHv2i7Y5m.png" srcset="/img/loading.gif" style="zoom:67%;" /><hr><p>训练测试集的情况如Table 6所示，最终结果如Table 7所示，P-R曲线如Figure 8所示。可以看到使用了SR特征的DNN效果由于没有使用SR特征的DNN。</p><img src="https://i.loli.net/2020/06/25/E6vapzhCiG9HTPu.png" srcset="/img/loading.gif" style="zoom:67%;" /><img src="https://i.loli.net/2020/06/25/tZAOg74flmE39oI.png" srcset="/img/loading.gif" style="zoom:67%;" />]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
      <category>Anomaly Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Time Series</tag>
      
      <tag>Anomaly Detection</tag>
      
      <tag>Machine Learning</tag>
      
      <tag>Deep Learning</tag>
      
      <tag>Spectral</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
