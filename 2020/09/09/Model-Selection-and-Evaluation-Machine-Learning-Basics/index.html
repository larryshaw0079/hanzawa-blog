<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2D5BA6">
  <meta name="description" content="">
  <meta name="author" content="Hanzawa">
  <meta name="keywords" content="">
  <title>Model Selection and Evaluation: Machine Learning Basics - Hanzawa の 部屋</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Hanzawa</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/bg/coffe_bear.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                Model Selection and Evaluation: Machine Learning Basics
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-09-09 11:33">
                    2020年9月9日 中午
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    3k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    33
                     分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="iconfont icon-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：2020年9月10日 下午
                
              </p>
            
            <article class="markdown-body">
              <h1 id="introduction">Introduction</h1>
<h1 id="overfitting">Overfitting</h1>
<p>我们将模型输出与真实值之间的差异称为误差，如对于分类问题，我们可以使用模型分类错误的样本数量占总样本数的比例。模型在训练集（我们收集到的数据）上的误差称作是<strong>训练误差 (training error)</strong>，而在新样本（这里指的是新的样本而不是测试集，训练集测试集是从我们收集到的数据上人为划分出来的）上的误差称作是<strong>泛化误差 (generalization error)</strong>。对于机器学习算法，我们希望算法能学到数据背后的普遍规律，所以我们总是希望模型的泛化误差越小越好。</p>
<p>不过测试集对训练过程来说是未知的，所以模型只能尽量从训练集中发掘数据的普遍规律，要是模型把训练集学得”太好“了，很可能把训练集中不属于普遍规律的部分特点作为了一般性质，这就会导致泛化性能下降，我们称这种情况为<strong>过拟合 (overfitting)</strong>。反之，模型对训练集的特性学得不够，就会出现<strong>欠拟合 (underfitting)</strong>。关于过拟合和欠拟合，周志华老师的《机器学习》中有一张很好的图：</p>
<p><img src="https://i.loli.net/2020/09/09/tVPeQfu9CWLaSi6.png" srcset="/img/loading.gif" style="zoom:67%;" /></p>
<p>一般来说，欠拟合比较容易克服，可以通过增加模型的复杂度来实现。而过拟合则比较难解决，一般而言可以通过增加数据量、加正则化约束来改善。</p>
<h1 id="model-selection">Model Selection</h1>
<p>对于一个机器学习任务，一般我们有多种模型供我们选择，并且模型也有不同的超参数，我们希望得到泛化性能尽可能高的模型。不过根据前面的讨论，新样本是未知的，所以没法直接得到泛化误差，而过拟合的存在使得我们不能贸然的根据模型在我们收集到的数据上的表现来选择模型（训练误差低不代表泛化误差低）。</p>
<p>我们假设无论是我们收集到的数据还是新样本都是从数据的真实分布中独立同分布采样得来，为此我们可以从数据中划分出一部分”测试集“，然后将模型在测试集上的表现作为泛化误差的近似，而剩下的部分用来模型训练。</p>
<p>那么如何划分训练集和测试集呢？比较常见的方法是”<span class="math inline">\(k\)</span>折交叉验证法“ (<span class="math inline">\(k\)</span>-fold cross validation)，一般<span class="math inline">\(k\)</span>常取<span class="math inline">\(10\)</span>，其基本思想如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/09/8KEWDe3qMTsQoUx.png" srcset="/img/loading.gif" style="zoom: 50%;" /></p>
<p><span class="math inline">\(k\)</span>折交叉验证法首先将数据集均匀地划分为<span class="math inline">\(k\)</span>个部分，然后进行<span class="math inline">\(k\)</span>个循环，在每个循环中将第<span class="math inline">\(k\)</span>份作为测试集，其余的作为训练集，最后得到的结果进行平均。</p>
<h1 id="evaluation-metrics">Evaluation Metrics</h1>
<p>前面我们讨论了评测的框架，但是没有说具体的评测指标。实际上评测指标要根据任务来确定，并且不同的评测指标也有自己的特点。</p>
<h2 id="regression">Regression</h2>
<p>回归任务比较常用的评测标准是<strong>均方误差 (Mean Squared Error)</strong>： <span class="math display">\[
\text{MSE}(f;D)=\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2
\]</span> 和<strong>平均绝对误差 (Mean Absolute Error)</strong>： <span class="math display">\[
\text{MAE}(f;D)=\frac{1}{m}\sum_{i=1}^m |f(x_i)-y_i|
\]</span></p>
<h2 id="classification">Classification</h2>
<h3 id="binary-classification">Binary Classification</h3>
<p>对于分类任务，最简单的想法是使用模型分类正确的比例来作为评测标准，我们称之为<strong>准确率 (Accuracy)</strong>： <span class="math display">\[
\text{ACC}(f;D)=\frac{1}{m}\sum_{i=1}^m \mathbb{I}(f(x_i)=y_i)
\]</span> 但准确率并不能满足我们的所有要求，比如说对于新冠病毒的分类任务，我们可能会更关注于对于所有患有新冠的病人，模型到底查出来了多少，而对于模型误把正常病人当作是患病的情况没有那么关注。对于二分类问题，我们可以将样例根据其真实类别与模型预测的类别划分为真正例 (true positive, TP)、假正例 (false positive, FP)、真反例 (true negative, TN) 和假反例 (false negative, FN) 四种，形成<strong>混淆矩阵 (Confusion Matrix)</strong>：</p>
<p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg" srcset="/img/loading.gif" /></p>
<p>下面给一个具体的例子：</p>
<p><img src="https://i.loli.net/2020/09/09/tCLxvZfNoEgqWID.png" srcset="/img/loading.gif" /></p>
<p>比如我们的任务是预测一张手写数字图片是不是<span class="math inline">\(5\)</span>，根据上图，右下角就是我们正确预测的是<span class="math inline">\(5\)</span>的图片，左下角就是本来是<span class="math inline">\(5\)</span>，但被预测成不是<span class="math inline">\(5\)</span>的图片；左上角是本来不是<span class="math inline">\(5\)</span>，我们也正确地预测出其不是<span class="math inline">\(5\)</span>的，右上角是本来不是<span class="math inline">\(5\)</span>却被预测成是<span class="math inline">\(5\)</span>的。是不是有点被绕晕了😀，只要记住T和F代表的是预测结果对还是不对，P和N代表的是模型预测当前样本是正例还是负例。</p>
<p>基于混淆矩阵，我们可以定义<strong>查准率 (Precision)</strong> 和<strong>查全率 (Recall)</strong> 这两个评测标准。</p>
<p>查准率，顾名思义，对于检测出来的正例，有多少是真正的正例，即查的准不准，公式为： <span class="math display">\[
\text{Precision}=\frac{TP}{TP+FP}
\]</span> 分母就是模型预测为正例的样本总数。</p>
<p>查全率，就对应刚才举的新冠的例子，我们比较在乎对于数据集中的正例，有多少被查出来了，公式为： <span class="math display">\[
\text{Recall} = \frac{TP}{TP+FN}
\]</span> 分母就是真实类别为正例的样本总数。一般来说，查准率和查全率是相互矛盾的，除非是特别简单的任务，很难兼顾查准率和查全率。</p>
<p><strong>F1分数 (F1 Score)</strong> 综合了查准率和查全率： <span class="math display">\[
\text{F}1=\frac{2\cdot\text{Precision}\cdot\text{Recall}}{\text{Precision}+\text{Recall}}
\]</span> 查准率和查全率中任意一项较低都会导致F1分数较低。有时候我们对待查准率和查全率的权重不同，这时候可以使用F<span class="math inline">\(_\beta\)</span>分数： <span class="math display">\[
\text{F}_\beta=\frac{(1+\beta^2)\cdot \text{Precision}\cdot\text{Recall}}{(\beta^2\cdot\text{Precision})+\text{Recall}}
\]</span> <span class="math inline">\(\beta=1\)</span>时等价于F1分数，<span class="math inline">\(\beta&gt;1\)</span>代表偏重查全率，<span class="math inline">\(\beta&lt;1\)</span>代表偏重查准率。</p>
<h3 id="multi-classification">Multi-classification</h3>
<p>前面的讨论都是基于二分类任务，如果是多分类任务的话， 对于每一类，我们将该类作为正例，其他类别作为负例，都能得到一个混淆矩阵。如果我们在每个混淆矩阵上计算评测指标，然后进行平均，这样就得到宏查准率 (macro-Precision)、宏查全率 (macro-Recall) 和宏F1分数 (macro-F1)。如果我们事先将混淆矩阵的TP、FP、TN、FN先进行平均，再计算评测指标，就得到了微查准率 (micro-Precision)、微查全率 (micro-Recall) 和微F1分数 (micro-F1)。</p>
<h3 id="pr-curve">PR-Curve</h3>
<p>很多情况下模型的输出是样本为正例的“概率值”或者是分数，分数越高的样本代表越可能是正例。这种时候需要人为划定阈值，规定高于阈值的样本是正例。不过阈值的划分相当于超参数的选取，同时我们会认为一个鲁棒的模型的性能应该不受阈值选取的左右。这个时候我们可以使用<strong>PR曲线 (Precision-Recall Curve)</strong>，即遍历所有可能的阈值，对于每个阈值，计算其对应的Precision和Recall，然后画在图上，最后会得到一系列离散的点（理论上应该是连续曲线，不过阈值是连续值，我们只能取离散值），形成PR-曲线。</p>
<p><img src="https://i.loli.net/2020/09/09/ecP8flTYZIDUBrV.png" srcset="/img/loading.gif" alt="2-class Precision-Recall curve: AP=0.88" style="zoom:67%;" /></p>
<p>模型性能越好，曲线就会越接近右上角的点，我们可以把PR曲线的曲线下面积 (PR-AUC) 作为评测标准。</p>
<h3 id="roc-curve">ROC-Curve</h3>
<p>ROC全称是<strong>受试者工作特征 (Receiver Operating Characteristic) 曲线</strong>, 和PR曲线类似，ROC曲线也是遍历不同的阈值计算点，不过ROC曲线计算的是真正例率 (True Positive Rate, TPR) 和假正例率 (False Positive Rate, FPR)，两者定义分别是： <span class="math display">\[
\begin{align}
\text{TPR}=\frac{TP}{TP+FN}\\
\text{FPR}=\frac{FP}{TN+FP}
\end{align}
\]</span> 其中TPR就是查全率，而FPR是所有负例中没有检测出来的比例，这一项是越低越好。</p>
<p><img src="https://i.loli.net/2020/09/09/CdHrDaKAns4EN93.png" srcset="/img/loading.gif" style="zoom:67%;" /></p>
<p>模型性能越好，曲线就会越接近左上角的点，我们可以把ROC曲线的曲线下面积 (ROC-AUC) 作为评测标准。</p>
<p>下面来总结一下PR曲线和ROC曲线之间的优缺点。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>纵轴</th>
<th>横轴</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>PR</strong></td>
<td><span class="math inline">\(\text{Precision}=\frac{TP}{TP+FP}\)</span></td>
<td><span class="math inline">\(\text{Recall} = \frac{TP}{TP+FN}\)</span></td>
</tr>
<tr class="even">
<td><strong>ROC</strong></td>
<td><span class="math inline">\(\text{TPR}=\frac{TP}{TP+FN}\)</span></td>
<td><span class="math inline">\(\text{FPR}=\frac{FP}{TN+FP}\)</span></td>
</tr>
</tbody>
</table>
<p><img src="https://i.loli.net/2020/09/09/xY8KAldMZSRwHnB.jpg" srcset="/img/loading.gif" /></p>
<p>ROC的优点：</p>
<ul>
<li>相比PR仅关注正例，ROC同时关注正例和负例</li>
<li>相比PR不易受到正负例相对数量的影响，ROC的两个指标的计算都只涉及到P、N中的一列，正例或负例增加对总体影响不大。而PR曲线就不一样，两个指标的计算都涉及到了P、N两列，那么正例或负例样本数量的变化会造成较大影响。如负例突然增大，那么FP也会增大，这样Precision会降低，而Recall却不变。</li>
</ul>
<p>ROC的缺点：</p>
<ul>
<li>对于类别不平衡问题，存在大量负例，这样会带来大量的FP，而ROC的FPR却不会因为FP的大幅增长而剧烈改变，结果是这一类错误很难在ROC曲线中体现出来。所以ROC会呈现出一个过于乐观的评价。</li>
</ul>
<p>我们来尝试下是否如此，下面是用随机森林分类器，测试样本正负例数量比为1:1的情况下的ROC曲线和PR曲线：</p>
<p><img src="https://i.loli.net/2020/09/10/yqMDQh5oTs96SJm.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>
<p><img src="https://i.loli.net/2020/09/10/zFW941YTMl8yxiP.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>
<p>在我们将正负例数量比调整为1:9之后（总数量相同），可以看到ROC曲线比较稳定，没出现较大变化，而PR曲线则出现了剧烈变化：</p>
<p><img src="https://i.loli.net/2020/09/10/HbnLtfGsiVc17q5.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>
<p><img src="https://i.loli.net/2020/09/10/FfYrb3SnkeZ9JTv.png" srcset="/img/loading.gif" alt="4" style="zoom:50%;" /></p>
<h1 id="bias-and-variance">Bias and Variance</h1>
<p>在机器学习中，偏差-方差分解是解释学习算法泛化性能的重要工具。假设我们要预测某一个地区的房子的房价，每一套房子都是一个样本，我们认为每个样本都是从总体分布<span class="math inline">\(P(X)\)</span>独立同分布采样得来的。不过我们不可能得到所有的样本，我们采样得到的训练集只是其中一个子集。那么，即使对于同样的测试样本，使用不同的训练集（训练集大小相同）训练出来的模型对测试样本的预测也是不一样的，我们将这一部分模型自身的不稳定性用<strong>方差 (Variance) </strong>来描述：<span class="math inline">\(\text{Var}(X)=E_D\left[(\hat f(X)-E[\hat f(X)])^2\right]\)</span>，方差越小代表模型稳定性越强。模型输出的期望与真实值之间的差距我们用<strong>偏差 (Bias) </strong>来描述：<span class="math inline">\(\text{Bias}(X)=E[\hat f(X)]-f(X)\)</span>。</p>
<p>泛化误差与方差、偏差有下列关系： <span class="math display">\[
\begin{align}
\text{Err}(X)&amp;=E\left[(y-\hat f(X))^2\right]\\
&amp;=E\left[(f(X)+\varepsilon-\hat f(X))^2\right]\\
&amp;= (E[\hat f(X)]-f(X))^2 + E\left[(\hat f(X)-E[\hat f(X)])^2\right]+\sigma_{\varepsilon}^2\\
&amp;=\text{Bias}^2 + \text{Variance} + \text{Random Error}
\end{align}
\]</span> 也就是说泛化误差可以分解为方差、偏差和随机噪声之和。偏差刻画了模型的期望预测与真实值之间的偏离程度，方差刻画了不同训练集对模型性能的影响，他们之间的关系如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/09/2IpmrwJGfqORU3z.png" srcset="/img/loading.gif" style="zoom: 33%;" /></p>
<p>图中左上角的部分是比较理想的情况，即方差和偏差都较小。但实际上方差和偏差往往是相互冲突的，如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/09/GsREiklKYfuX3Ub.png" srcset="/img/loading.gif" style="zoom:67%;" /></p>
<p>模型复杂度不足的时候，模型的拟合能力不够强，偏差主导了泛化误差，而随着模型复杂度的提高，模型的拟合能力逐渐提高，训练数据的扰动会造成模型发生显著变化，这时方差逐渐主导了泛化误差。</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Technical-Notes/">Technical Notes</a>
                    
                      <a class="hover-with-bg" href="/categories/Technical-Notes/Machine-Learning/">Machine Learning</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Overfitting/">Overfitting</a>
                    
                      <a class="hover-with-bg" href="/tags/Bias/">Bias</a>
                    
                      <a class="hover-with-bg" href="/tags/Variance/">Variance</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/09/02/Decision-Tree-Machine-Learning-Classification-Algorithms-3/">
                        <span class="hidden-mobile">Decision Tree: Machine Learning Classification Algorithms 3</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'http://qfxiao.me/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/';
        this.page.identifier = '/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/';
      };
      var oldLoadDq = window.onload;
      window.onload = function () {
        oldLoadDq && oldLoadDq();

        var d = document, s = d.createElement('script');
        s.type = 'text/javascript';
        s.src = '//' + 'http-larryshaw0079-coding-me-blog' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      };
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noopener">comments
        powered by Disqus.</a></noscript>
  </div>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  














</body>
</html>
