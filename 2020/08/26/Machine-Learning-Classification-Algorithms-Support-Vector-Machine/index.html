<!DOCTYPE html>
<html lang="zh-CN">
    <!-- title -->




<!-- keywords -->




<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="Hanzawa">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Hanzawa">
    
    <meta name="keywords" content="hexo,hexo-theme,hexo-blog">
    
    <meta name="description" content="">
    <meta name="description" content="Introduction Still working on it😅... blog Hyperplane 超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程： \[ a_1x_1+\cdots+a_nx_n&#x3D;d \] 的所有解形成的集合，其中\(a_1,\cdots,a_n\)为不全为\(0\)的实数，\(d\)也是实数。 从几何上来说，超平面可以看作是除空间\(R">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning Classification Algorithms: Support Vector Machine">
<meta property="og:url" content="http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/index.html">
<meta property="og:site_name" content="Hanzawa の 部屋">
<meta property="og:description" content="Introduction Still working on it😅... blog Hyperplane 超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程： \[ a_1x_1+\cdots+a_nx_n&#x3D;d \] 的所有解形成的集合，其中\(a_1,\cdots,a_n\)为不全为\(0\)的实数，\(d\)也是实数。 从几何上来说，超平面可以看作是除空间\(R">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg">
<meta property="og:image" content="https://i.loli.net/2020/08/26/vjuyCGXMr4msaUK.png">
<meta property="og:image" content="https://i.loli.net/2020/08/26/b6qLJWzHwFAPDne.png">
<meta property="og:image" content="https://i.loli.net/2020/09/08/kSTVgelDjWqtu8v.png">
<meta property="og:image" content="https://i.loli.net/2020/09/08/I6AonzFRHGVBU3t.png">
<meta property="og:image" content="https://i.loli.net/2020/09/08/Hmr79nMlK4C8GeJ.png">
<meta property="article:published_time" content="2020-08-25T18:09:24.000Z">
<meta property="article:modified_time" content="2021-02-19T10:23:31.925Z">
<meta property="article:author" content="Hanzawa">
<meta property="article:tag" content="SVM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    
    <title>Machine Learning Classification Algorithms: Support Vector Machine · fi3ework&#39;s Studio</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/assets/favicon.ico" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head>

    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >fi3ework&#39;s Studio.</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">Machine Learning Classification Algorithms: Support Vector Machine</a>
            </div>
    </div>
    
    <a class="home-link" href=/>fi3ework's Studio.</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/post-bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            Machine Learning Classification Algorithms: Support Vector Machine
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "SVM">SVM</a>
    
</div>
                
                
                    <div class="post-intro-read">
                        <span>字数统计: <span class="post-count word-count">2.5k</span>阅读时长: <span class="post-count reading-time">11 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/08/26</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <h1 id="introduction">Introduction</h1>
<p>Still working on it😅...</p>
<p><a target="_blank" rel="noopener" href="http://blog.pluskid.org/?page_id=683">blog</a></p>
<h1 id="hyperplane">Hyperplane</h1>
<p>超平面可以从代数和几何两方面来理解。超平面的代数定义可以看作是方程： <span class="math display">\[
a_1x_1+\cdots+a_nx_n=d
\]</span> 的所有解形成的集合，其中<span class="math inline">\(a_1,\cdots,a_n\)</span>为不全为<span class="math inline">\(0\)</span>的实数，<span class="math inline">\(d\)</span>也是实数。</p>
<p>从几何上来说，超平面可以看作是除空间<span class="math inline">\(R^n\)</span>自身外维度最大的仿射空间。</p>
<p><img src="https://i.loli.net/2020/09/07/WiMJQSe7lN8upfw.jpg" /></p>
<h1 id="maximum-margin-classifier">Maximum Margin Classifier</h1>
<p><img src="https://i.loli.net/2020/08/26/vjuyCGXMr4msaUK.png" style="zoom:67%;" /></p>
<p>要谈SVM就得先谈线性分类器，其设置是这样的。对于<span class="math inline">\(D\)</span>维空间，我们有一堆数据<span class="math inline">\(X\)</span>，进行二分类任务，标签记为<span class="math inline">\(y\)</span>，其中<span class="math inline">\(y=-1\)</span>和<span class="math inline">\(y=1\)</span>分别代表不同的类别。我们的任务就是找到一个超平面，将正负例切分开来（先假设数据是线性可分的），这个超平面的方程可以表示为： <span class="math display">\[
w^\top x+b=0
\]</span> 我们令<span class="math inline">\(f(x)=w^\top x+b\)</span>，对于<span class="math inline">\(f(x)&lt;0\)</span>的样本，我们赋予其类别<span class="math inline">\(-1\)</span>，对于<span class="math inline">\(f(x)&gt;0\)</span>的样本，我们可以赋予其类别<span class="math inline">\(1\)</span>。对于相同的分类结果，我们可以找出无限种超平面。不过，对于那些样本特别靠近超平面的情况，鲁棒性并不好。为什么呢？因为这时只要超平面有轻微的变化，样本的分类结果就会发生变化。直观上来说，我们希望样本到超平面的距离越大越好。</p>
<p>我们先定义函数间隔的概念，函数间隔<span class="math inline">\(\hat \gamma=y(w^\top x+b)\)</span>，乘以<span class="math inline">\(y\)</span>的目的主要是保持非负性，表示起来方便。可见函数间隔的大小并不能表示样本距离，因为同一个超平面，法向量<span class="math inline">\(w\)</span>可以任意增大，函数间隔也会相应增大。</p>
<p>下面来推导点<span class="math inline">\(x\)</span>到超平面的距离。设<span class="math inline">\(x\)</span>在超平面上的投影为<span class="math inline">\(x_0\)</span>，到超平面的距离为<span class="math inline">\(\gamma\)</span>，<span class="math inline">\(w\)</span>为法向量，那么有： <span class="math display">\[
x=x_0+\gamma\frac{w}{\parallel w\parallel}
\]</span> 将上式带入到超平面方程可以得到 <span class="math display">\[
\gamma=\frac{w^\top}{\parallel w\parallel}x+\frac{b}{\parallel w\parallel}
\]</span> 我们称<span class="math inline">\(\gamma\)</span>为几何间隔。</p>
<p><img src="https://i.loli.net/2020/08/26/b6qLJWzHwFAPDne.png" /></p>
<p>可以很容易看出函数间隔和几何间隔的关系： <span class="math display">\[
\gamma = \frac{\hat \gamma}{\parallel w\parallel}
\]</span> 前面提到我们希望几何间隔越大越好，于是可以直接最大化<span class="math inline">\(\gamma\)</span>，得到： <span class="math display">\[
\begin{align}
\max \space &amp;\gamma\\
s.t. \space &amp; y_i(w^\top x_i+b)=\hat\gamma_i\geq\hat\gamma, \space i=1,\cdots,n
\end{align}
\]</span> 这里<span class="math inline">\(\hat \gamma=\gamma \parallel w\parallel\)</span>，根据前面的分析我们知道，对于同一个超平面，函数间隔<span class="math inline">\(\hat\gamma\)</span>可以随着<span class="math inline">\(\parallel w\parallel\)</span>的变化而变化，所以为了找到最优的<span class="math inline">\(\gamma\)</span>，我们可以考虑固定<span class="math inline">\(\parallel w\parallel\)</span>或者<span class="math inline">\(\hat\gamma\)</span>，这里我们固定<span class="math inline">\(\hat \gamma=1\)</span>，所以有： <span class="math display">\[
\begin{align}
\max &amp; \space \frac{1}{\parallel w\parallel},\\ s.t. \space&amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n
\end{align}
\]</span></p>
<p>下面的约束条件代表前提是所有样本分类正确，而<span class="math inline">\(\max\frac{1}{\parallel w\parallel}\)</span>代表最大化间隔。为了方便，我们将其化为等价的最小化形式： <span class="math display">\[
\begin{align}
\min &amp; \space \frac{1}{2}\parallel w\parallel^2,\\ s.t. &amp; y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n
\end{align}
\]</span> 其中那些<span class="math inline">\(y_i(w^\top x_i+b)=1\)</span>的样本就是“支持向量”。这个优化问题是典型的二次凸优化问题，可以调用现成的算法去解决。不过我们可以使用拉格朗日乘子法来更高效的解决。</p>
<h1 id="dual-problem">Dual Problem</h1>
<p>拉格朗日乘子法可以将有<span class="math inline">\(d\)</span>个变量和<span class="math inline">\(k\)</span>个约束条件的最优化问题转化成有<span class="math inline">\(d+k\)</span>个变量的无约束最优化问题求解。</p>
<h2 id="lagrange-multiplier">Lagrange Multiplier</h2>
<p>对于以下有约束优化问题： <span class="math display">\[
\begin{align}
\min_x \space &amp; f(x)\\
\text{s.t.} \space &amp; h_i(x)=0 \space (i=1,\cdots,m),\\
&amp;g_j(x) \leq 0 \space (j=1,\cdots,n)
\end{align}
\]</span></p>
<p>引入拉格朗日乘子<span class="math inline">\(\boldsymbol\lambda = (\lambda_1,\lambda_2,\cdots,\lambda_n)^\top\)</span>和<span class="math inline">\(\boldsymbol\mu=(\mu_1,\mu_2,\cdots,\mu_m)^\top\)</span>，相应的广义拉格朗日函数 (generalized Lagrange function) 为： <span class="math display">\[
L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=f(\boldsymbol x)+\sum_{j=1}^n \lambda_j g_j(\boldsymbol x)+\sum_{i=1}^m \mu_i h_i(\boldsymbol x)
\]</span></p>
<p>其中<span class="math inline">\(\lambda_j\)</span>，<span class="math inline">\(\mu_i\)</span>被称作是拉格朗日乘子，<span class="math inline">\(\lambda_j \geq 0\)</span>。</p>
<h3 id="primal-problem">Primal Problem</h3>
<p>现在我们来讨论原问题的等价性。假设给定某个<span class="math inline">\(x\)</span>，如果<span class="math inline">\(x\)</span>违反约束条件，即存在某个<span class="math inline">\(x\)</span>使得<span class="math inline">\(h_i(x)\neq 0\)</span>或者<span class="math inline">\(g_j(x)&gt;0\)</span>，那么就有： <span class="math display">\[
\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)=+\infty
\]</span> 如果存在某个<span class="math inline">\(x\)</span>使得<span class="math inline">\(h_i(x)\neq 0\)</span>，那么可以令<span class="math inline">\(\lambda_j \rightarrow +\infty\)</span>，如果存在<span class="math inline">\(g_j(x)&gt;0\)</span>，那么可令<span class="math inline">\(\mu_ih_i(x)\rightarrow +\infty\)</span>。</p>
<p>如果考虑以下极小化问题： <span class="math display">\[
p^*=\min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)
\]</span> 他与原始带约束最优化问题是等价的（因为不符合约束时会有<span class="math inline">\(+\infty\)</span>，而我们考虑的是极小化问题），我们将其记为原问题 (Primal problem)。</p>
<h3 id="dual-problem-1">Dual Problem</h3>
<p>如果先考虑最小化<span class="math inline">\(x\)</span>，再考虑最大化<span class="math inline">\(\boldsymbol\lambda\)</span>和<span class="math inline">\(\boldsymbol\mu\)</span>，这时有： <span class="math display">\[
\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)
\]</span> 对偶问题 (Dual problem) <span class="math display">\[
d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu)
\]</span> 原问题和对偶问题的关系 <span class="math display">\[
d^*=\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0}\min_x L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) \leq \min_x\max\limits_{\boldsymbol\lambda,\boldsymbol\mu:\lambda_j\geq 0} L(\boldsymbol x,\boldsymbol\lambda,\boldsymbol\mu) = p^*
\]</span></p>
<h3 id="kkt-condition">KKT Condition</h3>
<blockquote>
<p>对于原问题和对偶问题，设<span class="math inline">\(f(x)\)</span>和<span class="math inline">\(g_i(x)\)</span>为凸函数，<span class="math inline">\(h_i(x)\)</span>为仿射函数，并且不等式约束<span class="math inline">\(c_i(x)\)</span>是严格可行的，则<span class="math inline">\(x^*\)</span>，<span class="math inline">\(\lambda^*\)</span>，<span class="math inline">\(\mu^*\)</span>分别是原问题和对偶问题的解的充分必要条件是满足下面的Karush-Kuhn-Tucker (KKT) 条件： <span class="math display">\[
\begin{cases}
\nabla_x L(x^*,\lambda^*,\mu^*)=0 &amp;\\ 
\lambda^*_j g_j(x^*)=0 &amp; j=1,\cdots n\\
g_j(x^*)\leq 0 &amp; j=1,\cdots n\\
\lambda_j^*\geq 0 &amp; j=1,\cdots n\\
h_i(x^*) = 0 &amp; i = 1, \cdots m
\end{cases}
\]</span></p>
</blockquote>
<p>这告诉我们</p>
<h2 id="dual-form-of-svm-optimization">Dual Form of SVM Optimization</h2>
<p>支持向量机优化的对偶问题可以写为： <span class="math display">\[
L(w,b,\alpha)=\frac{1}{2}\parallel w\parallel^2-\sum_{i=1}^n \alpha_i(y_i(w^\top x_i+b)-1)
\]</span> 我们先令： <span class="math display">\[
\begin{align}
\frac{\partial L}{\partial w}=0&amp;\Rightarrow w=\sum_{i=1}^n\alpha_i y_i x_i\\
\frac{\partial L}{\partial b}=0&amp;\Rightarrow \sum_{i=1}^n\alpha_i y_i =0
\end{align}
\]</span> 带回到<span class="math inline">\(L\)</span>得到： <span class="math display">\[
\begin{align}
L(w,b,\alpha)&amp;=\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_j y_i y_j x^\top_i x_j-\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_jx^\top_ix_j-b\sum_{i=1}^n\alpha_iy_i+\sum_{i=1}^n\alpha_i\\
&amp;=\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j
\end{align}
\]</span> 于是得到关于<span class="math inline">\(\alpha\)</span>的对偶优化问题： <span class="math display">\[
\begin{align}
\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j x^\top_i x_j\\
\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\\
&amp; \sum_{i=1}^n \alpha_i y_i = 0
\end{align}
\]</span></p>
<p>前面有提到我们根据<span class="math inline">\(f(x)=w^\top x + b\)</span>的输出来判定样本类别，而刚才得到<span class="math inline">\(w=\sum_{i=1}^n\alpha_i y_i x_i\)</span>，于是： <span class="math display">\[
\begin{align}
f(x) &amp;= (\sum_{i=1}^n \alpha_iy_ix_i)^\top x+b\\
&amp;= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b
\end{align}
\]</span> 最后的<span class="math inline">\(\sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b\)</span>值得特别注意，这意味着我们对于测试样本<span class="math inline">\(x\)</span>的预测，只需要计算它与训练集的内积即可，同时由于所有非支持向量对应的<span class="math inline">\(\alpha\)</span>都是<span class="math inline">\(0\)</span>，我们只需要求一小部分内积。同时这个内积计算也是后面核方法应用的前提。</p>
<h1 id="kernel">Kernel</h1>
<p>到目前为止，我们的讨论都是在数据是线性可分的前提下进行讨论的，那么对于线性不可分的情况呢？答案是使用核方法。</p>
<p><img src="https://i.loli.net/2020/09/08/kSTVgelDjWqtu8v.png" /></p>
<p>核方法的思想是，对于原始不可分的数据，我们假设原始数据通过一个映射<span class="math inline">\(\phi(\cdot)\)</span>就变得线性可分了。核方法相当于对数据找到了一种新的表示，如上图没法用一个超平面直接分割，但通过<span class="math inline">\(\phi(\cdot)\)</span>映射之后就变得可分了。原始的分类函数为： <span class="math display">\[
f(x)= \sum_{i=1}^n \alpha_i y_i \langle x_i, x\rangle + b
\]</span> 加上映射之后变为： <span class="math display">\[
f(x)= \sum_{i=1}^n \alpha_i y_i \langle \phi(x_i), \phi(x)\rangle + b
\]</span> 优化问题也变为： <span class="math display">\[
\begin{align}
\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j \langle\phi(x_i), \phi(x_j)\rangle\\
\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\\
&amp; \sum_{i=1}^n \alpha_i y_i = 0
\end{align}
\]</span> 我们把计算两个向量在映射后的空间中的内积的函数叫做核函数 <span class="math display">\[
f(x)= \sum_{i=1}^n \alpha_i y_i k(x_i, x) + b
\]</span> 优化问题改为： <span class="math display">\[
\begin{align}
\max_\alpha &amp;\sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_j y_i y_j k(\phi(x_i), \phi(x_j))\\
\text{s.t. }&amp; \alpha_i\geq 0, i=1,\cdots,n\\
&amp; \sum_{i=1}^n \alpha_i y_i = 0
\end{align}
\]</span> 实际上，通过核函数，我们隐式地定义了一个映射<span class="math inline">\(\phi(\cdot)\)</span></p>
<p>常用核函数</p>
<table>
<thead>
<tr class="header">
<th>名称</th>
<th>表达式</th>
<th>参数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>线性核</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>多项式核</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>RBF核</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>拉普拉斯核</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Sigmoid核</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="soft-margin">Soft Margin</h1>
<p>数据线性不可分的情况，除了数据本身结构非线性的原因之外（核方法），还有可能是因为噪声或者离群点。为了处理这种情况，我们可以允许一部分点在一定程度上偏离超平面，具体来说就是原来的约束条件<span class="math inline">\(y_i(w^\top x_i+b)\geq 1, \space i=1,\cdots,n\)</span>变成了： <span class="math display">\[
y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n
\]</span> 其中<span class="math inline">\(\xi_i\geq 0\)</span>称作是松弛变量，代表样本<span class="math inline">\(i\)</span>允许的偏离程度。当然松弛变量不可能无限大，所以我们需要将<span class="math inline">\(\xi_i\)</span>加入到优化目标函数中使其尽量小，于是有： <span class="math display">\[
\begin{align}
\min &amp; \space \frac{1}{2}\parallel w\parallel^2+C\sum_{i=1}^n \xi_i,\\ s.t. &amp; y_i(w^\top x_i+b)\geq 1-\xi_i, \space i=1,\cdots,n
\end{align}
\]</span> 其中<span class="math inline">\(C\)</span>为控制最优化<span class="math inline">\(\parallel w\parallel\)</span>和松弛变量这两项的权重。这里的优化函数还是对偶问题之前的形式，我们马上会讨论对偶问题。</p>
<h1 id="numerical-optimization">Numerical Optimization</h1>
<p>这里讨论SVM高效求解的Sequential Minimal Optimization (SMO)算法。</p>
<p>坐标下降法是一种非梯度优化算法，</p>
<p><img src="https://i.loli.net/2020/09/08/I6AonzFRHGVBU3t.png" /></p>
<p><img src="https://i.loli.net/2020/09/08/Hmr79nMlK4C8GeJ.png" /></p>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>原文作者：<a href="http://qfxiao.me">Hanzawa</a>
            <p>原文链接：<a href="http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/">http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/</a>
            <p>发表日期：<a href="http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/">August 26th 2020, 2:09:24 am</a>
            <p>更新日期：<a href="http://qfxiao.me/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/">February 19th 2021, 6:23:31 pm</a>
            <p>版权声明：本文采用<a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc/4.0/">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/" title= "Machine Learning Classification Algorithms: Decision Trees">
                    <div class="nextTitle">Machine Learning Classification Algorithms: Decision Trees</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2020/08/26/Boosting-and-AdaBoost-Machine-Learning-Ensemble-Algorithms-1/" title= "Boosting and AdaBoost: Machine Learning Ensemble Algorithms 1">
                    <div class="prevTitle">Boosting and AdaBoost: Machine Learning Ensemble Algorithms 1</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- gitalk评论 -->

    <!-- utteranc评论 -->

    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    

    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:12345@qq.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/fi3ework" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
            
                <span class="iconfont-archer wechat" title=wechat>
                  
                  <img class="profile-qr" src="/assets/example_qr.png" />
                </span>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
</footer>
    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hyperplane"><span class="toc-number">2.</span> <span class="toc-text">Hyperplane</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#maximum-margin-classifier"><span class="toc-number">3.</span> <span class="toc-text">Maximum Margin Classifier</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#dual-problem"><span class="toc-number">4.</span> <span class="toc-text">Dual Problem</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#lagrange-multiplier"><span class="toc-number">4.1.</span> <span class="toc-text">Lagrange Multiplier</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#primal-problem"><span class="toc-number">4.1.1.</span> <span class="toc-text">Primal Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dual-problem-1"><span class="toc-number">4.1.2.</span> <span class="toc-text">Dual Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kkt-condition"><span class="toc-number">4.1.3.</span> <span class="toc-text">KKT Condition</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dual-form-of-svm-optimization"><span class="toc-number">4.2.</span> <span class="toc-text">Dual Form of SVM Optimization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kernel"><span class="toc-number">5.</span> <span class="toc-text">Kernel</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#soft-margin"><span class="toc-number">6.</span> <span class="toc-text">Soft Margin</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#numerical-optimization"><span class="toc-number">7.</span> <span class="toc-text">Numerical Optimization</span></a></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 33
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/23</span><a class="archive-post-title" href= "/2020/09/23/Unsupervised-Feature-Learning-via-Non-Parametric-Instance-Discrimination/" >Unsupervised Feature Learning via Non-Parametric Instance Discrimination</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/17</span><a class="archive-post-title" href= "/2020/09/17/Representation-Learning-with-Contrastive-Predictive-Coding/" >Representation Learning with Contrastive Predictive Coding</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/09</span><a class="archive-post-title" href= "/2020/09/09/Model-Selection-and-Evaluation-Machine-Learning-Basics/" >Model Selection and Evaluation: Machine Learning Basics</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/02</span><a class="archive-post-title" href= "/2020/09/02/Machine-Learning-Classification-Algorithms-Decision-Trees/" >Machine Learning Classification Algorithms: Decision Trees</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/26</span><a class="archive-post-title" href= "/2020/08/26/Machine-Learning-Classification-Algorithms-Support-Vector-Machine/" >Machine Learning Classification Algorithms: Support Vector Machine</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/26</span><a class="archive-post-title" href= "/2020/08/26/Boosting-and-AdaBoost-Machine-Learning-Ensemble-Algorithms-1/" >Boosting and AdaBoost: Machine Learning Ensemble Algorithms 1</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/26</span><a class="archive-post-title" href= "/2020/08/26/Machine-Learning-Ensemble-Algorithms-GBDT-and-XGBoost/" >Machine Learning Ensemble Algorithms: GBDT and XGBoost</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/24</span><a class="archive-post-title" href= "/2020/08/24/Unsupervised-Representation-Learning-by-Predicting-Random-Distances/" >Unsupervised Representation Learning by Predicting Random Distances</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/14</span><a class="archive-post-title" href= "/2020/07/14/Effective-End-to-end-Unsupervised-Outlier-Detection-via-Linear-Priority-of-Discriminative-Network/" >Effective End-to-end Unsupervised Outlier Detection via Linear Priority of Discriminative Network</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/22</span><a class="archive-post-title" href= "/2020/06/22/Probability-Distributions-Binary-and-Multinomial-Variables/" >Probability Distributions - Binary and Multinomial Variables</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/13</span><a class="archive-post-title" href= "/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/" >Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/06</span><a class="archive-post-title" href= "/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/" >Generative Probabilistic Novelty Detection with Adversarial Autoencoders</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/02</span><a class="archive-post-title" href= "/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/" >Classification-based Anomaly Detection for General Data</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/02</span><a class="archive-post-title" href= "/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" >面向OpenPAI的Docker镜像配置及OpenPAI基本使用方法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/02</span><a class="archive-post-title" href= "/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA11-cuDNN8-Tensorflow-Pytorch/" >Ubuntu20.04LTS 深度学习环境配置 CUDA11 + cuDNN8 + Tensorflow + Pytorch</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/" >Deep Anomaly Detection Using Geometric Transformations</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">06/01</span><a class="archive-post-title" href= "/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/" >Cross-dataset Time Series Anomaly Detection for Cloud Systems</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">05/06</span><a class="archive-post-title" href= "/2020/05/06/Learning-Representations-of-Ultrahigh-dimensional-Data-for-Random-Distance-based-Outlier-Detection/" >Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/30</span><a class="archive-post-title" href= "/2020/03/30/Deep-Weakly-supervised-Anomaly-Detection/" >Deep Weakly-supervised Anomaly Detection</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/01</span><a class="archive-post-title" href= "/2020/03/01/Discovering-Physical-Concepts-with-Neural-Networks/" >Discovering Physical Concepts with Neural Networks</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/27</span><a class="archive-post-title" href= "/2020/02/27/Transfer-Anomaly-Detection-by-Inferring-Latent-Domain-Representations/" >Transfer Anomaly Detection by Inferring Latent Domain Representations</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/24</span><a class="archive-post-title" href= "/2020/02/24/Deep-Anomaly-Detection-with-Deviation-Networks/" >Deep Anomaly Detection with Deviation Networks</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/31</span><a class="archive-post-title" href= "/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/" >Geant4 安装教程与调试环境配置</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/09</span><a class="archive-post-title" href= "/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/" >Complementary Set Variational Autoencoder for Supervised Anomaly Detection</a>
        </li>
    
    
    
    
    
        </ul>
    
    <div class="archive-year"> 2019 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/29</span><a class="archive-post-title" href= "/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/" >Anomaly Detection in Streams with Extreme Value Theory</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/22</span><a class="archive-post-title" href= "/2019/10/22/An-Introduction-to-Variational-Autoencoders/" >An Introduction to Variational Autoencoders</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/18</span><a class="archive-post-title" href= "/2019/10/18/Recurrent-Neural-Networks-for-Multivariate-Time-Series-with-Missing-Values/" >Recurrent Neural Networks for Multivariate Time Series with Missing Values</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/18</span><a class="archive-post-title" href= "/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/" >Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">10/16</span><a class="archive-post-title" href= "/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/" >GAIN: Missing Data Imputation using Generative Adversarial Nets</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/" >Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2019/09/22/ALSR-An-adaptive-label-screening-and-relearning-approach-for-interval-oriented-anomaly-detection/" >ALSR: An Adaptive Label Screening and Relearning Approach for Interval-Oriented Anomaly Detection</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2019/09/22/Time-Series-Anomaly-Detection-Service-at-Microsoft/" >Time-Series Anomaly Detection Service at Microsoft</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">09/22</span><a class="archive-post-title" href= "/2019/09/22/Unsupervised-Anomaly-Detection-via-Variational-Auto-Encoder-for-Seasonal-KPIs-in-Web-Applications/" >Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="Variational Inference"><span class="iconfont-archer">&#xe606;</span>Variational Inference</span>
    
        <span class="sidebar-tag-name" data-tags="VAE"><span class="iconfont-archer">&#xe606;</span>VAE</span>
    
        <span class="sidebar-tag-name" data-tags="Deep Learning"><span class="iconfont-archer">&#xe606;</span>Deep Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Time Series"><span class="iconfont-archer">&#xe606;</span>Time Series</span>
    
        <span class="sidebar-tag-name" data-tags="Statistics"><span class="iconfont-archer">&#xe606;</span>Statistics</span>
    
        <span class="sidebar-tag-name" data-tags="Machine Learning"><span class="iconfont-archer">&#xe606;</span>Machine Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Anomaly Detection"><span class="iconfont-archer">&#xe606;</span>Anomaly Detection</span>
    
        <span class="sidebar-tag-name" data-tags="Boosting"><span class="iconfont-archer">&#xe606;</span>Boosting</span>
    
        <span class="sidebar-tag-name" data-tags="Adaboost"><span class="iconfont-archer">&#xe606;</span>Adaboost</span>
    
        <span class="sidebar-tag-name" data-tags="Transfer Learning"><span class="iconfont-archer">&#xe606;</span>Transfer Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Self-Supervised Learning"><span class="iconfont-archer">&#xe606;</span>Self-Supervised Learning</span>
    
        <span class="sidebar-tag-name" data-tags="GAN"><span class="iconfont-archer">&#xe606;</span>GAN</span>
    
        <span class="sidebar-tag-name" data-tags="Novelty Detection"><span class="iconfont-archer">&#xe606;</span>Novelty Detection</span>
    
        <span class="sidebar-tag-name" data-tags="Geant4"><span class="iconfont-archer">&#xe606;</span>Geant4</span>
    
        <span class="sidebar-tag-name" data-tags="Representation Learning"><span class="iconfont-archer">&#xe606;</span>Representation Learning</span>
    
        <span class="sidebar-tag-name" data-tags="ID3"><span class="iconfont-archer">&#xe606;</span>ID3</span>
    
        <span class="sidebar-tag-name" data-tags="C4.5"><span class="iconfont-archer">&#xe606;</span>C4.5</span>
    
        <span class="sidebar-tag-name" data-tags="CART"><span class="iconfont-archer">&#xe606;</span>CART</span>
    
        <span class="sidebar-tag-name" data-tags="SVM"><span class="iconfont-archer">&#xe606;</span>SVM</span>
    
        <span class="sidebar-tag-name" data-tags="Probability"><span class="iconfont-archer">&#xe606;</span>Probability</span>
    
        <span class="sidebar-tag-name" data-tags="GBDT"><span class="iconfont-archer">&#xe606;</span>GBDT</span>
    
        <span class="sidebar-tag-name" data-tags="XGBoost"><span class="iconfont-archer">&#xe606;</span>XGBoost</span>
    
        <span class="sidebar-tag-name" data-tags="Overfitting"><span class="iconfont-archer">&#xe606;</span>Overfitting</span>
    
        <span class="sidebar-tag-name" data-tags="Bias"><span class="iconfont-archer">&#xe606;</span>Bias</span>
    
        <span class="sidebar-tag-name" data-tags="Variance"><span class="iconfont-archer">&#xe606;</span>Variance</span>
    
        <span class="sidebar-tag-name" data-tags="RNN"><span class="iconfont-archer">&#xe606;</span>RNN</span>
    
        <span class="sidebar-tag-name" data-tags="Contrastive Learning"><span class="iconfont-archer">&#xe606;</span>Contrastive Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Self-supervised Learning"><span class="iconfont-archer">&#xe606;</span>Self-supervised Learning</span>
    
        <span class="sidebar-tag-name" data-tags="Flow-based Model"><span class="iconfont-archer">&#xe606;</span>Flow-based Model</span>
    
        <span class="sidebar-tag-name" data-tags="Spectral"><span class="iconfont-archer">&#xe606;</span>Spectral</span>
    
        <span class="sidebar-tag-name" data-tags="Shapelet"><span class="iconfont-archer">&#xe606;</span>Shapelet</span>
    
        <span class="sidebar-tag-name" data-tags="Pytorch"><span class="iconfont-archer">&#xe606;</span>Pytorch</span>
    
        <span class="sidebar-tag-name" data-tags="Tensorflow"><span class="iconfont-archer">&#xe606;</span>Tensorflow</span>
    
        <span class="sidebar-tag-name" data-tags="Docker"><span class="iconfont-archer">&#xe606;</span>Docker</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
jsonContent:
  meta: false
  pages: false
  posts:
    title: true
    date: true
    path: true
    text: false
    raw: false
    content: false
    slug: false
    updated: false
    comments: false
    link: false
    permalink: false
    excerpt: false
    categories: true
    tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="Research"><span class="iconfont-archer">&#xe60a;</span>Research</span>
    
        <span class="sidebar-category-name" data-categories="Research/Anomaly-Detection"><span class="iconfont-archer">&#xe60a;</span>Research/Anomaly-Detection</span>
    
        <span class="sidebar-category-name" data-categories="Research/Tutorial"><span class="iconfont-archer">&#xe60a;</span>Research/Tutorial</span>
    
        <span class="sidebar-category-name" data-categories="Technical-Notes"><span class="iconfont-archer">&#xe60a;</span>Technical-Notes</span>
    
        <span class="sidebar-category-name" data-categories="Research/Misc"><span class="iconfont-archer">&#xe60a;</span>Research/Misc</span>
    
        <span class="sidebar-category-name" data-categories="Research/Time-Series-Imputation"><span class="iconfont-archer">&#xe60a;</span>Research/Time-Series-Imputation</span>
    
        <span class="sidebar-category-name" data-categories="Technical-Notes/Misc"><span class="iconfont-archer">&#xe60a;</span>Technical-Notes/Misc</span>
    
        <span class="sidebar-category-name" data-categories="Technical-Notes/Machine-Learning"><span class="iconfont-archer">&#xe60a;</span>Technical-Notes/Machine-Learning</span>
    
        <span class="sidebar-category-name" data-categories="Research/Notes"><span class="iconfont-archer">&#xe60a;</span>Research/Notes</span>
    
        <span class="sidebar-category-name" data-categories="Research/RNN"><span class="iconfont-archer">&#xe60a;</span>Research/RNN</span>
    
        <span class="sidebar-category-name" data-categories="Research/Self-supervised-Learning"><span class="iconfont-archer">&#xe60a;</span>Research/Self-supervised-Learning</span>
    
        <span class="sidebar-category-name" data-categories="Research/Time-Series-Modeling"><span class="iconfont-archer">&#xe60a;</span>Research/Time-Series-Modeling</span>
    
        <span class="sidebar-category-name" data-categories="Research/Representation-Learning"><span class="iconfont-archer">&#xe60a;</span>Research/Representation-Learning</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "Hanzawa"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script>    
     
    </body>
</html>


