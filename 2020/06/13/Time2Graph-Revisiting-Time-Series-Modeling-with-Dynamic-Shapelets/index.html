<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduction 本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的time-aware shapelet，并且定义了shapele"><meta property="og:type" content="article"><meta property="og:title" content="Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:description" content="Introduction 本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的time-aware shapelet，并且定义了shapele"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/mKJH4c2EMAljavG.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/srW4Shk79XBFL3U.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/5b2TcjuBzlIFrPm.png"><meta property="og:image" content="https://i.loli.net/2020/07/07/FzGEbWJflHmQa9R.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/aq9tGuApSbiC67c.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/O5exTgsVLuRWQ42.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/zHjTKkUJB8fGwdi.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/jxKFpDVXdmc5tbE.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/hPfqAvNnOlEBQuw.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/ed5PwksC2l3OWE8.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/N2Vij8ODQaRuALJ.png"><meta property="article:published_time" content="2020-06-13T08:42:04.000Z"><meta property="article:modified_time" content="2020-07-07T03:15:36.315Z"><meta property="article:author" content="Hanzawa"><meta property="article:tag" content="Time Series"><meta property="article:tag" content="Shapelet"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/"},"headline":"Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets","image":["https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png","https://i.loli.net/2020/06/25/mKJH4c2EMAljavG.png","https://i.loli.net/2020/06/25/srW4Shk79XBFL3U.png","https://i.loli.net/2020/06/25/5b2TcjuBzlIFrPm.png","https://i.loli.net/2020/07/07/FzGEbWJflHmQa9R.png","https://i.loli.net/2020/06/25/aq9tGuApSbiC67c.png","https://i.loli.net/2020/06/25/O5exTgsVLuRWQ42.png","https://i.loli.net/2020/06/25/zHjTKkUJB8fGwdi.png","https://i.loli.net/2020/06/25/jxKFpDVXdmc5tbE.png","https://i.loli.net/2020/06/25/hPfqAvNnOlEBQuw.png","https://i.loli.net/2020/06/25/ed5PwksC2l3OWE8.png","https://i.loli.net/2020/06/25/N2Vij8ODQaRuALJ.png"],"datePublished":"2020-06-13T08:42:04.000Z","dateModified":"2020-07-07T03:15:36.315Z","author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":"Introduction\r 本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的time-aware shapelet，并且定义了shapele"}</script><link rel="canonical" href="https://larryshaw0079.github.io/hanzawa-blog/2020/06/13/Time2Graph-Revisiting-Time-Series-Modeling-with-Dynamic-Shapelets/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-06-13T08:42:04.000Z" title="2020-6-13 4:42:04 ├F10: PM┤">2020-06-13</time>发表</span><span class="level-item"><time dateTime="2020-07-07T03:15:36.315Z" title="2020-7-7 11:15:36 ├F10: AM┤">2020-07-07</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Time-Series-Modeling/">Time Series Modeling</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Time2Graph: Revisiting Time Series Modeling with Dynamic Shapelets</h1><div class="content"><h1 id="introduction">Introduction</h1>
<p>本文旨在提供一种可解释的高效的时间序列建模（表示学习）方法来更好地服务分类任务。Shapelet在时间序列分类任务上体现了良好的可解释性。不过传统的基于Shapelet的方法忽略了Shapelet在不同时间片段上的动态性，即整个时间维度上不同的时间片段可能适合用不同的Shapelet。作者基于此设计了动态的<em>time-aware shapelet</em>，并且定义了<em>shapelet evolution graph</em>来捕获Shapelet在时间维度上的动态变化。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.04143">📰Get Paper</a></p>
<h1 id="preliminaries">Preliminaries</h1>
<p>时间序列集合<span class="math inline">\(T=\{t_1,\cdots,t_{|T|}\}\)</span>包含若干条时序数据<span class="math inline">\(t=\{x_1,\cdots,x_n\}\)</span>。一个<span class="math inline">\(t\)</span>的片段<span class="math inline">\(s\)</span>是<span class="math inline">\(t\)</span>的一个连续子序列。如果<span class="math inline">\(t\)</span>能被切分成<span class="math inline">\(m\)</span>个长度都为<span class="math inline">\(l\)</span>的片段，那么我们就有<span class="math inline">\(t=\{\{x_{l*k+1},\cdots,x_{l*k+l}\},0\leq k\leq m-1\}\)</span>。两个长度相等的片段之间距离很好度量，直接计算欧式距离即可，那么两个片段长度不相等的情况呢？这就需要对其（Alignment）的概念。</p>
<blockquote>
<p><strong>Definition 1 </strong> <strong><em>Alignment</em></strong>. 给定两个长度分别为<span class="math inline">\(l_i\)</span>和<span class="math inline">\(l_j\)</span>的序列<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，一个<em>alignment</em> <span class="math inline">\(a=(a_1,a_2)\)</span>是一个满足以下条件的长度为<span class="math inline">\(p\)</span>的下标序列： <span class="math display">\[
1\leq a_k(1)\leq\cdots\leq a_k(p)=l_k,\\
a_k(n+1)-a_k(n)\leq 1,\\
\text{for }k=i,j,\text{ and }1\leq n\leq p-1
\]</span></p>
</blockquote>
<p>上述公式可能比较抽象，其实看了下图就不难理解：</p>
<p><img src="https://i.loli.net/2020/07/07/UE2GtoYK1vhDpLi.png" style="zoom:67%;" /></p>
<p>片段<span class="math inline">\(s_i\)</span>中的某个点<span class="math inline">\(a\)</span>，与片段<span class="math inline">\(s_j\)</span>中的某个点<span class="math inline">\(b\)</span>形成对应，然后在<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>之间连一条虚拟的线（不能与已有的线交叉），一直这么做直到短的那个片段中的每个点都找到对应，就是一个合理的<em>alignment</em>。对于两个长度不一样的片段<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>，会有很多种<em>alignment</em>。我们把<span class="math inline">\(s_i\)</span>和<span class="math inline">\(s_j\)</span>所有可能的<em>alignment</em>记为<span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>。在定义了<em>alignment</em>之后就可以定义DTW了。DTW (<em>Dynamic Time Warping</em>) 定义为在给定一个预定义的距离度量<span class="math inline">\(\tau\)</span>和所有可能的<em>alignment</em> <span class="math inline">\(\mathcal{A}(s_i,s_j)\)</span>的情况下，最小的距离<span class="math inline">\(\tau\)</span>： <span class="math display">\[
d_\text{DTW}(s_i,s_j)=\min_{a\in\mathcal{A}(s_i,s_j)}\tau(s_i,s_j|a)
\]</span></p>
<p>进一步的，因为时间序列<span class="math inline">\(t\)</span>也可以看作是一个片段，我们可以定义一个子序列<span class="math inline">\(s\)</span>和时间序列<span class="math inline">\(t\)</span>之间的距离度量： <span class="math display">\[
D(s,t)=\min_{1\leq k\leq m} d(s,s_k)
\]</span></p>
<p>这里<span class="math inline">\(\boldsymbol s_k\)</span>为时序<span class="math inline">\(\boldsymbol t\)</span>分解成的片段。之后Shapelet可以通过片段与时序的距离定义为最具有辨识度的有代表性的片段：</p>
<blockquote>
<p><strong>Definition 2 </strong> <strong>Shapelet. </strong>一个Shapelet <span class="math inline">\(\boldsymbol v\)</span>是对于特定类别时序的最具有代表性的片段。考虑时序分类任务，给定时序集合<span class="math inline">\(T\)</span>，可以通过与<span class="math inline">\(\boldsymbol v\)</span>相似或不相似而分成两个子集合，与<span class="math inline">\(\boldsymbol v\)</span>相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量小，与<span class="math inline">\(\boldsymbol v\)</span>不相似的集合与<span class="math inline">\(\boldsymbol v\)</span>的距离应当尽量大，此时损失函数可以形式化为： <span class="math display">\[
\mathcal L=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))
\]</span></p>
</blockquote>
<p><span class="math inline">\(\mathcal L\)</span>描述了在shapelet <span class="math inline">\(\boldsymbol v\)</span>下正负样本集的相异性。<span class="math inline">\(S_{*}(\boldsymbol v,T)\)</span>表示特定时序集合与<span class="math inline">\(\boldsymbol v\)</span>的距离集合，<span class="math inline">\(g(\cdot,\cdot)\)</span>为接受两个有限集合为输入的可微函数，并且能够度量两个集合的距离。</p>
<h1 id="framework">Framework</h1>
<p>本文主要是提出了一种时间序列表示学习方法。基于Shapelet在不同的时间片段上的作用是不同的观察，作者为不同的时间片段赋予了不同的Shapelet，而不是像传统方法一样整个时序对应一个Shapelet。接着基于这些Shapelet作者构造了图，并通过图嵌入得到了嵌入向量，作为时序的表示。</p>
<p><img src="https://i.loli.net/2020/06/25/mKJH4c2EMAljavG.png" style="zoom:80%;" /></p>
<h2 id="time-aware-shapelet-extraction">Time-Aware Shapelet Extraction</h2>
<p>第一步是捕获Shapelet在时间维度上的动态影响。我们定义了两个参数来定量的测量shapelet在不同时间上的动态性。第一个是局部因子<span class="math inline">\(\boldsymbol w_n\)</span>，用来控制shapelet内部<span class="math inline">\(n\)</span>个元素的权重，那么shapelet <span class="math inline">\(\boldsymbol v\)</span>和片段<span class="math inline">\(\boldsymbol s\)</span>的距离为： <span class="math display">\[
\begin{align}
\hat{d}(\boldsymbol v,\boldsymbol s|\boldsymbol w) &amp;= \tau(\boldsymbol v,\boldsymbol s|\boldsymbol a^*,\boldsymbol w)\\
&amp; = \left(\sum_{k=1}^{p}\boldsymbol w_{\boldsymbol a^*_1(k)}\cdot(\boldsymbol v_{\boldsymbol a^*_1(k)}-\boldsymbol s_{\boldsymbol a^*_2(k)})^2\right)^{\frac{1}{2}}
\end{align}
\]</span> 其中<span class="math inline">\(\boldsymbol a^*\)</span>为DTW距离下的最佳对齐。</p>
<p>第二个是全局因素<span class="math inline">\(\boldsymbol u_m\)</span>，这主要是通过对不同片段<span class="math inline">\(\boldsymbol s\)</span>施加不同的权重实现的，于是shapelet <span class="math inline">\(\boldsymbol v\)</span>和时间序列<span class="math inline">\(\boldsymbol t\)</span>的距离可以重写为： <span class="math display">\[
\hat{D}(\boldsymbol v,\boldsymbol t|\boldsymbol w,\boldsymbol u)=\min_{1\leq k\leq m}\boldsymbol u_k\cdot\hat{d}(\boldsymbol v,\boldsymbol s_k|\boldsymbol w)
\]</span> 其中<span class="math inline">\(\boldsymbol t\)</span>被分割为<span class="math inline">\(m\)</span>个片段：<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>。对于分类任务，具体的来说，我们先生成一堆Shapelet候选集，然后通过有监督的方法来挑选最佳的Shapelet和对应的参数<span class="math inline">\(\boldsymbol w\)</span>和<span class="math inline">\(\boldsymbol u\)</span>。</p>
<p>计算shapelet候选集的算法如下：</p>
<p><img src="https://i.loli.net/2020/06/25/srW4Shk79XBFL3U.png" /></p>
<p>在获取了Shapelet候选集合之后，我们有带有标签的时序集合<span class="math inline">\(T\)</span>，对于每一个Shapelet我们可以优化：</p>
<p><span class="math display">\[
\hat{\mathcal L}=-g(S_{pos}(\boldsymbol v,T),S_{neg}(\boldsymbol v,T))+\lambda\parallel \boldsymbol w\parallel+\epsilon\parallel \boldsymbol u\parallel
\]</span></p>
<p>来获取最优的<span class="math inline">\(\hat{\boldsymbol w}\)</span>和<span class="math inline">\(\hat{\boldsymbol u}\)</span>。然后，我们可以挑选出使得<span class="math inline">\(\hat{\mathcal L}\)</span>最小的前<span class="math inline">\(K\)</span>个Shapelet。整个过程的算法流程如下：</p>
<p><img src="https://i.loli.net/2020/06/25/5b2TcjuBzlIFrPm.png" /></p>
<h2 id="shapelet-evolution-graph">Shapelet Evolution Graph</h2>
<p>在获取了Shapelet之后，为了捕获Shapelet之间的相关性，我们定义了<em>Shapelet Evolution Graph</em>。</p>
<blockquote>
<p><strong>Definition 3 Shapelet Evolution Graph. </strong> <em>Shapelet Evolution Graph</em>为一个有向带权图<span class="math inline">\(G=(V,E)\)</span>，<span class="math inline">\(V\)</span>为<span class="math inline">\(K\)</span>个Shapelet，每条带有权重<span class="math inline">\(w_{ij}\)</span>的边<span class="math inline">\(e_{ij}\in E\)</span>代表两个Shapelet <span class="math inline">\(\boldsymbol v_i \in V\)</span>和<span class="math inline">\(\boldsymbol v_j \in V\)</span>被分配给相邻片段的概率。</p>
</blockquote>
<h3 id="graph-construction">Graph Construction</h3>
<p>这里来说一下，建图的具体过程。首先顶点为Shapelet，之后来进行边的构造。对于每一个片段<span class="math inline">\(\boldsymbol s_i\)</span>，我们会计算Shapelet到该片段的距离，距离越近代表这个Shapelet与片段越匹配。之后会设定一个阈值<span class="math inline">\(\delta\)</span>，然后将与片段的距离低于这个阈值的Shapelet分配给这个片段（一个Shapelet可能会分配给多个不同片段）。对于<span class="math inline">\(\boldsymbol s_i\)</span>的所有shapetlet我们记为<span class="math inline">\(\boldsymbol v_{i,*}\)</span>，我们会按照Shape到片段的距离进行归一化：</p>
<p><span class="math display">\[
\boldsymbol p_{i,j}=\frac{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\hat{d}_{i,j}(\boldsymbol v_{i,j},\boldsymbol s_i)}{\max(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))-\min(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i))}
\]</span></p>
<p>其中<span class="math inline">\(\hat{d}_{i,*}(\boldsymbol v_{i,*},\boldsymbol s_i)=\boldsymbol u_*[i]*\hat{d}(\boldsymbol v_{i,*},\boldsymbol s_i|\boldsymbol w_*)&lt;\delta\)</span>。这样对于每个片段<span class="math inline">\(\boldsymbol s_i\)</span>所分配的Shapelet对应的<span class="math inline">\(\boldsymbol p\)</span>之和会等于<span class="math inline">\(1\)</span>。对每一对相邻的片段<span class="math inline">\((\boldsymbol s_i,\boldsymbol s_{i+1})\)</span>的Shapelet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>和<span class="math inline">\(\boldsymbol v_{i+1,k}\)</span>，我们创建一条连接<span class="math inline">\(\boldsymbol v_{*,j}\)</span>和<span class="math inline">\(\boldsymbol v_{*,k}\)</span>的边<span class="math inline">\(e_{j,k}\)</span>，权重为<span class="math inline">\(\boldsymbol p_{i,j}\cdot\boldsymbol p_{i+1,k}\)</span>。最后，所有重复的边会被合并。</p>
<p><img src="https://i.loli.net/2020/07/07/FzGEbWJflHmQa9R.png" style="zoom: 33%;" /></p>
<p>如上图所示，假设有两个片段，每个片段分配了<span class="math inline">\(3\)</span>个Shapelet，Shapelet <span class="math inline">\(B\)</span>在片段<span class="math inline">\(1\)</span>对应的概率是<span class="math inline">\(p_{12}\)</span>，Shapelet <span class="math inline">\(C\)</span>在片段<span class="math inline">\(2\)</span>对应的概率是<span class="math inline">\(p_{23}\)</span>，那么由于片段<span class="math inline">\(1\)</span>和<span class="math inline">\(2\)</span>是相邻片段，会在<span class="math inline">\(B\)</span>和<span class="math inline">\(C\)</span>之间连一条边，边的权重为<span class="math inline">\(p_{12}*p_{23}\)</span>。</p>
<p>建图的算法流程图如下：</p>
<p><img src="https://i.loli.net/2020/06/25/aq9tGuApSbiC67c.png" /></p>
<h2 id="representation-learning">Representation Learning</h2>
<p>之后，我们使用DeepWalk算法来获取获取每个结点（Shapelet）的嵌入表示。对于时序<span class="math inline">\(\boldsymbol t=\{\boldsymbol s_1,\cdots,\boldsymbol s_m\}\)</span>即对应的Shapelet <span class="math inline">\(\{\boldsymbol v_{1,*},\cdots, v_{m,*}\}\)</span>和对应的概率<span class="math inline">\(\{\boldsymbol p_{1,*},\cdots,\boldsymbol p_{m,*}\}\)</span>，每个Shaplet <span class="math inline">\(\boldsymbol v_{i,j}\)</span>的表示记为<span class="math inline">\(\boldsymbol \mu(\boldsymbol v_{i,j})\)</span>。片段<span class="math inline">\(\boldsymbol s_i\)</span>对应的嵌入向量为对应的Shapelet嵌入向量与对应的概率值加权求和：</p>
<p><span class="math display">\[
\boldsymbol\Phi_i=\left(\sum_j p_{i,j}\cdot\boldsymbol \mu(\boldsymbol v_{i,j})\right),\space 1\leq i \leq m
\]</span></p>
<p>算法流程如下：</p>
<p><img src="https://i.loli.net/2020/06/25/O5exTgsVLuRWQ42.png" /></p>
<h1 id="experiments">Experiments</h1>
<h2 id="experimental-setup">Experimental Setup</h2>
<p>文中用了<em>Earthquakes</em> (EQS)、<em>WormsTwoClass</em> (WTC)、<em>Strawberry</em> (STB)、<em>Electricity Consumption Records</em> (ECR)和<em>Network Traffic Flow</em> (NTF) 这五个数据集，其中后两个为作者自己收集的数据集。五个数据集对应的统计信息如下：</p>
<p><img src="https://i.loli.net/2020/06/25/zHjTKkUJB8fGwdi.png" /></p>
<p>文中与多个Baseline进行了比较，包括:</p>
<ul>
<li><strong>Distance-based Models: </strong>文中使用了不同的距离度量与基于1-NN的模型进行组合，包括Euclidean Distance (ED)、Dynamic Time Warping (DTW)、Weighted DTW (WDTW)、Complexity-Invariant Distance (CID) 和 Derivative DTW (DDTW)；</li>
<li><strong>Feature-based Models: </strong>文中分别使用了提取特征（均值、标准差等）和原始序列来训练XGBoost。除此之外，还使用了 Bag-of-Patterns (BoP)、Time Series Forest (TSF)、Elastic Ensembles (EE) 和 基于SAX的 Vector Space Model (SAXVSM)；</li>
<li><strong>Shapelet-based Models: </strong>这部分模型包括 Learn Time Series Shapelets (LS)、Fast Shapelets (FS)、和 Learned Pattern Similarity (LPS)；</li>
<li><strong>Deep Learning Models: </strong>这部分模型包括MLP、LSTM和VAE。</li>
</ul>
<h2 id="comparison-results">Comparison Results</h2>
<p>对于前三个公共数据集评测标准采用Accuracy，后两个数据集因为样本类比不均衡，所以采用了Precision、Recall和F1作为评测标准。结果如下：</p>
<p><img src="https://i.loli.net/2020/06/25/jxKFpDVXdmc5tbE.png" style="zoom:67%;" /></p>
<p>在EQS数据集上，Time2Graph打败了所有Baseline，而在WTC和STB这两个数据集上也达到了较好的效果。在ECR和NTF这两个真实数据集上，Time2Graph在F1上打败了所有Baseline。</p>
<h2 id="parameter-analysis">Parameter Analysis</h2>
<p>本节对Shapelet的数量<span class="math inline">\(K\)</span>、嵌入维度<span class="math inline">\(B\)</span>和片段长度<span class="math inline">\(l\)</span>进行了参数分析。结果如下：</p>
<p><img src="https://i.loli.net/2020/06/25/hPfqAvNnOlEBQuw.png" /></p>
<h2 id="case-study-of-time-aware-shapelets">Case Study of Time-Aware Shapelets</h2>
<p>本节作者对提出的<em>Time-Aware Shapetlet</em>进行了细致的探究。第一个问题是不同Shapelet的区分能力是否不同？下图(a)里，作者在使用Shapelet进行二分类的任务中，将Shapelet按Loss（图中灰色的线）进行排序，并且绘制了对应的正负样本距离的KL散度（橘红色的点）。可以看到，在Loss曲线和KL散度呈反比关系。KL散度越高，我们可以认为该Shapelet的区分度越高，这说明不同Shapelet的区分度的确不同，并且这会与最终效果直接挂钩。图(b)展示了不同Shapelet的均值和方差（原文没有说清楚是什么的均值和方差）。</p>
<p>除此之外，作者和流行的Shapelet提取算法<em>LS</em>进行了比较，如图(c)和图(d)。从图中可以看到对于不同时间，本文的算法提取的Shapelet的确是具有时间动态性的。</p>
<p><img src="https://i.loli.net/2020/06/25/ed5PwksC2l3OWE8.png" /></p>
<h2 id="case-study-of-the-shapelet-evolution-graph">Case Study of the Shapelet Evolution Graph</h2>
<p>本节作者对<em>Shapelet Evolution Graph</em>进行了细致的探究。下图分别为一月份和七月份的<em>Shapelet Evolution Graph</em>。在一月，45号Shapelet的度较大，而且对应的时间因素在一月和二月也较大（图中深色部分）。说明45号Shapelet在一月份具有代表性。而在七月，45号Shapelet的重要性降低，而42号Shapelet在七月的重要性很高。</p>
<p><img src="https://i.loli.net/2020/06/25/N2Vij8ODQaRuALJ.png" /></p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Time-Series/">Time Series</a><a class="link-muted mr-2" rel="tag" href="/tags/Shapelet/">Shapelet</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/22/Probability-Distributions-Binary-and-Multinomial-Variables/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Probability Distributions - Binary and Multinomial Variables</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/"><span class="level-item">Generative Probabilistic Novelty Detection with Adversarial Autoencoders</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>