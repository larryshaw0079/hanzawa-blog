<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Deep Anomaly Detection Using Geometric Transformations - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduction 本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。 Proposed Method Problem Statement 本文考虑针对"><meta property="og:type" content="article"><meta property="og:title" content="Deep Anomaly Detection Using Geometric Transformations"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:description" content="Introduction 本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。 Proposed Method Problem Statement 本文考虑针对"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png"><meta property="og:image" content="https://i.loli.net/2020/06/23/fLkst4i7Hu6PhQl.png"><meta property="og:image" content="https://i.loli.net/2020/06/23/z8MpdeoD6ZGavlN.png"><meta property="og:image" content="https://i.loli.net/2020/06/24/gHZohrvz9MGYmxi.png"><meta property="og:image" content="https://i.loli.net/2020/06/24/8Pi4EKCRuBXrYgp.png"><meta property="article:published_time" content="2020-06-01T15:17:03.000Z"><meta property="article:modified_time" content="2020-06-26T16:25:25.079Z"><meta property="article:author" content="Hanzawa"><meta property="article:tag" content="Anomaly Detection"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/"},"headline":"Deep Anomaly Detection Using Geometric Transformations","image":["https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png","https://i.loli.net/2020/06/23/fLkst4i7Hu6PhQl.png","https://i.loli.net/2020/06/23/z8MpdeoD6ZGavlN.png","https://i.loli.net/2020/06/24/gHZohrvz9MGYmxi.png","https://i.loli.net/2020/06/24/8Pi4EKCRuBXrYgp.png"],"datePublished":"2020-06-01T15:17:03.000Z","dateModified":"2020-06-26T16:25:25.079Z","author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":"Introduction\r 本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。\r Proposed Method\r Problem Statement\r 本文考虑针对"}</script><link rel="canonical" href="https://larryshaw0079.github.io/hanzawa-blog/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-06-01T15:17:03.000Z" title="2020-6-1 11:17:03 ├F10: PM┤">2020-06-01</time>发表</span><span class="level-item"><time dateTime="2020-06-26T16:25:25.079Z" title="2020-6-27 12:25:25 ├F10: AM┤">2020-06-27</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Anomaly-Detection/">Anomaly Detection</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Deep Anomaly Detection Using Geometric Transformations</h1><div class="content"><h1 id="introduction">Introduction</h1>
<p>本文考虑图像数据的异常检测问题。与基于重构的方法不同，本文提出的方法通过对正常图片施加不同的几何变换之后，训练一个多分类器将无监督异常检测问题转化为一个有监督问题。本方法背后的直觉是在训练能够分辨不同变换后的图片之后，分类器一定学得了一些显著的几何特征，这些几何特征是正常类别独有的。</p>
<h1 id="proposed-method">Proposed Method</h1>
<h2 id="problem-statement">Problem Statement</h2>
<p>本文考虑针对图像的异常检测。记<span class="math inline">\(\mathcal X\)</span>为所有自然图像的空间，<span class="math inline">\(X\subseteq\mathcal X\)</span>为正常图像集合。给定数据集<span class="math inline">\(S\subseteq X\)</span>，异常检测的目的是学习一个分类器<span class="math inline">\(h_S(x):\mathcal X\rightarrow\{0,1\}\)</span>，其中<span class="math inline">\(h_S(x)=1\Leftrightarrow x\in X\)</span>。</p>
<p>为了兼顾查准率和查全率，常用的设置是学习一个打分函数<span class="math inline">\(n_S(x):\mathcal X\rightarrow\mathbb R\)</span>，分数越高代表样本属于<span class="math inline">\(X\)</span>的概率越大。之后，通过设定阈值，便可以构建异常分类器： <span class="math display">\[
\begin{align}
h_S^\lambda(x)=
\begin{cases}
1 &amp; n_S(x)\leq\lambda\\
0 &amp; n_S(x)&lt;\lambda
\end{cases}
\end{align}
\]</span></p>
<h2 id="discriminative-learning-of-an-anomaly-scoring-function-using-geometric-transformations">Discriminative Learning of an Anomaly Scoring Function Using Geometric Transformations</h2>
<p>有初始数据集<span class="math inline">\(S\)</span>，几何变换集合<span class="math inline">\(\mathcal T\)</span>，通过对<span class="math inline">\(S\)</span>中每个样本施加这<span class="math inline">\(|\mathcal T|\)</span>个几何变换得到新数据集记为<span class="math inline">\(S_\mathcal{T}\)</span>，且<span class="math inline">\(S_\mathcal{T}\)</span>中每个样本的标签为变换的序号。之后，在<span class="math inline">\(S_\mathcal{T}\)</span>上训练一个<span class="math inline">\(|\mathcal T|\)</span>分类器。在测试阶段，对测试样本同样施加<span class="math inline">\(|\mathcal T|\)</span>个几何变换，分类器会给出经过<span class="math inline">\(\mathrm{softmax}\)</span>的输出向量，最终的异常分数由经过输出的向量构造的分布对数似然得来。</p>
<h3 id="creating-and-learning-the-self-labeled-dataset">Creating and Learning the Self-Labeled Dataset</h3>
<p>设<span class="math inline">\(\mathcal T=\{T_0,T_1,\cdots,T_{k-1}\}\)</span>为几何变换集合，<span class="math inline">\(1\leq i\leq k-1,\space T_i:\mathcal X\rightarrow \mathcal X\)</span>，且<span class="math inline">\(T_0(x)=x\)</span>。<span class="math inline">\(S_\mathcal{T}\)</span>定义为：</p>
<p><span class="math display">\[
S_\mathcal T=\{(T_j(x),j):x\in S,T_j\in\mathcal T\}
\]</span> 对于每个<span class="math inline">\(x\in S\)</span>，<span class="math inline">\(j\)</span>为<span class="math inline">\(T_j(x)\)</span>的标签。我们直接学习一个<span class="math inline">\(K\)</span>类分类器<span class="math inline">\(f_\theta\)</span>，来预测输入样本对应的几何变换种类，这相当于是一个图像分类问题。</p>
<p><img src="https://i.loli.net/2020/06/24/XBFKcPio64u3U1C.png" style="zoom:67%;" /></p>
<h3 id="dirichlet-normality-score">Dirichlet Normality Score</h3>
<p>接下来要做的是如何定义异常分数，记为<span class="math inline">\(n_S(x)\)</span>，这是文中的一个重要的部分。设几何变换集合<span class="math inline">\(\mathcal T=\{T_0,T_1,\cdots,T_{k-1}\}\)</span>，且<span class="math inline">\(k\)</span>分类器<span class="math inline">\(f_\theta\)</span>在<span class="math inline">\(S_\mathcal{T}\)</span>上完成训练。对于任意一个样本<span class="math inline">\(x\)</span>，令<span class="math inline">\(\mathbf y(x)=\text{softmax}(f_{\theta}(x))\)</span>，即分类器<span class="math inline">\(f_\theta\)</span>输出的<span class="math inline">\(\text{softmax}\)</span>之后的向量。异常分数<span class="math inline">\(n_S(x)\)</span>定义为：</p>
<p><span class="math display">\[
n_S(x)=\sum\limits_{i=0}^{k-1}\log p(\mathbf y(T_i(x))|T_i)
\]</span></p>
<p>该异常分数定义为每个类别上，在几何变换<span class="math inline">\(T_i\)</span>的条件下，输出的<span class="math inline">\(\mathbf y\)</span>的对数似然之和。在文中，作者假设<span class="math inline">\(\mathbf y(T_i(x)|T_i\)</span>服从迪利克雷分布：<span class="math inline">\(\mathbf y(T_i(x))|T_i\sim\text{Dir}(\boldsymbol \alpha_i)\)</span>，其中<span class="math inline">\(\boldsymbol \alpha_i\in\mathbb R^k_+\)</span>，<span class="math inline">\(x\sim p_X(x)\)</span>，<span class="math inline">\(i\sim\text{Uni}(0,k-1)\)</span>，而<span class="math inline">\(p_X(x)\)</span>代表正常样本的真实数据分布。于是：</p>
<p><span class="math display">\[
n_S(x)=\sum_{i=0}^{k-1}\left[\log\Gamma(\sum_{j=0}^{k-1}[\tilde{\boldsymbol\alpha}_i]_j)-\sum_{j=0}^{k-1}\log\Gamma([\tilde{\boldsymbol\alpha}_i]_j)+\sum_{j=0}^{k-1}([\tilde{\boldsymbol\alpha}_i]_j-1)\log\mathbf y(T_i(x))_j\right]
\]</span></p>
<p>因为<span class="math inline">\(\tilde{\alpha}_i\)</span>相对于<span class="math inline">\(x\)</span>来说是常数，所以可以直接忽略，于是式子简化为： <span class="math display">\[
n_S(x)=\sum_{i=0}^{k-1}\sum_{j=0}^{k-1}([\tilde{\boldsymbol\alpha}_i]_j-1)\log\mathbf y(T_i(x))_j=\sum_{i=0}^{k-1}(\tilde{\boldsymbol \alpha}_i-1)\cdot\log\mathbf y(T_i(x))
\]</span></p>
<p>注意这里的每个<span class="math inline">\(\boldsymbol \alpha_i\)</span>都是一个向量，即对于每个变换<span class="math inline">\(i\)</span>，都对应一个迪利克雷分布，其参数为<span class="math inline">\(\boldsymbol\alpha_i\)</span>；在对训练集进行第<span class="math inline">\(i\)</span>个几何变换之后，我们得到了<span class="math inline">\(\{T_i(x)\}\)</span>，然后分类器<span class="math inline">\(f_\theta(\cdot)\)</span>的输出<span class="math inline">\(\mathbf y(T_i(x))\)</span>相当于迪利克雷分布的观测值，我们需要根据观测值来估计参数<span class="math inline">\(\boldsymbol \alpha_i\)</span>，然后根据这个参数来计算<span class="math inline">\(n_S(x)\)</span>。对于<span class="math inline">\(\boldsymbol\alpha_i\)</span>，可以知道其第<span class="math inline">\(i\)</span>个分量应该是相对比较大的，下面是运行官方代码得到的<span class="math inline">\(\boldsymbol\alpha_i\)</span>的结果（<span class="math inline">\(i=69\)</span>，<span class="math inline">\(i\)</span>从<span class="math inline">\(0\)</span>开始，总共为<span class="math inline">\(72\)</span>维），可以看到第<span class="math inline">\(69\)</span>个分量是最大的。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[INFO] value of mle_alpha_t:</span><br><span class="line"> [ 0.10228925  0.08997199  0.13083569  0.10862965  0.09811163  0.08527119</span><br><span class="line">  0.17637901  0.27628416  0.12873376  0.19197053  0.11587154  0.09873095</span><br><span class="line">  0.12700618  0.07688542  0.10488203  0.12499191  0.11637607  0.07739511</span><br><span class="line">  0.13049147  0.51031647  0.20546597  0.15558449  0.09288609  0.12134945</span><br><span class="line">  0.09324992  0.14650162  0.16281216  0.11827823  0.08214853  0.15618336</span><br><span class="line">  0.28129761  0.45293697  0.11485838  1.78598954  0.16556983  0.1141158</span><br><span class="line">  0.10909459  0.13916602  0.11563799  0.07309986  0.11049714  0.12974086</span><br><span class="line">  0.15930642  0.13714361  0.13938356  0.70619553  0.11174039  0.07201538</span><br><span class="line">  0.16626109  0.12153727  0.09548811  0.07940956  0.15832209  0.11035474</span><br><span class="line">  0.12487912  0.16937875  0.23212662  0.37041831  0.08557451  0.0839439</span><br><span class="line">  0.09924258  0.39766872  0.14917286  0.08704662  0.09554555  0.31047109</span><br><span class="line">  0.24504759  0.16812463  0.11508187 63.98878807  0.12971073  0.07972932]</span><br></pre></td></tr></table></figure>
<p>下图也展示了对于每个变换<span class="math inline">\(i\)</span>，<span class="math inline">\(\mathbf y(T_i(x)|T_i\)</span>分布的情况：</p>
<p><img src="https://i.loli.net/2020/06/23/fLkst4i7Hu6PhQl.png" style="zoom:67%;" /></p>
<p>作者还给出了一种简化的形式，<span class="math inline">\(\hat{n}_S(x)=\frac{1}{k}\sum^{k-1}_{j=0}[\mathbf y(T_j(x))]_j\)</span>。相当于说，对于每个变换<span class="math inline">\(T_i\)</span>分类器都会给出一个<span class="math inline">\(\text{softmax}\)</span>向量，取其第<span class="math inline">\(i\)</span>个分量<span class="math inline">\([\mathbf y(T_j(x))]_j\)</span>，然后把每个变换对应的<span class="math inline">\([\mathbf y(T_j(x))]_j\)</span>加起来。</p>
<p>整个算法的流程如下：</p>
<p><img src="https://i.loli.net/2020/06/23/z8MpdeoD6ZGavlN.png" style="zoom:67%;" /></p>
<p>这里结合作者的源代码简单说一下检测阶段的流程。</p>
<hr />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> t_ind <span class="keyword">in</span> <span class="built_in">range</span>(transformer.n_transforms):</span><br><span class="line">        observed_dirichlet = mdl.predict(transformer.transform_batch(observed_data, [t_ind] * <span class="built_in">len</span>(observed_data)), batch_size=<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<p>在训练好模型之后，对于训练集的所有样本，对其进行<span class="math inline">\(K\)</span>个几何变换之后，得到<span class="math inline">\(K\)</span>个样本<span class="math inline">\(\{T_i(x)\}\)</span>，对于所有第<span class="math inline">\(i\)</span>个几何变换对应的样本<span class="math inline">\(\{T_i(x)\}\)</span>，通过分类器<span class="math inline">\(f_\theta\)</span>会给出输出<span class="math inline">\(\mathbf y(T_i(x))\)</span>。这里对应算法中的第<span class="math inline">\(7-8\)</span>行，这个<code>observed_dirichlet</code>就是<span class="math inline">\(S_i\)</span>。</p>
<hr />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log_p_hat_train = np.log(observed_dirichlet).mean(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">alpha_sum_approx = calc_approx_alpha_sum(observed_dirichlet)</span><br><span class="line">alpha_0 = observed_dirichlet.mean(axis=<span class="number">0</span>) * alpha_sum_approx</span><br></pre></td></tr></table></figure>
<p>之后这部分主要对应算法中的<span class="math inline">\(9-11\)</span>行。作者把所有的第<span class="math inline">\(i\)</span>个变换，分类器的输出的集合（也就是变量<code>observed_dirichlet</code>）记为<span class="math inline">\(S_i\)</span>，<span class="math inline">\(\bar s\)</span>为<span class="math inline">\(S_i\)</span>的平均，<span class="math inline">\(\bar l\)</span>为<span class="math inline">\(S_i\)</span>对数的平均（变量<code>log_p_hat_train</code>），初始值<span class="math inline">\(\tilde{\alpha}_i\)</span>由<span class="math inline">\(\bar s\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}\)</span>给出（变量<code>alpha_0</code>）。函数<code>calc_approx_alpha_sum</code>实现的是算法中第<span class="math inline">\(11\)</span>行的<span class="math inline">\(\frac{(k-1)(-\Psi(1))}{\bar s\cdot\log\bar s-\bar s\cdot\bar l}\)</span>，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_approx_alpha_sum</span>(<span class="params">observations</span>):</span></span><br><span class="line">    N = <span class="built_in">len</span>(observations)</span><br><span class="line">    f = np.mean(observations, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (N * (<span class="built_in">len</span>(f) - <span class="number">1</span>) * (-psi(<span class="number">1</span>))) / (</span><br><span class="line">        N * np.<span class="built_in">sum</span>(f * np.log(f)) - np.<span class="built_in">sum</span>(f * np.<span class="built_in">sum</span>(np.log(observations), axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>
<hr />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mle_alpha_t = fixed_point_dirichlet_mle(alpha_0, log_p_hat_train)</span><br></pre></td></tr></table></figure>
<p>这里对应算法中的<span class="math inline">\(12-14\)</span>行，即重复<span class="math inline">\(\tilde\alpha_i\leftarrow\Psi^{-1}\left(\Psi(\sum_j[\alpha_i]_j)+\bar l\right)\)</span>来估计<span class="math inline">\(\alpha\)</span>，函数<code>fixed_point_dirichlet_mle</code>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fixed_point_dirichlet_mle</span>(<span class="params">alpha_init, log_p_hat, max_iter=<span class="number">1000</span></span>):</span></span><br><span class="line">    alpha_new = alpha_old = alpha_init</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        alpha_new = inv_psi(psi(np.<span class="built_in">sum</span>(alpha_old)) + log_p_hat)</span><br><span class="line">        <span class="keyword">if</span> np.sqrt(np.<span class="built_in">sum</span>((alpha_old - alpha_new) ** <span class="number">2</span>)) &lt; <span class="number">1e-9</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        alpha_old = alpha_new</span><br><span class="line">    <span class="keyword">return</span> alpha_new</span><br></pre></td></tr></table></figure>
<p><span class="math inline">\(\Psi^{-1}(\cdot)\)</span>是通过数值方法来估计的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inv_psi</span>(<span class="params">y, iters=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="comment"># initial estimate</span></span><br><span class="line">    cond = y &gt;= <span class="number">-2.22</span></span><br><span class="line">    x = cond * (np.exp(y) + <span class="number">0.5</span>) + (<span class="number">1</span> - cond) * <span class="number">-1</span> / (y - psi(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(iters):</span><br><span class="line">        x = x - (psi(x) - y) / polygamma(<span class="number">1</span>, x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<hr />
<p>最后，在得到对<span class="math inline">\(\alpha\)</span>的估计之后，可以来计算测试样本的分数了。这里对应的是算法中的第<span class="math inline">\(16\)</span>行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_test_p = mdl.predict(transformer.transform_batch(x_test, [t_ind] * <span class="built_in">len</span>(x_test)), batch_size=<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">scores += dirichlet_normality_score(mle_alpha_t, x_test_p)</span><br></pre></td></tr></table></figure>
<p>函数<code>dirichlet_normality_score</code>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dirichlet_normality_score</span>(<span class="params">alpha, p</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>((alpha - <span class="number">1</span>) * np.log(p), axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="experiments">Experiments</h1>
<h2 id="baselines">Baselines</h2>
<p>文中用到了如下的Baseline：</p>
<ul>
<li><strong>One-class SVM. </strong>单类支持向量机，作者使用了三个变体，分别为<strong>RAW-OC-SVM</strong>——使用原始数据作为输入，<strong>CAE-OC-SVM</strong>——使用一个卷积自编码器来获得低维表示作为输入和<strong>E2E-OC-SVM</strong>——全名为<strong>One-Class Deep Support Vector Data Description</strong>；</li>
<li><strong>Deep structured energy-based models. </strong></li>
<li><strong>Deep Autoencoding Gaussian Mixture Model. </strong></li>
<li><strong>Generative Adversarial Networks. </strong></li>
</ul>
<h2 id="datasets">Datasets</h2>
<p>文中用到了一下几个数据集：</p>
<ul>
<li><strong>CIFAR-10</strong></li>
<li><strong>CIFAR-100</strong></li>
<li><strong>Fashion-MNIST</strong></li>
<li><strong>CatsVsDogs</strong></li>
</ul>
<p>在实验中所有图片都被归一化到<span class="math inline">\([-1,1]\)</span>的范围。</p>
<h2 id="experimental-protocol">Experimental Protocol</h2>
<p>设数据集有<span class="math inline">\(C\)</span>个类，我们会进行<span class="math inline">\(C\)</span>次实验，在第<span class="math inline">\(c\)</span>次实验 (<span class="math inline">\(1\leq c \leq C\)</span>)中我们会将第<span class="math inline">\(c\)</span>个类作为正常样本，而其他类作为异常样本。在训练阶段，训练集只包含正常样本，而在测试阶段则会有正常样本和异常样本。在获得异常分数之后，阈值<span class="math inline">\(\lambda\)</span>则根据ROC曲线下面积选择。</p>
<p>实验中使用的几何变换基于以下三种基变换：</p>
<ul>
<li><strong>Horizontal flip: </strong> 记为<span class="math inline">\(T_b^{flip}(x)\)</span>，<span class="math inline">\(b\in\{T,F\}\)</span>代表是否翻转；</li>
<li><strong>Translation: </strong> 记为<span class="math inline">\(T_{s_h,s_w}^{trans}(x)\)</span>，其中<span class="math inline">\(s_h,s_w\in\{-1,0,1\}\)</span>。在长宽两个维度上位移分别为<span class="math inline">\(0.25\)</span>高度和<span class="math inline">\(0.25\)</span>宽度，这两个维度发生位移的方向由<span class="math inline">\(s_h\)</span>和<span class="math inline">\(s_w\)</span>决定，当<span class="math inline">\(s_h=s_w=0\)</span>时代表不移动；</li>
<li><strong>Rotation by multiples 90 degrees: </strong> 记为<span class="math inline">\(T_k^{rot}(x)\)</span>，<span class="math inline">\(k\in\{0,1,2,3\}\)</span>。旋转<span class="math inline">\(k\times90\)</span>度。</li>
</ul>
<p>将三种基变换叠加有： <span class="math display">\[
\mathcal T=\left\{
 T_k^{rot}\circ T_{s_h,s_w}^{trans}\circ T_b^{flip} : \begin{matrix}
 b &amp;\in \{T,F\}\\
 s_h,s_w&amp;\in\{-1,0,1\}\\
 k&amp;\in\{0,1,2,3\}
 \end{matrix} 
\right\}
\]</span> 最终几何变换种数为<span class="math inline">\(2\times3\times3\times4=72\)</span>种。</p>
<p>分类器模型使用的是<strong>Wide Residual Network</strong>，优化器为Adam，Batch size为128，训练轮数为200。</p>
<h2 id="results">Results</h2>
<p>下面是不同方法在不同数据集上的实验结果：</p>
<p><img src="https://i.loli.net/2020/06/24/gHZohrvz9MGYmxi.png" /></p>
<p>评测标准使用的是AUROC。作者关于结果的分析主要有以下几点：</p>
<ol type="1">
<li>在绝大多数情况下，我们的算法都比Baseline要好，而且是越大的数据集效果越好。CatsVsDogs数据集每张图片的大小比其他几个数据集都要大，而Baseline在这个数据集上的结果都在<span class="math inline">\(50\%\)</span>或不到<span class="math inline">\(50\%\)</span>，这基本等同于瞎猜；</li>
<li>在CIFAR-100数据集里，由于将这100类聚合为了20类，所以存在类内样本差异大的问题。比如在类<span class="math inline">\(5\)</span>、类<span class="math inline">\(7\)</span>和类<span class="math inline">\(13\)</span>上，模型表现就不够好；</li>
<li>在Fashion-MNIST数据集上几乎所有方法（除了DAGMM）都表现很好。</li>
</ol>
<h2 id="on-the-intuition-for-using-geometric-transformations">On the Intuition for Using Geometric Transformations</h2>
<p>这里作者对所选用的几何变换做了一些解释。实验中选用的三种基本几何变换都是可逆的线性几何变换（且为双射），作者也试过一些复杂的非线性变换，如高斯模糊、锐化、伽马校正等等，但是效果并不好。</p>
<p>作者认为分类器能够分辨不同变换的能力与最终性能成正比，为了验证这一点，进行了<span class="math inline">\(3\)</span>个实验。从MNIST数据集选择一个数字作为正常样本，几何变换只采用两个，然后选择另一个数字作为异常样本，结果如下：</p>
<ul>
<li><strong>Normal digit: 8，Anomaly: 3，Transformations: Identity and horizontal flip. </strong>由于数字<span class="math inline">\(8\)</span>是对称的，所以要让分类器分辨原始的<span class="math inline">\(8\)</span>和翻转之后的<span class="math inline">\(8\)</span>是很难的，AUROC只有<span class="math inline">\(0.646\)</span>；</li>
<li><strong>Normal digit: 3，Anomaly: 8，Transformations: Identity and horizontal flip. </strong>这里把<span class="math inline">\(3\)</span>作为正常样本，由于<span class="math inline">\(3\)</span>不是对称的，所以两种变换是可以分辨的，AUROC达到了<span class="math inline">\(0.957\)</span>；</li>
<li><strong>Normal digit: 8，Anomaly: 3，Transformations: Identity and translation by 7 pixels. </strong>同样是把<span class="math inline">\(8\)</span>作为正常样本，但变换用的是平移，AUROC达到了<span class="math inline">\(0.919\)</span>。</li>
</ul>
<p>除此之外，作者还设计了一个实验，目的是测试什么样的图像会获得较高的分数<span class="math inline">\(n_S(x)\)</span>。在给定训练好的分类器的情况下，优化输入的图像，目标函数是最大化分数<span class="math inline">\(n_S(x)\)</span>。下图为实验结果：</p>
<p><img src="https://i.loli.net/2020/06/24/8Pi4EKCRuBXrYgp.png" /></p>
<p>在左图中，将数字<span class="math inline">\(3\)</span>作为正常样本训练的分类器、原始输入为数字<span class="math inline">\(0\)</span>的图片时，随着优化的进行，图片慢慢地变得像数字<span class="math inline">\(3\)</span>。在右图中，同样是将数字<span class="math inline">\(3\)</span>作为正常样本训练的分类器，不过原始输入也是数字<span class="math inline">\(3\)</span>，这时图像却没有怎么变化。</p>
<h1 id="remark">Remark</h1>
<ul>
<li>文中提到的在CIFAR100数据的实验上，由于类间差异比较大导致效果较差，那么很自然地，不同的变换样本对应的集簇实际上应当足够分开，集簇内的样本要足够进，这样对于分类器来说才能比较好的分类。不过采用的几何变换并没有针对这一点进行特别设计；</li>
<li>文中强调了所使用的变换为几何变换，其实除此之外，所使用的变换还都是可以用矩阵表示的可逆的变换。</li>
</ul>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Anomaly-Detection/">Anomaly Detection</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/02/Ubuntu20-4LTS-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-CUDA11-cuDNN8-Tensorflow-Pytorch/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Ubuntu20.04LTS 深度学习环境配置 CUDA11 + cuDNN8 + Tensorflow + Pytorch</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/06/01/Cross-dataset-Time-Series-Anomaly-Detection-for-Cloud-Systems/"><span class="level-item">Cross-dataset Time Series Anomaly Detection for Cloud Systems</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>