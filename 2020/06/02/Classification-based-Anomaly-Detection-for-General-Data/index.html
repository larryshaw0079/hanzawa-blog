<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Classification-based Anomaly Detection for General Data - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduction 本文主要是对NIPS18这篇异常检测文章的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：  Reconstruction Methods： 这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误"><meta property="og:type" content="article"><meta property="og:title" content="Classification-based Anomaly Detection for General Data"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:description" content="Introduction 本文主要是对NIPS18这篇异常检测文章的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：  Reconstruction Methods： 这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png"><meta property="og:image" content="https://i.loli.net/2020/06/24/j4Y29tB6k1Aipgo.png"><meta property="og:image" content="https://i.loli.net/2020/06/24/D3opwrLnSGmcsyM.png"><meta property="og:image" content="https://i.loli.net/2020/06/24/e6PfIDOVwlzrSWi.png"><meta property="article:published_time" content="2020-06-02T15:01:34.000Z"><meta property="article:modified_time" content="2020-06-26T12:55:43.589Z"><meta property="article:author" content="Hanzawa"><meta property="article:tag" content="Anomaly Detection"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/"},"headline":"Classification-based Anomaly Detection for General Data","image":["https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png","https://i.loli.net/2020/06/24/j4Y29tB6k1Aipgo.png","https://i.loli.net/2020/06/24/D3opwrLnSGmcsyM.png","https://i.loli.net/2020/06/24/e6PfIDOVwlzrSWi.png"],"datePublished":"2020-06-02T15:01:34.000Z","dateModified":"2020-06-26T12:55:43.589Z","author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":"Introduction\r 本文主要是对NIPS18这篇异常检测文章的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：\r \r Reconstruction Methods： 这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误"}</script><link rel="canonical" href="https://larryshaw0079.github.io/hanzawa-blog/2020/06/02/Classification-based-Anomaly-Detection-for-General-Data/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-06-02T15:01:34.000Z" title="2020-6-2 11:01:34 ├F10: PM┤">2020-06-02</time>发表</span><span class="level-item"><time dateTime="2020-06-26T12:55:43.589Z" title="2020-6-26 8:55:43 ├F10: PM┤">2020-06-26</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Anomaly-Detection/">Anomaly Detection</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Classification-based Anomaly Detection for General Data</h1><div class="content"><h1 id="introduction">Introduction</h1>
<p>本文主要是对<a target="_blank" rel="noopener" href="http://qfxiao.me/2020/06/01/Deep-Anomaly-Detection-Using-Geometric-Transformations/">NIPS18这篇异常检测文章</a>的改进，首先是利用了标签信息来提升算法的表现，其次是将算法扩展到了非图像数据。作者对现有的异常检测算法进行了回顾：</p>
<ul>
<li><strong>Reconstruction Methods： </strong>这一部分方法假设异常样本和正常样本能够通过重构任务来进行区分。通过在正常样本上学习重构任务，之后对于正常样本，模型能够很好地进行重构，而异常样本则会有较高的重构误差。</li>
<li><strong>Distributional Methods： </strong>这一部分方法将异常检测看作是密度估计问题。通过对正常样本的分布进行估计，异常样本在该正常分布下的似然将会很低。</li>
<li><strong>Classification-based Methods： </strong>这一部分方法主要是指的单分类方法和通过几何变换构造分类任务的方法。本文使用的就是这类方法。</li>
</ul>
<h1 id="proposed-method">Proposed Method</h1>
<h2 id="classification-based-anomaly-detection">Classification-based Anomaly Detection</h2>
<p>假设所有数据位于空间<span class="math inline">\(R^L\)</span>内，而正常数据位于子空间<span class="math inline">\(X\subset R^L\)</span>内。我们假设所有的异常样本位于<span class="math inline">\(X\)</span>之外。为了检测异常，我们希望学习一个分类器<span class="math inline">\(C\)</span>使得对于所有的<span class="math inline">\(x\in X\)</span>有<span class="math inline">\(C(x)=1\)</span>，而对所有的<span class="math inline">\(x\in R^L\backslash X\)</span>有<span class="math inline">\(C(x)=0\)</span>。</p>
<p>单分类方法的思想是直接学习<span class="math inline">\(P(x\in X)\)</span>，代表的方法有One-Class SVM，DSVDD等。传统的OC-SVM直接在原始空间或者核空间学习分类器。比较新的方法，如Deep-SVDD则是先将样本转换到一个特征空间，然后在这个特征空间上学习使得半径<span class="math inline">\(R\)</span>最小的超球体（球心<span class="math inline">\(c_0\)</span>），来覆盖住所有正常样本。异常的判定则通过计算<span class="math inline">\(\parallel f(x)-c_0\parallel^2-R^2\)</span>来实现。不过学习一个好的样本到特征空间的变换并不是一件容易的事情，比如说<span class="math inline">\(f(x)=0, \forall x \in X\)</span>就是一个使得超球体最小的解。所以需要很多trick来避免诸如此类的情况。</p>
<p><em>Geometric-transformation classification</em> (GEOM) 则将数据空间<span class="math inline">\(X\)</span>通过<span class="math inline">\(M\)</span>个几何变换转换到一系列子空间<span class="math inline">\(X_1,\cdots,X_M\)</span>。之后训练一个分类器来预测样本<span class="math inline">\(T(x,m)\)</span>对应的几何变换的种类<span class="math inline">\(m\)</span>。转换后的正常图片空间记为<span class="math inline">\(\cup_m X_m\)</span>，所以该方法尝试估计以下条件概率： <span class="math display">\[
P(m^\prime|T(x,m))=\frac{P(T(x,m)\in X_{m^\prime})P(m^\prime)}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})P(\tilde{m})}-\frac{P(T(x,m)\in X_{m^\prime})}{\sum_{\bar{m}}P(T(x,m)\in X_{\bar{m}})}
\]</span></p>
<p>对于异常的样本<span class="math inline">\(x\in R^L\backslash X\)</span>，在经过几何变换之后，都不会位于正确的子空间中，即<span class="math inline">\(T(x,m)\in R^L\backslash X_m\)</span>。之后，使用<span class="math inline">\(P(m|T(x,m))\)</span>来判定异常。</p>
<p>作者认为，这种方法的问题是分类器<span class="math inline">\(P(m^\prime|T(x,m))\)</span>只在正常数据上训练，而对于异常样本的异常分数会出现方差很大的问题。</p>
<p>一种解决方式是加入异常样本进行训练，但是作者认为在有的任务中标签很难获取，于是作者使用了另外一种方法来解决这个问题。</p>
<h2 id="distance-based-multiple-transformation-classification">Distance-based Multiple Transformation Classification</h2>
<p>和GEOM一样，先对每个样本进行<span class="math inline">\(M\)</span>个几何变换，然后学习一个特征提取器<span class="math inline">\(f(x)\)</span>，将<span class="math inline">\(X_m\)</span>映射到特征空间。之后和OC-SVM类似，假设特征<span class="math inline">\(\{f(x)|x\in X_m\}\)</span>为球心为<span class="math inline">\(c_m=\frac{1}{N}\sum_{x\in X} f(T(x,m))\)</span>的超球体。样本属于某一类<span class="math inline">\(m^\prime\)</span>的概率由下式给出：</p>
<p><span class="math display">\[
P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2}}{\sum_{\bar m}e^{-\parallel f(T(x,m))-c_{\bar m}\parallel^2}}
\]</span></p>
<p>目标函数采用的是Triplet Loss：</p>
<p><span class="math display">\[
L=\sum_i\max(\parallel f(T(x_i,m))-c_m\parallel^2+s-\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2,0)
\]</span></p>
<p><span class="math inline">\(\parallel f(T(x_i,m))-c_m\parallel^2\)</span>相当于最小化了类内距离，<span class="math inline">\(\min_{m^\prime\neq m}\parallel f(T(x_i,m))-c_{m^\prime}\parallel^2\)</span>最大化了每个类对应的集簇间距离。在检测阶段，为了避免一些数值问题，作者做了一些平滑操作：</p>
<p><span class="math display">\[
\tilde P(m^\prime|T(x,m))=\frac{e^{-\parallel f(T(x,m))-c_{m^\prime}\parallel^2+\epsilon}}{\sum_{\tilde m}e^{-\parallel f(T(x,m))-c_{\tilde m}\parallel^2+M\cdot\epsilon}}
\]</span></p>
<p>最后的评判分数由下式给出：</p>
<p><span class="math display">\[
Score(x)=-\log P(x\in X)=-\sum_m\log \tilde{P}(T(x,m)\in X_m)=-\sum_m\log\tilde{P}(m|T(x,m))
\]</span></p>
<p>算法流程图如下：</p>
<p><img src="https://i.loli.net/2020/06/24/r48h1RJxcXF6YDM.png" style="zoom:67%;" /></p>
<h2 id="parameterizing-the-set-of-transformations">Parameterizing the Set of Transformations</h2>
<p>在GEOM中，由于使用的几何变换都是针对图像的，所以对于其他类型的数据并不适用。本文中作者对非图像数据设计了以下变换：</p>
<p><span class="math display">\[
T(x,m)=W_mx+b_m
\]</span></p>
<p>不同的参数<span class="math inline">\(W_m\)</span>和<span class="math inline">\(b_m\)</span>即为不同的几何变换，可以考虑采用随机采样的方式。</p>
<h1 id="experiments">Experiments</h1>
<h2 id="image-experiments">Image Experiments</h2>
<p>对于图像数据的异常检测实验，作者采用了CIFAR10、FasionMNIST这两个数据集，实验结果如下：</p>
<p><img src="https://i.loli.net/2020/06/24/j4Y29tB6k1Aipgo.png" style="zoom:67%;" /></p>
<p><img src="https://i.loli.net/2020/06/24/D3opwrLnSGmcsyM.png" style="zoom:67%;" /></p>
<h2 id="tabular-data-experiments">Tabular Data Experiments</h2>
<p>对于非图像数据，作者采用了几个小的数据集：Arrhythmia、Thyroid、KDD和KDDRev。采用的Baseline包括OC-SVM、E2E-AE、LOF、DAGMM和FB-AE (Feature Bagging Autoencoder)。对于几何变换的参数，采样自标准正态分布。结果如下：</p>
<p><img src="https://i.loli.net/2020/06/24/e6PfIDOVwlzrSWi.png" style="zoom:67%;" /></p>
<h1 id="remark">Remark</h1>
<p>结合<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=H1lK_lBtvS">OpenReview</a>上的一些讨论，这里提出一些问题和总结：</p>
<ul>
<li>KDD数据集太简单了，正常、异常样本能够很容易被分开；</li>
<li>对于图像数据作者只使用了CIFAR10和FashionMNIST这两个比较小的数据集，而在GEOM中还使用了CIFAR100和CatsVsDogs。并且GEOM原文中提到数据集（指图像大小）越大，GEOM的优势就越明显，所以在本文的实验中只使用这两个数据集说服力略显不够；</li>
<li>关于评测标准的问题，作者在图像数据中用的是AUROC，而非图像数据用的是F1 score。像AUPR、AUROC这种评测标准往往更加全面，而F1 score依赖于阈值的选取。如果是遍历阈值找到最好的那个F1 score，则无法全面考察模型的鲁棒性，模型有可能只是在特定的阈值下表现很好，而阈值稍微偏差一下性能可能就会大幅下降。我看到的大多数异常检测文章都是使用AUROC或者F1加上AUROC作为评测指标；</li>
<li>文中在第二节“CLASSIFICATION-BASED ANOMALY DETECTION”的末尾两段关于GEOM方法的缺点说的很模糊。异常分数的方差大到底指的是什么；</li>
<li>关于作者提出的变换<span class="math inline">\(T(x,m)=W_mx+b_m\)</span>并没有用到图像数据的实验上，而且在实验中<span class="math inline">\(b_m\)</span>这个参数实际上是被忽略掉了的，<span class="math inline">\(b_m\)</span>的作用究竟如何不得而知。而且GEOM中的几何变换的Motivation在原文中是做了实验充分讨论了的，GEOM的作者认为这些几何变换保留了图像的高阶语义信息。而本文中的变换中的参数只是随机采样而来，并不存在说保留原始数据中的结构信息。如果忽略掉这一层变换，那就类似于加了神经网络提取特征的OC-SVM。</li>
</ul>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Anomaly-Detection/">Anomaly Detection</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/06/Generative-Probabilistic-Novelty-Detection-with-Adversarial-Autoencoders/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Generative Probabilistic Novelty Detection with Adversarial Autoencoders</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/06/02/%E9%9D%A2%E5%90%91OpenPAI%E7%9A%84Docker%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE%E5%8F%8AOpenPAI%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"><span class="level-item">面向OpenPAI的Docker镜像配置及OpenPAI基本使用方法</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>