<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Complementary Set Variational Autoencoder for Supervised Anomaly Detection - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduction对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。 Proposed ModelConventional VAE首先回顾一下原始的VAE。 原始VAE中的损失函数为：$$"><meta property="og:type" content="article"><meta property="og:title" content="Complementary Set Variational Autoencoder for Supervised Anomaly Detection"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:description" content="Introduction对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。 Proposed ModelConventional VAE首先回顾一下原始的VAE。 原始VAE中的损失函数为：$$"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/06/25/vrxAzRVCtaE3oLc.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/QHXo24cKj9uRwzW.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/wrmzADXtsyuJ6EZ.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/ifcIxr9zOpEhksA.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/YTpO98y1ZPmAK3g.png"><meta property="article:published_time" content="2020-01-09T02:15:03.000Z"><meta property="article:modified_time" content="2020-06-25T05:25:53.385Z"><meta property="article:author" content="Hanzawa"><meta property="article:tag" content="Anomaly Detection"><meta property="article:tag" content="VAE"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/06/25/vrxAzRVCtaE3oLc.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"},"headline":"Complementary Set Variational Autoencoder for Supervised Anomaly Detection","image":["https://i.loli.net/2020/06/25/vrxAzRVCtaE3oLc.png","https://i.loli.net/2020/06/25/QHXo24cKj9uRwzW.png","https://i.loli.net/2020/06/25/wrmzADXtsyuJ6EZ.png","https://i.loli.net/2020/06/25/ifcIxr9zOpEhksA.png","https://i.loli.net/2020/06/25/YTpO98y1ZPmAK3g.png"],"datePublished":"2020-01-09T02:15:03.000Z","dateModified":"2020-06-25T05:25:53.385Z","author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":"Introduction对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。 Proposed ModelConventional VAE首先回顾一下原始的VAE。 原始VAE中的损失函数为：$$"}</script><link rel="canonical" href="https://larryshaw0079.github.io/hanzawa-blog/2020/01/09/Complementary-Set-Variational-Autoencoder-for-Supervised-Anomaly-Detection/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-01-09T02:15:03.000Z" title="2020-1-9 10:15:03 ├F10: AM┤">2020-01-09</time>发表</span><span class="level-item"><time dateTime="2020-06-25T05:25:53.385Z" title="2020-6-25 1:25:53 ├F10: PM┤">2020-06-25</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Anomaly-Detection/">Anomaly Detection</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Complementary Set Variational Autoencoder for Supervised Anomaly Detection</h1><div class="content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对于异常检测问题，异常的模式是多种多样的。有监督模型能够较好地处理训练集中出现过的模式，无监督模型能够处理训练集中未出现过的模式，但对于训练集中出现过的异常模型并没有学习。本文提出了一种既能学习训练集中出现过的异常模式，同时能处理未出现过的异常模式的方法。</p>
<h1 id="Proposed-Model"><a href="#Proposed-Model" class="headerlink" title="Proposed Model"></a>Proposed Model</h1><h2 id="Conventional-VAE"><a href="#Conventional-VAE" class="headerlink" title="Conventional VAE"></a>Conventional VAE</h2><p>首先回顾一下原始的VAE。</p>
<p>原始VAE中的损失函数为：<br>$$<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})=\mathbb{E}<em>{q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})}[\log p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})]-\text{KL}[q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi}\parallel p(\boldsymbol{z}))]<br>$$<br>原文中作者证明了$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\leq\log p(\boldsymbol{x};\boldsymbol{\theta})$，所以$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})$可以看作是数据分布$p(\boldsymbol{x})$对数似然的一个下界。$\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})$又被称为证据下界 (ELBO)。$\mathbb{E}</em>{q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})}[\log p(\boldsymbol{x}|\boldsymbol{z};\boldsymbol{\theta})]$中的期望一般用蒙特卡洛来进行估计：<br>$$<br>\begin{align}<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\simeq&amp; \frac{1}{L}\sum\limits_l\log p(\boldsymbol{x}|\boldsymbol{z}^{(l)};\boldsymbol{\theta})-\text{KL}[q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi})\parallel p(\boldsymbol{z})],\<br>\boldsymbol{z}^{(l)}&amp;\sim q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\phi}), \space l\in{1,2,\cdots,L}<br>\end{align}<br>$$<br>对于隐变量$\boldsymbol{z}$，一般假设先验服从标准高斯分布，后验服从均值为$\mu$，方差为$\sigma^2$的高斯分布，故KL散度能直接写出解析式：<br>$$<br>\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi};\boldsymbol{x})\simeq \frac{1}{L}\sum\limits_l\log p(\boldsymbol{x}|\boldsymbol{z}^{(l)};\boldsymbol{\theta})-C(-\frac{1}{2}-\log\sigma+\frac{1}{2}\sigma^2+\frac{1}{2}\mu^2)<br>$$<br>使用VAE来做异常检测通常是在正常数据上进行训练，在检测阶段，如果是异常样本，那么VAE不能很好地重构它，这样会导致较大的重构误差。</p>
<h2 id="Prior-Distribution-for-Anomalies"><a href="#Prior-Distribution-for-Anomalies" class="headerlink" title="Prior Distribution for Anomalies"></a>Prior Distribution for Anomalies</h2><img src="https://i.loli.net/2020/06/25/vrxAzRVCtaE3oLc.png" style="zoom:67%;" />

<p>在原始VAE异常检测中，无论输入样本$\boldsymbol{x}$是否异常，VAE都会使对应编码的后验$p(\boldsymbol{z}|\boldsymbol{x})$服从高斯分布，且施加标准高斯分布的约束。在本文中，作者对异常和正常样本对应的隐变量的先验分布做了不同假设。首先，正常先验依然是标准高斯分布，记为$p_n(\boldsymbol{z})$。而对于异常先验，作者认为异常即为“不正常”，和正常是补集的关系。作者在文中定义异常先验分布$p_a(\boldsymbol{z})$为：<br>$$<br>p_a(\boldsymbol{z})=\frac{1}{Y^\prime}(\max\limits_{\boldsymbol{z}^\prime}p_n(\boldsymbol{z}^\prime)-p_n(\boldsymbol{z}))<br>$$</p>
<p>其中$Y^\prime$为使$p_a(\boldsymbol{z})$成为一个概率分布的调节因子。实际上，$Y^\prime$往往会成为无限大，因为$p(\boldsymbol z)$在整个定义域上都有定义。为了解决这个问题，作者加入了$p_w(\boldsymbol z)$，一个在每个维度都足够宽的辅助分布：</p>
<p>$$<br>p_a(\boldsymbol z)=\frac{1}{Y}p_w(\boldsymbol z)\left(\max\limits_{\boldsymbol z^\prime}p_n(\boldsymbol z^\prime)-p_n(\boldsymbol z)\right)<br>$$</p>
<p>其中$Y$为有限的常数。在文中$p_n(\boldsymbol z)$和$p_w(\boldsymbol z)$都为高斯分布，那么$p_a(\boldsymbol z)$的具体形式为：</p>
<p>$$<br>p_a(\boldsymbol z)=\frac{1}{Y}\mathcal{N}(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2){\max\limits_{\boldsymbol z^\prime}\mathcal N(\boldsymbol z^\prime;\boldsymbol 0,\boldsymbol 1)-\mathcal N(\boldsymbol z;\boldsymbol 0,\boldsymbol 1)}<br>$$</p>
<p>其中：</p>
<p>$$<br>\max\limits_{\boldsymbol z^\prime}\mathcal N(\boldsymbol z^\prime;\boldsymbol 0,\boldsymbol 1)=\frac{1}{\sqrt{2\pi}}<br>$$</p>
<p>$$<br>Y=\int_{-\infty}^{\infty}p_a(\boldsymbol z)\mathrm{d}\boldsymbol z=\frac{1}{\sqrt{2\pi}}\left{1-\frac{1}{\boldsymbol s^2+1}\right}<br>$$</p>
<p>$\boldsymbol s^2$为超参数，控制分布的宽度。用文中的先验替换VAE原始的KL散度，可写为：</p>
<p>$$<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]=\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\frac{\mathcal N(\boldsymbol z;\boldsymbol\mu,\boldsymbol\sigma^2)}{\frac{1}{Y}\mathcal N(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2)\left{\frac{1}{2\pi}-\mathcal N(\boldsymbol z;\boldsymbol0,\boldsymbol 1)\right}}\mathrm{d}\boldsymbol z<br>$$</p>
<p>展开后：</p>
<p>$$<br>\begin{align}<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]&amp;=<br>\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\mathcal{N}(\boldsymbol z;\boldsymbol\mu,\boldsymbol\sigma^2)\mathrm{d}\boldsymbol z\<br>&amp;+\log Y\<br>&amp;-\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\mathcal{N}(\boldsymbol z;\boldsymbol 0,\boldsymbol s^2)\mathrm{d}\boldsymbol z\<br>&amp;-\int_{-\infty}^\infty\mathcal{N}(\boldsymbol z;\boldsymbol \mu,\boldsymbol \sigma^2)\log\left{\frac{1}{\sqrt{2\pi}}-\mathcal{N}(\boldsymbol z;\boldsymbol 0, \boldsymbol 1)\right}\mathrm{d}\boldsymbol z<br>\end{align}<br>$$</p>
<p>使用泰勒展开，$\log (x+\frac{1}{2\pi})\simeq-\log 2\pi+2\pi x$，KL散度可以用下式估计：</p>
<p>$$<br>\begin{align}<br>\text{KL}\left[q(\boldsymbol z|\boldsymbol x;\phi)\parallel p_a(\boldsymbol z)\right]&amp;\simeq\sqrt{\frac{2\pi}{\boldsymbol\sigma^2+1}}\exp\left(\frac{-\boldsymbol\mu^2}{2(\boldsymbol\sigma^2+1)}\right)\<br>&amp;+\frac{\boldsymbol\mu^2+\boldsymbol\sigma^2}{2\boldsymbol s^2}-\log\boldsymbol\sigma+\log\boldsymbol s+\log\left(\sqrt{\boldsymbol s^2+1}-1\right)\<br>&amp;-\frac{\log(\boldsymbol s^2+1)}{2}+\frac{\log(2\pi)-1}{2}<br>\end{align}<br>$$</p>
<p>下图为一维时$p_n(\boldsymbol z)$和$p_a(\boldsymbol z)$的示例：</p>
<img src="https://i.loli.net/2020/06/25/QHXo24cKj9uRwzW.png" style="zoom:67%;" />

<h3 id="Implementation-of-proposed-method"><a href="#Implementation-of-proposed-method" class="headerlink" title="Implementation of proposed method"></a>Implementation of proposed method</h3><p>文中使用编码器输出的分布$\mathcal{N}(\boldsymbol z;\boldsymbol \mu, \boldsymbol \sigma^2)$与标准正态分布之间的KL散度来作为异常分数。在每一轮的训练过程中，加入一轮使用Anomaly Prior的训练。</p>
<img src="https://i.loli.net/2020/06/25/wrmzADXtsyuJ6EZ.png" style="zoom:67%;" />

<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h2><p>作者设计了两个Task：</p>
<ol>
<li>Task 1. $N$ vs. $\bar{N}$. 将手写数字中的一个作为已知异常，其他作为正常，并加入均匀分布作为未知的异常。</li>
<li>Task 2. 手写数字被分为3组：已知异常，正常，未知异常。</li>
</ol>
<p>细节如下表所示：</p>
<img src="https://i.loli.net/2020/06/25/ifcIxr9zOpEhksA.png" style="zoom:67%;" />

<p>在实现上，使用Adam优化器，<code>batch_size</code>为100，<code>epochs</code>为200。<code>Encoder</code>和<code>Decoder</code>都由三层感知机组成，超参数$s^2$设置为400。评测标准使用AUC (area under the receiver characteristic curve)。</p>
<p>下表为实验结果：</p>
<img src="https://i.loli.net/2020/06/25/YTpO98y1ZPmAK3g.png" style="zoom:67%;" /></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Anomaly-Detection/">Anomaly Detection</a><a class="link-muted mr-2" rel="tag" href="/tags/VAE/">VAE</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/01/31/Geant4-%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Geant4 安装教程与调试环境配置</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/"><span class="level-item">Anomaly Detection in Streams with Extreme Value Theory</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>