<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>GAIN: Missing Data Imputation using Generative Adversarial Nets - Hanzawa の 部屋</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hanzawa の 部屋"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Abstract本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器$G$从隐空间$Z$生成完整的样本，而判别器$D$则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。 原文 MethodologyProblem Formulation考虑一个$d$维的空"><meta property="og:type" content="article"><meta property="og:title" content="GAIN: Missing Data Imputation using Generative Adversarial Nets"><meta property="og:url" content="https://larryshaw0079.github.io/hanzawa-blog/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"><meta property="og:site_name" content="Hanzawa の 部屋"><meta property="og:description" content="Abstract本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器$G$从隐空间$Z$生成完整的样本，而判别器$D$则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。 原文 MethodologyProblem Formulation考虑一个$d$维的空"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/06/25/wCK3J8MoTASrj9Y.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/znABi6x9mJuvDOX.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/EenX2YO8aDxQAk3.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/PzeWKdGu4wADshV.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/IKtoTj8xgG1yJDk.png"><meta property="og:image" content="https://i.loli.net/2020/06/25/uy2jPcnbtSrC6vI.png"><meta property="article:published_time" content="2019-10-16T12:19:10.000Z"><meta property="article:modified_time" content="2020-06-25T05:38:07.244Z"><meta property="article:author" content="Hanzawa"><meta property="article:tag" content="Time Series"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="GAN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://i.loli.net/2020/06/25/wCK3J8MoTASrj9Y.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://larryshaw0079.github.io/hanzawa-blog/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"},"headline":"GAIN: Missing Data Imputation using Generative Adversarial Nets","image":["https://i.loli.net/2020/06/25/wCK3J8MoTASrj9Y.png","https://i.loli.net/2020/06/25/znABi6x9mJuvDOX.png","https://i.loli.net/2020/06/25/EenX2YO8aDxQAk3.png","https://i.loli.net/2020/06/25/PzeWKdGu4wADshV.png","https://i.loli.net/2020/06/25/IKtoTj8xgG1yJDk.png","https://i.loli.net/2020/06/25/uy2jPcnbtSrC6vI.png"],"datePublished":"2019-10-16T12:19:10.000Z","dateModified":"2020-06-25T05:38:07.244Z","author":{"@type":"Person","name":"Hanzawa"},"publisher":{"@type":"Organization","name":"Hanzawa の 部屋","logo":{"@type":"ImageObject"}},"description":"Abstract本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器$G$从隐空间$Z$生成完整的样本，而判别器$D$则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。 原文 MethodologyProblem Formulation考虑一个$d$维的空"}</script><link rel="canonical" href="https://larryshaw0079.github.io/hanzawa-blog/2019/10/16/GAIN-Missing-Data-Imputation-using-Generative-Adversarial-Nets/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Hanzawa の 部屋" type="application/atom+xml">
</head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Hanzawa の 部屋</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-10-16T12:19:10.000Z" title="2019-10-16 8:19:10 ├F10: PM┤">2019-10-16</time>发表</span><span class="level-item"><time dateTime="2020-06-25T05:38:07.244Z" title="2020-6-25 1:38:07 ├F10: PM┤">2020-06-25</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/Research/">Research</a><span> / </span><a class="link-muted" href="/categories/Research/Time-Series-Imputation/">Time Series Imputation</a></span></div></div><h1 class="title is-3 is-size-4-mobile">GAIN: Missing Data Imputation using Generative Adversarial Nets</h1><div class="content"><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文基于GAN提出了一种时间序列缺失值填充（Time Series Imputation）的方法。其主要的思路为生成器$G$从隐空间$Z$生成完整的样本，而判别器$D$则输出样本中不同部分为真实的概率。除此之外，作者提出了使用Hint Vector来揭示原始数据中缺失部分的信息，来优化训练过程。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.02920">原文</a></p>
<h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><p>考虑一个$d$维的空间$\mathcal{X}=\mathcal{X}_1\times \cdots\times \mathcal{X}_d$，设$\mathbf{X}=(X_1,\cdots,X_d)$维空间$\mathcal{X}$上的随机向量（即理想的完整的时间序列），记其分布为$P(\mathbf{X})$。设$\mathbf{M}=(M_1,\cdots,M_d)$为Mask向量表示$\mathbf{X}$中被观察到的部分。（即标识时间序列哪些部分有缺失），取值为${0,1}^d$。</p>
<p>对于每一个$i\in{1,\cdots,d}$，我们定义一个新空间$\tilde{\mathcal{X}}=\mathcal{X}\cup{<em>}$，其中$</em>$表示不属于任意$\mathcal{X}_i$的一个点。令$\tilde{\mathcal{X}}=\tilde{\mathcal{X}<em>1}\times\cdots\times\tilde{\mathcal{X}_d}$，同时定义一个新的随机变量（即我们观测到的含有缺失值的时间序列）$\tilde{\mathbf{X}}=(\tilde{X}_1,\cdots,\tilde{X}_d)\in \tilde{\mathcal{X}}$：<br>$$<br>\tilde{X}_i=\begin{cases}X_i,&amp;\text{if } M_i=1\*,&amp;\text{otherwise}\end{cases}<br>$$<br>假设数据集的形式为$\mathcal{D}={(\tilde{x}^i,m^i)}^n</em>{i=1}$，我们的任务是从$P(\mathbf{X}|\tilde{\mathbf{X}}=\tilde{x}^i)$上采样来对缺失值进行填充。</p>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><p>模型的架构如下图所示：</p>
<img src="https://i.loli.net/2020/06/25/wCK3J8MoTASrj9Y.png" style="zoom:67%;" />

<h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><p>生成器的输入有三项：$\tilde{\mathbf{X}}$，$\mathbf{M}$和随机噪声$\mathbf{Z}$，输出设为$\bar{\mathbf{X}}$。设生成器为映射$G: \tilde{\mathcal{X}}\times{0,1}^d\times[0,1]^d\rightarrow \mathcal{X}$，而$\mathbf{Z}$为$d$维的高斯噪声。生成器的输出和填充后的时间序列定义为：<br>$$<br>\begin{align}<br>\bar{\mathbf{X}}&amp;=G(\tilde{\mathbf{X}},\mathbf{M},(1-\mathbf{M})\odot\mathbf{Z})\<br>\hat{\mathbf{X}}&amp;=\mathbf{M}\odot\tilde{\mathbf{X}}+(1-\mathbf{M})\odot\bar{\mathbf{X}}<br>\end{align}<br>$$<br>$\bar{\mathbf{X}}$即为生成器的直接输出，因为其实有些部分没有缺失，生成器还是会为每个部分输出值。</p>
<p>$\hat{\mathbf{X}}$为填充后的时间序列，对于缺失的部分采用生成器的输出进行填充。</p>
<h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><p>和原始的GAN不同的是，我们不需要判断整个样本是真实的或者是生成的，而是需要判断样本的那些部分是真实的或者是生成的，所以判别器为映射$D: \mathcal{X}\rightarrow[0,1]^d$。判别器的具体目标函数将在后面讨论。</p>
<h3 id="Hint"><a href="#Hint" class="headerlink" title="Hint"></a>Hint</h3><p>Hint是一种提示机值，是一个和$\mathbf{X}$相同维度的随机变量$\mathbf{H}$，其分布依赖于$\mathbf{M}$。$\mathbf{H}$是由用户自己定义的，相当于一种不完整的$\mathbf{M}$，用来作为判别器的额外输入。</p>
<h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>我们训练判别器最大化正确预测$\mathbf{M}$的概率，而生成器最小化判别器正确预测$\mathbf{M}$的概率，目标函数如下：<br>$$<br>\begin{align}<br>V(D,G)=&amp;\mathbb{E}<em>{\hat{X},M,H}[\mathbf{M}^T\log D(\hat{\mathbf{X}},\mathbf{H})\&amp;+(1-\mathbf{M})^T\log(1-D(\hat{\mathbf{X}},\mathbf{H}))]<br>\end{align}<br>$$<br>按照标准的GAN可以将优化函数写成以下的形式：<br>$$<br>\min_G\max_D V(D,G)<br>$$<br>在这里判别器的任务可以看作是一个二分类，而目标函数就是二值交叉熵的定义，因此可以写为：<br>$$<br>\mathcal{L}(a,b)=\sum\limits</em>{i=1}^d[a_i\log(b_i)+(1-a_i)\log(1-b_i)]<br>$$<br>$\mathbf{M}$可以看作Ground Truth，记$\hat{\mathbf{M}}=D(\hat{\mathbf{X},\mathbf{H}})$，即判别器输出的预测，因此优化函数可以简记为：<br>$$<br>\min_G\max_D\mathbb{E}[\mathcal{L}(\mathbf{M},\hat{\mathbf{M}})]<br>$$</p>
<h2 id="GAIN-Algorithm"><a href="#GAIN-Algorithm" class="headerlink" title="GAIN Algorithm"></a>GAIN Algorithm</h2><p>下面讨论GAIN算法的训练流程。</p>
<p>本文通过理论讨论，给出了生成Hint Vector的一个方法，首先定义随机变量$\mathbf{B}=(B_1,\cdots,B_d)\in{0,1}^d$，$\mathbf{B}$通过从${1,\cdots,d}$随机均匀采样一个$k$，然后由下列公式得到：<br>$$<br>B_j=\begin{cases}1, &amp;\text{if }j\neq k\0, &amp;\text{if }j=k\end{cases}<br>$$<br>定义空间$\mathcal{H}={0,0.5,1}^d$，Hint Vector为$\mathbf{H}=\mathbf{B}\odot\mathbf{M}+0.5(1-\mathbf{B})\in\mathcal{H}$。</p>
<p>判别器的训练过程如下：固定生成器$G$，对一个大小为$k_D$的mini-batch，独立同分布采样$k_D$个$z$和$b$，用来计算$\mathbf{Z}$和$\mathbf{B}$。判别器的损失函数定义如下：<br>$$<br>\mathcal{L}<em>D(m,\hat{m},b)=\sum\limits</em>{i:b_i=0}[m_i\log(\hat{m}_i)+(1-m_i)\log(1-\hat{m}_i)]<br>$$<br>判别器的优化函数为：<br>$$<br>\min_D-\sum\limits_{j=1}^{k_D}\mathcal{L}_D(m(j),\hat{m}(j),b(j))<br>$$<br>其中$\hat{m}(j)=D(\hat{x}(j),m(j))$。</p>
<p>在优化了判别器之后，需要优化生成器，对一个大小为$k_G$的mini-batch，生成器的损失函数包含两个部分，一个是在缺失部分的损失：</p>
<p>$$<br>\mathcal{L}<em>G(m,\hat{m},b)=-\sum\limits</em>{i:b_i=0}(1-m_i)\log(\hat{m}<em>i)<br>$$<br>一个是未缺失部分的损失：<br>$$<br>\mathcal{L}<em>M(x,x^\prime)=\sum\limits</em>{i=1}^d m_iL_M(x_i,x_i^\prime)<br>$$<br>其中：<br>$$<br>L_M(x_i,x_i^\prime)=\begin{cases}(x_i^\prime-x_i)^2, &amp;\text{if }x_i\text{ is continuours},\-x_i\log(x_i^\prime), &amp;\text{if }x_i\text{ is binary}.\end{cases}<br>$$<br>最终的优化函数为：<br>$$<br>\min_G\sum\limits</em>{j=1}^{k_G}\mathcal{L}_G(m(j),\hat{m}(j),b(j))+\alpha\mathcal{L}_M(\tilde{x}(j),\hat{x}(j))<br>$$<br>算法流程如下：</p>
<img src="https://i.loli.net/2020/06/25/znABi6x9mJuvDOX.png" style="zoom:67%;" />

<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>下表为在5个不同数据集上实验，与其他5种方法对比的结果：</p>
<img src="https://i.loli.net/2020/06/25/EenX2YO8aDxQAk3.png" style="zoom:67%;" />

<p>上图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例、样本数量、特征维度下的对比曲线图。</p>
<p>下表为使用不同模型对时间序列进行填充之后，使用逻辑回归进行回归任务的性能：</p>
<img src="https://i.loli.net/2020/06/25/PzeWKdGu4wADshV.png" style="zoom:67%;" />

<p>下图为GAIN、MissForest和Autoencoder三种模型在不同缺失比例下的AUROC曲线图：</p>
<img src="https://i.loli.net/2020/06/25/IKtoTj8xgG1yJDk.png" style="zoom:67%;" />

<p>下表展示的是作者对时间序列填充算法保持特征-标签关系的能力。作者分别用完整的数据和填充后的数据用逻辑回归模型进行训练，将两者的权重求绝对值和均方根的结果。</p>
<img src="https://i.loli.net/2020/06/25/uy2jPcnbtSrC6vI.png" style="zoom:67%;" />

</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Time-Series/">Time Series</a><a class="link-muted mr-2" rel="tag" href="/tags/Deep-Learning/">Deep Learning</a><a class="link-muted mr-2" rel="tag" href="/tags/GAN/">GAN</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/10/18/Robust-Anomaly-Detection-for-Multivariate-Time-Series-through-Stochastic-Recurrent-Neural-Network/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/09/22/Anomaly-Detection-with-Generative-Adversarial-Networks-for-Multivariate-Time-Series/"><span class="level-item">Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Hanzawa の 部屋</a><p class="is-size-7"><span>&copy; 2021 Hanzawa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>