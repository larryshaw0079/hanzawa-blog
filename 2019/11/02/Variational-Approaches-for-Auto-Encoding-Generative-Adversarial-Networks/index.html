<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2D5BA6">
  <meta name="description" content="">
  <meta name="author" content="Hanzawa">
  <meta name="keywords" content="">
  <title>Variational Approaches for Auto-Encoding Generative Adversarial Networks - Hanzawa の 部屋</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Hanzawa</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/bg/coffe_bear.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
                Variational Approaches for Auto-Encoding Generative Adversarial Networks
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2019-11-02 23:28">
                    2019年11月2日 晚上
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    2.6k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    36
                     分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="iconfont icon-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p class="note note-info">
                
                  本文最后更新于：2020年6月25日 下午
                
              </p>
            
            <article class="markdown-body">
              <h1 id="abstract">Abstract</h1>
<p>本文揭示了对抗生成网络（Generative Adversarial Networks, GAN）和变分自编码器（Variational Auto-encoders, VAE）之间的联系，并据此提出了一种将两者结合的新模型。文中主要是将不可解的似然函数和未知的后验分布用一个非确定的分布（Immplicit Distribution）替代，并加入判别器来使得该分布逼近真实的分布。通过这个方法，作者将VAE中的损失函数进行了替换，变成了GAN中的“生成-判别”模式。</p>
<p><a href="https://arxiv.org/abs/1706.04987" target="_blank" rel="noopener">原文</a></p>
<h1 id="contribution">Contribution</h1>
<p>本文有如下贡献：</p>
<ul>
<li>本文提出变分推断（Variational Inference）也能通过对非确定分布的估计应用在GAN中；</li>
<li>基于似然的模型（Likelihood-based Models）和非似然模型（Likelihood-free Models）能够通过对抗学习结合起来；</li>
<li>作者根据文中提出的新观点修改了VAE的损失函数，将其称之为Auto-encoding GAN (<span class="math inline">\(\alpha\)</span>-GAN)，并提出了对应的实用的改进；</li>
<li>本文与众多State-of-Art模型进行了对比</li>
</ul>
<h1 id="methodology">Methodology</h1>
<h2 id="overcoming-intractability-in-generative-models">Overcoming Intractability in Generative Models</h2>
<h3 id="latent-variable-models">Latent Variable Models</h3>
<p>隐变量模型通过隐变量的形式描述了数据的产生过程。最简单的形式是假设隐变量<span class="math inline">\(\mathbf{z}\)</span>服从一个先验分布<span class="math inline">\(\mathbf{z}\sim p(\mathbf{z})\)</span>，而数据<span class="math inline">\(\mathbf{x}\)</span>从条件分布<span class="math inline">\(p(\mathbf{x}|\mathbf{z})\)</span>抽样产生。通常来说描述<span class="math inline">\(p(\mathbf{x}|\mathbf{z})\)</span>的模型称为生成器<span class="math inline">\(\mathcal{G}_\theta(\mathbf{z})\)</span>，带有可优化的参数<span class="math inline">\(\theta\)</span>，而<span class="math inline">\(\mathbf{z}\)</span>通常假设为正态分布<span class="math inline">\(\mathbf{z}\sim\mathcal{N}(\mathbf{0},\mathbf{I})\)</span>。</p>
<p>文中区分了两种隐变量模型，一种是<em>Implicit Latent Variable Models</em>，一种是<em>Prescribed Latent Variable Models</em>。文中的描述不太清楚，个人认为两者的区别是前者图模型中的<span class="math inline">\(\mathbf{x}\)</span>不是一个随机变量，在优化的时候需要用一个刻画生成的<span class="math inline">\(\mathbf{x}\)</span>和真实的<span class="math inline">\(\mathbf{x}\)</span>的差别的函数<span class="math inline">\(\delta(\mathbf{x}-\mathcal{G}_\theta(\mathbf{z}))\)</span>，而后者图模型中<span class="math inline">\(\mathbf{x}\)</span>是一个随机变量，这样可以写出似然函数用极大似然估计。</p>
<p>无论是GAN还是VAE都需要通过边缘分布<span class="math inline">\(p_\theta(\mathbf{x})\)</span>来刻画建模的好坏，比如说根据<span class="math inline">\(p_\theta(\mathbf{x})\)</span>与真实分布<span class="math inline">\(p^*_\theta(\mathbf{x})\)</span>之间的KL散度<span class="math inline">\(\text{KL}\left[p_\theta(\mathbf{x})\parallel p_\theta^*(\mathbf{x})\right]\)</span>。但通常情况下<span class="math inline">\(p_\theta(\mathbf{x})\)</span>都是不可解的，而GAN和VAE通过不同的途径解决了这个问题。</p>
<h3 id="generative-adversarial-networks">Generative Adversarial Networks</h3>
<p>GAN没有直接计算<span class="math inline">\(p_\theta(\mathbf{x})\)</span>，而是使用了一个判别器来判别样本是从<span class="math inline">\(p_\theta(\mathbf{x})\)</span>还是<span class="math inline">\(p_\theta^*(\mathbf{x})\)</span>采样得到的，如果判别器无法进行区分，那我们认为此时<span class="math inline">\(p_\theta(\mathbf{x})\approx p_\theta^*(\mathbf{x})\)</span>。</p>
<p>令随机变量<span class="math inline">\(y\in\{0,1\}\)</span>，<span class="math inline">\(y=1\)</span>表示样本<span class="math inline">\(\mathbf{x}\)</span>来自真实分布，<span class="math inline">\(y=0\)</span>表示样本<span class="math inline">\(\mathbf{x}\)</span>来自生成分布，而判别器的输出为<span class="math inline">\(\mathbf{x}\)</span>来自真实分布的概率<span class="math inline">\(\mathcal{D}_\phi(\mathbf{x})=p(y=1|\mathbf{x})\)</span>。GAN通过对来自真实分布和生成分布的样本求二元交叉熵来作为判别器损失函数： <span class="math display">\[
\textbf{Discriminator Loss: }\mathbb{E}_{p^*(\mathbf{x})}[-\log\mathcal{D}_\phi(\mathbf{x})]+\mathbb{E}_{p_\theta(\mathbf{x})}[-\log(1-\mathcal{D}_\phi(\mathbf{x}))]
\]</span></p>
<p>生成器将最大化判别器对生成样本判定为真的概率作为损失函数，同时还有一个等价的但在实践中表现更好的替代版本：</p>
<p><span class="math display">\[
\textbf{Generator Loss: }\mathbb{E}_{p_\theta(\mathbf{x})}[\log(1-\mathcal{D}_\phi(\mathbf{x}))];\textbf{ Alternative Loss: }\mathbf{E}_{p_\theta(\mathbf{x})}[-\log\mathcal{D}_\phi(\mathbf{x})]
\]</span></p>
<h3 id="the-density-ratio-trick">The Density Ratio Trick</h3>
<p>令<span class="math inline">\(p^*(\mathbf{x})=p(\mathbf{x}|y=1)\)</span>，<span class="math inline">\(p_\theta(\mathbf{x})=p(\mathbf{x}|y=0)\)</span>。定义<em>Density Ratio</em> <span class="math inline">\(r_\phi(\mathbf{x})\)</span>为真实分布和生成分布之间的比例：</p>
<p><span class="math display">\[
r_\phi(\mathbf{x})=\frac{p^*(\mathbf{x})}{p_\theta(\mathbf{x})}=\frac{p(\mathbf{x}|y=1)}{p(\mathbf{x}|y=0)}=\frac{p(y=1|\mathbf{x})}{p(y=0|\mathbf{x})}=\frac{\mathcal{D}_\phi(\mathbf{x})}{1-\mathcal{D}_\phi(\mathbf{x})}
\]</span></p>
<p>上式表明了<em>Density Ratio</em>的计算可以仅通过从两个分布上采样得到的样本加上一个二分类器<span class="math inline">\(\mathcal{D}_\phi(\mathbf{x})\)</span>实现（假设<span class="math inline">\(p(y=0)=p(y=1)\)</span>）。更深入的说，对于不可解的分布<span class="math inline">\(p_\theta^*(\mathbf{x})\)</span>，我们可以通过计算<em>Density Ratio</em>来了解我们近似的分布<span class="math inline">\(p_\theta(\mathbf{x})\)</span>和真实的<span class="math inline">\(p_\theta^*(\mathbf{x})\)</span>之间的相对性。而且我们只需要能够在两个分布上进行采样，并且训练一个判别器即可。因为判别器是一个普通的分类器，所以大量的主流分类器都可以使用。</p>
<h3 id="variational-inference">Variational Inference</h3>
<p>现在来看VAE，另一种解决不可解分布的方法是近似。<em>Variational Inference</em>通过引入一个变分分布<span class="math inline">\(q_\eta(\mathbf{z}|\mathbf{x})\)</span>推出了不可解的<span class="math inline">\(\mathbf{x}\)</span>的对数似然的下界（常被称为证据下界ELBO）：</p>
<p><span class="math display">\[
\log p_\theta(\mathbf{x})=\log\int p_\theta(\mathbb{x}|\mathbb{z})p(\mathbf{z})\text{d}\mathbf{z}\geq \mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log p_\theta(\mathbf{x}|\mathbf{z})\right]-\text{KL}\left[q_\eta(\mathbf{z}|\mathbf{x})\parallel p(\mathbf{z})\right]=\mathcal{F}(\boldsymbol{\theta}, \boldsymbol{\eta})
\]</span></p>
<p>VAE是<em>Variational Inference</em>的一种实现，变分分布通过一个神经网络进行建模，并且建立起了完整的可优化的模型。</p>
<h3 id="synthetic-likelihood">Synthetic Likelihood</h3>
<p>当似然函数未知（GAN中没有显式的似然函数，而VAE中有）的时候，<em>Variational Inference</em>便无法直接使用。对于没有显式的似然函数的情况，以VAE的ELBO的第一项为例，假设<span class="math inline">\(p_\theta(\mathbf{x}|\mathbf{z})\)</span>分布的具体形式未知，我们只有从<span class="math inline">\(p_\theta(\mathbf{x}|\mathbf{z})\)</span>采样得到的样本，如何计算<span class="math inline">\(\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})]\)</span>呢？一个方法是乘以<span class="math inline">\(p_\theta^*(\mathbf{x})\)</span>再除以<span class="math inline">\(p_\theta^*(\mathbf{x})\)</span>：</p>
<p><span class="math display">\[
\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})]=\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{p_\theta(\mathbf{x}|\mathbf{z})}{p^*(\mathbf{x})}\right]+\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}[\log p^*(\mathbf{x})]
\]</span></p>
<p>公式(5)中的第一项包括了合成似然<span class="math inline">\(R(\theta)=\frac{p_\theta(\mathbf{x}|\mathbf{z})}{p^*(\mathbf{x})}\)</span>，优化<span class="math inline">\(R(\theta)\)</span>相当于优化<span class="math inline">\(\log p_\theta(\mathbf{x}|\mathbf{z})\)</span>。第二项与生成网络的参数<span class="math inline">\(\theta\)</span>无关，所以在优化的时候可以忽略。</p>
<h2 id="a-fusion-of-variational-and-adversarial-learning">A Fusion of Variational and Adversarial Learning</h2>
<p>GAN和VAE分别从不同的角度解决了生成模型的推断问题，我们下面从VAE出发，考虑将两者结合起来。</p>
<h3 id="implicit-variational-distributions">Implicit Variational Distributions</h3>
<p>变分推断<strong>Variational Inference</strong>的主要任务就是确定<span class="math inline">\(q_\eta(\mathbf{z}|\mathbf{x})\)</span>，通常的做法如<strong>Mean-field Variational Inference</strong>会假设一个简单的分布，如高斯分布。在本文中不对<span class="math inline">\(q_\eta(\mathbf{z}|\mathbf{x})\)</span>的形式作假设，仅假设其为一个隐含的分布。运用上文提到的<em>Density Ratio Trick</em>，我们可以将VAE损失函数中的第二项改写为：</p>
<p><span class="math display">\[
-\text{KL}[q_\eta(\mathbf{z}|\mathbf{x})\parallel p(\mathbf{z})]=\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{p(\mathbf{z})}{q_\eta(\mathbf{z}|\mathbf{x})}\right]\approx\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}{1-\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}\right]
\]</span></p>
<p>文中引入了一个隐变量分类器（Latent Classifier）<span class="math inline">\(\mathcal{C}_{\boldsymbol{\omega}}(\mathbf{z})\)</span>，用来判别<span class="math inline">\(\mathbf{z}\)</span>是从编码网络还是从标准高斯分布中采样得到的（猜测这样做的好处是不用再对<span class="math inline">\(\mathbf{z}\)</span>的后验做高斯分布的假设了，也不需要在变分网络输出形成的高斯分布上采样得到<span class="math inline">\(\mathbf{z}\)</span>了，这样重参数技巧也省了）。具体实现上，期望可以用蒙特卡洛方法（采样多次取均值）进行计算。</p>
<h3 id="likelihood-choice">Likelihood Choice</h3>
<p>对于VAE损失函数第一项，对应生成网络，我们可以选择对<span class="math inline">\(p(\mathbf{x}|\mathbf{z})\)</span>分布的具体形式做假设， 这样对应<em>Likelihood-based</em>的情况。文中选择的是<em>Zero-mean Laplace Distribution</em> <span class="math inline">\(p_\theta(\mathbf{x}|\mathbf{z})\propto\exp(-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1)\)</span>（不就是<span class="math inline">\(L_1\)</span> Loss吗？？？）。</p>
<p>对于<em>Likelihood-free</em>的情况，可以继续使用上面提到的<em>Density Ratio Trick</em>，这时需要加一个一个判别器。</p>
<p><span class="math display">\[
\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1\right]\space\space\text{  or  }\space\space\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\log\frac{\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}{1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}\right]
\]</span></p>
<p>对于两种选择，前者对应VAE，好处是不会出现模式崩溃的情况，后者对应GAN，容易出现模式崩溃的情况，但是可以使用对抗学习的方式（这是优点？？？），本文选择两种都用（我全都要.jpg）。</p>
<h3 id="hybrid-loss-functions">Hybrid Loss Functions</h3>
<p>将前面的讨论结合起来，最后的损失函数就是：</p>
<p><span class="math display">\[
\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\eta})=\mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[-\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1+\log\frac{\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}{1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))}+\log\frac{\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}{1-\mathcal{C}_\boldsymbol{\omega}(\mathbf{z})}\right]
\]</span></p>
<p>最后模型包含四个网络：生成网络<span class="math inline">\(p_\theta(\mathbf{x}|\mathbf{z})\)</span>、推断网络<span class="math inline">\(q_\eta(\mathbf{z}|\mathbf{x})\)</span>以及两个判别器<span class="math inline">\(\mathcal{C}_{\boldsymbol{\omega}}\)</span>和<span class="math inline">\(\mathcal{D}_\phi\)</span>，作者将其命名为<span class="math inline">\(\alpha\)</span>-GAN。</p>
<p>算法流程如下：</p>
<p><img src="https://i.loli.net/2020/06/25/hkIY9xuDWl4GbLz.png" srcset="/img/loading.gif" style="zoom:67%;" /></p>
<h3 id="improved-techniques">Improved Techniques</h3>
<p>作者为了改进模型的稳定性和效率，将生成器的Loss中的<span class="math inline">\(-\log(1-\mathcal{D}_\phi)\)</span>修改为了<span class="math inline">\(\log\mathcal{D}_\phi-\log(1-\mathcal{D}_\phi)\)</span>，并声称这样能提供非饱和（Non-saturating）的梯度：</p>
<p><span class="math display">\[
\textbf{Generator Loss: } \mathbb{E}_{q_\eta(\mathbf{z}|\mathbf{x})}\left[\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1-\log\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z}))+\log(1-\mathcal{D}_\phi(\mathcal{G}_\theta(\mathbf{z})))\right]
\]</span></p>
<p>作者认为在生成器损失函数中加入<span class="math inline">\(\lambda\parallel\mathbf{x}-\mathcal{G}_\theta(\mathbf{z})\parallel_1\)</span>能够在一定程度防止模式崩溃。</p>
<p>除此之外，作者发现将真实样本（原文是The Samples）作为生成的样本输入到判别器中能够提升性能。作者给出的解释是根据Jensen不等式：<span class="math inline">\(\log p_\theta(\mathbf{x})=\log\int p_\theta(\mathbf{x}|\mathbf{z})p(\mathbf{z})\text{d}\mathbf{z}\geq \mathbb{E}_{p(\mathbf{z})}[\log p_\theta(\mathbf{x}|\mathbf{z})]\)</span>，</p>
<p>[TODO]</p>
<h2 id="related-work">Related Work</h2>
<p>[TODO]</p>
<p><img src="https://i.loli.net/2020/06/25/TKt3yUwPDQm4MeV.png" srcset="/img/loading.gif" style="zoom: 50%;" /></p>
<p><img src="https://i.loli.net/2020/06/25/5jg9wNMoXuTzeVY.png" srcset="/img/loading.gif" style="zoom: 50%;" /></p>
<h1 id="experiments">Experiments</h1>
<p>[TODO]</p>
<h2 id="metrics">Metrics</h2>
<p>本文使用了几种不同的评测生成模型的方法：</p>
<ul>
<li><strong>Inception Score: </strong></li>
<li><strong>Multi-scale Structural Similarity (MS-SSIM): </strong></li>
<li><strong>Independent Wasserstein Critic: </strong></li>
</ul>
<h2 id="results-on-colormnist">Results on ColorMNIST</h2>
<p><img src="https://i.loli.net/2020/06/25/QRBKHn51fxO2WUq.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>
<p><img src="https://i.loli.net/2020/06/25/kM4lrsBVSDKaJwW.png" srcset="/img/loading.gif" style="zoom: 50%;" /></p>
<h2 id="results-on-celeba">Results on CelebA</h2>
<p><img src="https://i.loli.net/2020/06/25/mzdjY67uH9pZ1ny.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>
<h2 id="results-on-cifar-10">Results on CIFAR-10</h2>
<p><img src="https://i.loli.net/2020/06/25/nDGgM6AHVyKwIam.png" srcset="/img/loading.gif" style="zoom: 50%;" /></p>
<p><img src="https://i.loli.net/2020/06/25/K1RQdMyj8zbqlCJ.png" srcset="/img/loading.gif" style="zoom:50%;" /></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Research/">Research</a>
                    
                      <a class="hover-with-bg" href="/categories/Research/GAN/">GAN</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Deep-Learning/">Deep Learning</a>
                    
                      <a class="hover-with-bg" href="/tags/Variational-Inference/">Variational Inference</a>
                    
                      <a class="hover-with-bg" href="/tags/VAE/">VAE</a>
                    
                      <a class="hover-with-bg" href="/tags/GAN/">GAN</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/01/06/Unsupervised-Anomaly-Detection-for-Intricate-KPIs-via-Adversarial-Training-of-VAE/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Unsupervised Anomaly Detection for Intricate KPIs via Adversarial Training of VAE</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2019/10/29/Anomaly-Detection-in-Streams-with-Extreme-Value-Theory/">
                        <span class="hidden-mobile">Anomaly Detection in Streams with Extreme Value Theory</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div class="disqus" style="width:100%">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'http://qfxiao.me/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/';
        this.page.identifier = '/2019/11/02/Variational-Approaches-for-Auto-Encoding-Generative-Adversarial-Networks/';
      };
      var oldLoadDq = window.onload;
      window.onload = function () {
        oldLoadDq && oldLoadDq();

        var d = document, s = d.createElement('script');
        s.type = 'text/javascript';
        s.src = '//' + 'http-larryshaw0079-coding-me-blog' + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      };
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="nofollow noopener noopener">comments
        powered by Disqus.</a></noscript>
  </div>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div>
    
      <!-- 不蒜子统计PV -->
      
      <span id="busuanzi_container_site_pv" style="display: none">
      总访问量 <span id="busuanzi_value_site_pv"></span> 次
    </span>
    
    
      <!-- 不蒜子统计UV -->
      
      <span id="busuanzi_container_site_uv" style="display: none">
      总访客数 <span id="busuanzi_value_site_uv"></span> 人
    </span>
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->





  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  














</body>
</html>
